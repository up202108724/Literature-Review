@inproceedings{10.1145/3746252.3761007,
author = {Li, Xinhui and Yue, Kun and Yu, Lixing and Yang, Peizhong},
title = {Structural Entropy-based Multivariate Time Series Forecasting},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761007},
doi = {10.1145/3746252.3761007},
abstract = {Multivariate time series (MTS) forecasting is crucial for predicting the future states of complexly coupled variables based on historical observations. To effectively capture the intricate interdependencies within MTS, graph-based methods have emerged as powerful tools. However, existing graph construction methods often produce structures that fail to preserve key temporal and cross-variable dependencies, introducing redundant or irrelevant connections. To address these challenges, we propose a structural entropy-based approach for MTS forecasting. The approach optimizes graph structures by reducing structural redundancy, thereby improving forecasting accuracy. Initially, we represent the temporal dependences by constructing an encoding tree incrementally. Through hierarchical organization of time steps, the temporal evolution is adaptively captured. Subsequently, we give the community-aware representation by building an encoding tree over the variables in MTS, extracting homogeneous communities from the tree structure while integrating community influence to better capture inter-variable dependencies. Finally,we present a training algorithm designed to generate accurate predictions for MTS, accompanied by a unified loss function that integrates forecasting inaccuracies with variations in structural entropy. Empirical findings on real-world datasets substantiate that our approach outperforms state-of-the-art models in capturing dependencies and enhancing forecasting precision.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {1696–1705},
numpages = {10},
keywords = {encoding tree, interseries correlation, intra-series correlation, multivariate time series forecasting, structural entropy},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@inproceedings{10.1145/3746252.3761173,
author = {Wu, Binqing and Shang, Zongjiang and Huang, Jianlong and Chen, Ling},
title = {MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761173},
doi = {10.1145/3746252.3761173},
abstract = {Multi-variate time series (MTS) forecasting is crucial for various applications. Existing methods have shown promising results owing to their strong ability to capture intra- and inter-variate dependencies. However, these methods often overlook lead-lag dependencies at multiple grouping scales, failing to capture hierarchical lead-lag effects in complex systems. To this end, we propose MillGNN, a novel graph neural network-based method that learns multiple grouping scale lead-lag dependencies for MTS forecasting, which can comprehensively capture lead-lag effects considering variate-wise and group-wise dynamics and decays. Specifically, MillGNN introduces two key innovations: (1) a scale-specific lead-lag graph learning module that integrates cross-correlation coefficients and dynamic decaying features derived from real-time inputs and time lags to learn lead-lag dependencies for each scale, which can model evolving lead-lag dependencies with statistical interpretability and data-driven flexibility; (2) a hierarchical lead-lag message passing module that passes lead-lag messages at multiple grouping scales in a structured way to simultaneously propagate intra- and inter-scale lead-lag effects, which can capture multi-scale lead-lag effects with a balance of comprehensiveness and efficiency. Experimental results on 11 datasets demonstrate the superiority of MillGNN for long-term and short-term MTS forecasting, compared with 16 state-of-the-art methods.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {3344–3354},
numpages = {11},
keywords = {hypergraph modeling, multivariate time series forecasting, spatial temporal graph neural network},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@inproceedings{10.1145/3534678.3539396,
author = {Shao, Zezhi and Zhang, Zhao and Wang, Fei and Xu, Yongjun},
title = {Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539396},
doi = {10.1145/3534678.3539396},
abstract = {Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1567–1577},
numpages = {11},
keywords = {multivariate time series forecasting, pre-training model, spatial-temporal graph neural network},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3711896.3736899,
author = {Zhou, Pengfei and Liu, Yunlong and Liang, Junli and Song, Qi and Li, Xiangyang},
title = {CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736899},
doi = {10.1145/3711896.3736899},
abstract = {Time series forecasting with exogenous variables is a critical emerging paradigm that presents unique challenges in modeling dependencies between variables. Traditional models often struggle to differentiate between endogenous and exogenous variables, leading to inefficiencies and overfitting. In this paper, we introduce CrossLinear, a novel Linear-based forecasting model that addresses these challenges by incorporating a plug-and-play cross-correlation embedding module. This lightweight module captures the dependencies between variables with minimal computational cost and seamlessly integrates into existing neural networks. Specifically, it captures time-invariant and direct variable dependencies while disregarding time-varying or indirect dependencies, thereby mitigating the risk of overfitting in dependency modeling and contributing to consistent performance improvements. Furthermore, CrossLinear employs patch-wise processing and a global linear head to effectively capture both short-term and long-term temporal dependencies, further improving its forecasting precision. Extensive experiments on 12 real-world datasets demonstrate that CrossLinear achieves superior performance in both short-term and long-term forecasting tasks. The ablation study underscores the effectiveness of the cross-correlation embedding module. Additionally, the generalizability of this module makes it a valuable plug-in for various forecasting tasks across different domains. Codes are available at https://github.com/mumiao2000/CrossLinear.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {4120–4131},
numpages = {12},
keywords = {deep learning, exogenous variables, time series forecasting},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3746252.3761281,
author = {Wu, Binqing and Huang, Jianlong and Shang, Zongjiang and Chen, Ling},
title = {ST-Hyper: Learning High-Order Dependencies Across Multiple Spatial-Temporal Scales for Multivariate Time Series Forecasting},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761281},
doi = {10.1145/3746252.3761281},
abstract = {In multivariate time series (MTS) forecasting, many deep learning based methods have been proposed for modeling dependencies at multiple spatial (inter-variate) or temporal (intra-variate) scales. However, existing methods may fail to model dependencies across multiple spatial-temporal scales (ST-scales, i.e., scales that jointly consider spatial and temporal scopes). In this work, we propose ST-Hyper to model the high-order dependencies across multiple ST-scales through adaptive hypergraph modeling. Specifically, we introduce a Spatial-Temporal Pyramid Modeling (STPM) module to extract features at multiple ST-scales. Furthermore, we introduce an Adaptive Hypergraph Modeling (AHM) module that learns a sparse hypergraph to capture robust high-order dependencies among features. In addition, we interact with these features through tri-phase hypergraph propagation, which can comprehensively capture multi-scale spatial-temporal dynamics. Experimental results on six real-world MTS datasets demonstrate that ST-Hyper achieves the state-of-the-art performance, outperforming the best baselines with an average MAE reduction of 3.8\% and 6.8\% for long-term and short-term forecasting, respectively. Code is available at https://anonymous.4open.science/ST-Hyper-83E7.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {3333–3343},
numpages = {11},
keywords = {hypergraph modeling, multivariate time series forecasting, spatial temporal graph neural network},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@article{10.1145/3653447,
author = {Yi, Kun and Zhang, Qi and He, Hui and Shi, Kaize and Hu, Liang and An, Ning and Niu, Zhendong},
title = {Deep Coupling Network for Multivariate Time Series Forecasting},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3653447},
doi = {10.1145/3653447},
abstract = {Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this article, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {127},
numpages = {28},
keywords = {Multivariate time series forecasting, deep coupling network, mutual information}
}

@article{10.1145/3543511,
author = {Chen, Hongjie and Rossi, Ryan A. and Mahadik, Kanak and Kim, Sungchul and Eldardiry, Hoda},
title = {Graph Deep Factors for Probabilistic Time-series Forecasting},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/3543511},
doi = {10.1145/3543511},
abstract = {Effective time-series forecasting methods are of significant importance to solve a broad spectrum of research problems. Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, a relational global model learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, a relational local model not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average. Furthermore, we target addressing the common nature of many time-series forecasting applications where time-series are provided in a streaming version; however, most methods fail to leverage the newly incoming time-series values and result in worse performance over time. In this article, we propose an online incremental learning framework for probabilistic forecasting. The framework is theoretically proven to have lower time and space complexity. The framework can be universally applied to many other machine learning-based methods.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {26},
numpages = {30},
keywords = {time-series forecasting, Graph Neural Network, Incremental online learning}
}

@article{10.1145/3701038,
author = {Chen, Donghui and Chen, Ling and Shang, Zongjiang and Zhang, Youdong and Wen, Bo and Yang, Chenghu},
title = {Scale-Aware Neural Architecture Search for Multivariate Time Series Forecasting},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/3701038},
doi = {10.1145/3701038},
abstract = {Multivariate time series (MTS) forecasting has attracted much attention in many intelligent applications. It is not a trivial task, as we need to consider both intra-variable dependencies and inter-variable dependencies. However, existing works are designed for specific scenarios and require much domain knowledge and expert efforts, which is difficult to transfer between different scenarios. In this article, we propose a scale-aware neural architecture search framework for MTS forecasting (SNAS4MTF). A multi-scale decomposition module transforms raw time series into multi-scale sub-series, which can preserve multi-scale temporal patterns. An adaptive graph learning module infers the different inter-variable dependencies under different time scales without any prior knowledge. For MTS forecasting, a search space is designed to capture both intra-variable dependencies and inter-variable dependencies at each time scale. The multi-scale decomposition, adaptive graph learning, and neural architecture search modules are jointly learned in an end-to-end framework. Extensive experiments on two real-world datasets demonstrate that SNAS4MTF achieves a promising performance compared with the state-of-the-art methods.},
journal = {ACM Trans. Knowl. Discov. Data},
month = dec,
articleno = {11},
numpages = {23},
keywords = {Multivariate time series forecasting, neural architecture search, graph learning, multi-scale decomposition}
}

@inproceedings{10.1145/3690771.3690784,
author = {Bautista, Philippe Anthony C. and Chan Shio, Christian Paul O. and Abu, Patricia Angela R.},
title = {Telecommunications Product Revenue Time-Series Forecasting Using Target Variable Preprocessing Methods},
year = {2025},
isbn = {9798400710018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690771.3690784},
doi = {10.1145/3690771.3690784},
abstract = {Accurate revenue forecasting is critical for decision-making support of telecommunications companies (telcos). This study explored the use of machine learning for time-series revenue forecasting of a telco product. While existing research explores machine learning for time-series forecasting primarily for stocks price prediction and different use cases in other industries, this study focused on telco revenue and the impact of target variable preprocessing on forecasting accuracy. Two datasets with different business rules for the same attribute were used, with two preprocessing techniques for converting monthly revenue data to daily applied to each dataset: even distribution and a weighted distribution based on daily subscriber count. Recurrent neural networks (RNNs), specifically long short-term memory (LSTM) and gated recurrent unit (GRU), were employed for revenue prediction. Various factors were used to produce additional model variations, specifically seed selection, dataset, preprocessing technique, and input window size. Mean Absolute Percentage Error (MAPE) was the key metric for comparison of model performance. The results showed that weighted preprocessing produced the most accurate model with an MAPE of 3.08\% despite its reliance on a specific variable combination. This study concludes that target variable preprocessing impacts model outputs, with weighted distribution offering the highest accuracy for telco product revenue forecasting using RNNs.},
booktitle = {Proceedings of the 2024 6th Asia Conference on Machine Learning and Computing},
pages = {53–61},
numpages = {9},
keywords = {recurrent neural network, long short-term memory, gated recurring unit, time-series forecasting},
location = {
},
series = {ACMLC '24}
}

@article{10.14778/3636218.3636230,
author = {Zhao, Kai and Guo, Chenjuan and Cheng, Yunyao and Han, Peng and Zhang, Miao and Yang, Bin},
title = {Multiple Time Series Forecasting with Dynamic Graph Modeling},
year = {2023},
issue_date = {December 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3636218.3636230},
doi = {10.14778/3636218.3636230},
abstract = {Multiple time series forecasting plays an essential role in many applications. Solutions based on graph neural network (GNN) that deliver state-of-the-art forecasting performance use the relation graph which can capture historical correlations among time series. However, in real world, it is common that correlations among time series evolve across time, resulting in dynamic relation graph, where the future correlations may be different from those in history. To address this problem, we propose multiple time series forecasting with dynamic graph modeling (MTSF-DG) that is able to learn historical relation graphs and predicting future relation graphs to capture the dynamic correlations. We also propose a causal GNN to extract features from both kinds of relation graphs efficiently. Then we propose a reasoning network to explicitly learn the variant influence from historical timestamps to future timestamps for final forecasting. Extensive experiments on six benchmark datasets show that MTSF-DG consistently outperforms state-of-the-art baselines, and justify our design with dynamic relation graph modeling.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {753–765},
numpages = {13}
}

@article{10.14778/3636218.3636231,
author = {Cheng, Yunyao and Chen, Peng and Guo, Chenjuan and Zhao, Kai and Wen, Qingsong and Yang, Bin and Jensen, Christian S.},
title = {Weakly Guided Adaptation for Robust Time Series Forecasting},
year = {2023},
issue_date = {December 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3636218.3636231},
doi = {10.14778/3636218.3636231},
abstract = {Robust multivariate time series forecasting is crucial in many cyberphysical and Internet of Things applications. Existing state-of-the-art robust forecasting models decompose time series into independent functions covering trends and periodicities. However, these independent functions fail to capture correlations among multiple time series, thereby reducing prediction accuracy. Moreover, existing robust forecasting models treat certain abrupt but normal changes, e.g., caused by holidays, as outliers because they occur infrequently and have data distributions that resemble those of outliers. This exacerbates model bias and reduces prediction accuracy. This paper aims to capture correlations across multiple time series and abrupt but normal changes, thereby improving prediction accuracy. We employ weak labels to partition the dataset into source and target domains. Then, we propose the Domain Adversarial Robust Forecaster (DARF). This forecasting model is based on adversarial domain adaptation and includes two novel modules: Correlated Robust Forecaster (CORF) and Domain Critic. Specifically, CORF constitutes an encoder-decoder framework proficient at robust multivariate time series forecasting, and Domain Critic works to reduce data bias. Extensive experiments and discussions show that DARF is capable of state-of-the-art forecasting accuracy.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {766–779},
numpages = {14}
}

@inproceedings{10.1145/3704558.3707079,
author = {Zhu, Liming and Kong, Xu and Li, Ming and Qin, Ting and Chen, Yangjun and Chang, Junyu and Chen, Xu},
title = {A Distribution Graph Guided Network with Dual Track Self-Supervised Strategy for Tobacco Pest Time Series Forecasting},
year = {2025},
isbn = {9798400710681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704558.3707079},
doi = {10.1145/3704558.3707079},
abstract = {Tobacco pest is one of the main factors that harm tobacco quality in tobacco factories, leading to economic losses. Accurate prediction of pest distribution is crucial for the management and production of tobacco factories. Nevertheless, conventional time series forecasting techniques prove inadequate in capturing sufficient information for fine-grained forecasting tasks involving district-variable-level and day-sampling-level tobacco pest datasets. This limitation arises from the lack of consideration for the knowledge pertaining to the migration and reproduction patterns of tobacco pests. In this work, a dual track self-supervised and distribution graph guided network (DTSSDGN) is proposed to handle this problem. First, a distribution graph guided feature extraction module is designed to help capture the internal and external patterns of pest distribution. Subsequently, a two-stage training strategy is devised, comprising a dual-track self-supervised training phase to acquire features that possess a comprehensive understanding of the pest distribution trend, followed by a fine-grained fine-tuning phase that leverages this knowledge to achieve accurate forecasting outcomes. The effectiveness and superiority of the proposed method are illustrated on a real tobacco pest distribution dataset.},
booktitle = {Proceedings of the 2024 2nd International Conference on Frontiers of Intelligent Manufacturing and Automation},
pages = {406–410},
numpages = {5},
keywords = {Distribution graph, deep learning, dual track self-supervised, graph neural network, time series forecasting},
location = {
},
series = {CFIMA '24}
}

@inproceedings{10.1145/3731715.3733272,
author = {Lei, Jierui and Chen, Fangzheng and Tang, Haina},
title = {AGGA-MVFLN: Multivariate Time Series Forecasting via Adaptive Generalized Graph Accompanied with Multi-View Learning in Frequency Domain},
year = {2025},
isbn = {9798400718779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731715.3733272},
doi = {10.1145/3731715.3733272},
abstract = {A growing body of recent researches have migrated graph structure learning (GSL) to the multivariate time series forecasting (MTSF), which lays the foundation for the promotion of ''Generalized Graph'' for multimedia MTSF applications. In other words, we expect generalized graph to encompass the learning of inter-variable, inter-temporal and latent correlations, becoming a universal tool for multivariate correlations learning. However, due to the heterogeneity of multivariate time series in distribution, graph learning inevitably captures inaccurate relationships, which requires the quality of graph learning; Meanwhile MTSF often requires instant predictions for decision-making in real-world, which also challenges the speed of GSL. To solve these challenges, we propose AGGA-MVFLN, namely Adaptive Generalized Graph Accompanied Multi-View Frequency Learning Network. Specifically, we introduce an adaptive generalized graph structure from multi-view (global and local) to capture diverse ''spatio-temporal patterns''. Subsequently, we utilize the Fast Fourier Transform to map them into the frequency domain, and enhance the quality of the generalized graph by collaboratively learning the complementarities and differences through reconstructed ''spatio-temporal patterns'' and error-driven supervised training of adaptive graph. The benefits are: (1) The frequency domain can disentangle complex temporal patterns, making the process of learning multivariate relationships more robust. (2) Multi-view learning can significantly reduce training time by preset and seamless integration (i.e., the multi-task loss form). (3) ''Generalized Graph'' can be regarded as universal component for multivariate correlation learning. Evaluation of 9 real-world datasets confirms the superiority of AGGA-MVFLN over SOTA benchmark.},
booktitle = {Proceedings of the 2025 International Conference on Multimedia Retrieval},
pages = {653–661},
numpages = {9},
keywords = {adaptive graph learning, frequency domain analysis, multi-view learning, multivariate time series forecasting},
location = {Chicago, IL, USA},
series = {ICMR '25}
}

@inproceedings{10.1145/3762249.3762299,
author = {Wang, Xiaoguo and Zheng, Yuheng and Zhu, Hongming and Chen, Chao and Li, Huanzhang},
title = {Credit Card Transaction Trend Forecasting Based on Graph Neural Network},
year = {2025},
isbn = {9798400713491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762249.3762299},
doi = {10.1145/3762249.3762299},
abstract = {Accurate prediction of customer transaction trend can provide effective technical support for banks in managing their credit card business. Customer transaction behaviors often involve multiple types of consumption, and existing forecasting methods typically concatenate multi-type features into a unified input, which inadequately accounts for structural differences and interactions among different transaction types. To address this issue, this paper proposes TTF-GNN, a credit card transaction trend forecasting model based on graph neural networks. The proposed method effectively explores customer behavioral characteristics in multi-type transaction scenarios by integrating type-aware embedding with time-varying sensitive graph construction. It jointly captures temporal dynamics and interdependencies among multiple transaction types through spatio-temporal graph convolution, thereby enabling accurate prediction of future trends. Experimental results on three public datasets demonstrate that the proposed method significantly outperforms several exiting forecasting models across multiple evaluation metrics, confirming its effectiveness and adaptability.},
booktitle = {Proceedings of the 2025 2nd International Conference on Digital Economy, Blockchain and Artificial Intelligence},
pages = {326–332},
numpages = {7},
keywords = {Credit Card Transaction Trend Forecasting, Customer Behavior Analysis, Graph Neural Network},
location = {
},
series = {DEBAI '25}
}

@inproceedings{10.1145/3534678.3539274,
author = {Ye, Junchen and Liu, Zihan and Du, Bowen and Sun, Leilei and Li, Weimiao and Fu, Yanjie and Xiong, Hui},
title = {Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539274},
doi = {10.1145/3534678.3539274},
abstract = {Recent studies have shown great promise in applying graph neural networks for multivariate time series forecasting, where the interactions of time series are described as a graph structure and the variables are represented as the graph nodes. Along this line, existing methods usually assume that the graph structure (or the adjacency matrix), which determines the aggregation manner of graph neural network, is fixed either by definition or self-learning. However, the interactions of variables can be dynamic and evolutionary in real-world scenarios. Furthermore, the interactions of time series are quite different if they are observed at different time scales. To equip the graph neural network with a flexible and practical graph structure, in this paper, we investigate how to model the evolutionary and multi-scale interactions of time series. In particular, we first provide a hierarchical graph structure cooperated with the dilated convolution to capture the scale-specific correlations among time series. Then, a series of adjacency matrices are constructed under a recurrent manner to represent the evolving correlations at each layer. Moreover, a unified neural network is provided to integrate the components above to get the final prediction. In this way, we can capture the pair-wise correlations and temporal dependency simultaneously. Finally, experiments on both single-step and multi-step forecasting tasks demonstrate the superiority of our method over the state-of-the-art approaches.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2296–2306},
numpages = {11},
keywords = {deep learning, graph neural network, time series forecasting},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3637528.3672055,
author = {Yu, Chengqing and Wang, Fei and Shao, Zezhi and Qian, Tangwen and Zhang, Zhao and Wei, Wei and Xu, Yongjun},
title = {GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672055},
doi = {10.1145/3637528.3672055},
abstract = {Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90\% of variables are missing, it can still accurately predict the future values of all variables.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3989–4000},
numpages = {12},
keywords = {adaptive graph convolution, graph interpolation attention recursive network, interpolation attention, multivariate time series forecasting, variable missing},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3694784,
author = {Anand, Vineeta and Maurya, Ashish Kumar},
title = {A Survey on Recommender Systems Using Graph Neural Network},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3694784},
doi = {10.1145/3694784},
abstract = {The expansion of the Internet has resulted in a change in the flow of information. With the vast amount of digital information generated online, it is easy for users to feel overwhelmed. Finding the specific information can be a challenge, and it can be difficult to distinguish credible sources from unreliable ones. This has made recommender system (RS) an integral part of the information services framework. These systems alleviate users from information overload by analyzing users’ past preferences and directing only desirable information toward users. Traditional RSs use approaches like collaborative and content-based filtering to generate recommendations. Recently, these systems have evolved to a whole new level, intuitively optimizing recommendations using deep network models. graph neural networks (GNNs) have become one of the most widely used approaches in RSs, capturing complex relationships between users and items using graphs. In this survey, we provide a literature review of the latest research efforts done on GNN-based RSs. We present an overview of RS, discuss its generalized pipeline and evolution with changing learning approaches. Furthermore, we explore basic GNN architecture and its variants used in RSs, their applications, and some critical challenges for future research.},
journal = {ACM Trans. Inf. Syst.},
month = nov,
articleno = {9},
numpages = {49},
keywords = {Recommender Systems, Graph Neural Network, Collaborative Filtering, Attention Mechanisms, GNN-based Recommender Models}
}

@inproceedings{10.1145/3637528.3671881,
author = {Yeh, Chin-Chia Michael and Fan, Yujie and Dai, Xin and Saini, Uday Singh and Lai, Vivian and Aboagye, Prince Osei and Wang, Junpeng and Chen, Huiyuan and Zheng, Yan and Zhuang, Zhongfang and Wang, Liang and Zhang, Wei},
title = {RPMixer: Shaking Up Time Series Forecasting with Random Projections for Large Spatial-Temporal Data},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671881},
doi = {10.1145/3637528.3671881},
abstract = {Spatial-temporal forecasting systems play a crucial role in addressing numerous real-world challenges. In this paper, we investigate the potential of addressing spatial-temporal forecasting problems using general time series forecasting models, i.e., models that do not leverage the spatial relationships among the nodes. We propose a all-Multi-Layer Perceptron (all-MLP) time series forecasting architecture called RPMixer. The all-MLP architecture was chosen due to its recent success in time series forecasting benchmarks. Furthermore, our method capitalizes on the ensemble-like behavior of deep neural networks, where each individual block within the network behaves like a base learner in an ensemble model, particularly when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby improving the overall performance of the network. Extensive experiments conducted on the largest spatial-temporal forecasting benchmark datasets demonstrate that the proposed method outperforms 14 alternative methods.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3919–3930},
numpages = {12},
keywords = {forecasting, large spatial-temporal graph, time series},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3485447.3512037,
author = {Kamarthi, Harshavardhan and Kong, Lingkai and Rodriguez, Alexander and Zhang, Chao and Prakash, B Aditya},
title = {CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512037},
doi = {10.1145/3485447.3512037},
abstract = {Probabilistic time-series forecasting enables reliable decision making across many domains. Most forecasting problems have diverse sources of data containing multiple modalities and structures. Leveraging information from these data sources for accurate and well-calibrated forecasts is an important but challenging problem. Most previous works on multi-view time-series forecasting aggregate features from each data view by simple summation or concatenation and do not explicitly model uncertainty for each data view. We propose a general probabilistic multi-view forecasting framework CAMul, which can learn representations and uncertainty from diverse data sources. It integrates the information and uncertainty from each data view in a dynamic context-specific manner, assigning more importance to useful views to model a well-calibrated forecast distribution. We use CAMul for multiple domains with varied sources and modalities and show that CAMul outperforms other state-of-art probabilistic forecasting models by over 25\% in accuracy and calibration.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {3174–3185},
numpages = {12},
keywords = {Multi-source multi-modal data, Probabilistic forecasting, Time-series Forecasting, Uncertainty quantification},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@article{10.1145/3675165,
author = {Yi, Peiyu and Huang, Feihu and Peng, Jian and Bao, Zhifeng},
title = {Dynamic Spatial-Temporal Embedding via Neural Conditional Random Field for Multivariate Time Series Forecasting},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
issn = {2374-0353},
url = {https://doi.org/10.1145/3675165},
doi = {10.1145/3675165},
abstract = {How to capture dynamic spatial-temporal dependencies remains an open question in multivariate time series (MTS) forecasting. Although recent advanced spatial-temporal graph neural networks (STGNNs) achieve superior forecasting performance, they either consider pre-defined spatial correlations or simply learn static graphs. Some research has tried to learn many adjacent matrices to reveal time-varying spatial correlations, but they generate discrete graphs which cannot encode evolutionary information and also face computational complexity problem. In this article, we propose two significant plugins to help automatically learn enhanced dynamic spatial-temporal embedding of MTS data: (1) a novel neural conditional random field (CRF) layer. We find that the implicit time-varying spatial dependencies are reflected by the explicit changeable links between edges, and we propose the neural CRF to encode such pairwise changeable evolutionary inter-dependencies; (2) a structure adaptive graph convolution (SAGC) that does not require pre-defined graphs to capture semantically richer spatial correlations. Then, we integrate the neural CRF, SAGC with recurrent neural network to develop a new STGNN paradigm termed Adaptive Spatial-Temporal graph neural network with Conditional Random Field (ASTCRF), which can be trained in an end-to-end fashion. We validate the effectiveness, efficiency, and scalability of ASTCRF on five public benchmark MTS datasets.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = oct,
articleno = {35},
numpages = {23},
keywords = {Multivariate time series, spatial-temporal embedding, conditional random field, evolving inter-series correlations}
}

@article{10.1145/3690388,
author = {Feng, Jiahui and Liu, Hefu and Zhou, Jingmei and Zhou, Yang},
title = {A Spatial-Temporal Aggregated Graph Neural Network for Docked Bike-sharing Demand Forecasting},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {1556-4681},
url = {https://doi.org/10.1145/3690388},
doi = {10.1145/3690388},
abstract = {Predicting the number of rented and returned bikes at each station is crucial for operators to proactively manage shared bike relocation. Although existing research has proposed spatial-temporal prediction models that significantly advance traffic prediction, these models often neglect the unique characteristics of shared bike systems (BSS). Spatially, the entire bike-sharing system (BSS) experiences peak activity during morning and evening rush hours, whereas, during other periods, activity is localized to local stations, with some recording no rides, highlighting the need to distinguish between global and local spatial information across different times. Temporally, the historical riding records for each station exhibit non-stationary patterns, necessitating the analysis of both global trends and local fluctuations. Existing Graph Neural Network (GNN) approaches to predicting shared bike demand primarily capture static spatial-temporal data and fail to account for the dynamic nature of bike flows. Moreover, these studies focus on global spatial-temporal information without considering local nuances, making it challenging to capture spatiotemporal dynamics in fluctuating BSS. To address these challenges, we introduce the Spatial-Temporal Aggregated Graph Neural Network (STAGNN). Our model first constructs a dynamic adjacent matrix to describe the evolving connections between stations, followed by local and global information layers to capture spatial-temporal information from large-scale shared bike networks accurately. Our methodology has been validated through experiments on four real-world datasets, comparing it against benchmark models to demonstrate superior prediction accuracy. Additionally, we conduct extended experiments on four datasets during the morning and evening rush hours, and the results also affirm the efficacy of the STAGNN in enhancing prediction performance.},
journal = {ACM Trans. Knowl. Discov. Data},
month = nov,
articleno = {232},
numpages = {27},
keywords = {Bike sharing prediction, Spatiotemporal dependency, Local and global information, Dynamic graph neural network}
}

@article{10.1145/3453724,
author = {Li, Yangfan and Li, Kenli and Chen, Cen and Zhou, Xu and Zeng, Zeng and Li, Keqin},
title = {Modeling Temporal Patterns with Dilated Convolutions for Time-Series Forecasting},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/3453724},
doi = {10.1145/3453724},
abstract = {Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated CNN for time-series forecasting tasks. The core component in HyDCNN is a proposed hybrid module, in which our proposed position-aware dilated CNNs are utilized to capture the sequential non-linear dynamics and an autoregressive model is leveraged to capture the sequential linear dependencies. To further capture the periodic temporal patterns, a novel hop scheme is introduced in the hybrid module. HyDCNN is then composed of multiple hybrid modules to capture the sequential and periodic patterns. Each of these hybrid modules targets on either the sequential pattern or one kind of periodic patterns. Extensive experiments on five real-world datasets have shown that the proposed HyDCNN is better compared with state-of-the-art baselines and is at least 200\% better than RNN baselines. The datasets and source code will be published in Github to facilitate more future work.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jul,
articleno = {14},
numpages = {22},
keywords = {time-series forecasting, dilated convolutions, Convolutional neural networks}
}

@inproceedings{10.1145/3604237.3626864,
author = {Ibrahim, Shibal and Tell, Max and Mazumder, Rahul},
title = {Dyn-GWN: Time-Series Forecasting using Time-varying Graphs with Applications to Finance and Traffic Prediction},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626864},
doi = {10.1145/3604237.3626864},
abstract = {Spatio-temporal modeling is an essential lens to understand many real-world phenomena from traffic to finance. There has been exciting work that explores spatio-temporal modeling with temporal graph convolutional networks. Often these methods assume that the spatial structure is static. We propose a new model Dyn-GWN&nbsp;for spatio-temporal learning from time-varying graphs. Our model relies on a novel module called the Tensor Graph Convolutional Module&nbsp;(TGCM), which captures dynamic trends in graphs effectively in the time-varying graph representations. This module has two components: (i) it applies temporal dilated convolutions both on the time-varying graph adjacency space and the time-varying features. (ii) it aggregates the higher-level latent representations from both time-varying components through a proposed layer TGCL. Experiments demonstrate the efficacy of these model across time-series data from finance and traffic domains. Dyn-GWN&nbsp; can give up to better out-of-sample performance than prior methods that learn from time-varying graphs, e.g., EvolveGCN and TM-GCN. Interestingly, Dyn-GWN&nbsp; can be ∼ 300 \texttimes{} faster than EvolveGCN, which is the more competitive baseline from state-of-the-art models that cater to time-varying graphs.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {167–175},
numpages = {9},
keywords = {Graph neural networks, Spatio-temporal modeling, Time-series forecasting, Time-varying graphs.},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@article{10.1145/3665141,
author = {Zhou, Binbin and Zhou, Hang and Wang, Weikun and Chen, Liming and Ma, Jianhua and Zheng, Zengwei},
title = {HDM-GNN: A Heterogeneous Dynamic Multi-view Graph Neural Network for Crime Prediction},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1550-4859},
url = {https://doi.org/10.1145/3665141},
doi = {10.1145/3665141},
abstract = {Smart cities have drawn a lot of interest in recent years, which employ Internet of Things (IoT)-enabled sensors to gather data from various sources and help enhance the quality of residents’ life in multiple areas, e.g. public safety. Accurate crime prediction is significant for public safety promotion. However, the complicated spatial-temporal dependencies make the task challenging, due to two aspects: 1) spatial dependency of crime includes correlations with spatially adjacent regions and underlying correlations with distant regions, e.g. mobility connectivity and functional similarity; 2) there are near-repeat and long-range temporal correlations between crime occurrences across time. Most existing studies fall short in tackling with multi-view correlations, since they usually treat them equally without consideration of different weights for these correlations. In this paper, we propose a novel model for region-level crime prediction named as Heterogeneous Dynamic Multi-view Graph Neural Network (HDM-GNN). The model can represent the dynamic spatial-temporal dependencies of crime with heterogeneous urban data, and fuse various types of region-wise correlations from multiple views. Global spatial dependencies and long-range temporal dependencies can be derived by integrating the multiple GAT modules and Gated CNN modules. Extensive experiments are conducted to evaluate the effectiveness of our method using several real-world datasets. Results demonstrate that our method outperforms state-of-the-art baselines. All the code are available at https://github.com/ZJUDataIntelligence/HDM-GNN.},
note = {Just Accepted},
journal = {ACM Trans. Sen. Netw.},
month = may,
keywords = {crime prediction, graph neural network, data fusion, spatio-temporal prediction}
}

@inproceedings{10.1145/3697355.3697401,
author = {Wang, Hao and Sun, Fuyong and Si, Jinxin and Ma, Qiuzhe and Zeng, Wenjing and Zang, Xiuhuan and Cao, Junxi and Song, Shuaibing and Wang, Nan},
title = {Robust Spatio-Temporal Graph Neural Network for Electricity Consumption Forecasting},
year = {2024},
isbn = {9798400717529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697355.3697401},
doi = {10.1145/3697355.3697401},
abstract = {Precise electricity consumption forecasting is pivotal in the energy schedule of new electric power systems. It is also significant for improving robustness of smart power grid. Existing multivariate time series predictions have made effective achievements in modeling sequential tendency and periodicity, but they lack of considering time series noises due to data sensing or transferring. Therefore, we focus on a robust approach to capture intricate correlations of multivariate time series data for forecasting. Specifically, we exploit gated dilated causal convolution as projection layer to capture latent semantic information from a temporal perspective. Furthermore, we combine time series decomposition and adaptive normalization to learn latent representations of each time series. Finally, we devise spatio-temporal modeling for capturing heterogeneous correlations. Extensive experiments are implemented on real-scenario public datasets. The performances show the effectiveness of proposed approach for electricity consumption forecasting.},
booktitle = {Proceedings of the 2024 8th International Conference on Big Data and Internet of Things},
pages = {276–281},
numpages = {6},
keywords = {electricity consumption forecasting, spatio-temporal modeling, data mining, smart grid},
location = {
},
series = {BDIOT '24}
}

@article{10.1145/3588951,
author = {Wu, Xinle and Zhang, Dalin and Zhang, Miao and Guo, Chenjuan and Yang, Bin and Jensen, Christian S.},
title = {AutoCTS+: Joint Neural Architecture and Hyperparameter Search for Correlated Time Series Forecasting},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3588951},
doi = {10.1145/3588951},
abstract = {Sensors in cyber-physical systems often capture interconnected processes and thus emit correlated time series (CTS), the forecasting of which enables important applications. The key to successful CTS forecasting is to uncover the temporal dynamics of time series and the spatial correlations among time series. Deep learning-based solutions exhibit impressive performance at discerning these aspects. In particular, automated CTS forecasting, where the design of an optimal deep learning architecture is automated, enables forecasting accuracy that surpasses what has been achieved by manual approaches. However, automated CTS solutions remain in their infancy and are only able to find optimal architectures for predefined hyperparameters and scale poorly to large-scale CTS. To overcome these limitations, we propose AutoCTS+, a joint, scalable framework, to automatically devise effective CTS forecasting models. Specifically, we encode each candidate architecture and accompanying hyperparameters into a joint graph representation. We introduce an efficient Architecture-Hyperparameter Comparator (AHC) to rank all architecture-hyperparameter pairs, and we then further evaluate the top-ranked pairs to select an architecture-hyperparameter pair as the final model. Extensive experiments on six benchmark datasets demonstrate that AutoCTS+ not only eliminates manual efforts but also is capable of better performance than manually designed and existing automatically designed CTS models. In addition, it shows excellent scalability to large CTS.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {97},
numpages = {26},
keywords = {architecture-hyperparameter comparator, correlated time series, efficiency, joint search, scalability}
}

@article{10.1145/3721289,
author = {Shen, Minghua and Qin, Aoxiang and Xiao, Nong},
title = {ODGS: Dependency-Aware Scheduling for High-Level Synthesis with Graph Neural Network and Reinforcement Learning},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {2},
issn = {1544-3566},
url = {https://doi.org/10.1145/3721289},
doi = {10.1145/3721289},
abstract = {Scheduling determines the execution order and time of operations in a program. The order is related to operation dependencies, including data and resource dependencies. Data dependency is intrinsic in a program, showing operation data flow. Resource dependency is determined by scheduling methods, resolving operation resource contention. Existing scheduling methods focus on data dependency, rather than building and exploiting operation dependency graph (ODG) with extra resource dependency. As ODG contains all dependencies determining operation execution order, it provides global program information, facilitating efficient scheduling. In this work, we propose ODGS, a dependency-aware scheduling method for high-level synthesis with graph neural network (GNN) and reinforcement learning (RL). We adopt GNN to perceive accurate relations between operations. We use the relations to guide an RL agent in building a complete ODG. We perform feedback-guided iterative scheduling with ODG to converge to a high-quality solution. Experiments show that our method reduces 16.4\% latency and 26.5\% resource usage on average, compared with the latest RL-based method. Moreover, we reduce an average 2.9\% latency over the GNN-based method under the same resource usage. The same resource usage is obtained by improving the GNN-based method with manual resource constraint tuning. Without tuning, its basic version consumes an average 237.6\% more resources than our method.},
journal = {ACM Trans. Archit. Code Optim.},
month = jun,
articleno = {58},
numpages = {25},
keywords = {Operation dependency graph, resource dependency, high-level synthesis}
}

@inproceedings{10.1145/3394486.3403118,
author = {Wu, Zonghan and Pan, Shirui and Long, Guodong and Jiang, Jing and Chang, Xiaojun and Zhang, Chengqi},
title = {Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403118},
doi = {10.1145/3394486.3403118},
abstract = {Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework. Experimental results show that our proposed model outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets and achieves on-par performance with other approaches on two traffic datasets which provide extra structural information.},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
pages = {753–763},
numpages = {11},
keywords = {spatial-temporal graphs, multivariate time series forecasting, graph structure learning, graph neural networks},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{10.14778/3489496.3489503,
author = {Cui, Yue and Zheng, Kai and Cui, Dingshan and Xie, Jiandong and Deng, Liwei and Huang, Feiteng and Zhou, Xiaofang},
title = {METRO: a generic graph neural network framework for multivariate time series forecasting},
year = {2021},
issue_date = {October 2021},
publisher = {VLDB Endowment},
volume = {15},
number = {2},
issn = {2150-8097},
url = {https://doi.org/10.14778/3489496.3489503},
doi = {10.14778/3489496.3489503},
abstract = {Multivariate time series forecasting has been drawing increasing attention due to its prevalent applications. It has been commonly assumed that leveraging latent dependencies between pairs of variables can enhance prediction accuracy. However, most existing methods suffer from static variable relevance modeling and ignorance of correlation between temporal scales, thereby failing to fully retain the dynamic and periodic interdependencies among variables, which are vital for long- and short-term forecasting. In this paper, we propose METRO, a generic framework with multi-scale temporal graphs neural networks, which models the dynamic and cross-scale variable correlations simultaneously. By representing the multivariate time series as a series of temporal graphs, both intra- and inter-step correlations can be well preserved via message-passing and node embedding update. To enable information propagation across temporal scales, we design a novel sampling strategy to align specific steps between higher and lower scales and fuse the cross-scale information efficiently. Moreover, we provide a modular interpretation of existing GNN-based time series forecasting works as specific instances under our framework. Extensive experiments conducted on four benchmark datasets demonstrate the effectiveness and efficiency of our approach. METRO has been successfully deployed onto the time series analytics platform of Huawei Cloud, where a one-month online test demonstrated that up to 20\% relative improvement over state-of-the-art models w.r.t. RSE can be achieved.},
journal = {Proc. VLDB Endow.},
month = oct,
pages = {224–236},
numpages = {13}
}

@inproceedings{10.1145/3637528.3671508,
author = {Luo, Yang and Gao, Mohan and Yu, Zhemeng and Ge, Haoyuan and Gao, Xiaofeng and Cai, Tengwei and Chen, Guihai},
title = {Integrating System State into Spatio Temporal Graph Neural Network for Microservice Workload Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671508},
doi = {10.1145/3637528.3671508},
abstract = {Microservice architecture has become a driving force in enhancing the modularity and scalability of web applications, as evidenced by the Alipay platform's operational success. However, a prevalent issue within such infrastructures is the suboptimal utilization of CPU resources due to inflexible resource allocation policies. This inefficiency necessitates the development of dynamic, accurate workload prediction methods to improve resource allocation. In response to this challenge, we present STAMP, a &lt;u&gt;S&lt;/u&gt;patio &lt;u&gt;T&lt;/u&gt;emporal Gr&lt;u&gt;a&lt;/u&gt;ph Network for &lt;u&gt;M&lt;/u&gt;icroservice Workload &lt;u&gt;P&lt;/u&gt;rediction. STAMP is designed to comprehensively address the multifaceted interdependencies between microservices, the temporal variability of workloads, and the critical role of system state in resource utilization. Through a graph-based representation, STAMP effectively maps the intricate network of microservice interactions. It employs time series analysis to capture the dynamic nature of workload changes and integrates system state insights to enhance prediction accuracy. Our empirical analysis, using three distinct real-world datasets, establishes that STAMP exceeds baselines by achieving an average boost of 5.72\% in prediction precision, as measured by RMSE. Upon deployment in Alipay's microservice environment, STAMP achieves a 33.10\% reduction in resource consumption, significantly outperforming existing online methods. This research solidifies STAMP as a validated framework, offering meaningful contributions to the field of resource management in microservice architecture-based applications.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5521–5531},
numpages = {11},
keywords = {microservice, spatio temporal gnn, workload prediction},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3462203.3475929,
author = {Li, Yi-Fan and Dong, Bo and Khan, Latifur and Thuraisingham, Bhavani and Brandt, Patrick T. and D'Orazio, Vito J.},
title = {Data-Driven Time Series Forecasting for Social Studies Using Spatio-Temporal Graph Neural Networks},
year = {2021},
isbn = {9781450384780},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3462203.3475929},
doi = {10.1145/3462203.3475929},
abstract = {Time series forecasting with additional spatial information has attracted a tremendous amount of attention in recent research, due to its importance in various real-world applications on social studies, such as conflict prediction and pandemic forecasting. Conventional machine learning methods either consider temporal dependencies only, or treat spatial and temporal relations as two separate autoregressive models, namely, space-time autoregressive models. Such methods suffer when it comes to long-term forecasting or predictions for large-scale areas, due to the high nonlinearity and complexity of spatio-temporal data. In this paper, we propose to address these challenges using spatio-temporal graph neural networks. Empirical results on Violence Early Warning System (ViEWS) dataset and U.S. Covid-19 dataset indicate that our method significantly improved performance over the baseline approaches.},
booktitle = {Proceedings of the Conference on Information Technology for Social Good},
pages = {61–66},
numpages = {6},
keywords = {Conflict prediction, Graph neural networks, Pandemic forecasting, Spatio-temporal modeling},
location = {Roma, Italy},
series = {GoodIT '21}
}

@article{10.14778/3641204.3641217,
author = {Han, Jindong and Zhang, Weijia and Liu, Hao and Tao, Tao and Tan, Naiqiang and Xiong, Hui},
title = {BigST: Linear Complexity Spatio-Temporal Graph Neural Network for Traffic Forecasting on Large-Scale Road Networks},
year = {2024},
issue_date = {January 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/3641204.3641217},
doi = {10.14778/3641204.3641217},
abstract = {Spatio-Temporal Graph Neural Network (STGNN) has been used as a common workhorse for traffic forecasting. However, most of them require prohibitive quadratic computational complexity to capture long-range spatio-temporal dependencies, thus hindering their applications to long historical sequences on large-scale road networks in the real-world. To this end, in this paper, we propose BigST, a linear complexity spatio-temporal graph neural network, to efficiently exploit long-range spatio-temporal dependencies for large-scale traffic forecasting. Specifically, we first propose a scalable long sequence feature extractor to encode node-wise long-range inputs (e.g., thousands of time-steps in the past week) into low-dimensional representations encompassing rich temporal dynamics. The resulting representations can be pre-computed and hence significantly reduce the computational overhead for prediction. Then, we build a linearized global spatial convolution network to adaptively distill time-varying graph structures, which enables fast runtime message passing along spatial dimensions in linear complexity. We empirically evaluate our model on two large-scale real-world traffic datasets. Extensive experiments demonstrate that BigST can scale to road networks with up to one hundred thousand nodes, while significantly improving prediction accuracy and efficiency compared to state-of-the-art traffic forecasting models.},
journal = {Proc. VLDB Endow.},
month = jan,
pages = {1081–1090},
numpages = {10}
}

@inproceedings{10.1145/3603719.3603740,
author = {Khlaisamniang, Pitikorn and Phoomvuthisarn, Suronapee},
title = {ST-CopulaGNN : A Multi-View Spatio-Temporal Graph Neural Network for Traffic Forecasting},
year = {2023},
isbn = {9798400707469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603719.3603740},
doi = {10.1145/3603719.3603740},
abstract = {Modern cities heavily rely on complex transportation, making accurate traffic speed prediction crucial for traffic management authorities. Classical methods, including statistical techniques and traditional machine learning techniques, fail to capture complex relationships, while deep learning approaches may have weaknesses such as error accumulation, difficulty in handling long sequences, and overlooking spatial correlations. Graph neural networks (GNNs) have shown promise in extracting spatial features from non-Euclidean graph structures, but they usually initialize the adjacency matrix based on distance and may fail to detect hidden statistical correlations. The choice of correlation measure can have a significant impact on the resulting adjacency matrix and the effectiveness of graph-based models. This paper proposes a novel approach for accurately forecasting traffic patterns by utilizing a multi-view spatio-temporal graph neural network that captures data from both realistic and statistical domains. Unlike traditional correlation measures such as Pearson correlation, copula models are utilized to extract hidden statistical correlations and construct multivariate distribution functions to obtain the correlation relationship among traffic nodes. A two-step approach is adopted, which involves selecting and testing different types of bivariate copulas to identify the ones that best fit the traffic data, and utilizing these copulas to create multi-weight adjacency matrices. The second step involves utilizing a graph convolutional network to extract spatial information and capturing temporal trends using dilated causal convolutions. The proposed ST-CopulaGNN model outperforms other models in spatio-temporal traffic forecasting that solely rely on distance-based adjacency matrices, such as DCRNN and Graph WaveNet. It also achieves the lowest MAE for 30 and 60 minutes ahead and the lowest MAPE for 15 minutes ahead on the PEMS-BAY dataset. The model incorporates copulas, and the study explores copula function selection and the impact of using paired time-series with a time lag. The findings suggest that using copula-based adjacency matrix configurations, particularly those including Clayton and Gumbel copulas, can enhance traffic forecasting accuracy.},
booktitle = {Proceedings of the 35th International Conference on Scientific and Statistical Database Management},
articleno = {8},
numpages = {12},
keywords = {Copula, Correlation, Graph Neural Networks, Traffic Forecasting},
location = {Los Angeles, CA, USA},
series = {SSDBM '23}
}

@inproceedings{10.1145/3767052.3767086,
author = {Xu, Qingqing},
title = {Capturing Structural Evolution in Financial Markets with Graph Neural Time Series Models},
year = {2025},
isbn = {9798400716010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3767052.3767086},
doi = {10.1145/3767052.3767086},
abstract = {This paper proposes a stock price prediction method based on a graph neural network architecture. The method is designed to address key characteristics of the stock market, including high nonlinearity, multivariable dependencies, and dynamically changing structural relationships. It constructs a dynamic stock graph to represent the evolving relationship network among individual stocks over time. A temporal-aware graph neural network module is designed to jointly model node features through structural propagation and temporal dependence. Specifically, the model incorporates multi-source heterogeneous information to build the dynamic graph structure. This enables explicit representation of the time-varying linkages between stocks within the graph. Graph convolution is then applied to extract structural features at each time step. A temporal module is used to model the evolution of these features over time. To validate the effectiveness of the method, the model is compared with existing graph-based and time-series models across multiple evaluation metrics. Ablation studies, robustness tests, and performance assessments under different market conditions are conducted to comprehensively analyze the model's behavior in various scenarios. Experimental results show that the proposed method achieves low prediction error while maintaining strong stability and generalization ability. It significantly improves the accuracy of modeling asset price trends in financial markets. This study provides a unified solution for structural and dynamic aspects of the stock prediction problem and extends the application scope of graph neural networks in financial time series analysis.},
booktitle = {Proceedings of the 2025 International Conference on Big Data, Artificial Intelligence and Digital Economy},
pages = {219–226},
numpages = {8},
keywords = {Structural modeling, graph neural networks, stock price forecasting, time series forecasting},
location = {
},
series = {BDAIE '25}
}

@inproceedings{10.1145/3589132.3625567,
author = {Hajisafi, Arash and Lin, Haowen and Shaham, Sina and Hu, Haoji and Siampou, Maria Despoina and Chiang, Yao-Yi and Shahabi, Cyrus},
title = {Learning Dynamic Graphs from All Contextual Information for Accurate Point-of-Interest Visit Forecasting},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3625567},
doi = {10.1145/3589132.3625567},
abstract = {Forecasting the number of visits to Points-of-Interest (POI) in an urban area is critical for planning and decision making in various application domains, from urban planning and transportation management to public health and social studies. Although this forecasting problem can be formulated as a multivariate time-series forecasting task, current approaches cannot fully exploit the ever-changing multi-context correlations among POIs. Therefore, we propose Busyness Graph Neural Network (BysGNN), a temporal graph neural network designed to learn and uncover the underlying multi-context correlations between POIs for accurate visit forecasting. Unlike other approaches where only time-series data is used to learn a dynamic graph, BysGNN utilizes all contextual information and time-series data to learn an accurate dynamic graph representation. By incorporating all contextual, temporal, and spatial signals, we observe a significant improvement in our forecasting accuracy over state-of-the-art forecasting models in our experiments with real-world datasets across the United States.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {22},
numpages = {12},
keywords = {graph neural networks, time-series forecasting, POI visiting patterns, multi-context correlations},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.1145/3736425.3770109,
author = {Sohrabbeig, Amirhossein and Ardakanian, Omid and Musilek, Petr},
title = {Long-Term Forecasting of Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3770109},
doi = {10.1145/3736425.3770109},
abstract = {Long-term forecasting of multivariate urban data poses a significant challenge due to the complex spatiotemporal dependencies inherent in such datasets. This paper presents DST, a novel multivariate time-series forecasting model that integrates graph attention and temporal convolution within a Graph Neural Network (GNN) to effectively capture spatial and temporal dependencies, respectively. To enhance model performance, we apply a decomposition-based preprocessing step that isolates trend, seasonal, and residual components of the time series, enabling the learning of distinct graph structures for different time-series components. Extensive experiments on real-world urban datasets—including electricity demand, weather metrics, carbon intensity, and air pollution—demonstrate the effectiveness of DST across a range of forecast horizons, from several days to one month. Specifically, our approach achieves an average improvement of 2.89\% to 9.10\% in long-term forecasting accuracy over state-of-the-art time-series forecasting models.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {161–170},
numpages = {10},
keywords = {multivariate time-series, long-term forecasting, spatio-temporal graph neural networks, time-series decomposition},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3747227.3747240,
author = {Chen, Yunhao and Xu, Hui},
title = {Traffic Flow Prediction Using Spatio-Temporal Graph Neural Networks Based on Hybrid Adaptive Feature Enhancement},
year = {2025},
isbn = {9798400714382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3747227.3747240},
doi = {10.1145/3747227.3747240},
abstract = {Aiming at the poor adaptation of most current models to dynamic maps and the difficulty in capturing long-term spatio-temporally relevant features, this paper proposes a hybrid adaptive feature-enhanced graph neural network (HAFEGNN) model. To address these challenges, we propose a new approach based on graph neural networks that integrates multiple state-of-the-art enhancement feature representation mechanisms. The model enhances the representation of dynamic spatio-temporal features by integrating multi-scale convolution, channel self-attention and spatial self-attention mechanisms. On top of that, temporal self-attention mechanism is also introduced to focus on learning long-term dependencies, which leads to better understanding of patterns in historical data and making more accurate predictions. The model further incorporates Dynamic Graph Convolutional Recurrent Network (DGCRN) to capture spatio-temporal dynamics. To enhance the adaptability to dynamic graph structures, it integrates spatial location embedding with graph attention mechanisms to form a spatially aware module, which improves the prediction accuracy. Our experimental evaluation on the widely used PeMS04 and PeMS08 datasets demonstrates the effectiveness of the proposed HAFEGNN. The model achieves significant improvements in key metrics such as MAE, RMSE, and MAPE, outperforming existing state-of-the-art methods and validating its ability to handle complex traffic data. This study provides a new solution for traffic flow prediction and demonstrates its potential in handling complex traffic data.},
booktitle = {Proceedings of the 2025 International Conference on Machine Learning and Neural Networks},
pages = {82–90},
numpages = {9},
keywords = {feature enhancement, graph neural network, spatiotemporal correlation, traffic flow prediction},
location = {
},
series = {MLNN '25}
}

@article{10.1145/3605894,
author = {Deng, Jiewen and Deng, Jinliang and Yin, Du and Jiang, Renhe and Song, Xuan},
title = {TTS-Norm: Forecasting Tensor Time Series via Multi-Way Normalization},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/3605894},
doi = {10.1145/3605894},
abstract = {Tensor time series (TTS) data, a generalization of one-dimensional time series on a high-dimensional space, is ubiquitous in real-world applications. Compared to modeling time series or multivariate time series, which has received much attention and achieved tremendous progress in recent years, tensor time series has been paid less effort. However, properly coping with the TTS is a much more challenging task, due to its high-dimensional and complex inner structure. In this article, we start by revealing the structure of TTS data from afn statistical view of point. Then, in line with this analysis, we perform Tensor Time Series forecasting via a proposed Multi-way Normalization (TTS-Norm), which effectively disentangles multiple heterogeneous low-dimensional substructures from the original high-dimensional structure. Finally, we design a novel objective function for TTS forecasting, accounting for the numerical heterogeneity among different low-dimensional subspaces of TTS. Extensive experiments on two real-world datasets verify the superior performance of our proposed model.1},
journal = {ACM Trans. Knowl. Discov. Data},
month = aug,
articleno = {3},
numpages = {25},
keywords = {Tensor time series forecasting, representation learning, normalization, neural network}
}

@article{10.5555/3648699.3648941,
author = {Cini, Andrea and Zambon, Daniele and Alippi, Cesare},
title = {Sparse graph learning from spatiotemporal time series},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Outstanding achievements of graph neural networks for spatiotemporal time series analysis show that relational constraints introduce an effective inductive bias into neural forecasting architectures. Often, however, the relational information characterizing the underlying data-generating process is unavailable and the practitioner is left with the problem of inferring from data which relational graph to use in the subsequent processing stages. We propose novel, principled--yet practical--probabilistic score-based methods that learn the relational dependencies as distributions over graphs while maximizing end-to-end the performance at task. The proposed graph learning framework is based on consolidated variance reduction techniques for Monte Carlo score-based gradient estimation, is theoretically grounded, and, as we show, effective in practice. In this paper, we focus on the time series forecasting problem and show that, by tailoring the gradient estimators to the graph learning problem, we are able to achieve state-of-the-art performance while controlling the sparsity of the learned graph and the computational scalability. We empirically assess the effectiveness of the proposed method on synthetic and real-world benchmarks, showing that the proposed solution can be used as a stand-alone graph identification procedure as well as a graph learning component of an end-to-end forecasting architecture.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {242},
numpages = {36},
keywords = {graph learning, spatiotemporal data, graph-based forecasting, time series forecasting, score-based learning, graph neural networks}
}

@inproceedings{10.1145/3533271.3561678,
author = {Wang, Yuanrong and Aste, Tomaso},
title = {Network Filtering of Spatial-temporal GNN for Multivariate Time-series Prediction},
year = {2022},
isbn = {9781450393768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533271.3561678},
doi = {10.1145/3533271.3561678},
abstract = {We propose an architecture for multivariate time-series prediction that integrates a spatial-temporal graph neural network with a filtering module which filters the inverse correlation matrix into a sparse network structure. In contrast with existing sparsification methods adopted in graph neural networks, our model explicitly leverages time-series filtering to overcome the low signal-to-noise ratio typical of complex systems data. We present a set of experiments, where we predict future sales volume from a synthetic time-series sales volume dataset. The proposed spatial-temporal graph neural network displays superior performances to baseline approaches with no graphical information, fully connected, disconnected graphs, and unfiltered graphs, as well as the state-of-the-art spatial-temporal GNN. Comparison of the results with Diffusion Convolutional Recurrent Neural Network (DCRNN) suggests that, by combining a (inferior) GNN with graph sparsification and filtering, one can achieve comparable or better efficacy than the state-of-the-art in multivariate time-series regression.},
booktitle = {Proceedings of the Third ACM International Conference on AI in Finance},
pages = {463–470},
numpages = {8},
keywords = {Attention, Complex Network, Correlation Matrix, Information Filtering Network, LSTM, Multivariate Time-series Forecasting, Sparse Graph, Spatial-temporal GNN},
location = {New York, NY, USA},
series = {ICAIF '22}
}

@inproceedings{10.1145/3627673.3679642,
author = {Jing, Baoyu and Zhou, Dawei and Ren, Kan and Yang, Carl},
title = {Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679642},
doi = {10.1145/3627673.3679642},
abstract = {Spatiotemporal time series are usually collected via monitoring sensors placed at different locations, which usually contain missing values due to various failures, such as mechanical damages and Internet outages. Imputing the missing values is crucial for analyzing time series. When recovering a specific data point, most existing methods consider all the information relevant to that point regardless of the cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths and establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could cause overfitting. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective and show how to block the confounders via the frontdoor adjustment. Based on the results of frontdoor adjustment, we introduce a novel &lt;u&gt;C&lt;/u&gt;ausality-&lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;Sp&lt;/u&gt;atiot&lt;u&gt;e&lt;/u&gt;mpo&lt;u&gt;r&lt;/u&gt;al Graph Neural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and a Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of confounders and SCA could discover the sparse causal relationships among embeddings. Theoretical analysis reveals that SCA discovers causal relationships based on the values of gradients. We evaluate Casper on three real-world datasets, and the experimental results show that Casper could outperform the baselines and could effectively discover the causal relationships.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1027–1037},
numpages = {11},
keywords = {causal attention, spatiotemporal graph neural network, spatiotemporal time series imputation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3724154.3724271,
author = {Deng, Tingting and Bi, Shuochen and Xiao, Jue},
title = {Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming},
year = {2025},
isbn = {9798400711862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724154.3724271},
doi = {10.1145/3724154.3724271},
abstract = {As the financial industry becomes more interconnected and reliant on digital systems, fraud detection systems must evolve to meet growing threats. Cloud-enabled Transformer models present a transformative opportunity to address these challenges. By leveraging the scalability, flexibility, and advanced AI capabilities of cloud platforms, companies can deploy fraud detection solutions that adapt to real-time data patterns and proactively respond to evolving threats. Using the Graph self-attention Transformer neural network module, we can directly excavate gang fraud features from the transaction network without constructing complicated feature engineering. Finally, the fraud prediction network is combined to optimize the topological pattern and the temporal transaction pattern to realize the high-precision detection of fraudulent transactions. The results of anti-fraud experiments on credit card transaction data show that the proposed model outperforms the 7 baseline models on all evaluation indicators: In the transaction fraud detection task, the average accuracy (AP) increased by 20\% and the area under the ROC curve (AUC) increased by 2.7\% on average compared with the benchmark graph attention neural network (GAT), which verified the effectiveness of the proposed model in the detection of credit card fraud transactions.},
booktitle = {Proceedings of the 2024 5th International Conference on Big Data Economy and Information Management},
pages = {702–707},
numpages = {6},
keywords = {Cloud computing, Credit Card Transaction, Fraud Detection, Graph Neural Network, Transformer Model},
location = {
},
series = {BDEIM '24}
}

@inproceedings{10.1145/3534678.3539109,
author = {Yan, Shifu and Shan, Caihua and Yang, Wenyi and Xu, Bixiong and Li, Dongsheng and Qiu, Lili and Tong, Jie and Zhang, Qi},
title = {CMMD: Cross-Metric Multi-Dimensional Root Cause Analysis},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539109},
doi = {10.1145/3534678.3539109},
abstract = {In large-scale online services, crucial metrics, a.k.a., key performance indicators (KPIs), are monitored periodically to check the running statuses. Generally, KPIs are aggregated along multiple dimensions and derived by complex calculations among fundamental metrics from the raw data. Once abnormal KPI values are observed, root cause analysis (RCA) can be applied to identify the reasons for anomalies, so that we can troubleshoot quickly. Recently, several automatic RCA techniques were proposed to localize the related dimensions (or a combination of dimensions) to explain the anomalies. However, their analyses are limited to the data on the abnormal metric and ignore the data of other metrics which are also related to the anomalies, leading to imprecise or even incorrect root causes. To this end, we propose a cross-metric multi-dimensional root cause analysis method, named CMMD, which consists of two key components: 1) relationship modeling, which utilizes graph neural network (GNN) to model the unknown complex calculation among metrics and aggregation function among dimensions from historical data; 2) root cause localization, which adopts the genetic algorithm to efficiently and effectively dive into the raw data and localize the abnormal dimension(s) once the KPI anomalies are detected. Experiments on synthetic datasets, real-world datasets and online production environments demonstrate the superiority of our proposed CMMD method compared with baselines. Currently, CMMD is running as an online service in Microsoft Azure.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4310–4320},
numpages = {11},
keywords = {genetic algorithm, graph neural network, root cause analysis},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3615900.3628769,
author = {Karimi Monsefi, Amin and Shiri, Pouya and Mohammadshirazi, Ahmad and Karimi Monsefi, Nastaran and Davies, Ron and Moosavi, Sobhan and Ramnath, Rajiv},
title = {CrashFormer: A Multimodal Architecture to Predict the Risk of Crash},
year = {2023},
isbn = {9798400703621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615900.3628769},
doi = {10.1145/3615900.3628769},
abstract = {Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose Crash-Former, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8\% in F1-score on average when using "sparse" input data.},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on Advances in Urban-AI},
pages = {42–51},
numpages = {10},
keywords = {accident prediction, long sequence time-series forecasting, transformer, multimodal architecture},
location = {Hamburg, Germany},
series = {UrbanAI '23}
}

@inproceedings{10.1145/3746252.3761432,
author = {Yu, Tao and Wan, Junhong and Fu, Yao and Jiang, Weihao and Zhu, Jiang},
title = {Decoder-only Pre-training Enhancement for Spatio-temporal Traffic Forecasting},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761432},
doi = {10.1145/3746252.3761432},
abstract = {Although spatio-temporal graph neural networks (STGNNs) become widely used methods in traffic forecasting, they still encounter an issue named short-sightedness. Specifically, due to high model complexity and GPU memory usage, STGNNs are restricted to processing only very short input time series. This limited context often causes STGNNs to focus on local variations and overlook long-term patterns, leading to misinterpretation of time series trends. To tackle this issue, recent studies propose to perform mask reconstruction pre-training on traffic series to enhance STGNNs. However, we argue that mask reconstruction is a suboptimal pre-training paradigm for traffic forecasting, because there exists a great gap between pre-training and downstream forecasting, caused by their inconsistent training targets. To eliminate this gap, we propose a new pre-training paradigm named next patch prediction and prove its advantages from both empirical and theoretical perspectives. Based on this paradigm, we introduce a new framework called Decoder-only Pre-training Enhancement (DoP) to unleash the potential of traffic pre-training model. Specifically, DoP uses Transformer decoders as infrastructure, and leverages next patch prediction as target to conduct pre-training. In addition, we propose a new dual-view temporal embedding to fully capture temporal information and spatial spectral enhancement to model spatial information. After pre-training, DoP enhances existing STGNNs seamlessly with periodic enhancement mechanism. On four real-world traffic benchmarks, we demonstrate its start-of-the-art performance.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {3942–3951},
numpages = {10},
keywords = {pre-training model, spatio-temporal graph neural network, traffic forecasting},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@article{10.1145/3735646,
author = {Peng, Han and Li, Wengen and Jin, Chang and Zhang, Yichao and Guan, Jihong and Yang, Hanchen and Zhou, Shuigeng},
title = {Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation for Wide-Area SST Prediction},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3735646},
doi = {10.1145/3735646},
abstract = {Accurate prediction of Sea Surface Temperature (SST) is of high importance in marine science, benefiting applications ranging from ecosystem protection to extreme weather forecasting and climate analysis. Wide-area SST usually shows diverse SST patterns in different sea areas due to the changes of temperature zones and the dynamics of ocean currents. However, existing studies on SST prediction often focus on small-area predictions and lack the consideration of diverse SST patterns. Furthermore, SST shows an annual periodicity, but the periodicity is not strictly adherent to an annual cycle. Existing SST prediction methods struggle to adapt to this non-strict periodicity. To address these two issues, we proposed the Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation (RGCN-PSA) model which is equipped with the Cross-Region Graph Convolutional Network module and the Periodicity Shift Adaption module. The Cross-Region Graph Convolutional Network module enhances wide-area SST prediction by learning and incorporating diverse SST patterns. Meanwhile, the periodicity Shift Adaptation module accounts for the annual periodicity and enable the model to adapt to the possible temporal shift automatically. We conduct experiments on two real-world SST datasets, and the results demonstrate that our RGCN-PSA model obviously outperforms baseline models in terms of prediction accuracy. The code of RGCN-PSA model is available at .},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jul,
articleno = {87},
numpages = {23},
keywords = {Wide-area SST prediction, graph neural network, diverse SST patterns, periodicity shift adaptation}
}

@article{10.14778/3746405.3746436,
author = {Li, Ruikun and Shi, Dai and Xiao, Ye and Gao, Junbin},
title = {UFGTime: Mining Intertwined Dependencies in Multivariate Time Series via an Efficient Pure Graph Approach},
year = {2025},
issue_date = {May 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3746405.3746436},
doi = {10.14778/3746405.3746436},
abstract = {Graph Neural Networks (GNNs) have become a cornerstone in multivariate time series forecasting by addressing the challenge of modeling inter-series dependencies often overlooked by traditional temporal approaches. However, real-world temporal dependencies (inter- and intra-dependencies) are inherently intertwined, making it difficult to treat them as separate processes. Recent pure graph paradigms attempt to capture these dependencies holistically by transforming time series into fully connected graphs. While effective, these methods suffer from prohibitive computational complexity O((NT)2), limiting their scalability for large-scale data and long-term forecasting. To address these challenges, we propose UFGTime, a novel framework that leverages spectral signals to construct a "spectral-variate graph," embedding multivariate temporal dependencies in a compact spectral representation and modeling inter- and intra-signal connections through frequency similarities. Empowered by our proposed graph framelet message-passing function, UFGTime efficiently aggregates global information, avoids over-smoothing, and achieves near-linear complexity O(kNT). Extensive experiments on diverse datasets demonstrate that UFG-Time consistently outperforms state-of-the-art baselines, offering a scalable, accurate, and resource-efficient pure graph solution for multivariate time series forecasting.},
journal = {Proc. VLDB Endow.},
month = may,
pages = {3175–3188},
numpages = {14}
}

@inproceedings{10.1145/3708657.3708664,
author = {Han, Jingxiao and Song, Yufei and Wu, Qi and Han, Baiyang and Zhang, Tiankui},
title = {Divide and Conquer: Adaptive Graph Neural Networks Leveraging Sequence Factorization for IP Network},
year = {2025},
isbn = {9798400717444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708657.3708664},
doi = {10.1145/3708657.3708664},
abstract = {Accurate IP network traffic prediction is vital for the efficient management of metropolitan area networks, allowing operators to foresee potential issues and maintain optimal service quality. Existing methods struggle with the complex spatio-temporal characteristics of traffic sequences and their dependence on precise network topology. To overcome these challenges, we propose an innovative prediction framework leveraging discrete wavelet transform (DWT) and a dual-channel adaptive spatial-temporal graph convolutional network (ASTGCN) with feature fusion : WASTGCN. We start with a divide-and-conquer approach, using a multilevel DWT to decompose multimodal traffic into simpler factor sequences. We then introduce an ASTGCN that learns spatial dependencies directly from the data, minimizing the need for predefined structures and reducing preprocessing. The ASTGCN features a dual-channel setup: one branch captures short-term events using temporal attention, while the other models long-term trends with temporal convolution, effectively analyzing temporal dynamics. A multi-head cross attention fusion module then integrates these features. Our experimental results show that this method surpasses traditional approaches in predictive accuracy and stability, without depending on physical topology, highlighting its potential for improved network planning and management.},
booktitle = {Proceedings of the 2024 10th International Conference on Communication and Information Processing},
pages = {41–45},
numpages = {5},
keywords = {Adaptive Graph Neural Network, IP Network Traffic Prediction, Sequence Factorization},
location = {
},
series = {ICCIP '24}
}

@inproceedings{10.1145/3637528.3672030,
author = {Lin, Li and Lu, Zhiqiang and Wang, Shuai and Liu, Yunhuai and Hong, Zhiqing and Wang, Haotian and Wang, Shuai},
title = {MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672030},
doi = {10.1145/3637528.3672030},
abstract = {Recently, integrated warehouse and distribution logistics systems are widely used in E-commerce industries to adjust to constantly changing customer demands. It makes the prediction of purchase demand and delivery supply capacity a crucial problem to streamline operations and improve efficiency. The interaction between such demand and supply not only relies on their economic relationships but also on consumer psychology caused by daily events, such as epidemics, promotions, and festivals. Although existing studies have made great efforts in the joint prediction of demand and supply considering modeling the demand-supply interactions, they seldom refer to the impacts of diverse events. In this work, we propose MulSTE, a Multi-view Spatio-Temporal learning framework with heterogeneous Event fusion. Firstly, an Event Fusion Representation (EFR) module is designed to fuse the textual, numerical, and categorical heterogeneous information for emergent and periodic events. Secondly, a Multi-graph Adaptive Convolution Recurrent Network (MGACRN) is developed as the spatio-temporal encoder (ST-Encoder) to capture the evolutional features of demand, supply, and events. Thirdly, the Event Gated Demand-Supply Interaction Attention (EGIA) module is designed to model the demand-supply interactions during events. The evaluations are conducted on two real-world datasets collected from JD Logistics and public websites. The experimental results show that our method outperforms state-of-the-art baselines in various metrics.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1781–1792},
numpages = {12},
keywords = {demand-supply prediction, event representation, graph neural network, spatio-temporal graphs},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3583788.3583799,
author = {Chen, Bingbing and Liao, Yong},
title = {Spatio-Temporal Deep Fusion Graph Convolutional Networks for Crime Prediction},
year = {2023},
isbn = {9781450398633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583788.3583799},
doi = {10.1145/3583788.3583799},
abstract = {Effective crime prediction plays a key role in sustaining the stability of society. In recent years, researchers have proposed a number of prediction methods that extract spatial and temporal features separately and fuse afterward. However, the strict distinction between spatial feature extraction and temporal feature extraction can result in the loss of useful information. To this end, we propose a spatio-temporal deep fusion graph convolution network (STDGCN), which embodies the intra-region spatio-temporal features and the inter-region spatio-temporal associations on a single graph. STDGCN performs the convolution without distinguishing between space and time to simultaneously extract spatio-temporal features. Our evaluations of two real-world datasets demonstrate the effectiveness of STDGCN.},
booktitle = {Proceedings of the 2023 7th International Conference on Machine Learning and Soft Computing},
pages = {75–81},
numpages = {7},
keywords = {Crime Prediction, Graph Neural Network, Spatio-Temporal Prediction},
location = {Chongqing, China},
series = {ICMLSC '23}
}

@article{10.1145/3568683,
author = {Liu, Hao and Guo, Qingyu and Zhu, Hengshu and Fu, Yanjie and Zhuang, Fuzhen and Ma, Xiaojuan and Xiong, Hui},
title = {Characterizing and Forecasting Urban Vibrancy Evolution: A Multi-View Graph Mining Perspective},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3568683},
doi = {10.1145/3568683},
abstract = {Urban vibrancy describes the prosperity, diversity, and accessibility of urban areas, which is vital to a city’s socio-economic development and sustainability. While many efforts have been made for statically measuring and evaluating urban vibrancy, there are few studies on the evolutionary process of urban vibrancy, yet we know little about the relationship between urban vibrancy evolution and sophisticated spatiotemporal dynamics. In this article, we make use of multi-sourced urban data to develop a data-driven framework, U-Evolve, to investigate urban vibrancy evolution. Specifically, we first exploit the spatiotemporal characteristics of urban areas to create multi-view time-dependent graphs. Then, we analyze the contextual features and graph patterns of multi-view time-dependent graphs in terms of informing future urban vibrancy variations. Our analysis validates the informativeness of multi-view time-dependent graphs for characterizing and informing future urban vibrancy evolution. After that, we construct a feature based model to forecast future urban vibrancy evolution and quantify each feature’s importance. Moreover, to further enhance the forecasting effectiveness, we propose a graph learning based model to capture spatiotemporal autocorrelation of urban areas based on multi-view time-dependent graphs in an end-to-end manner. Finally, extensive experiments on two metropolises, Beijing and Shanghai, demonstrate the effectiveness of our forecasting models. The U-Evolve framework has also been deployed in the production environment to deliver real-world urban development and planning insights for various cities in China.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {68},
numpages = {24},
keywords = {Urban vibrancy forecasting, spatiotemporal data mining, graph neural network}
}

@inproceedings{10.1145/3340531.3411975,
author = {Deng, Songgaojun and Wang, Shusen and Rangwala, Huzefa and Wang, Lijing and Ning, Yue},
title = {Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3411975},
doi = {10.1145/3340531.3411975},
abstract = {Forecasting influenza-like illness (ILI) is of prime importance to epidemiologists and health-care providers. Early prediction of epidemic outbreaks plays a pivotal role in disease intervention and control. Most existing work has either limited long-term prediction performance or fails to capture spatio-temporal dependencies in data. In this paper, we design a cross-location attention based graph neural network (Cola-GNN) for learning time series embeddings in long-term ILI predictions. We propose a graph message passing framework to combine graph structures (e.g., geolocations) and time-series features (e.g., temporal sequences) in a dynamic propagation process. We compare the proposed method with state-of-the-art statistical approaches and deep learning models. We conducted a set of extensive experiments on real-world epidemic-related datasets from the United States and Japan. The proposed method demonstrated strong predictive performance and leads to interpretable results for long-term epidemic predictions.},
booktitle = {Proceedings of the 29th ACM International Conference on Information \&amp; Knowledge Management},
pages = {245–254},
numpages = {10},
keywords = {ILI prediction, dynamic graph neural network, spatial attention},
location = {Virtual Event, Ireland},
series = {CIKM '20}
}

@inproceedings{10.1145/3580305.3599285,
author = {Ma, Yunshan and Ye, Chenchen and Wu, Zijian and Wang, Xiang and Cao, Yixin and Chua, Tat-Seng},
title = {Context-aware Event Forecasting via Graph Disentanglement},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599285},
doi = {10.1145/3580305.3599285},
abstract = {Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information.To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual information. First, the categorical context provides supplementary fine-grained information to the coarse-grained events. Second and more importantly, the context provides additional information towards specific situation and condition, which is crucial or even determinant to what will happen next. However, it is challenging to properly integrate context into the event forecasting framework, considering the complex patterns in the multi-context scenario. Towards this end, we design a novel framework named Separation and Collaboration Graph Disentanglement (short as SeCoGD) for context-aware event forecasting. In the separation stage, we leverage the context as a prior guidance to disentangle the event graph into multiple sub-graphs, followed by a context-specific module to model the relational-temporal patterns within each context. In the collaboration stage, we design a cross-context module to retain the collaborative associations among multiple contexts. Since there is no available dataset for this novel task, we construct three large- scale datasets based on GDELT. Experimental results demonstrate hat our model outperforms a list of SOTA methods. The dataset and code are released via https://github.com/yecchen/SeCoGD.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1643–1652},
numpages = {10},
keywords = {graph disentanglement, graph neural network, temporal event forecasting, temporal knowledge graph},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3459637.3481927,
author = {Zheng, Shun and Gao, Zhifeng and Cao, Wei and Bian, Jiang and Liu, Tie-Yan},
title = {HierST: A Unified Hierarchical Spatial-temporal Framework for COVID-19 Trend Forecasting},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3481927},
doi = {10.1145/3459637.3481927},
abstract = {The outbreak of the COVID-19 pandemic has largely influenced the world and our normal daily lives. To combat this pandemic efficiently, governments usually need to coordinate essential resources across multiple regions and adjust intervention polices at the right time, which all call for accurate and robust forecasting of future epidemic trends. However, designing such a forecasting system is non-trivial, since we need to handle all kinds of locations at different administrative levels, which include pretty different epidemic-evolving patterns. Moreover, there are dynamic and volatile correlations of pandemic conditions among these locations, which further enlarge the difficulty in forecasting. With these challenges in mind, we develop a novel spatial-temporal forecasting framework. First, to accommodate all kinds of locations at different administrative levels, we propose a unified hierarchical view, which mimics the aggregation procedure of pandemic statistics. Then, this view motivates us to facilitate joint learning across administrative levels and inspires us to design the cross-level consistency loss as an extra regularization to stabilize model training. Besides, to capture those dynamic and volatile spatial correlations, we design a customized spatial module with adaptive edge gates, which can both reinforce effective messages and disable irrelevant ones. We put this framework into production to help the battle against COVID-19 in the United States. A comprehensive online evaluation across three months demonstrates that our projections are the most competitive ones among all results produced by dozens of international group and even surpass the official ensemble in many cases. We also visualize our unique edge gates to understand the evolvement of spatial correlations and present intuitive case studies. Besides, we open source our implementation at https://github.com/dolphin-zs/HierST to facilitate future research towards better epidemic modeling.},
booktitle = {Proceedings of the 30th ACM International Conference on Information \&amp; Knowledge Management},
pages = {4383–4392},
numpages = {10},
keywords = {covid-19, graph neural networks, spatial-temporal forecasting, time-series forecasting},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@article{10.1145/3565973,
author = {Dong, Guimin and Tang, Mingyue and Wang, Zhiyuan and Gao, Jiechao and Guo, Sikun and Cai, Lihua and Gutierrez, Robert and Campbel, Bradford and Barnes, Laura E. and Boukhechba, Mehdi},
title = {Graph Neural Networks in IoT: A Survey},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3565973},
doi = {10.1145/3565973},
abstract = {The Internet of Things (IoT) boom has revolutionized almost every corner of people’s daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.},
journal = {ACM Trans. Sen. Netw.},
month = apr,
articleno = {47},
numpages = {50},
keywords = {Graph neural network, Internet of Things, sensor network, survey}
}

@inproceedings{10.1145/3490354.3494390,
author = {Ang, Gary and Lim, Ee-Peng},
title = {Learning knowledge-enriched company embeddings for investment management},
year = {2022},
isbn = {9781450391481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490354.3494390},
doi = {10.1145/3490354.3494390},
abstract = {Relationships between companies serve as key channels through which the effects of past stock price movements and news events propagate and influence future price movements. Such relationships can be implicitly found in knowledge bases or explicitly represented as knowledge graphs. In this paper, we propose Knowledge-Enriched Company Embedding (KECE), a novel multi-stage attention-based dynamic network embedding model combining multimodal information of companies with knowledge from Wikipedia and knowledge graph relationships from Wikidata to generate company entity embeddings that can be applied to a variety of downstream investment management tasks. Experiments on an extensive set of real-world stock prices and news datasets show that the proposed KECE model outperforms other state-of-the-art models on key investment management tasks.},
booktitle = {Proceedings of the Second ACM International Conference on AI in Finance},
articleno = {25},
numpages = {9},
keywords = {attention mechanisms, embeddings, finance, graph neural networks, networks, multimodality, time-series forecasting, transformers},
location = {Virtual Event},
series = {ICAIF '21}
}

@inproceedings{10.1145/3447548.3467079,
author = {Xing, Mingzhe and Bian, Shuqing and Zhao, Wayne Xin and Xiao, Zhen and Luo, Xinji and Yin, Cunxiang and Cai, Jing and He, Yancheng},
title = {Learning Reliable User Representations from Volatile and Sparse Data to Accurately Predict Customer Lifetime Value},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467079},
doi = {10.1145/3447548.3467079},
abstract = {In industry, customer lifetime value (LTV) prediction is a challenging task, since user consumption data is usually volatile, noisy, or sparse. To address these issues, this paper presents a novel Temporal-Structural User Representation (named TSUR) network to predict LTV. We utilize historical revenue time series and user attributes to learn both temporal and structural user representations, respectively. Specifically, the temporal representation is learned with a temporal trend encoder based on a novel multi-channel Discrete Wavelet Transform~(DWT) module, while the structural representation is derived with Graph Attention Network (GAT) on an attribute similarity graph. Furthermore, a novel cluster-alignment regularization method is employed to align and enhance these two kinds of representations. In essence, such a fusion way can be considered as the association of temporal and structural representations in the low-pass representation space, which is also useful to prevent the data noise from being transferred across different views. To our knowledge, it is the first time that temporal and structural user representations are jointly learned for LTV prediction. Extensive offline experiments on two large-scale real-world datasets and online A/B tests have shown the superiority of our approach over a number of competitive baselines.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {3806–3816},
numpages = {11},
keywords = {discrete wavelet transform, graph neural network, lifetime value},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3533271.3561702,
author = {Ibrahim, Shibal and Chen, Wenyu and Zhu, Yada and Chen, Pin-Yu and Zhang, Yang and Mazumder, Rahul},
title = {Knowledge Graph Guided Simultaneous Forecasting and Network Learning for Multivariate Financial Time Series},
year = {2022},
isbn = {9781450393768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533271.3561702},
doi = {10.1145/3533271.3561702},
abstract = {Financial time series forecasting is challenging due to limited sample size, correlated samples, low signal strengths, among others. Additional information with knowledge graphs (KGs) can allow for improved prediction and decision making. In this work, we explore a framework GregNets&nbsp;for jointly learning forecasting models and correlations structures that exploit graph connectivity from KGs. We propose novel regularizers based on KG relations to guide estimation of correlation structure. We develop a pseudo-likelihood layer that can learn the error residual structure for any multivariate time-series forecasting architecture in deep learning APIs (e.g. Tensorflow). We evaluate our modeling and algorithmic proposals in small sample regimes in real-world financial markets with two types of KGs. Our empirical results demonstrate sparser connectivity structures, runtime improvements and high-quality predictions.},
booktitle = {Proceedings of the Third ACM International Conference on AI in Finance},
pages = {480–488},
numpages = {9},
keywords = {financial markets, graph neural networks, knowledge graphs, multivariate time-series, precision matrix, sparsity},
location = {New York, NY, USA},
series = {ICAIF '22}
}

@inproceedings{10.1145/3589335.3651918,
author = {Huang, Feihu and Yi, Peiyu and Li, Shan and Xu, Haiwen},
title = {Data Quality-based Gradient Optimization for Recurrent Neural Networks},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651918},
doi = {10.1145/3589335.3651918},
abstract = {Time series forecasting holds significant value in various application scenarios. However, existing forecasting methods primarily focus on optimizing model architecture while neglecting the substantial impact of data quality on model learning. In this study, we aim to enhance model performance by optimizing data utilization based on data quality and propose a Data Quality-based Gradient Optimization (DQGO) method to facilitate training of recurrent neural networks. Firstly, we define sample quality as the matching degree between samples and model, and suggest using the attention entropy to calculate the sample quality through an attention mechanism. Secondly, we optimize the model's gradient vector by giving different weights to samples with different quality. Through experiments conducted on six datasets, the results demonstrate that DQGO significantly improves LSTM's performance. In certain cases, it even surpasses the state-of-the-art models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1496–1501},
numpages = {6},
keywords = {data quality, gradient optimization, recurrent neural network, time series},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3746252.3761330,
author = {Wang, Zhaoyan and Song, Xiangchi and Ko, In-Young},
title = {Forecasting at Full Spectrum: Holistic Multi-Granular Traffic Modeling under High-Throughput Inference Regimes},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761330},
doi = {10.1145/3746252.3761330},
abstract = {Notably, current intelligent transportation systems rely heavily on accurate traffic forecasting and swift inference provision to make timely decisions. While Graph Convolutional Networks (GCNs) have shown benefits in modeling complex traffic dependencies, the existing GCN-based approaches cannot fully extract and fuse multi-granular spatiotemporal features across various spatial and temporal scales sufficiently in a complete manner, proven to yield less accurate results. As extracting multi-granular features across scales has been a promising strategy across domains such as computer vision, natural language processing, and time-series forecasting, pioneering studies have attempted to leverage a similar mechanism for spatiotemporal traffic data mining. However, additional feature extraction branches introduced in prior studies critically increased model complexity and extended inference time, making it challenging to provide fast forecasts. In this paper, we propose MultiGran-STGCNFog, an efficient fog distributed inference system with a novel traffic forecasting model that employs multi-granular spatiotemporal feature fusion on generated dynamic traffic graphs to fully capture interdependent traffic dynamics. The proposed scheduling algorithm GA-DPHDS, optimizing layer execution order and layer-device scheduling scheme simultaneously, contributes to considerable inference throughput improvement by coordinating heterogeneous fog devices in a pipelined manner. Extensive experiments on real-world datasets demonstrate the superiority of the proposed method over selected GCN baselines.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {3240–3249},
numpages = {10},
keywords = {distributed inference system, graph convolutional network, multi-granular spatiotemporal feature fusion, traffic forecasting},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@article{10.1145/3604808,
author = {Choi, Jeongwhan and Park, Noseong},
title = {Graph Neural Rough Differential Equations for Traffic Forecasting},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3604808},
doi = {10.1145/3604808},
abstract = {Traffic forecasting is one of the most popular spatio-temporal tasks in the field of machine learning. A prevalent approach in the field is to combine graph convolutional networks and recurrent neural networks for the spatio-temporal processing. There has been fierce competition and many novel methods have been proposed. In this article, we present the method of spatio-temporal graph neural rough differential equation (STG-NRDE). Neural rough differential equations (NRDEs) are a breakthrough concept for processing time-series data. Their main concept is to use the log-signature transform to convert a time-series sample into a relatively shorter series of feature vectors. We extend the concept and design two NRDEs: one for the temporal processing and the other for the spatial processing. After that, we combine them into a single framework. We conduct experiments with 6 benchmark datasets and 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming all those 27 baselines by non-trivial margins.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jul,
articleno = {74},
numpages = {27},
keywords = {Traffic forecasting, spatio-temporal data, signature transform, neural rough differential equation, graph neural network}
}

@inproceedings{10.1145/3447548.3467357,
author = {Chen, Hongjie and Rossi, Ryan A. and Mahadik, Kanak and Kim, Sungchul and Eldardiry, Hoda},
title = {Graph Deep Factors for Forecasting with Applications to Cloud Resource Allocation},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467357},
doi = {10.1145/3447548.3467357},
abstract = {Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, we propose a relational global model that learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, we learn a relational local model that not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {106–116},
numpages = {11},
keywords = {deep learning, graph neural networks, probabilistic model, relational time-series, time-series forecasting},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1145/3701988,
author = {Zhang, Zeyang and Wang, Xin and Chen, Haibo and Li, Haoyang and Zhu, Wenwu},
title = {Disentangled Dynamic Graph Attention Network for Out-of-Distribution Sequential Recommendation},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3701988},
doi = {10.1145/3701988},
abstract = {Sequential recommendation, leveraging user-item interaction histories to provide personalized and timely suggestions, has drawn significant research interest recently. With the power of exploiting spatio-temporal dynamics, Dynamic Graph Neural Networks (DyGNNs) show great potential in sequential recommendation by modeling the dynamic relationship between users and items. However, spatio-temporal distribution shifts naturally exist in out-of-distribution sequential recommendation, where both user-item relationships and temporal sequences demonstrate pattern shifts. The out-of-distribution scenarios may lead to the failure of existing DyGNNs in handling spatio-temporal distribution shifts in sequential recommendation, given that the patterns they exploit tend to be variant w.r.t labels under distribution shifts. In this article, we propose Disentangled Intervention-based Dynamic graph Attention networks with Invariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in sequential recommendation by discovering and utilizing invariant patterns, i.e., structures and features whose predictive abilities are stable across distribution shifts. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns. By utilizing the disentangled patterns, we design a spatio-temporal intervention mechanism to create multiple interventional distributions and an environment inference module to infer the latent spatio-temporal environments, and minimize the invariance loss to leverage the invariant patterns with stable predictive abilities under distribution shifts. Extensive experiments demonstrate the superiority of our method over state-of-the-art sequential recommendation baselines under distribution shifts.},
journal = {ACM Trans. Inf. Syst.},
month = dec,
articleno = {19},
numpages = {42},
keywords = {Recommender systems, Sequential Recommendation, Graph Machine Learning, Dynamic Graph Neural Network, Out-Of-Distribution Generalization}
}

@article{10.1145/3451394,
author = {Xia, Tong and Lin, Junjie and Li, Yong and Feng, Jie and Hui, Pan and Sun, Funing and Guo, Diansheng and Jin, Depeng},
title = {3DGCN: 3-Dimensional Dynamic Graph Convolutional Network for Citywide Crowd Flow Prediction},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3451394},
doi = {10.1145/3451394},
abstract = {Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin–destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn and incorporate urban structures in crowd flow prediction, we design the GCN aggregator to be learned from both crowd flow prediction and region function inference at the same time. Extensive experiments with real-world datasets in two cities demonstrate that our model outperforms state-of-the-art baselines by 9.6\%∼19.5\% for the next-time-interval prediction.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jun,
articleno = {110},
numpages = {21},
keywords = {Graph neural network, traffic flow prediction, urban computing}
}

@inproceedings{10.1145/3650215.3650345,
author = {Zhao, Yangshuowen and Ge, Lei and Ye, Jinchao},
title = {Securities Price Movement Prediction Based on Graph Neural Networks},
year = {2024},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650215.3650345},
doi = {10.1145/3650215.3650345},
abstract = {Securities play a crucial role in the modern economy. However, securities price movement prediction, a type of time-series forecasting problem, remains challenging. This paper suggests that the underutilization of temporal structural information in the data hinders the improvement of accuracy in securities price movement prediction. Therefore, this paper proposes a securities price movement prediction method based on graph computing. By abstracting trading days and the temporal relationships between them as nodes and edges, the method transforms historical trading data into graph data. Subsequently, graph neural networks (GNN) are used to process the graph data and make predictions about stock price movements. Experiments show that the proposed method effectively improves the performance of price movement prediction. Thus, the proposed method is a simple, effective way to utilize time-series data and holds substantial value in securities price movement prediction.},
booktitle = {Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
pages = {743–750},
numpages = {8},
location = {Hangzhou, China},
series = {ICMLCA '23}
}

@inproceedings{10.1145/3511808.3557386,
author = {Xie, Jiandong and Cui, Yue and Huang, Feiteng and Liu, Chao and Zheng, Kai},
title = {MARINA: An MLP-Attention Model for Multivariate Time-Series Analysis},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557386},
doi = {10.1145/3511808.3557386},
abstract = {The proliferation of real-time monitoring applications such as Artificial Intelligence for IT Operations (AIOps) and the Internet of Things (IoT) has led to the generation of a vast amount of time-series data. To extract the underlying value of the data, both the industry and the academia are in dire need of efficient and effective methods for time-series analysis. To this end, in this paper, we propose a Multi-layer perceptron (&lt;u&gt;M&lt;/u&gt;LP)-&lt;u&gt;a&lt;/u&gt;ttention based multivariate time-se&lt;u&gt;ri&lt;/u&gt;es a&lt;u&gt;na&lt;/u&gt;lysis model MARINA. MARINA is designed to simultaneously learn the temporal and spatial correlations among multivariate time-series. Also, the model is versatile in that it is suitable for major time-series analysis tasks such as forecasting and anomaly detection. Through extensive comparisons with the representative multivariate time-series forecasting and anomaly detection algorithms, MARINA is shown to achieve state-of-the-art (SOTA) performance in both forecasting and anomaly detection tasks.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
pages = {2230–2239},
numpages = {10},
keywords = {anomaly detection, forecasting, time-series analysis},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@article{10.14778/3659437.3659458,
author = {Zirak, Farzaneh and Choudhury, Farhana and Borovica-Gajic, Renata},
title = {SeLeP: Learning Based Semantic Prefetching for Exploratory Database Workloads},
year = {2024},
issue_date = {April 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3659437.3659458},
doi = {10.14778/3659437.3659458},
abstract = {Prefetching is a crucial technique employed in traditional databases to enhance interactivity, particularly in the context of data exploration. Data exploration is a query processing paradigm in which users search for insights buried in the data, often not knowing what exactly they are looking for. Data exploratory tools deal with multiple challenges such as the need for interactivity with no a priori knowledge being present to help with the system tuning. The state-of-the-art prefetchers are specifically designed for navigational workloads only, where the number of possible actions is limited. The prefetchers that work with SQL-based workloads, on the other hand, mainly rely on data logical addresses rather than the data semantics. They fail to predict complex access patterns in cases where the database size is substantial, resulting in an extensive address space, or when there is frequent co-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher that makes prefetching decisions for both types of workloads, based on the encoding of the data values contained inside the accessed blocks. Following the popular path of using machine learning approaches to automatically learn the hidden patterns, we formulate the prefetching task as a time-series forecasting problem and use an encoder-decoder LSTM architecture to learn the data access pattern. Our extensive experiments, across real-life exploratory workloads, demonstrate that SeLeP improves the hit ratio up to 40\% and reduces I/O time up to 45\% compared to the state-of-the-art, attaining 96\% hit ratio and 84\% I/O reduction on average.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {2064–2076},
numpages = {13}
}

@inproceedings{10.1145/3543507.3583202,
author = {Zhu, Ruitao and Lv, Detao and Yu, Yao and Zhu, Ruihao and Zheng, Zhenzhe and Bu, Ke and Lu, Quan and Wu, Fan},
title = {LINet: A Location and Intention-Aware Neural Network for Hotel Group Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583202},
doi = {10.1145/3543507.3583202},
abstract = {Motivated by the collaboration with Fliggy1, a leading Online Travel Platform (OTP), we investigate an important but less explored research topic about optimizing the quality of hotel supply, namely selecting potential profitable hotels in advance to build up adequate room inventory. We formulate a WWW problem, i.e., within a specific time period (When) and potential travel area (Where), which hotels should be recommended to a certain group of users with similar travel intentions (Why). We identify three critical challenges in solving the WWW problem: user groups generation, travel data sparsity and utilization of hotel recommendation information (e.g., period, location and intention). To this end, we propose LINet, a Location and Intention-aware neural Network for hotel group recommendation. Specifically, LINet first identifies user travel intentions for user groups generalization, and then characterizes the group preferences by jointly considering historical user-hotel interaction and spatio-temporal features of hotels. For data sparsity, we develop a graph neural network, which employs long-term data, and further design an auxiliary loss function of location that efficiently exploits data within the same and across different locations. Both offline and online experiments demonstrate the effectiveness of LINet when compared with state-of-the-art methods. LINet has been successfully deployed on Fliggy to retrieve high quality hotels for business development, serving hundreds of hotel operation scenarios and thousands of hotel operators.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {779–789},
numpages = {11},
keywords = {Deep Neural Network, Group Recommendation, Location-aware, Travel Intention},
location = {Austin, TX, USA},
series = {WWW '23}
}

@article{10.1145/3721982,
author = {Shi, Hongyu and Chen, Ling and Tang, Xing and Lyu, Dandan},
title = {DHFM: Diversity-Enhanced Hypergraph Factorization Machines for Feature Interaction Modeling},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1556-4681},
url = {https://doi.org/10.1145/3721982},
doi = {10.1145/3721982},
abstract = {Feature interaction modeling, which exploits interactive information between features, has been widely explored in various applications. Recently, many graph neural network (GNN)-based models are proposed to model feature interactions by predicting the existence of edges between pairwise nodes that represent features. However, these models can only directly model 2-order feature interactions. Although stacking multiple GNN layers can implicitly capture the arbitrary high-order feature interactions, it may lead to the over-smoothing problem. To this end, we propose Diversity-Enhanced Hypergraph Factorization Machines (DHFMs) that incorporate hypergraphs into feature interaction modeling, which can model the diverse feature interactions of different orders explicitly. Specifically, the order-wise hyperedge predictors are proposed to discover beneficial feature interactions and explicitly model the feature interactions of different orders. In addition, diversity measures are introduced in hyperedge predictors and in the results of feature interactions to make discovered feature interactions as diverse as possible and avoid generating correlated errors. Extensive experiments on four real-world datasets demonstrate the superiority of the proposed model. In addition, the case study is conducted to further justify the effectiveness of the proposed model.},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {85},
numpages = {19},
keywords = {Feature interaction, Factorization machines, Hypergraph neural networks, Ensemble diversity}
}

@inproceedings{10.1145/3580305.3599440,
author = {Li, Shuangli and Zhou, Jingbo and Liu, Ji and Xu, Tong and Chen, Enhong and Xiong, Hui},
title = {Multi-Temporal Relationship Inference in Urban Areas},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599440},
doi = {10.1145/3580305.3599440},
abstract = {Finding multiple temporal relationships among locations can benefit a bunch of urban applications, such as dynamic offline advertising and smart public transport planning. While some efforts have been made on finding static relationships among locations, little attention is focused on studying time-aware location relationships. Indeed, abundant location-based human activities are time-varying and the availability of these data enables a new paradigm for understanding the dynamic relationships in a period among connective locations. To this end, we propose to study a new problem, namely multi-Temporal relationship inference among locations (Trial for short), where the major challenge is how to integrate dynamic and geographical influence under the relationship sparsity constraint. Specifically, we propose a solution to Trial with a graph learning scheme, which includes a spatially evolving graph neural network (SEENet) with two collaborative components: spatially evolving graph convolution module (SEConv) and spatially evolving self-supervised learning strategy (SE-SSL). SEConv performs the intra-time aggregation and inter-time propagation to capture the multifaceted spatially evolving contexts from the view of location message passing. In addition, SE-SSL designs time-aware self-supervised learning tasks in a global-local manner with additional evolving constraint to enhance the location representation learning and further handle the relationship sparsity. Finally, experiments on four real-world datasets demonstrate the superiority of our method over several state-of-the-art approaches.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1316–1327},
numpages = {12},
keywords = {graph neural networks, relationship inference, spatial graph},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3511808.3557243,
author = {Li, Fuxian and Yan, Huan and Jin, Guangyin and Liu, Yue and Li, Yong and Jin, Depeng},
title = {Automated Spatio-Temporal Synchronous Modeling with Multiple Graphs for Traffic Prediction},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557243},
doi = {10.1145/3511808.3557243},
abstract = {Traffic prediction plays an important role in many intelligent transportation systems. Many existing works design static neural network architecture to capture complex spatio-temporal correlations, which is hard to adapt to different datasets. Although recent neural architecture search approaches have addressed this problem, it still adopts a coarse-grained search with pre-defined and fixed components in the search space for spatio-temporal modeling. In this paper, we propose a novel neural architecture search framework, entitled AutoSTS, for automated spatio-temporal synchronous modeling in traffic prediction. To be specific, we design a graph neural network (GNN) based architecture search module to capture localized spatio-temporal correlations, where multiple graphs built from different perspectives are jointly utilized to find a better message passing way for mining such correlations. Further, we propose a convolutional neural network (CNN) based architecture search module to capture temporal dependencies with various ranges, where gated temporal convolutions with different kernel sizes and convolution types are designed in search space. Extensive experiments on six public datasets demonstrate that our model can achieve 4\%-10\% improvements compared with other methods.},
booktitle = {Proceedings of the 31st ACM International Conference on Information \&amp; Knowledge Management},
pages = {1084–1093},
numpages = {10},
keywords = {graph convolution, spatio-temporal modeling, traffic prediction},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@article{10.1145/3655629,
author = {Wang, Pengyu and Luo, Xuechen and Tai, Wenxin and Zhang, Kunpeng and Trajcevsky, Goce and Zhou, Fan},
title = {Score-based Graph Learning for Urban Flow Prediction},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3655629},
doi = {10.1145/3655629},
abstract = {Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP, a novel probabilistic graph-based framework for UFP. DiffUFP&nbsp;consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP&nbsp;over the state-of-the-art UFP&nbsp;models and the effect of the two specific modules.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {59},
numpages = {25},
keywords = {Flow prediction, spatio-temporal learning, graph neural networks, score-based model, urban computing}
}

@inproceedings{10.1145/3695053.3731091,
author = {Wu, Chunshu and Song, Ruibing and Liu, Chuan and Haghi, Pouya and Li, Ang and Huang, Michael and Geng, Tong (Tony)},
title = {DS-TPU: Dynamical System for on-Device Lifelong Graph Learning with Nonlinear Node Interaction},
year = {2025},
isbn = {9798400712616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695053.3731091},
doi = {10.1145/3695053.3731091},
abstract = {Graph learning on dynamical systems has recently surfaced as an emerging research domain. By leveraging a novel electronic Dynamical System (DS), various graph learning challenges have been effectively tackled through a rapid, spontaneous natural annealing process. This method has attracted increasing attention due to its orders-of-magnitude improvements in speed and energy efficiency compared to traditional Graph Neural Network (GNN) approaches for inference tasks. However, (1) the current DS hardware only supports inference, missing its native solution for training; while relying on conventional hardware is likely more expensive than GNNs. (2) The current DS architecture only allows linear interactions among its nodes, limiting training accuracy.In this work, we present a Dynamical-System Training-Processing Unit (DS-TPU) developed through algorithm-architecture co-design to tackle the two major challenges: (1) An on-device lifelong learning mechanism that leverages feedback electric current as the loss function in response to the observed training data, allowing electron-speed refinement on the present model parameters. (2) A nonlinear DS node interaction mechanism constructed from Chebyshev polynomials to significantly improve the compatibility between the DS hardware and the embedded relation of graph data. Extensive evaluations using six real-world graph learning applications demonstrate that for accuracy, DS-TPU achieves 10.8\% MAE reduction over the best results of five widely used GNNs. In terms of training performance, the 5-Watt DS-TPU architecture achieves on-average 810 \texttimes{} speedup over the offline training for DS on an Nvidia A100 GPU, and 640 \texttimes{} over GNN training on the same GPU. In terms of inference performance, DS-TPU achieves 2548 \texttimes{} over the A100 GPU and 115 \texttimes{} over the best state-of-the-art GNN accelerators.},
booktitle = {Proceedings of the 52nd Annual International Symposium on Computer Architecture},
pages = {1867–1879},
numpages = {13},
keywords = {Dynamical System, Energy-Based Model, Graph Learning},
location = {
},
series = {ISCA '25}
}

@inproceedings{10.1145/3580305.3599893,
author = {Kang, Johan Kok Zhi and Tan, Sien Yi and He, Bingsheng and Zhang, Zhen},
title = {Real Time Index and Search Across Large Quantities of GNN Experts for Low Latency Online Learning},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599893},
doi = {10.1145/3580305.3599893},
abstract = {Online learning is a powerful technique that allows models to adjust to concept drift in dynamically changing graphs. This approach is crucial for large mobility-based companies like Grab, where batch-learning methods fail to keep up with the large amount of training data. Our work focuses on scaling graph neural network mixture of expert (MoE) models for real-time traffic speed prediction on road networks, while meeting high accuracy and low latency requirements. Conventional spatio-temporal and incremental MoE frameworks struggle with poor inference accuracy and linear time complexity when scaling experts, for the latter, leading to prohibitively high latency in model updates. To address this issue, we introduce the Indexed Router, a novel method that categorizes experts into a structured hierarchy called the indexed tree. This approach reduces the time to scale and search N number of experts from O(N) to O(log N), making it ideal for online learning under tight service level agreements. Our experiments show that these time savings do not compromise inference accuracy, and our Indexed Router outperforms state-of-the-art spatio-temporal and incremental MoE models in terms of traffic speed prediction accuracy on real-life GPS traces from Grab's database and publicly available records. In summary, the Indexed Router enables MoE models to scale across large numbers of experts with low latency, while accurately identifying the relevant experts for inference.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4308–4319},
numpages = {12},
keywords = {mixture of experts, online learning, temporal concept drift},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3442381.3449945,
author = {Tran, Alasdair and Mathews, Alexander and Ong, Cheng Soon and Xie, Lexing},
title = {Radflow: A Recurrent, Aggregated, and Decomposable Model for Networks of Time Series},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449945},
doi = {10.1145/3442381.3449945},
abstract = {We propose a new model for networks of time series that influence each other. Graph structures among time series are found in diverse domains, such as web traffic influenced by hyperlinks, product sales influenced by recommendation, or urban transport volume influenced by road networks and weather. There has been recent progress in graph modeling and in time series forecasting, respectively, but an expressive and scalable approach for a network of series does not yet exist. We introduce Radflow, a novel model that embodies three key ideas: a recurrent neural network to obtain node embeddings that depend on time, the aggregation of the flow of influence from neighboring nodes with multi-head attention, and the multi-layer decomposition of time series. Radflow naturally takes into account dynamic networks where nodes and edges change over time, and it can be used for prediction and data imputation tasks. On real-world datasets ranging from a few hundred to a few hundred thousand nodes, we observe that Radflow variants are the best performing model across a wide range of settings. The recurrent component in Radflow also outperforms N-BEATS, the state-of-the-art time series model. We show that Radflow can learn different trends and seasonal patterns, that it is robust to missing nodes and edges, and that correlated temporal patterns among network neighbors reflect influence strength. We curate WikiTraffic, the largest dynamic network of time series with 366K nodes and 22M time-dependent links spanning five years. This dataset provides an open benchmark for developing models in this area, with applications that include optimizing resources for the web. More broadly, Radflow has the potential to improve forecasts in correlated time series networks such as the stock market, and impute missing measurements in geographically dispersed networks of natural phenomena.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {730–742},
numpages = {13},
keywords = {graphs, networks, sequence models, time series, wikipedia},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/3292500.3330790,
author = {Huang, Chao and Wu, Xian and Zhang, Xuchao and Zhang, Chuxu and Zhao, Jiashu and Yin, Dawei and Chawla, Nitesh V.},
title = {Online Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330790},
doi = {10.1145/3292500.3330790},
abstract = {Online purchase forecasting is of great importance in e-commerce platforms, which is the basis of how to present personalized interesting product lists to individual customers. However, predicting online purchases is not trivial as it is influenced by many factors including: (i) the complex temporal pattern with hierarchical inter-correlations; (ii) arbitrary category dependencies. To address these factors, we develop a Graph Multi-Scale Pyramid Networks (GMP) framework to fully exploit users' latent behavioral patterns with both multi-scale temporal dynamics and arbitrary inter-dependencies among product categories. In GMP, we first design a multi-scale pyramid modulation network architecture which seamlessly preserves the underlying hierarchical temporal factors--governing users' purchase behaviors. Then, we employ convolution recurrent neural network to encode the categorical temporal pattern at each scale. After that, we develop a resolution-wise recalibration gating mechanism to automatically re-weight the importance of each scale-view representations. Finally, a context-graph neural network module is proposed to adaptively uncover complex dependencies among category-specific purchases. Extensive experiments on real-world e-commerce datasets demonstrate the superior performance of our method over state-of-the-art baselines across various settings.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining},
pages = {2613–2622},
numpages = {10},
keywords = {deep neural networks, purchase prediction, recommendation systems, temporal dynamics},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@inproceedings{10.1145/3704323.3704369,
author = {Chen, Yao and Li, Shaorong and Zhao, Na and Zheng, RunZe and Li, Yaokun},
title = {BiLSTM-KAN: A Time Series-based Traffic Flow Forecasting Model},
year = {2025},
isbn = {9798400717482},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704323.3704369},
doi = {10.1145/3704323.3704369},
abstract = {Currently, the task of traffic flow prediction poses a significant challenge. Most existing works utilize spatial features for overall forecasting, without giving much consideration to the issue of extracting data features from individual time series data. In the absence of knowledge about road topology, extracting effective time series features for a single node becomes particularly important. The BiLSTM-KAN model proposed in this paper is an innovative sequence-to-sequence (Seq2Seq) forecasting model designed to significantly enhance the accuracy and efficiency of time series data processing. This model deeply integrates the advanced feature extraction capabilities of Bidirectional Long Short-Term Memory Networks (BiLSTM) with Kolmogorov-Arnold Networks (KAN), forming a unique and powerful data processing mechanism. With the application of the BiLSTM-KAN model, it will be possible to more accurately capture the complex dynamic changes and underlying patterns in time series data, thereby providing more reliable and precise forecasting results for traffic flow prediction and other related field sequence data processing tasks.},
booktitle = {Proceedings of the 2024 13th International Conference on Computing and Pattern Recognition},
pages = {314–319},
numpages = {6},
keywords = {Bidirectional Long Short-Term Memory Networks, Kolmogorov-Arnold Networks, Time series data, Traffic flow prediction},
location = {
},
series = {ICCPR '24}
}

@inproceedings{10.1145/3437963.3441827,
author = {Hu, Wenjie and Yang, Yang and Cheng, Ziqiang and Yang, Carl and Ren, Xiang},
title = {Time-Series Event Prediction with Evolutionary State Graph},
year = {2021},
isbn = {9781450382977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437963.3441827},
doi = {10.1145/3437963.3441827},
abstract = {The accurate and interpretable prediction of future events in time-series data often requires the capturing of representative patterns (or referred to as states) underpinning the observed data. To this end, most existing studies focus on the representation and recognition of states, but ignore the changing transitional relations among them. In this paper, we present evolutionary state graph, a dynamic graph structure designed to systematically represent the evolving relations (edges) among states (nodes) along time. We conduct analysis on the dynamic graphs constructed from the time-series data and show that changes on the graph structures (e.g., edges connecting certain state nodes) can inform the occurrences of events (i.e., time-series fluctuation). Inspired by this, we propose a novel graph neural network model, Evolutionary State Graph Network (EvoNet), to encode the evolutionary state graph for accurate and interpretable time-series event prediction. Specifically, EvoNet models both the node-level (state-to-state) and graph-level (segment-to-segment) propagation, and captures the node-graph (state-to-segment) interactions over time. Experimental results based on five real-world datasets show that our approach not only achieves clear improvements compared with 11 baselines, but also provides more insights towards explaining the results of event predictions.},
booktitle = {Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
pages = {580–588},
numpages = {9},
keywords = {evolutionary state graph, graph networks, time series prediction},
location = {Virtual Event, Israel},
series = {WSDM '21}
}

@inproceedings{10.1145/3447548.3467341,
author = {Xia, Wenwen and Li, Yuchen and Tian, Jianwei and Li, Shenghong},
title = {Forecasting Interaction Order on Temporal Graphs},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467341},
doi = {10.1145/3447548.3467341},
abstract = {Link prediction is a fundamental task for graph analysis and the topic has been studied extensively for static or dynamic graphs. Essentially, the link prediction is formulated as a binary classification problem about two nodes. However, for temporal graphs, links (or interactions) among node sets appear in sequential orders. And the orders may lead to interesting applications. While a binary link prediction formulation fails to handle such an order-sensitive case. In this paper, we focus on such an interaction order prediction problem among a given node set on temporal graphs. For the technical aspect, we develop a graph neural network model named Temporal ATtention network (TAT), which utilizes the fine-grained time information on temporal graphs by encoding continuous real-valued timestamps as vectors. For each transformation layer of the model, we devise an attention mechanism to aggregate neighborhoods' information based on their representations and time encodings attached to their specific edges. We also propose a novel training scheme to address the permutation-sensitive property of the problem. Experiments on several real-world temporal graphs reveal that TAT outperforms some state-of-the-art graph neural networks by 55\% on average under the AUC metric.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {1884–1893},
numpages = {10},
keywords = {graph neural networks, interaction order prediction, temporal graphs},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3746252.3761399,
author = {Wang, Shurui and Yan, Wenbo and Tan, Ying},
title = {Spatio-Temporal Wavelet Enhanced Attention Mamba for Stock Price Forecasting},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761399},
doi = {10.1145/3746252.3761399},
abstract = {Stock price forecasting remains a critical challenge due to market non-stationarity and the influence of multiple factors. Existing studies apply frequency domain analysis methods to mitigate the impacts of non-stationarity by decoupling high- and low-frequency variation patterns. However, these approaches primarily focus on single series decomposition while neglecting cross frequency interactions among different stocks. Moreover, as a key indicator of overall market trends, current methods inadequately utilize market index information. In this paper, we propose STEAM, a Spatio-Temporal Wavelet Enhanced Attention Mamba model. We introduce Discrete Wavelet Transform (DWT) to disentangle multi-frequency temporal features and propose Wavelet Enhanced Attention (WEA) to capture cross frequency spatial dependencies, effectively leveraging both local and global inter-stock relationships. To extract the synergistic spatio-temporal dependencies in stock data, AMamba module is designed that integrates WEA into the Mamba-2 architecture. Additionally, to further enhance the model's perception of macro-market conditions, we incorporate market index as a prefix, guiding predictions with holistic market information in both spatial and temporal dependencies learning. Extensive experiments across multiple national stock markets demonstrate that STEAM achieves state-of-the-art forecasting performance.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {3050–3059},
numpages = {10},
keywords = {computational finance, spatio-temporal time series, stock price forecasting},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@inproceedings{10.1145/3690624.3709323,
author = {Lyu, Tengfei and Zhang, Weijia and Deng, Jinliang and Liu, Hao},
title = {AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709323},
doi = {10.1145/3690624.3709323},
abstract = {Spatio-temporal forecasting is a critical component of various smart city applications, such as transportation optimization, energy management, and socio-economic analysis. Recently, several automated spatio-temporal forecasting methods have been proposed to automatically search the optimal neural network architecture for capturing complex spatio-temporal dependencies. However, the existing automated approaches suffer from expensive neural architecture search overhead, which hinders their practical use and the further exploration of diverse spatio-temporal operators in a finer granularity. In this paper, we propose AutoSTF, a decoupled automatic neural architecture search framework for cost-effective automated spatio-temporal forecasting. From the efficiency perspective, we first decouple the mixed search space into temporal space and spatial space and respectively devise representation compression and parameter-sharing schemes to mitigate the parameter explosion. The decoupled spatio-temporal search not only expedites the model optimization process but also leaves new room for more effective spatio-temporal dependency modeling. From the effectiveness perspective, we propose a multi-patch transfer module to jointly capture multi-granularity temporal dependencies and extend the spatial search space to enable finer-grained layer-wise spatial dependency search. Extensive experiments on eight datasets demonstrate the superiority of AutoSTF in terms of both accuracy and efficiency. Specifically, our proposed method achieves up to 13.48x speed-up compared to state-of-the-art automatic spatio-temporal forecasting methods while maintaining the best forecasting accuracy. The source code and data are available at https://github.com/usail-hkust/AutoSTF.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {985–996},
numpages = {12},
keywords = {automated spatio-temporal forecasting, neural architecture search, spatio-temporal modeling},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3770177.3770325,
author = {Qi, Ruolin},
title = {DecisionFlow for SMEs: A Lightweight Visual Framework for Multi-Task Joint Prediction and Anomaly Detection},
year = {2025},
isbn = {9798400720109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3770177.3770325},
doi = {10.1145/3770177.3770325},
abstract = {The digital transformation of industry has placed immense pressure on small and medium-sized enterprises (SMEs), which often lack the resources and technical infrastructure to adopt complex AI pipelines and data visualization systems. This creates a pressing challenge: how can SMEs leverage real-time business intelligence without heavy computational or financial burdens. We propose the DecisionFlow framework to generate interactive KPI dashboards on the fly using Vega-Lite declarative syntax through a low-latency visualization engine. To run at the edge, we distilled the long sequence of self-attention into linear Performer blocks, using cross-prediction step weight sharing and 8-bit quantization, so that the model only contained 4.3 M parameters and could be deployed on a common CPU or browser WebAssembly environment. Secondly, the model couples continuous probability prediction with rare event detection with a joint uncertainty loss function, as well as a cross-layer visual feedback closed-loop in which the user interacts with real-time update of the attention mask, so as to support online incremental learning. On Online Retail II (UCI), a dataset for SMEs, DecisionFlow reduced inference latency by 68\%, demand forecasting MAE by 17\%, and anomaly detection F1 to 0.91.},
booktitle = {Proceedings of the 2025 International Conference on Economic Management and Big Data Application},
pages = {899–903},
numpages = {5},
keywords = {Anomaly Detection, Lightweight Visual Framework, Multi-Task Joint Prediction, Small Medium-sized Enterprises},
location = {
},
series = {ICEMBDA '25}
}

@inproceedings{10.1145/3711896.3737194,
author = {Tu, Shihao and Yang, Yang and Ding, Wenyue and Lu, Yicheng and Ren, Qingkai and Zhang, Yupeng and Zhang, Yin},
title = {ASTNet: Asynchronous Spatio-Temporal Network for Large-Scale Chemical Sensor Forecasting},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737194},
doi = {10.1145/3711896.3737194},
abstract = {The chemical industry is faced with the urgent challenge of effectively harnessing the vast amounts of time-series data generated by thousands of sensors, which is essential for forecasting chemical states, achieving accurate real-time control of production processes. Traditional forecasting methods suffer from high computational latency and struggle with the complexity of spatiotemporal dependencies. As a result, modeling this data becomes challenging. This paper introduces a novel approach, referred to as ASTNet, designed to address these challenges. ASTNet integrates an asynchronous spatiotemporal modeling framework that combines temporal and spatial encoders, enabling concurrent learning of temporal and spatial dependencies while reducing computational latency. Additionally, it introduces a gated graph fusion mechanism that adaptively combines static (meta) and evolving (dynamic) sensor graphs, enhancing the handling of heterogeneous sensor data and spatial correlations. Extensive experiments on three real-world chemical sensor datasets demonstrate that ASTNet outperforms SOTA methods in terms of both prediction accuracy and computational efficiency, making ASTNet successfully deployed in chemical engineering industrial scenarios.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {4913–4924},
numpages = {12},
keywords = {chemical process, deep learning, forecasting, multivariate time series},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3716554.3716619,
author = {Brimos, Petros and Kalampokis, Evangelos and Tarabanis, Konstantinos},
title = {Pre-trained Time Series Foundation Models for Traffic Flow Prediction Using Open Government Data: The case of Attica traffic OGD},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716619},
doi = {10.1145/3716554.3716619},
abstract = {Rapid urbanization and increase in vehicular traffic in metropolitan areas necessitate advanced predictive models to enhance traffic management systems. Open Government Data (OGD) portals provide accessible, high-quality traffic datasets, offering a valuable resource for developing and evaluating such models. This paper investigates the effectiveness of pre-trained Time Series Foundation Models, specifically Lag-Llama, in forecasting urban traffic flow using open government traffic data from the Greek OGD portal. We assess Lag-Llama’s performance in both zero-shot and fine-tuned settings and compare it with traditional deep learning models, including Long Short-Term Memory (LSTM) networks and Graph Neural Networks (GNNs). Our experimental results demonstrate that Lag-Llama, especially when fine-tuned on traffic OGD, outperforms conventional models in prediction accuracy. These findings highlight the potential of combining foundation models with traffic open government data to advance intelligent transportation systems and contribute to the development of more robust and reliable traffic forecasting models, as well as provide innovative and efficient public services for citizens and businesses.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {424–430},
numpages = {7},
keywords = {Foundation Models, Traffic forecasting, Open Government Data, Foundation Models for Time Series, Large Language Models},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3711896.3736980,
author = {Hao, Qi and Gao, Yue and Liang, Runchang and Zhang, Yunhe and Wang, Pengyang},
title = {Generative Imputation with Multi-level Causal Consistency for Variable Subset Forecasting},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3736980},
doi = {10.1145/3711896.3736980},
abstract = {Variable Subset Forecasting (VSF) poses critical challenges in time series analysis when entire variables become unavailable during inference. Existing imputation methods relying on inter-variable correlations fail catastrophically in VSF due to two inherent limitations: (1) Missing variable collapse, where the complete absence of certain variables invalidates correlation-based dependency learning, and (2) Temporal covariate shift, where time-evolving data distributions destabilize correlation patterns learned from training data. To address these fundamental issues, we propose Generative Imputation with Multi-level Causal Consistency (GIMCC ), establishing causality-driven imputation as the first principled solution for VSF. Our key innovation lies in enforcing causal invariance through dual consistency constraints: global causal isomorphism ensures the imputed variables preserve the ground-truth causal graph structure of the complete system, while local causal subgraph alignment maintains consistency between observed variables and their causal neighborhood dependencies. By decoupling causality from spurious correlations, GIMCC provides time-invariant imputation signals robust to distribution shifts, which explicitly preserves causal relationships via multivariate spectral convolutions. Extensive experiments across five real-world domains demonstrate that GIMCC achieves average improvements of 20-60\% in MAE/RMSE over correlation-based imputation baselines, remarkably outperforming full-variable training ( Oracle ) in temporal covariate shift scenarios. Our work bridges the critical gap between causal analysis and practical forecasting systems under variable absence, offering theoretically grounded guarantees for real-world deployment.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {838–849},
numpages = {12},
keywords = {granger causality, variable subset forecasting},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inbook{10.1145/3729706.3729756,
author = {He, Ruoyan and Xiao, Hao},
title = {MSMixer-GCN: A Hybrid Deep Learning Model for Stock Price Prediction Using Multi-Scale Convolution, MLP-Mixer and Graph Convolution Networks},
year = {2025},
isbn = {9798400712715},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729706.3729756},
abstract = {Stock price prediction is a challenging problem in the field of finance that receives significant attention. Researchers have developed combinations of neural network models, such as RNNs, GNNs, and Transformers, which show great potential for stock forecasting. However, these models often struggle with the complex nonlinear dynamics of the stock market and neglect the intertwined spatial relationships and temporal features among stocks. This oversight can adversely affect prediction accuracy. Therefore, we propose a stock price prediction model named MSMixer-GCN in this paper, which is based on a multi-scale convolutional MLP Mixer and a spatio-temporal graph convolutional network. Firstly, we adopt a multi-scale convolution combined with the MLP-Mixer approach to construct the MS-MLP Mixer module, which captures trends in stock indicators and temporal dimensions, thereby enhancing the utilization of historical time series information. Next, we develop a dynamic spatio-temporal graph convolutional network that allows spatial structural information to interact with features across different time scales, significantly improving the accuracy of stock price predictions. Finally, through extensive experiments on three datasets from the United States stock market, our proposed MSMixer-GCN model demonstrates outstanding performance, surpassing state-of-the-art models in terms of IC ranking metrics and the Sharpe Ratio, achieving average relative performance gains of 6.25\% and 8.67\%, respectively. This confirms the superior performance and generalization capability of the model.},
booktitle = {Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy},
pages = {314–321},
numpages = {8}
}

@inbook{10.1145/3756423.3756560,
author = {Pan, Yue},
title = {A Study on the Application of Artificial Intelligence in Digital Twin Monitoring of Building Structural Health},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756560},
abstract = {With the continuous expansion of urban building volume and the significant increase of operational complexity, the monitoring of the health status of building structures has become a key means to ensure urban safety and sustainable operation of buildings. This paper focuses on the integration and application of artificial intelligence and digital twin technology in building structural health monitoring, and systematically constructs an intelligent monitoring system architecture driven by multi-source sensing data, with AI model as the core and digital twin platform as the carrier. Through the design of multi-dimensional sensing network, the dynamic perception of stress, vibration, displacement and other behaviors of key building components is realized; combined with AI models such as convolutional neural network (CNN), graphical neural network (GNN), and long and short-term memory network (LSTM), the ability of structural state identification, damage prediction and trend modeling is enhanced; and three-dimensional visualization and interactive display of the structural state of health is realized by relying on the BIM platform. The article selects a number of typical engineering scenarios such as high-rise steel structure buildings, underground hubs, and protective buildings to carry out experiments and case studies, and verifies the significant advantages of the AI-driven digital twin system in terms of real-time, accuracy, and adaptability.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {833–837},
numpages = {5}
}

@inproceedings{10.1145/3768740.3768798,
author = {Li, Xin and Gao, Pei and Zhou, Jian and Xu, Xinyue and Li, Xiyao},
title = {Architectural Bias vs. Feature Engineering: Deconstructing the Limits of Tabular Foundation Models in Traffic Forecasting},
year = {2025},
isbn = {9798400720987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768740.3768798},
doi = {10.1145/3768740.3768798},
abstract = {Although spatio-temporal graph neural networks (STGNNs) demonstrate efficacy in the domain of traffic prediction, they are characterised by elevated data requirements and computational costs. Concurrently, pre-trained foundation models, such as the Prior-data Fitted Network (TabPFN), have demonstrated noteworthy performance in general tabular tasks with high efficiency. This juxtaposition gives rise to a critical question: can a general-purpose foundation model, augmented with domain-specific feature engineering, match the performance of specialized architectures in a complex domain such as traffic forecasting? In order to investigate this, an evaluation framework was introduced, known as TabPFN-ST-AR. This is an adaptation of TabPFN that has been designed for traffic prediction using a comprehensive spatio-temporal feature set. A rigorous comparison against a wide range of baselines is conducted on the benchmark METR-LA dataset. The baselines include state-of-the-art STGNNs (Graph WaveNet, DCRNN, STGCN, ASTGCN), traditional machine learning models (XGBoost, CatBoost), and classic deep learning models (LSTM). The findings demonstrate that while top-tier STGNNs such as GraphWaveNet maintain a clear performance advantage, our TabPFN-ST-AR framework is highly competitive, outperforming not only traditional baselines but also some established STGNN models. This outcome serves to emphasise the efficacy of feature engineering, while concurrently providing a quantifiable measurement of the residual performance disparity when compared to contemporary specialist models. It is concluded that, while feature engineering is beneficial, it cannot fully substitute for the architectural inductive biases inherent to models designed for spatio-temporal graph structures. This finding indicates a potential direction for future research, namely the exploration of hybrid modelling and the adaptation of foundation models to specific domains.},
booktitle = {Proceedings of the 2025 International Conference on Simulation, Modeling and Big Data},
pages = {369–380},
numpages = {12},
keywords = {Architectural Inductive Bias, Feature Engineering, Foundation Model, STGNNs, Traffic Forecasting},
location = {
},
series = {SMBD '25}
}

@inproceedings{10.1145/3696409.3700258,
author = {Chen, Dongming and Nie, Mingshuo and Sun, Zhengping and Chen, Huilin and Wang, Dongqi},
title = {An Information Cascade Prediction Algorithm Based on Time Series},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696409.3700258},
doi = {10.1145/3696409.3700258},
abstract = {The prediction of information cascades is a crucial task in data mining, which aims to understand the patterns of information diffusion at macroscopic and microscopic levels. The objective of the macro level is to predict the popularity of information cascades in the future. However, the current macro information cascade prediction algorithms produce a fixed popularity prediction value for a specific future time, which lacks flexibility. In this paper, we propose a novel information cascade prediction algorithm, named CasInformer. This algorithm views information cascades as a sequence of cascaded graph snapshots and employs time series prediction to make inferences. CasInformer enhances the selection method of cascaded snapshots and utilizes diverse information to encode supplementary data, which significantly enhances prediction accuracy compared to existing algorithms. CasInformer can predict the cascading popularity at multiple different times to obtain the future trend of information cascading popularity, which is more practical in real scenarios. Experimental results on real datasets show that CasInformer has achieved significant improvement in both prediction accuracy and prediction ability compared to existing research.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia},
articleno = {96},
numpages = {1},
keywords = {Information cascade prediction, Dynamic graph, Time series prediction, Transformer, Position encoding},
location = {
},
series = {MMAsia '24}
}

@inproceedings{10.1145/3725472.3725475,
author = {Hu, Wei and Xu, Jianqiu and Zhao, Xujian},
title = {Multivariate Time-Series Data Anomaly Detection via Dimension Independence and Reconstruction},
year = {2025},
isbn = {9798400710391},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3725472.3725475},
doi = {10.1145/3725472.3725475},
abstract = {Time-series data anomaly detection has received widespread attention from academia and industry, with crucial applications in service monitor, IoT surveillance, and network security. Existing anomaly detection methods for multivariate time-series data (MTS) typically (1) focus solely on low-accuracy anomalies, neglecting explicit errors, which limits the applicability; (2) treat data dimensionality as a fixed parameter during training and inference, which limits the scalability of trained model to data with varying dimensions. To address these problems, we propose a Transformer framework for MTS anomaly detection based on dimension independence and reconstruction. The framework comprises three components: (1) time-series data preprocessing, (2) MTS reconstruction model, and (3) anomaly detection. Preprocessing step resolves explicit errors and prepares data. MTS reconstruction model built on dimension independence and Transformer encoder, reconstructs each MTS dimension independently. Anomaly detection step identifies low-accuracy anomaly and outputs the final anomaly detection results. Comparative experiments demonstrate that the proposed framework outperforms all baseline methods on two real-world datasets and achieves second place on the remaining two datasets. Furthermore, preprocessing and scalability experiments yield highly satisfactory results, validating the completeness and scalability of the framework.},
booktitle = {Proceedings of the 2025 8th International Conference on Data Storage and Data Engineering},
pages = {15–22},
numpages = {8},
keywords = {Anomaly detection, Dimension independence, Multivariate time-series data, Reconstruction model, Transformer},
location = {
},
series = {DSDE '25}
}

@inproceedings{10.1145/3724154.3724348,
author = {Zhang, Wenqing and Cheng, Zhan and Lei, Fu and Liu, Beichen and Gu, Dian and Wang, Zeyu},
title = {Enhancing Logical Reasoning in Large Language Models via Multi-Stage Ensemble Architecture with Adaptive Attention and Decision Voting},
year = {2025},
isbn = {9798400711862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724154.3724348},
doi = {10.1145/3724154.3724348},
abstract = {Increasing difficulty of logical reasoning tasks suggests the deficiency of conventional large language models (LLMs) in solving multi-step reasoning problems. This paper presents a novel multi-stage ensemble method to enhance LLMsQS reasoning capability. The design includes cascading networks, in which dynamic candidates are selected as the inputs and an adaptive self-attention mechanism and voting are applied for decision- making, which together enhance the model's accuracy and robustness. Based on the confidence levels, candidate selection is carried out and the candidates are then refined utilizing multi-head adaptive attention. Then, decision voting fuses reasoning results of several different models, which improves the stability and diversity of the model. Proposed different from state-of-the-art methods, the multi-stage ensemble approach significantly enhances the logic reasoning ability of the model, especially in more complex multi-step problems according to the experimental results. An ablation study validates that the adaptive attention mechanism and ensemble decision method contribute positively to enhancing the model performance. Not only does this out-perform classical models in accuracy, but it also strikes a great balance in reasoning efficiency and model interpretability, thus establishing a new paradigm for AI-based logical reasoning tasks.},
booktitle = {Proceedings of the 2024 5th International Conference on Big Data Economy and Information Management},
pages = {1201–1205},
numpages = {5},
location = {
},
series = {BDEIM '24}
}

@article{10.14778/3734839.3734862,
author = {Kong, Weiyang and Wu, Kaiqi and Zhang, Sen and Liu, Yubao},
title = {GraphSparseNet: A Novel Method for Large Scale Traffic Flow Prediction},
year = {2025},
issue_date = {March 2025},
publisher = {VLDB Endowment},
volume = {18},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3734839.3734862},
doi = {10.14778/3734839.3734862},
abstract = {Traffic flow forecasting is a critical spatio-temporal data mining task with wide-ranging applications in intelligent route planning and dynamic traffic management. Recent advancements in deep learning, particularly through Graph Neural Networks (GNNs), have significantly enhanced the accuracy of these forecasts by capturing complex spatio-temporal dynamics. However, the scalability of GNNs remains a challenge due to their exponential growth in model complexity with increasing nodes in the graph. Existing methods to address this issue, including sparsification, decomposition, and kernel-based approaches, either do not fully resolve the complexity issue or risk compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet), a novel framework designed to improve both the scalability and accuracy of GNN-based traffic forecasting models. GraphSparseNet is comprised of two core modules: the Feature Extractor and the Relational Compressor. These modules operate with linear time and space complexity, thereby reducing the overall computational complexity of the model to a linear scale. Our extensive experiments on multiple real-world datasets demonstrate that GraphSparseNet not only significantly reduces training time by 3.51x compared to state-of-the-art linear models but also maintains high predictive performance.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {2295–2307},
numpages = {13}
}

@inproceedings{10.1145/3582515.3609561,
author = {Zhang, Gaowei and Wang, Wei and Wang, Yi},
title = {Towards Spatio-temporal Sea Surface Temperature Forecasting via Dynamic Personalized Graph Network},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609561},
doi = {10.1145/3582515.3609561},
abstract = {Sea surface temperature (SST) is uniquely important to the Earth’s atmosphere since its dynamics are a major force in shaping local and global climate and profoundly affect our ecosystems. Accurate forecasting of SST brings significant economic and social implications, for example, better preparation for extreme weather such as severe droughts or tropical cyclones months ahead. However, such a task faces unique challenges due to the intrinsic complexity and uncertainty of ocean systems. Recently, deep learning techniques, such as graphical neural networks (GNN), have been applied to address this task. While such techniques achieve certain levels of success, they often have significant limitations in exploring dynamic spatio-temporal dependencies between signals. To solve this problem, this paper proposes a novel graph convolution network architecture with static and dynamic learning layers for SST forecasting. Specifically, two adaptive adjacency matrices are firstly constructed to respectively model the stable long-term and short-term evolutionary patterns hidden in the multivariate SST signals. Then, a personalized convolution layer is designed to fuse these information. The developed network can be learned in an end-to-end manner. Our experiments on real SST datasets demonstrate the state-of-the-art performances of the proposed approach on the forecasting task.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {403–409},
numpages = {7},
keywords = {SST, graph neural networks, transformer},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@inproceedings{10.1145/3762249.3762309,
author = {Wu, You and Qin, Ying and Su, Xin and Lin, Yuxiu},
title = {Transformer-Based Risk Monitoring for Anti-Money Laundering with Transaction Graph Integration},
year = {2025},
isbn = {9798400713491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762249.3762309},
doi = {10.1145/3762249.3762309},
abstract = {This study addresses the growing complexity of transaction behaviors and the highly concealed nature of money laundering paths in current financial AML scenarios. It proposes a Transformer-based risk monitoring model for anti-money laundering. The approach is grounded in transaction sequence modeling and integrates the structural information of transaction graphs. A context-aware classifier is introduced to enable accurate identification and risk scoring of high-risk accounts. The model first applies feature embedding and positional encoding to each transaction. It then uses multiple Transformer layers to capture long-range behavioral dependencies. At the same time, it incorporates account interaction information from the graph structure. This enhances the model's ability to detect abnormal transaction chains across accounts. At the output stage, a classifier that fuses sequential semantics with graph context is used to determine the overall money laundering risk of each account. Multiple experiments were conducted on the publicly available Elliptic dataset. Results show that the proposed method outperforms existing mainstream models on evaluation metrics such as AUC, F1-Score, and Accuracy. It also demonstrates stronger discriminative power and greater stability in identifying high-risk accounts. Further analysis of model depth sensitivity and case-based verification supports the model's effectiveness in real-world complex transaction environments. The proposed method offers a more adaptable technical solution for financial institutions dealing with large-scale suspicious behavior detection tasks.},
booktitle = {Proceedings of the 2025 2nd International Conference on Digital Economy, Blockchain and Artificial Intelligence},
pages = {388–393},
numpages = {6},
keywords = {Anti-money laundering, Transformer model, financial behavior analysis, transaction graph modeling},
location = {
},
series = {DEBAI '25}
}

@inproceedings{10.1145/3711650.3711665,
author = {Fofanah, Abdul Joseph and Sankoh, Albert Patrick and Dumbuya, Ibrahim and Kamara, Alpha Alimamy and Conteh, Zachariyah Bai},
title = {ST-FLAM: Evaluating Performance of Deep Learning Models on Mobility Patterns for EVD Forecasting based on Spatio-Temporal Feature Learning},
year = {2025},
isbn = {9798400717352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711650.3711665},
doi = {10.1145/3711650.3711665},
abstract = {Ebola Virus Disease (EVD) is a highly contagious and fatal disease that poses a serious threat to public health and security. Accurate and timely forecasting of EVD outbreaks is essential for effective prevention and control measures. However, traditional epidemiological models often fail to capture the complex and dynamic nature of human mobility, which plays a key role in EVD transmission. In this paper, we propose a novel framework for EVD forecasting based on spatio-temporal feature learning called ST-FLAM. We use various types of mobility data, such as phone records, Global Positioning System (GPS) traces, and social media posts, to extract meaningful and representative features that reflect the mobility patterns of individuals and populations. Next, we employ ST-FLAM architectures, which incorporate Graph Neural Networks (GNN) and Long Short Term Memory (LSTM), to establish connections and dependencies between mobility features and EVD cases in both space and time. We evaluate the performance of our framework on real-world datasets from the 2014–2016 West Africa EVD outbreak and the 2015–2016 EVD and human mobility in Sierra Leone. We compare our framework with baseline methods to handle traditional epidemiological challenges during an outbreak. We conduct ablation studies and analyse the impact of different mobility data sources, feature extraction methods, and deep learning architectures on EVD forecasting accuracy. Our results show that our framework outperforms the baselines and achieves state-of-the-art performance in EVD forecasting. We also demonstrate that our framework can provide interpretable and actionable insights for EVD prevention and control.},
booktitle = {Proceedings of the 2024 13th International Conference on Networks, Communication and Computing},
pages = {98–106},
numpages = {9},
keywords = {Time Series, Ebola Virus Disease, Deep Learning, Spatio-Temporal, Population Mobility},
location = {
},
series = {ICNCC '24}
}

@inproceedings{10.1145/3701716.3717376,
author = {Lan, Disen and Zhang, Guibin and Guo, Rongjin},
title = {Diffusion Graph Model for Time Series Anomaly Detection via Anomaly-aware Graph Sparsification and Augmentation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717376},
doi = {10.1145/3701716.3717376},
abstract = {Unsupervised methods, particularly reconstruction-based methods have become the dominant approach for multivariate time series anomaly detection (TSAD), which distinguish between normal and abnormal series based on the magnitude of the reconstruction error. However, in this process, the heterophilic connections (normal \l{}eftrightarrow abnormal datapoints) often lead the model to simultaneously capture the distributions of both normal and abnormal data, impeding effective anomaly detection based on reconstruction error. To address this challenge, we introduce a novel diffusion graph model framework, dubbed \o{}urmethod, which jointly models spatial-temporal correlations and explicitly severs heterophilic connections for improved reconstruction. Specifically, \o{}urmethod first transforms multivariate time series into a spatial-temporal joint graph and utilizes graph diffusion to progressively denoise and learn anomaly-free node representations. Through the tailored anomaly-aware graph sparsification and contrastive augmentation, \o{}urmethod effectively captures anomaly patterns and eliminates anomaly-related heterophily correlations on the spatio-temporal joint graph. Extensive experiments on TSAD datasets demonstrate that \o{}urmethod achieves state-of-the-art performance, showcasing the expressiveness of our framework.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2207–2214},
numpages = {8},
keywords = {diffusion model, graph neural networks, time series anomaly detection},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3589132.3625614,
author = {Wen, Haomin and Lin, Youfang and Xia, Yutong and Wan, Huaiyu and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
title = {DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting  with Denoising Diffusion Models},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3625614},
doi = {10.1145/3589132.3625614},
abstract = {Spatio-temporal graph neural networks (STGNN) have emerged as the dominant model for spatio-temporal graph (STG) forecasting. Despite their success, they fail to model intrinsic uncertainties within STG data, which cripples their practicality in downstream tasks for decision-making. To this end, this paper focuses on probabilistic STG forecasting, which is challenging due to the difficulty in modeling uncertainties and complex ST dependencies. In this study, we present the first attempt to generalize the popular de-noising diffusion probabilistic models to STGs, leading to a novel non-autoregressive framework called DiffSTG, along with the first denoising network UGnet for STG in the framework. Our approach combines the spatio-temporal learning capabilities of STGNNs with the uncertainty measurements of diffusion models. Extensive experiments validate that DiffSTG reduces the Continuous Ranked Probability Score (CRPS) by 4\%-14\%, and Root Mean Squared Error (RMSE) by 2\%-7\% over existing methods on three real-world datasets.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {60},
numpages = {12},
keywords = {diffusion model, probabilistic forecasting, spatio-temporal graph forecasting},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.1145/3746709.3746760,
author = {Wu, Zhendong and Yu, Weihao and Zhang, Tinghua and Huang, Jin},
title = {ASTGCL: Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction},
year = {2025},
isbn = {9798400713163},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746709.3746760},
doi = {10.1145/3746709.3746760},
abstract = {With the rise of intelligent urban systems, traffic flow prediction has emerged as a vital element within intelligent transportation frameworks. Graph neural networks (GNNs) are crucial for traffic flow prediction due to the non-Euclidean nature of traffic networks. Most GNN-based approaches depend on predefined adjacency matrices, frequently failing to model complex global dependencies. Additionally, these methods primarily use supervised learning, which is highly dependent on data quality. However, traffic data often suffers from missing values caused by sensor malfunctions, hindering effective feature extraction. To overcome these limitations, a novel framework called Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction (ASTGCL) is introduced to improve prediction performance. Specifically, ASTGCL implements two data augmentation strategies: first, it employs an adaptive, learnable adjacency matrix to enhance the predefined matrix, enabling the model to capture both local and global topological features; second, it integrates three traffic data augmentation techniques to reduce the influence of data noise on prediction accuracy. The enhanced adjacency matrix and augmented traffic data are then utilized in a spatio-temporal contrastive learning process to extract higher-order spatio-temporal features from the traffic flow data. Experiments conducted on four real-world datasets reveal that ASTGCL surpasses baseline models, confirming the efficacy of the proposed framework.},
booktitle = {Proceedings of the 2025 6th International Conference on Computer Information and Big Data Applications},
pages = {296–302},
numpages = {7},
keywords = {Contrastive Learning, Data augmentation, Traffic flow prediction},
location = {
},
series = {CIBDA '25}
}

@inbook{10.1145/3729706.3729772,
author = {Feng, Mengdie and Chen, Xinying},
title = {Traffic Flow Prediction in Attention Mechanism and Temporal Graph Convolutional Networks},
year = {2025},
isbn = {9798400712715},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729706.3729772},
abstract = {To address the challenges posed by the intricate dynamic spatiotemporal dependencies within traffic networks, and the nonlinear nature of traffic data, we propose a traffic flow prediction model that uses an attention mechanism and temporal graph convolutional network (AMTGCN). First, an encoder-decoder architecture and a Graph Convolutional Recurrent Unit (NTGCCU) have been used to capture spatiotemporal dependencies effectively. Then, an attention mechanism module is employed to enhance the prioritization and emphasis on critical spatiotemporal characteristics. Finally, a memory network module has been added to discern abrupt changes in traffic conditions. To validate the efficacy and practicality of the proposed model, experimental analyses are conducted on real-world datasets. Experimental results show that the proposed method exhibits a higher prediction accuracy than current mainstream traffic forecasting models.},
booktitle = {Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy},
pages = {418–424},
numpages = {7}
}

@inproceedings{10.1145/3674029.3674059,
author = {Romanova, Alex},
title = {GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis},
year = {2024},
isbn = {9798400716379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674029.3674059},
doi = {10.1145/3674029.3674059},
abstract = {The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series for climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends. We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.},
booktitle = {Proceedings of the 2024 9th International Conference on Machine Learning Technologies},
pages = {181–187},
numpages = {7},
keywords = {Anomaly Detection, City-Graph Method, GNN Graph Classification, Graph Neural Networks, Sliding Window Graph, Time Series Analysis},
location = {Oslo, Norway},
series = {ICMLT '24}
}

@article{10.1145/3727622,
author = {Liu, Zhanyu and Zheng, Guanjie and Yu, Yanwei},
title = {Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1556-4681},
url = {https://doi.org/10.1145/3727622},
doi = {10.1145/3727622},
abstract = {Traffic forecasting is crucial for intelligent transportation systems (ITS), aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank (MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, the traffic data of the data-scarce target city could query the traffic pattern bank, facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn, assumes a pivotal role as a robust guide in subsequent processes involving graph reconstruction and forecasting. Empirical assessments conducted on real-world traffic datasets affirm the superior performance of MTPB, surpassing existing methods across various categories and exhibiting numerous attributes conducive to the advancement of cross-city few-shot forecasting methodologies. The code is available in .},
journal = {ACM Trans. Knowl. Discov. Data},
month = may,
articleno = {94},
numpages = {24},
keywords = {Traffic Forecasting, Few-shot learning, Spatial-temporal data, Traffic Pattern}
}

@inproceedings{10.1145/3580305.3599549,
author = {Wang, Jingyuan and Yang, Chen and Jiang, Xiaohan and Wu, Junjie},
title = {WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599549},
doi = {10.1145/3580305.3599549},
abstract = {Given its broad applications, time series analysis has gained substantial research attention but remains a very challenging task. Recent years have witnessed the great success of deep learning methods, eg., CNN and RNN, in time series classification and forecasting, but heterogeneity as the very nature of time series has not yet been addressed adequately and remains the performance "treadstone." In this light, we argue that the intra-sequence non-stationarity and inter-sequence asynchronism are two types of heterogeneities widely existed in multiple times series, and propose a hybrid attention network called WHEN as deep learning solution. WHEN features in two attention mechanisms in two different modules. In the WaveAtt module, we propose a novel data-dependent wavelet function and integrate it into the BiLSTM network as the wavelet attention, for the purpose of analyzing dynamic frequency components in nonstationary time series. In the DTWAtt module, we transform the dynamic time warping (DTW) technique into the form as the DTW attention, where all input sequences are synchronized with a universal parameter sequence to overcome the time distortion problem in multiple time series. WHEN with the hybrid attentions is then formulated as task-dependent neural network for either classification or forecasting tasks. Extensive experiments on 30 UEA datasets and 3 real-world datasets with rich competitive baselines demonstrate the excellent performance of our model. The ability of WHEN in dealing with time series heterogeneities is also elaborately explored via specially designed analysis.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2361–2373},
numpages = {13},
keywords = {attentions, dynamic time warping, time series, wavelet},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@article{10.1145/3744350,
author = {Sikder, Md Nazmul Kabir and Batarseh, Feras A.},
title = {Context-driven Deep Learning Forecasting for Wastewater Treatment Plants},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2378-962X},
url = {https://doi.org/10.1145/3744350},
doi = {10.1145/3744350},
abstract = {Wastewater‑treatment utilities face various operational challenges that could benefit from embodied AI and other advanced cyber‑physical technologies. These challenges include optimizing pump schedules, managing energy and chemical consumption during extreme weather events, and interpreting sensor data for water‑quality treatment. Addressing these issues requires accurate short‑term, multi‑step forecasting tools to provide reliable real‑time decision support, particularly during heavy‑rainfall events that can overwhelm operations. Leading water‑system operators and vendors in the United States report that tools capable of forecasting 4–6 hours ahead can significantly enhance resource management, including energy, chemicals, and manpower. However, accurate short‑term forecasting is particularly difficult because of the non‑linearities and seasonal variations inherent in plant data, which limit effective decision‑making. To address these challenges, we propose cP2O, a context‑driven forecasting solution, a novel hybrid deep‑learning architecture integrating dynamic context extraction with hierarchical, dilated long‑short‑term‑memory (LSTM) cells. The proposed model utilizes internal water‑system data, such as flow rates and tunnel levels, along with exogenous variables including weather, river flow, and demographic information to derive relevant context. It captures both short‑term fluctuations and long‑term dependencies in water‑level data, while an internal attention mechanism dynamically weighs the importance of exogenous information. We validate the model on two full‑scale utilities: tunnel‑water‑level forecasting at DC Water’s Blue Plains facility and nitrate‑level prediction at AlexRenew. Relative to strong baselines, cP2O reduces mean absolute percentage error by 22 \% and 19 \%, respectively, and its 90 \% prediction bands cover 90.5 \% ± 3.2 \% of observations (5.9 \% below, 3.6 \% above). By dynamically incorporating contextual information, especially under critical conditions, the model delivers reliable real‑time forecasts that enhance resource allocation and strengthen the overall resilience of wastewater‑treatment operations.},
note = {Just Accepted},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jun,
keywords = {Context, Hybrid Deep Learning, Wastewater Treatment, Short-term Forecasting, Dilated Recurrent Neural Networks, Attention}
}

@inproceedings{10.1145/3627673.3679841,
author = {He, Jing and Ji, Junzhong and Lei, Minglong},
title = {Spatio-Temporal Transformer Network with Physical Knowledge Distillation for Weather Forecasting},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679841},
doi = {10.1145/3627673.3679841},
abstract = {Weather forecasting has become a popular research topic recently, which mainly benefits from the development of spatio-temporal neural networks to effectively extract useful patterns from weather data. Generally, the weather changes in the meteorological system are governed by physical principles. However, it is challenging for spatio-temporal methods to capture the physical knowledge of meteorological dynamics. To address this problem, we propose in this paper a spatio-temporal Transformer network with physical knowledge distillation (PKD-STTN) for weather forecasting. First, the teacher network is implemented by a differential equation network that models weather changes by the potential energy in the atmosphere to reveal the physical mechanism of atmospheric movements. Second, the student network uses a spatio-temporal Transformer that concurrently utilizes three attention modules to comprehensively capture the semantic spatial correlation, geographical spatial correlation, and temporal correlation from weather data. Finally, the physical knowledge of the teacher network is transferred to the student network by inserting a distillation position encoding into the Transformer. Notice that the output of the teacher network is distilled to the position encoding rather than the output of the student network, which can largely utilize physical knowledge without influencing the feature extraction process of Transformers. Experiments on benchmark datasets show that the proposed method can effectively utilize physical principles of weather changes and has obvious performance advantages compared with several strong baselines.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {819–828},
numpages = {10},
keywords = {knowledge distillation, physics-guided neural network, spatio-temporal transformer, weather forecasting},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3760658.3760677,
author = {Luo, Jiandong and Kuang, Jianyu and Wei, Tongshou and Yang, Meng and Hu, Zhongrui and Du, Ye},
title = {Enhancing Transformer Models for Long-Term Time Series Classification with Multi-Channel Frequency-Domain Filters},
year = {2025},
isbn = {9798400718526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760658.3760677},
doi = {10.1145/3760658.3760677},
abstract = {Time-series classification plays a critical role in numerous domains such as healthcare, activity recognition, and industrial monitoring. Traditional Transformer models, while effective in modeling long-range dependencies, tend to focus disproportionately on high-energy frequency components, potentially overlooking valuable low-frequency information. To address this issue, we propose a frequency-domain filter Transformer model that incorporates a multi-channel frequency decomposition module prior to the Transformer encoder. This module applies parallel frequency-specific filters to segment the input sequence into distinct bands, enabling the model to extract features from both high- and low-frequency components. Each frequency stream is processed by a dedicated Transformer branch, and the results are aggregated to form a comprehensive representation. Extensive experiments on benchmark datasets such as KU-HAR demonstrate that our model significantly outperforms baseline methods, including CNN, CNN-LSTM, and Transformer architectures, achieving superior accuracy and robustness. The proposed approach effectively mitigates the attention bias toward single-band information and enhances the interpretability and performance of Transformer-based time-series classifiers.},
booktitle = {Proceedings of the 2025 9th International Conference on Deep Learning Technologies},
pages = {124–130},
numpages = {7},
keywords = {Time-series classification, Filter, Transformer, Frequency-Domain},
location = {
},
series = {ICDLT '25}
}

@article{10.1145/3712702,
author = {Fan, Yu and Lu, Xinjiang and Liu, Hao and Wang, Pengfei and Liu, Liang and Ma, Huadong and Zhou, Jingbo},
title = {Towards Predicting Urban Land Use Changes: A Dynamic Graph Alignment Perspective},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3712702},
doi = {10.1145/3712702},
abstract = {Urban land use, intrinsically linked to people’s daily activities, undergoes continuous evolution, presenting a complex interplay that remains partially understood. To bridge this gap, our study leverages fine-grained human mobility data to predict these changes, adopting a novel approach that conceptualizes “community-level” land use shifts as a regression problem and represents citywide changes through dynamic graphs. We harness recent advancements in graph neural networks (GNNs), which, despite their success in various applications, face challenges in directly predicting land use changes due to the temporal mismatch between the slow evolution of urban land and the immediacy of human mobility data. Our research stands out by introducing a temporal skeleton for dynamic GNNs to synchronize human activity graphs with urban land use changes, a dynamic heterogeneous GNN approach for integrating diverse human activity data to capture essential temporal dependencies, and a novel algorithm powered by causal inference to elucidate the primary factors influencing land use predictions at the community level, all of which contribute to a training process informed by the generated causal graph. Empirically validated on three real-world datasets, our model demonstrates a performance leap over state-of-the-art baselines, marking a pivotal step toward understanding and predicting the dynamics of urban land use.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {44},
numpages = {24},
keywords = {Land Use Change Prediction, Dynamic Graph, Graph Neural Networks}
}

@inproceedings{10.1145/3745533.3745595,
author = {Li, Zhuolin and Zhou, Chi},
title = {Automobile sales forecasting based on Special Zero-inflated Data},
year = {2025},
isbn = {9798400713873},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3745533.3745595},
doi = {10.1145/3745533.3745595},
abstract = {Car sales projections are important for manufacturers in terms of production adjustments and strategic planning. Traditionally, such predictions tend to focus only on brand performance across a wide range of markets. The LSTM model showed good prediction results. Due to the increasing importance of Market Segmentation, the demand for some car sales forecasts (PAS) has increased, and PAS data contains a large number of zero values and has significant cyclicality. This creates problems with traditional statistical methods and becomes difficult to capture the nuances of the data. To solve this problem, a method is proposed that combines short-and long-term memory (LSTM) networks and zero-expansion Poisson models. The latter is suitable for processing data with superfluous zero values and complex patterns. The mixed-loss zero-expansion LSTM system (Zim-LSTM) has also been implemented to improve robust and long-term forecasting capabilities for future pa. Zim-LSTM has advantages in modeling common zero values and stores historical information to facilitate the short-sighted task of predicting time series. Using a method of verifying sales data of real cars and comparing them with existing reference models, the results show that the accuracy and reliability of Zim-LSTM have improved, making it a promising solution for predicting PAS..},
booktitle = {Proceedings of the 2025 5th International Conference on Applied Mathematics, Modelling and Intelligent Computing},
pages = {377–382},
numpages = {6},
keywords = {LSTM, Partial automobile sales forecasting, Time series, Zero-inflated poisson},
location = {
},
series = {CAMMIC '25}
}

@inproceedings{10.1145/3662739.3672175,
author = {Li, Yangyi and Dong, Danhuang and Gu, Chenlin and Feng, Yi and Zhang, Peng},
title = {Photovoltaic Power Output Prediction Based on Simple Weather Data and Graph Convolutional Networks},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3672175},
doi = {10.1145/3662739.3672175},
abstract = {Graph neural networks, as a class of models capable of handling graph-structured data, have been widely applied and researched in various fields in recent years. In the power industry, photovoltaic power output prediction is an important topic, and the relative positions of photovoltaic power stations, as a form of unstructured information, provide an opportunity for the application of graph neural networks. In this context, we utilize multiple layers of graph convolutional layers to construct the network, stack the graph convolutional layer with the normalization layer and connect two fully connected layers at the end. Regarding the dataset, existing algorithms may face challenges such as difficulty in acquisition and lack of sufficient data support. To address this, we use simple weather data as input variables, simultaneously construct regression models for meteorological indicators, and employ the variance inflation factor to remove highly similar nodes, aiming to reduce the complexity of the graph. The specific operation is to set the threshold, establish a regression model between each meteorological indicator of each node and the meteorological indicators of other nodes, and calculate the variance inflation factor. Filter the removable nodes according to the variance inflation factor, randomly remove a node and refit the regression. model, by iterating until the remaining nodes are not highly relevant. Experimental validation shows that our method outperforms existing approaches in terms of accuracy.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {162–167},
numpages = {6},
keywords = {Graph convolution, Photovoltaic power output, Simple weather data, Variance inflation factor},
location = {Ningbo, China},
series = {MIDA '24}
}

@inbook{10.1145/3718491.3718669,
author = {Yang, Shuxin and Guo, Min and Wu, Jianqing and Chen, Yishan and Huang, Guangjian and Zeng, Bowen},
title = {Hybrid Inverted Transformer-CNN Model for Train Primary-Delay Recovery Time Prediction},
year = {2025},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718491.3718669},
abstract = {The delay can easily propagate once the train is delayed, causing further delays in subsequent trains. Modeling the recovery process from train delays is essential in supporting decision-making and operational efficiency. Previous methods for predicting train delay recovery have focused mainly on temporal analysis, emphasizing operational time, delay duration, and stop time. However, models incorporating spatial information have been relatively underexplored. This paper proposes an Inverted Transformer Convolutional Neural Network (iTransformer-CNN) to predict train delay recovery time. The proposed model can more efficiently uncover the spatiotemporal relationships within the data, enhancing the accuracy of delay recovery predictions. The experiment results demonstrate that the iTransformer-CNN model can significantly improve the precision of train delay recovery predictions based on real-world data.},
booktitle = {Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
pages = {1103–1110},
numpages = {8}
}

@article{10.1145/3776557,
author = {Xue, Xin and Zhou, Haoyi and Li, Lanhao and Lin, Yihan and Chen, Tianyu and Li, Jianxin},
title = {Leveraging LLMs for Semantic Correlation Enhancement in Spatial-temporal Imputation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3776557},
doi = {10.1145/3776557},
abstract = {Spatial-temporal imputation remains a challenging problem in transportation, environment and healthcare, where the missing value is filled based on spatial, temporal, and cross correlations. Previous research mainly focused on feature-level correlation integration and comprehension with the hand-crafted enhancement strategy. Meanwhile, the recently prevalent large language models (LLMs) provide token-level understanding for language linguistics, and whether they could be applied for spatial-temporal correlation enhancement is under exploration. To this end, we proposed an LLM-native framework STOMA to fully utilize the intrinsic relevance. We designed semantic enhancing methods by converting the complex correlations, e.g. spatial correlation in network, temporal correlation with periodicity and cross correlation from human behavior, into the embedded tokens. Specifically, we reform dynamic time warping as an asymmetric correlation constructor for complex dynamics. We adapt the proposed backbone along with the spatial-temporal fine-tuning technique, and the empirical results demonstrate the effectiveness of our methods over recent LLM-inspired methods evaluating on real-world datasets.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
keywords = {Spatial-temporal Modeling, Neural Networks, Graph, Time series}
}

@inproceedings{10.1145/3603781.3603907,
author = {Gan, Tian and Xu, Beining and Li, Jin},
title = {Transportation Flow Prediction Based on Graph Attention Echo State Network},
year = {2023},
isbn = {9798400700705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603781.3603907},
doi = {10.1145/3603781.3603907},
abstract = {Abstract—Traffic flow prediction is of great importance in applications such as traffic management and urban planning. The complex spatial and temporal dependence of traffic flow between different roads poses a great challenge for accurate real-time traffic flow prediction. Traditional traffic flow prediction methods rely on the assumption of data smoothness, and the prediction accuracy decreases significantly in the face of complex, variable and large amount of traffic flow data. Spatio-temporal prediction models based on graph neural networks and recurrent neural networks can achieve better prediction accuracy, but there are still some problems, such as the need for a known static graph structure, inadequate spatial extraction and long training time of the model. To improve traffic flow prediction accuracy and real-time performance, this paper proposes a novel end-to-end deep learning framework called graph attention echo state network (GAESN), which uses attention mechanism and echo state network to extract spatio-temporal features. Experimental results on four real traffic flow datasets show that our proposed model achieves 17.35, 21.34, 24.12 and 17.31 in mean absolute error(MAE); 29.31, 32.67, 37.51and 26.84 in root mean square error(RMSE); 16.76\%, 15.44\%, 10.33\% and 10.94\% in mean absolute percentage error(MAPE), respectively. Compared with other existing models, this model reduces the number of parameters to be trained and the time required for model training, and also improves the accuracy of traffic flow prediction.},
booktitle = {Proceedings of the 2023 4th International Conference on Computing, Networks and Internet of Things},
pages = {708–713},
numpages = {6},
keywords = {Echo state network, Graph attention network, Multi-headed attention mechanism, Spatio-temporal dependence, Traffic prediction},
location = {Xiamen, China},
series = {CNIOT '23}
}

@inproceedings{10.1145/3696673.3723071,
author = {Kulkarni, Adita},
title = {Cyber Social Threats: A Data-centric AI Perspective},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723071},
doi = {10.1145/3696673.3723071},
abstract = {With the proliferation of social media platforms, cyber social threats such as fake news, hate speech, and cyberbullying have increased significantly. With the availability of abundant data for building machine learning models, artificial intelligence (AI) is making a deep impact in almost every domain, including detecting and mitigating cyber social threats on social media platforms. As the role of data in AI has significantly intensified in recent years, the concept of data-centric AI has emerged, gradually shifting the research focus from improving model design to enhancing the quality and quantity of data. In this paper, we first present the limitations of model-centric AI in the context of cyber social threats, then discuss the existing literature that uses data-centric AI techniques to detect and mitigate cyber social threats. We finally present the major challenges that social media data presents to deal with cyber social threats using data-centric AI and describe future research opportunities.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {85–94},
numpages = {10},
keywords = {cyber social threats, artificial intelligence, data-centric AI, model-centric AI},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3649476.3658696,
author = {Petrolo, Vincenzo and Medya, Sourav and Graziano, Mariagrazia and Pal, Debjit},
title = {DETECTive: Machine Learning-driven Automatic Test Pattern Prediction for Faults in Digital Circuits},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649476.3658696},
doi = {10.1145/3649476.3658696},
abstract = {Due to the continuous technology scaling and the ever-increasing complexity and size of the hardware designs, manufacturing defects have become a key obstacle in meeting end-user demand. Despite decades of research, traditional test-generation techniques often struggle to scale to massive and complex designs. Such scalability issues stem from the numerous backtracking the traditional test generation techniques perform before converging to a test pattern. In this work, we present DETECTive that leverages deep learning on graphs to learn fault characteristics and predict test pattern(s) to expose faults without requiring backtracking. DETECTive is trained on small circuits, and its learned knowledge is transferable to predict test patterns for circuits that contain up to 29 \texttimes{} more gates than the training circuits. Since DETECTive avoids backtracking completely, it can predict test patterns up to 15 \texttimes{} faster than academic tools and up to 2 \texttimes{} faster than commercial tools. DETECTive achieves up to 100\% pattern accuracy on synthetic designs and up to 95\% test pattern accuracy on realistic designs. To our knowledge, DETECTive is the first to leverage deep learning to predict test patterns for digital hardware designs that can complement the traditional test generation techniques for faster design closure.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2024},
pages = {32–37},
numpages = {6},
keywords = {ATPG, Deep Learning, Graph Neural Networks},
location = {Clearwater, FL, USA},
series = {GLSVLSI '24}
}

@inproceedings{10.1145/3679240.3734642,
author = {Loffa, Maria Adelaide and Macii, Enrico and Patti, Edoardo and Bottaccioli, Lorenzo},
title = {Physics-Informed vs. Deep Learning: Indoor Temperature Prediction with Different Data Availability},
year = {2025},
isbn = {9798400711251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679240.3734642},
doi = {10.1145/3679240.3734642},
abstract = {Reducing energy consumption in the building sector is crucial for global sustainability. Achieving energy efficiency requires advanced technologies and robust building models that address uncertainties and environmental variations. White-box models, based on physical principles, provide interpretability but require significant expertise and resources. In contrast, black-box models rely on historical data, lacking interpretability and being dataset-dependent. To bridge this gap, Scientific Machine Learning integrates physical insights into machine learning frameworks, ensuring interpretability while maintaining the accuracy and computational efficiency of models like neural networks. This work incorporates physical knowledge through Ordinary Differential Equations into the neural network framework, developing a physics-informed model to predict indoor air temperature based on external conditions, system thermal powers, and building internal gains. Datasets from four cities with diverse climatic conditions were used, and the model was trained on varying amounts of data, from two weeks to two years. This approach offers a novel exploration of model performance under different data availability and multiple scenarios. A comparative analysis with a Long Short-Term Memory neural network shows that, especially with limited training data, the Physics-Informed Neural Network outperforms the conventional model, with a Mean Absolute Error up to 0.69°C lower. This advantage is due to the incorporation of physics-based constraints, reducing reliance on large datasets. Additionally, the Physics-Informed Neural Network demonstrates stable accuracy across seasonal and uncontrolled dynamics conditions, highlighting its potential for temperature prediction and building control applications.},
booktitle = {Proceedings of the 16th ACM International Conference on Future and Sustainable Energy Systems},
pages = {742–750},
numpages = {9},
keywords = {physics-informed, neural network, building, modeling, Ordinary Differential Equation},
location = {
},
series = {E-Energy '25}
}

@inproceedings{10.1145/3746252.3761182,
author = {Zhang, Xin and Zheng, Jianming and Cai, Fei and Pan, Zhiqiang and Chen, Wanyu and Chen, Chonghao and Chen, Honghui},
title = {Tide: A Time-Wise Causal Debiasing Framework for Generative Dynamic Link Prediction},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761182},
doi = {10.1145/3746252.3761182},
abstract = {Dynamic link prediction aims to predict the future links in dynamic graphs. Existing generative dynamic link prediction studies utilize the global degree distribution for mitigating the over-estimation problem, which can model the time-invariant features while neglecting the time-varying features, resulting in capturing inaccurate evolution patterns. However, such time related features are intrinsically coupled, which makes simultaneously and independently modeling both features infeasible. Motivated by these issues, we propose a Time-wise causal debiasing framework (Tide) for generative dynamic link prediction, which does not resort to any extra trainable modules. Instead, to obtain the time-invariant features, we first utilize a time-invariant deconfounded learning mechanism for decoupling the prediction score with the degree distribution. To leverage the time-varying features, we intervene in the model during the inference stage by a predicted future degree distribution, aiming to make the accurate predictions for dynamic graphs. Experiments conducted on four public datasets under both inductive and transductive settings present that our Tide enhanced models can outperform their corresponding vanilla versions by up to 21.42\% and 27.73\% in terms of NDCG and Jaccard, respectively.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {4232–4241},
numpages = {10},
keywords = {causal inference, dynamic link prediction, generative model},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@inproceedings{10.1145/3637528.3671709,
author = {Zhang, Zeyang and Wang, Xin and Zhang, Ziwei and Li, Haoyang and Qin, Yijian and Zhu, Wenwu},
title = {LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671709},
doi = {10.1145/3637528.3671709},
abstract = {In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities. Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes are publicly available at Github.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4350–4361},
numpages = {12},
keywords = {benchmark, disentanglement, dynamic graph, evaluation, large language model, spatial-temporal},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3644713.3644792,
author = {Xoliyarov, Farhod and Gulomov, Sherzod and Bozorov, Suhrobjon},
title = {The Impact of Artificial Neural Network Architecture on Network Attack Detection},
year = {2024},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644713.3644792},
doi = {10.1145/3644713.3644792},
abstract = {Artificial Neural Networks (ANNs) have emerged as a powerful tool for network attack detection due to their ability to learn complex patterns and behaviors. The architecture of an ANN plays a critical role in determining its performance and effectiveness in detecting network attacks. This article explores the impact of ANN architecture on network attack detection, highlighting different types of architectures used in the field of cybersecurity. It discusses the advantages and disadvantages of these architectures, along with the challenges associated with their usage. By understanding the significance of ANN architecture, security professionals can make informed decisions to enhance network defense mechanisms and protect against evolving cyber threats.},
booktitle = {Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
pages = {532–539},
numpages = {8},
location = {Dubai, United Arab Emirates},
series = {ICFNDS '23}
}

@inproceedings{10.1145/3605098.3635928,
author = {Seo, Kanghyeon and Yang, Jihoon},
title = {Exploring The Efficient Market Hypothesis for Accurate Stock Movement Prediction via Feature-Axis Transformer},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635928},
doi = {10.1145/3605098.3635928},
abstract = {Stock movement forecasting is a significant challenge in financial machine-learning application fields due to its profound impact on financial markets. While the Efficient Market Hypothesis (EMH) [10] postulates that predicting stock movement is nearly impossible, recent studies using deep learning methodologies exhibit promising results. The EMH is based on the assumption that stock prices immediately incorporate all available information, such as financial statements, earnings announcements, and macroeconomic news. Input features used by the prior studies commonly include Open, High, Low, Close, and Adjusted Close (OHLCA), which potentially contain salient information for forecasting movements. However, most have yet to extract the information implicit in each price separately and utilize it to make predictions. This paper proposes FATE: Feature-Axis Transformer based on EMH designed to leverage each OHLCA component to facilitate stock movement prediction. FATE consists of three modules: 1) capturing each feature's temporal correlation between various stocks; 2) generating global market context data; and 3) constructing a contextual vector through correlating to other prices around the closing price. Experimental results show that FATE demonstrates better predictive results than state-of-the-art baselines on six real-world datasets. FATE also yields profitable portfolio trading gains compared to the baselines. Furthermore, it offers interpretable visualized results during its stock movement forecasting operations.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {892–901},
numpages = {10},
keywords = {stock movement prediction, fintech, deep learning},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3605098.3635976,
author = {Paul, Steve and Witter, Jhoel and Chowdhury, Souma},
title = {Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand \&amp; Uncertainties},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635976},
doi = {10.1145/3605098.3635976},
abstract = {This paper develops a graph reinforcement learning approach to online planning of the schedule and destinations of electric aircraft that comprise an urban air mobility (UAM) fleet operating across multiple vertiports. This fleet scheduling problem is formulated to consider time-varying demand, constraints related to vertiport capacity, aircraft capacity and airspace safety guidelines, uncertainties related to take-off delay, weather-induced route closures, and unanticipated aircraft downtime. Collectively, such a formulation presents greater complexity, and potentially increased realism, than in existing UAM fleet planning implementations. To address these complexities, a new policy architecture is constructed, primary components of which include: graph capsule conv-nets for encoding vertiport and aircraft-fleet states both abstracted as graphs; transformer layers encoding time series information on demand and passenger fare; and a Multi-head Attention-based decoder that uses the encoded information to compute the probability of selecting each available destination for an aircraft. Trained with Proximal Policy Optimization, this policy architecture shows significantly better performance in terms of daily averaged profits on unseen test scenarios involving 8 vertiports and 40 aircraft, when compared to a random baseline and genetic algorithm-derived optimal solutions, while being nearly 1000 times faster in execution than the latter.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {638–645},
numpages = {8},
keywords = {multi-agent systems, urban air mobility, reinforcement learning},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3600100.3623726,
author = {Prabowo, Arian and Chen, Kaixuan and Xue, Hao and Sethuvenkatraman, Subbu and Salim, Flora D.},
title = {Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: Benchmarking energy load forecasting models without and with continual learning},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3623726},
doi = {10.1145/3600100.3623726},
abstract = {In traditional deep learning algorithms, one of the key assumptions is that the data distribution remains constant during both training and deployment. However, this assumption becomes problematic when faced with Out-of-Distribution periods, such as the COVID-19 lockdowns, where the data distribution significantly deviates from what the model has seen during training. This paper employs a two-fold strategy: utilizing continual learning techniques to update models with new data and harnessing human mobility data collected from privacy-preserving pedestrian counters located outside buildings. In contrast to online learning, which suffers from ’catastrophic forgetting’ as newly acquired knowledge often erases prior information, continual learning offers a holistic approach by preserving past insights while integrating new data. This research applies FSNet, a powerful continual learning algorithm, to real-world data from 13 building complexes in Melbourne, Australia, a city which had the second longest total lockdown duration globally during the pandemic. Results underscore the crucial role of continual learning in accurate energy forecasting, particularly during Out-of-Distribution periods. Secondary data such as mobility and temperature provided ancillary support to the primary forecasting model. More importantly, while traditional methods struggled to adapt during lockdowns, models featuring at least online learning demonstrated resilience, with lockdown periods posing fewer challenges once armed with adaptive learning techniques. This study contributes valuable methodologies and insights to the ongoing effort to improve energy load forecasting during future Out-of-Distribution periods.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {41–50},
numpages = {10},
keywords = {benchmarking, continual learning, electricity use, energy use, out-of-distribution, timeseries forecasting},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@article{10.1145/3777547,
author = {Pan, Yicheng and Wang, Haowei and Ma, Meng and Wang, Ping},
title = {Enhancing Spatial-Temporal Prediction Models with Dynamic Causal Graphs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2374-0353},
url = {https://doi.org/10.1145/3777547},
doi = {10.1145/3777547},
abstract = {Spatial-temporal prediction has become an important task in many applications, such as traffic forecasting. Due to the spatial-temporal nature of data, most state-of-the-art methods heavily depend on graph neural networks to model the inherent spatial relationships. However, most of them process the spatial data by applying the prior adjacency knowledge or learning a static adaptive adjacency matrix. Thus, their prediction performance is limited on dynamic situations where the spatial dependencies change w.r.t time. Furthermore, considering the stochastic training process, learning an adaptive adjacency matrix from scratch also makes it difficult for the neural network to achieve stable parameters and performance. To address the above challenges, this paper proposes three practical extensions that incorporate dynamic causal knowledge into the training of graph convolution networks. We first analyze the dynamic causal graphs between traffic nodes with one dynamic causal discovery algorithm in each extended model. Subsequently, the spatial module employs dynamic causal graphs to reveal the evolving connections among nodes. Extensive experiments demonstrate that our method has successfully enhanced state-of-the-art traffic forecasting models on two benchmarks.},
note = {Just Accepted},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = nov,
keywords = {spatial-temporal prediction, graph convolution, causality analysis, traffic forecasting.}
}

@inproceedings{10.1145/3669754.3669825,
author = {Tan, HongYuan and He, Pan and Sun, Xiaoyong and Zhao, Yongting},
title = {A Clustering-based Multi-Task Learning Method using Graph Attention Network for Short-term Traffic Forecasting},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669825},
doi = {10.1145/3669754.3669825},
abstract = {In modern intelligent transportation systems, accurate short-term traffic forecasting is pivotal for managers and travelers. While recent spatio-temporal traffic forecasting models excel in short-term predictions, data from different traffic node inherently possesses diverse characteristics, yet existing models tend to neglect the disparities between these nodes and treat neighboring nodes with different data in a uniform manner, overlooking their unique attributes, which can result in imprecise prediction results. To address these concerns, this paper introduces, the Clustering-based Multi-Task Learning Method using Graph Attention Network (CMTGAT). This model adopts a multi-task learning framework, enhanced with time-series clustering for nuanced pattern recognition and improved prediction accuracy in diverse traffic scenarios. Experimental results demonstrate that the CMTGAT model outperforms existing methods, almost doubling in forecasting precision. The integration of the time series clustering and the graph attention mechanism helps to reduce the MAPE approximately by 6\%.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {456–463},
numpages = {8},
keywords = {Graph self-attention network, Spatio-temporal graph, Traffic forecasting, multi-task learning, time-series clustering},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3664647.3681229,
author = {Gong, Zixuan and Zhang, Qi and Bao, Guangyin and Zhu, Lei and Zhang, Yu and Liu, Ke and Hu, Liang and Miao, Duoqian},
title = {Lite-Mind: Towards Efficient and Robust Brain Representation Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681229},
doi = {10.1145/3664647.3681229},
abstract = {The limited data availability and the low signal-to-noise ratio of fMRI signals lead to the challenging task of fMRI-to-image retrieval. State-of-the-art MindEye remarkably improves fMRI-to-image retrieval performance by leveraging a large model, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to the final hidden layer of CLIP's Vision Transformer (ViT). However, significant individual variations exist among subjects, even under identical experimental setups, mandating the training of large subject-specific models. The substantial parameters pose significant challenges in deploying fMRI decoding on practical devices. To this end, we propose Lite-Mind, a lightweight, efficient, and robust brain representation learning paradigm based on Discrete Fourier Transform (DFT), which efficiently aligns fMRI voxels to fine-grained information of CLIP. We elaborately design a DFT backbone with Spectrum Compression and Frequency Projector modules to learn informative and robust voxel embeddings. Our experiments demonstrate that Lite-Mind achieves an impressive 94.6\% fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7\% fewer parameters than MindEye. Lite-Mind is also proven to be able to be migrated to smaller fMRI datasets and establishes a new state-of-the-art for zero-shot classification on the GOD dataset.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4014–4023},
numpages = {10},
keywords = {brain-computer interface (bci), cross-modal retrieval, fmri},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3534540.3534691,
author = {Guan, Mingyu and Iyer, Anand Padmanabha and Kim, Taesoo},
title = {DynaGraph: dynamic graph neural networks at scale},
year = {2022},
isbn = {9781450393843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534540.3534691},
doi = {10.1145/3534540.3534691},
abstract = {In this paper, we present DynaGraph, a system that supports dynamic Graph Neural Networks (GNNs) efficiently. Based on the observation that existing proposals for dynamic GNN architectures combine techniques for structural and temporal information encoding independently, DynaGraph proposes novel techniques that enable cross optimizations across these tasks. It uses cached message passing and timestep fusion to significantly reduce the overhead associated with dynamic GNN processing. It further proposes a simple distributed data-parallel dynamic graph processing strategy that enables scalable dynamic GNN computation. Our evaluation of DynaGraph on a variety of dynamic GNN architectures and use cases shows a speedup of up to 2.7X compared to existing state-of-the-art frameworks.},
booktitle = {Proceedings of the 5th ACM SIGMOD Joint International Workshop on Graph Data Management Experiences \&amp; Systems (GRADES) and Network Data Analytics (NDA)},
articleno = {6},
numpages = {10},
location = {Philadelphia, Pennsylvania},
series = {GRADES-NDA '22}
}

@inproceedings{10.1145/3627915.3628025,
author = {Huo, Xiaokai and Yu, Xiaofei and Wu, Juan},
title = {Research and Application of Edge Cloud Load Prediction Based on DR-STGNN?},
year = {2023},
isbn = {9798400700590},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627915.3628025},
doi = {10.1145/3627915.3628025},
abstract = {Cloud servers generate a large amount of monitoring data in real-time, which is often composed of multiple time series monitoring indicators. Accurately predicting cloud load data is significant for capacity forecasting and reasonable resource allocation of cloud platforms. Multidimensional cloud load data has the characteristics of an extended period, low information density, and complex calling relationships between indicators. However, most current time series prediction algorithms perform poorly in cloud load prediction, the specific manifestation lies in the inadequate handling of cloud workload data with long-term dependencies, as well as situations involving multidimensional metrics with complex invocation relationships. This paper proposes the DR-STGNN algorithm for cloud load prediction scenarios. We designed temporal module and spatial module separately to address the challenges of long-term dependency relationships between historical and future data and complex calling relationships between indicators. A bidirectional residual structure was used to connect the modules to avoid the influence of gradient disappearance. We verified the model using the GWA-T-12 rnd trace dataset provided by Bitbrains and compared it with models such as informer, MTGNN, stemGNN, reformer, and TPA-LSTM. MAE and RMSE were used as evaluation indicators, and the results showed that DR-STGNN performed outstandingly in cloud load prediction.},
booktitle = {Proceedings of the 7th International Conference on Computer Science and Application Engineering},
articleno = {7},
numpages = {7},
keywords = {Cloud load prediction, DR-STGNN model, Deep learning, Spatial correlation, Temporal correlation},
location = {Virtual Event, China},
series = {CSAE '23}
}

@inproceedings{10.1145/3627673.3679810,
author = {Gu, Zehao and Zhou, Shiyang and Xiong, Yun and Luo, Yang and Ren, Hongrun and Wang, Qiang and Gao, Xiaofeng and Yu, Philip},
title = {MSTEM: Masked Spatiotemporal Event Series Modeling for Urban Undisciplined Events Forecasting},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679810},
doi = {10.1145/3627673.3679810},
abstract = {Urban undisciplined events (UUE) are of increasing concern to urban officials because they reduce the quality of life and cause societal disorder. How to accurately predict future occurrences is a key point in preventing these events. However, existing supervised methods struggle to perform well on sparse UUEs while self-supervised MAE-based methods adopt a traditional random masking strategy which leads to limited performance on UUE forecasting. Fortunately, we have designed an innovative spatiotemporal masking strategy and its corresponding pre-training task called &lt;u&gt;M&lt;/u&gt;asked &lt;u&gt;S&lt;/u&gt;patio-&lt;u&gt;T&lt;/u&gt;emporal &lt;u&gt;E&lt;/u&gt;vent Series &lt;u&gt;M&lt;/u&gt;odeling (MSTEM). Through Cluster-assisted region masking, MSTEM efficiently distributes masked regions evenly among different clusters, enhancing the model's ability to capture spatial correlation and heterogeneity while addressing sparse region distribution of UUEs. Frequency-enhanced patch masking helps the model to sufficiently extract the temporal features of UUEs by reconstructing multiple views. Additionally, we propose future merge and cluster label modeling to enhance the extraction of spatiotemporal dependencies, thereby improving the performance of MSTEM on downstream prediction tasks. Experimental evaluations on four real-world datasets including crimes and disorderly conduct show that our masked autoencoder with MSTEM outperforms most of the state-of-the-art baselines.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {685–694},
numpages = {10},
keywords = {masked autoencoder, self-supervised learning, smart city, spatiotemporal prediction},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679716,
author = {Zheng, Liangwei Nathan and Li, Zhengyang and Dong, Chang George and Zhang, Wei Emma and Yue, Lin and Xu, Miao and Maennel, Olaf and Chen, Weitong},
title = {Irregularity-Informed Time Series Analysis: Adaptive Modelling of Spatial and Temporal Dynamics},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679716},
doi = {10.1145/3627673.3679716},
abstract = {Irregular Time Series Data (IRTS) has shown increasing prevalence in real-world applications. We observed that IRTS can be divided into two specialized types: Natural Irregular Time Series (NIRTS) and Accidental Irregular Time Series (AIRTS). Various existing methods either ignore the impacts of irregular patterns or statically learn the irregular dynamics of NIRTS and AIRTS data and suffer from limited data availability due to the sparsity of IRTS. We proposed a novel transformer-based framework for general irregular time series data that treats IRTS from four views: Locality, Time, Spatio and Irregularity to motivate the data usage to the highest potential. Moreover, we design a sophisticated irregularity-gate mechanism to adaptively select task-relevant information from irregularity, which improves the generalization ability to various IRTS data. We implement extensive experiments to demonstrate the resistance of our work to three highly missing ratio datasets (88.4\%, 94.9\%, 60\% missing value) and investigate the significance of the irregularity information for both NIRTS and AIRTS by additional ablation study. We release our implementation in https://github.com/IcurasLW/MTSFormer-Irregular_Time_Series.git.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3405–3414},
numpages = {10},
keywords = {data mining, irregular time series data, medical machine learning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679544,
author = {Du, Kelvin and Mao, Rui and Xing, Frank and Cambria, Erik},
title = {Explainable Stock Price Movement Prediction using Contrastive Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679544},
doi = {10.1145/3627673.3679544},
abstract = {Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of "integrated textual information and quantitative indicators". We refer to the target past-l-day tweet-price time series as the "anchor instance". Each anchor instance is paired with a "positive instance" characterized by highly correlated return trends yet significant differences across the entire feature space, and a "negative instance" that exhibits similar return trends along with high proximity in the feature space. The model is designed with the objective of (1) minimizing the cross entropy loss between input logits and target, (2) minimizing the distance between the anchor instances and positive instances, and (3) maximizing the distance between the anchor instances and negative instances. Our framework's effectiveness is demonstrated through extensive testing, showing superior performance on stock prediction benchmarks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {529–537},
numpages = {9},
keywords = {AI, NLP, contrastive learning, explainability, stock price},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3663760,
author = {Zhuo, Xingrui and Qian, Shengsheng and Hu, Jun and Dai, Fuxin and Lin, Kangyi and Wu, Gongqing},
title = {Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3663760},
doi = {10.1145/3663760},
abstract = {A Session-Based Recommendation (SBR) seeks to predict users’ future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model’s ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M3T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M2T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M3T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.},
journal = {ACM Trans. Inf. Syst.},
month = jul,
articleno = {144},
numpages = {28},
keywords = {Session-based recommendation, multi-view intention fusion, memory Transformer, multi-hop graph embedding}
}

@inproceedings{10.1145/3711896.3737149,
author = {Han, Xiaolin and Zhang, Yikun and Ma, Chenhao and Song, Lingyun and Cheng, Reynold and Shang, Xuequn},
title = {TempASD: Temporal Anomalous Subgraph Discovery in Large-Scale Dynamic Financial Networks},
year = {2025},
isbn = {9798400714542},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711896.3737149},
doi = {10.1145/3711896.3737149},
abstract = {In this paper, we investigate the discovery of temporal anomalous subgraphs in large-scale financial networks, aiming to identify abnormal transaction behaviors among users over time. This task is crucial for the real-time detection of transaction anomalies in financial networks, such as money laundering and trading fraud. However, it poses significant challenges due to the diverse distribution of transactions, the dynamic nature of temporal networks, and the absence of theoretical foundation. To tackle these challenges, we introduce a novel Temporal Anomalous Subgraph Discovery (TempASD) algorithm with theoretical analysis. First, we propose a temporal candidate detection module that quickly pinpoints abnormal candidates by detecting anomalies in both the temporal structure and transaction distribution. Then, we introduce a carefully crafted reinforcement-learning-based refiner to optimize these candidates toward the most abnormal directions. We conducted extensive evaluations against thirteen advanced competitors. TempASD achieves an average improvement of 7x in abnormal degree compared to the state-of-the-art and is efficient in large-scale dynamic financial networks.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2},
pages = {826–837},
numpages = {12},
keywords = {dynamic networks, temporal anomalous subgraph discovery},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3627673.3679854,
author = {Lin, Li and Xia, Kaiwen and Zheng, Anqi and Hu, Shijie and Wang, Shuai},
title = {Hierarchical Spatio-Temporal Graph Learning Based on Metapath Aggregation for Emergency Supply Forecasting},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679854},
doi = {10.1145/3627673.3679854},
abstract = {Integrated Warehousing and Distribution Supply Networks (IWDSN) have shown their high efficiency in E-commerce. Efficient supply capacity prediction is crucial for logistics systems to maintain the delivery capacity to meet users' requirements. However, unforeseen events such as extreme weather and public health emergencies pose challenges in supply forecasting. Previous work mainly infers supply optimization based on the invariant topology of logistic networks, neglecting dynamic routing and distinct node effects reacting to emergencies. To address these challenges, the hierarchical relations among warehouses, sorting centers, and delivery stations in logistic networks are necessary to learn the diverse reactions. In this paper, we propose a hierarchical spatio-temporal graph learning model to predict the emergency supply capacity of IWDSN based on micro and macro graphs. The micro graph shows transportation connectivity while the macro graph shows the geographical correlation. Specifically, it consists of three components. (1) For micro graphs, a metapath aggregation strategy is designed to capture dynamic routing information on both route-view and event-view graphs. (2) For macro graphs, a bipartite graph learning approach to extract spatial representations. (3) For spatio-temporal feature fusion, the spatio-temporal joint forecasting module combines the temporal feature from the time-series encoder with hierarchical spatial features to predict the future supply capacity. The extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model, which achieves state-of-the-art performance compared with advanced baselines.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1410–1419},
numpages = {10},
keywords = {emergency supply network, heterogeneous information network, metapath aggregation, supply forecasting},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3652583.3658111,
author = {Li, Yilin and Guo, Tszyin and Qiao, Ying and Bo, Zitong and Wang, Hongan},
title = {FEST: A Multi-way Framework with Enhanced Spatial-Temporal Modeling for Traffic Forecasting},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658111},
doi = {10.1145/3652583.3658111},
abstract = {Accurately forecasting traffic flow using time-series data from multimedia sensors remains a significant challenge, despite its importance for advancing intelligent transportation systems. Recent advancements in attention-based models have shown promise in capturing spatial-temporal dependencies in traffic flow data. Yet, these models exhibit three principal limitations: (1) they employ either factorized or coupled spatial-temporal attention mechanisms, potentially failing to fully harness the potential of these distinct approaches; (2) the attention allocation for spatial nodes is predominantly data-centric, which may overlook existing knowledge about the nodes' importance within the transportation network; (3) while traditional attention-based methods effectively capture long-term dependencies, they often struggle with adapting to the disparate lengths of temporal contexts. To overcome these limitations, we introduce a multi-way framework dubbed FEST that innovatively integrates both factorized and coupled spatial-temporal attention mechanisms. We then enhance FEST by incorporating PageRank-derived node importance scores to guide focus on nodes. Moreover, a novel multi-scale temporal learning approach is proposed to improve model capability with both long- and short-term temporal dynamics. Extensive experiments on real-world datasets under long- and short-term prediction scenarios confirm the effectiveness of our method.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {599–607},
numpages = {9},
keywords = {forecasting, spatial-temporal, traffic flow},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3589132.3625631,
author = {W\"{o}lker, Yannick and Beth, Christian and Renz, Matthias and Biastoch, Arne},
title = {SUSTeR: Sparse Unstructured Spatio Temporal Reconstruction on Traffic Prediction},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3625631},
doi = {10.1145/3589132.3625631},
abstract = {Mining spatio-temporal correlation patterns for traffic prediction is a well-studied field. However, most approaches are based on the assumption of the availability of and accessibility to a sufficiently dense data source, which is rather the rare case in reality. Traffic sensors in road networks are generally highly sparse in their distribution: fleet-based traffic sensing is sparse in space but also sparse in time. There are also other traffic application, besides road traffic, like moving objects in the marine space, where observations are sparsely and arbitrarily distributed in space. In this paper, we tackle the problem of traffic prediction on sparse and spatially irregular and non-deterministic traffic observations. We draw a border between imputations and this work as we consider high sparsity rates and no fixed sensor locations. We advance correlation mining methods with a Sparse Unstructured Spatio Temporal Reconstruction (SUSTeR) framework that reconstructs traffic states from sparse non-stationary observations. For the prediction the framework creates a hidden context traffic state which is enriched in a residual fashion with each observation. Such an assimilated hidden traffic state can be used by existing traffic prediction methods to predict future traffic states. We query these states with query locations from the spatial domain.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {81},
numpages = {10},
keywords = {sparse data, spatio-temporal, unstructured observations, imputation, traffic prediction},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.1145/3732945.3732978,
author = {Yang, Yifan and Qu, Hua and Zhao, Jihong},
title = {Dynamic Routing Method for Integrated Satellite–Terrestrial Multi-Domain Networks Based on Transfer Learning},
year = {2025},
isbn = {9798400715204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3732945.3732978},
doi = {10.1145/3732945.3732978},
abstract = {With the development of communication technology and the diversification of users' needs, the space-earth integrated multi-domain network has become the core of modern communication system. However, rapidly changing topologies, frequent satellite switching, and heterogeneous traffic conditions can challenge classical deep reinforcement learning (DRL) algorithms, affecting real-time accuracy and robust convergence. Given that these networks continue to evolve, rapid adaptation is critical to maintaining data throughput and a seamless user experience. To solve these problems, this paper introduces STGT (Space-Ground Generative Transport), a novel dynamic routing framework that combines generative adversarial network (GAN) with near-end Policy Optimization (PPO) algorithm.STGT uses transfer learning to leverage the knowledge of previously trained models, reducing the training overhead under changing topological conditions. It can achieve stable convergence in the case of constant link fluctuation. Numerous experiments have shown that STGT outperforms leading DRL-based approaches, including PPO, DQN, SAP, and ospf, in terms of convergence speed, robustness, and flexibility. Notably, under the same constellation observed at different times, the STGT trained 5.7 times faster than the baseline PPO. As a result, STGT strikes a critical balance between adaptive speed and decision accuracy, resulting in stable, high-performance routing across a range of real-time conditions. These findings demonstrate that combining GAN and PPO through transfer learning effectively addresses dynamic routing challenges in satellite-ground integrated multi-domain networks, providing an efficient and scalable solution for real-world deployment.},
booktitle = {Proceedings of the 2025 4th International Conference on Intelligent Systems, Communications and Computer Networks},
pages = {216–227},
numpages = {12},
keywords = {Dynamic Routing, Integrated Satellite–Terrestrial, Multi-Domain Network, Transfer Learning},
location = {
},
series = {ISCCN '25}
}

@inproceedings{10.1145/3584871.3584872,
author = {Patel, Manali and Jariwala, Krupa and Chattopadhyay, Chiranjoy},
title = {Deep Learning techniques for stock market forecasting: Recent trends and challenges},
year = {2023},
isbn = {9781450398237},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584871.3584872},
doi = {10.1145/3584871.3584872},
abstract = {Stock market forecasting has been a very intensive area of research in recent years due to the highly uncertain and volatile nature of stock data which makes this task challenging. By accurately predicting a particular stock's price investors can gain maximum profit out of their investment. With the great success of Deep Learning methods in various domains, it has attracted the research community to apply these models for financial domain also. These DL methods have been proven to achieve better accuracy and predictions compared to econometric and traditional ML methods. This work reviews recent papers according to various Deep Learning models which included: Artificial Neural Networks, Convolution Neural Networks, Sequence to Sequence models, Generative Adversarial Networks, Graph Neural Networks and Transformers applied for stock market forecasting. Furthermore this work also reviews datasets, features, evaluation parameters and results of various methods. From the analysis done on various DL models we found that Graph Neural Networks and Transformer models have potential to interpret dynamic and non-linear patterns of financial time series data with greater accuracy. In addition to this, correlation among various stock indices and investors sentiment along with historical data has great influence on the prediction accuracy. We also identified the benchmark datasets for stock market forecasting based on market capitalization value of an economy. The aim of this paper is to provide insight into most recent work done in the finance domain and identify future directions for more accurate predictions.},
booktitle = {Proceedings of the 2023 6th International Conference on Software Engineering and Information Management},
pages = {1–11},
numpages = {11},
keywords = {Corporate relationship, Deep Learning, Graph Neural Networks, Sentiment analysis, Stock market forecasting, Transformers},
location = {Palmerston North, New Zealand},
series = {ICSIM '23}
}

@article{10.1145/3749156,
author = {Liao, Ningyi and Liu, Haoyu and Zhu, Zulun and Luo, Siqiang and Lakshmanan, Laks V.S.},
title = {A Comprehensive Benchmark on Spectral GNNs: The Impact on Efficiency, Memory, and Effectiveness},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
url = {https://doi.org/10.1145/3749156},
doi = {10.1145/3749156},
abstract = {With recent advancements in graph neural networks (GNNs), spectral GNNs have received increasing popularity by virtue of their ability to retrieve graph signals in the spectral domain. These models feature uniqueness in efficient computation as well as rich expressiveness, which stems from advanced management and profound understanding of graph data. However, few systematic studies have been conducted to assess spectral GNNs, particularly in benchmarking their efficiency, memory consumption, and effectiveness in a unified and fair manner. There is also a pressing need to select spectral models suitable for learning specific graph data and deploying them to massive web-scale graphs, which is currently constrained by the varied model designs and training settings.In this work, we extensively benchmark spectral GNNs with a focus on the spectral perspective, demystifying them as spectral graph filters. We analyze and categorize 35 GNNs with 27 corresponding filters, spanning diverse formulations and utilizations of the graph data. Then, we implement the filters within a unified spectral-oriented framework with dedicated graph computations and efficient training schemes. In particular, our implementation enables the deployment of spectral GNNs over million-scale graphs and various tasks with comparable performance and less overhead. Thorough experiments are conducted on the graph filters with comprehensive metrics on effectiveness and efficiency, offering novel observations and practical guidelines that are only available from our evaluations across graph scales. Different from the prevailing belief, our benchmark reveals an intricate landscape regarding the effectiveness and efficiency of spectral graph filters, demonstrating the potential to achieve desirable performance through tailored spectral manipulation of graph data.},
journal = {Proc. ACM Manag. Data},
month = sep,
articleno = {238},
numpages = {29},
keywords = {efficiency and scalability, graph neural networks, graph spectrum}
}

@inproceedings{10.1145/3580305.3599925,
author = {Liu, Hao and Jiang, Wenzhao and Liu, Shui and Chen, Xi},
title = {Uncertainty-Aware Probabilistic Travel Time Prediction for On-Demand Ride-Hailing at DiDi},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599925},
doi = {10.1145/3580305.3599925},
abstract = {Travel Time Estimation (TTE) aims to accurately forecast the expected trip duration from an origin to a destination. As one of the world's largest ride-hailing platforms, DiDi answers billions of TTE queries per day. The quality of TTE directly decides the customer's experience and the effectiveness of passenger-to-driver matching. However, existing studies mainly regard TTE as a deterministic regression problem and focus on improving the prediction accuracy of a single label, which overlooks the travel time uncertainty induced by various dynamic contextual factors. To this end, in this paper, we propose a probabilistic framework, ProbTTE, for uncertainty-aware travel time prediction. Specifically, the framework first transforms the single-label regression task to a multi-class classification problem to estimate the implicit travel time distribution. Moreover, we propose an adaptive local label-smoothing scheme to capture the ordinal inter-class relationship among soft travel time labels. Furthermore, we construct a route-wise log-normal distribution regularizer to absorb prior knowledge from large-scale historical trip data. By explicitly considering the travel uncertainty, the proposed approach not only improves the TTE accuracy but also provides additional travel time information to benefit downstream tasks in ride-hailing. Extensive experiments on real-world datasets demonstrate the superiority of the proposed framework compared with state-of-the-art travel time prediction algorithms. In addition, ProbTTE has been deployed in production at DiDi in late 2022 to empower various order dispatching services, and improves passenger and driver experiences significantly.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4516–4526},
numpages = {11},
keywords = {deep neural networks, order dispatching, probabilistic forecasting, travel time estimation},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3580305.3599934,
author = {Wang, Lu and Zhang, Chaoyun and Ding, Ruomeng and Xu, Yong and Chen, Qihang and Zou, Wentao and Chen, Qingjun and Zhang, Meng and Gao, Xuedong and Fan, Hao and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
title = {Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599934},
doi = {10.1145/3580305.3599934},
abstract = {In microservice systems, the identification of root causes of anomalies is imperative for service reliability and business impact. This process is typically divided into two phases: (i)constructing a service dependency graph that outlines the sequence and structure of system components that are invoked, and (ii) localizing the root cause components using the graph, traces, logs, and Key Performance Indicators (KPIs) such as latency. However, both phases are not straightforward due to the highly dynamic and complex nature of the system, particularly in large-scale commercial architectures like Microsoft Exchange.In this paper, we propose a new framework that employs Hierarchical Reinforcement Learning from Human Feedback (HRLHF) to address these challenges. Our framework leverages the static topology of the microservice system and efficiently employs the feedback of engineers to reduce uncertainty in the discovery of the service dependency graph. The framework utilizes reinforcement learning to reduce the number of queries required from O(N2) to O(1), enabling the construction of the dependency graph with high accuracy and minimal human effort. Additionally, we extend the discovered dependency graphs to window causal graphs that capture the characteristics of time series over a specified time period, resulting in improved root cause analysis accuracy and robustness. Evaluations on both real datasets from Microsoft Exchange and synthetic datasets with injected anomalies demonstrate superior performance on various metrics compared to state-of-the-art methods. It is worth mentioning that, our framework has been integrated as a crucial component in Microsoft M365 Exchange service.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5116–5125},
numpages = {10},
keywords = {causal discovery, reinforcement learning from human feedback, root cause analysis},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3534678.3539397,
author = {Liu, Dachuan and Wang, Jin and Shang, Shuo and Han, Peng},
title = {MSDR: Multi-Step Dependency Relation Networks for Spatial Temporal Forecasting},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539397},
doi = {10.1145/3534678.3539397},
abstract = {Spatial temporal forecasting plays an important role in improving the quality and performance of Intelligent Transportation Systems. This task is rather challenging due to the complicated and long-range spatial temporal dependencies in traffic network. Existing studies typically employ different deep neural networks to learn the spatial and temporal representations so as to capture the complex and dynamic dependencies. In this paper, we argue that it is insufficient to capture the long-range spatial dependencies from the implicit representations learned by temporal extracting modules. To address this problem, we propose Multi-Step Dependency Relation (MSDR), a brand new variant of recurrent neural network. Instead of only looking at the hidden state from only one latest time step, MSDR explicitly takes those of multiple historical time steps as the input of each time unit. We also develop two strategies to incur the spatial information into the dependency relation embedding between multiple historical time steps and the current one in MSDR. On the basis of it, we propose the Graph-based MSDR (GMSDR) framework to support general spatial temporal forecasting applications by seamlessly integrating graph-based neural networks with MSDR. We evaluate our proposed approach on several popular datasets. The results show that the proposed GMSDR framework outperforms state-of-the-art methods by an obvious margin.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1042–1050},
numpages = {9},
keywords = {multi-step dependency, neural networks, relation embedding, traffic forecasting},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3627673.3679610,
author = {Liu, Yuli and Liu, Min and Walder, Christian and Xie, Lexing},
title = {A Universal Sets-level Optimization Framework for Next Set Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679610},
doi = {10.1145/3627673.3679610},
abstract = {Next Set Recommendation (NSRec), encompassing related tasks such as next basket recommendation and temporal sets prediction, stands as a trending research topic. Although numerous attempts have been made on this topic, there are certain drawbacks: (i) Existing studies are still confined to utilizing objective functions commonly found in Next Item Recommendation (NIRec), such as binary cross entropy and BPR, which are calculated based on individual item comparisons; (ii) They place emphasis on building sophisticated learning models to capture intricate dependency relationships across sequential sets, but frequently overlook pivotal dependency in their objective functions; (iii) Diversity factor within sequential sets is frequently overlooked. In this research, we endeavor to unveil a universal and Sets-level optimization framework for Next Set Recommendation (SNSRec), offering a holistic fusion of diversity distribution and intricate dependency relationships within temporal sets. To realize this, the following contributions are made: (i) We directly model the temporal set in a sequence as a cohesive entity, leveraging the Structured Determinantal Point Process (SDPP), wherein the probabilistic DPP distribution prioritizes collections of structures (sequential sets) instead of individual items; (ii) We introduce a co-occurrence representation to discern and acknowledge the importance of different sets; (iii) We propose a sets-level optimization criterion, which integrates the diversity distribution and dependency relations across the entire sequence of sets, guiding the model to recommend relevant and diversified set. Extensive experiments on real-world datasets show that our approach consistently outperforms previous methods on both relevance and diversity.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1544–1554},
numpages = {11},
keywords = {next set prediction, optimization approach, sdpps},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1109/ASONAM55673.2022.10068595,
author = {Shen, Chen and Han, Chao and He, Lihong and Mukherjee, Arjun and Obradovic, Zoran and Dragut, Eduard},
title = {Session-Based News Recommendation from Temporal User Commenting Dynamics},
year = {2023},
isbn = {9781665456616},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASONAM55673.2022.10068595},
doi = {10.1109/ASONAM55673.2022.10068595},
abstract = {With the increase in volume of daily online news items, it is more and more difficult for readers to identify news articles relevant to their interests. Thus, effective recommendation systems are critical for an effective user news consumption experience. Existing news recommendation methods usually rely on the news click history to model user interest. However, there are other signals about user behaviors, such as user commenting activity, which have not been used before. We propose a recommendation algorithm that predicts articles a user may be interested in, given her historical sequential commenting behavior on news articles. We show that following this sequential user behavior the news recommendation problem falls into in the class of session-based recommendation. The techniques in this class seek to model users' sequential and temporal behaviors. While we seek to follow the general directions in this space, we face unique challenges specific to news in modeling temporal dynamics, e.g., users' interests shift over time, users comment irregularly on articles, and articles are perishable items with limited lifespans. We propose a recency-regularized neural attentive framework for session-based news recommendation. The proposed method is able to capture the temporal dynamics of both users and news articles, while maintaining interpretability. We design a lag-aware attention and a recency regularization to model the time effect of news articles and comments. We conduct extensive empirical studies on 3 real-world news datasets to demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {163–170},
numpages = {8},
keywords = {recommender systems, neural networks, session based recommendation},
location = {Istanbul, Turkey},
series = {ASONAM '22}
}

@inproceedings{10.1145/3678717.3691237,
author = {Gao, Qiang and Wang, Zizheng and Huang, Li and Trajcevski, Goce and Zhang, Kunpeng and Chen, Xueqin},
title = {Enhancing Dependency Dynamics in Traffic Flow Forecasting via Graph Risk Bootstrap},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691237},
doi = {10.1145/3678717.3691237},
abstract = {Graph neural networks, as well as attention mechanisms, have gained widespread popularity for traffic flow forecasting due to their capacity to incorporate the complicated interactions behind flow dynamics. However, existing solutions either formulate a graph-based skeleton with narrow (e.g., static) interaction capture or build the spatiotemporal (e.g., dynamic) attention without proper comprehension of diverse risks, which inevitably burdens the generalization of high-accuracy traffic trends. In this study, we introduce Gboot (Graph bootstrap) enhancement framework for traffic flow forecasting. Gboot takes the traffic flow forecasting problem from a dependency dynamic learning perspective by treating each traffic sensor as the graph node while regarding the observed flows at each sensor as the node feature. In addition to exposing the explicit spatial connectivity behind traffic flows, we hierarchically devise temporal-aware and factual-aware graph learning blocks to consider temporal interactive dynamics and factual interactive dynamics. The former shows the trend dependencies behind flow signals and the latter uncovers different views of traffic situations (e.g., current observation vs. historical observation). More importantly, we present a Dual-view Bootstrap (DvBoot) mechanism in Gboot, which includes both risk-free and risk-aware stands. DvBoot attempts to flexibly align these two views in the latent space to enhance the generalization capability of capturing dynamic dependencies. Experiments on several real-world traffic datasets demonstrate the superiority of our Gboot over representative approaches.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {147–159},
numpages = {13},
keywords = {bootstrap learning, dependency dynamics, exponential moving average, risk enhancement, traffic flow forecasting},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3578741.3578757,
author = {Xie, Huo Shen and Wang, Weijie},
title = {Long Short-term Dynamic Graph Neural Networks: for short-term intense rainfall forecasting},
year = {2023},
isbn = {9781450399067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578741.3578757},
doi = {10.1145/3578741.3578757},
abstract = {In practice, accurate and timely forecasting of short-term intense rainfall is critical, but the problem is extremely difficult because to its complicated spatial-temporal association. Although several spatial-temporal series forecasting methods have been used to rainfall prediction, these models continue to suffer from inadequate modeling of data’s complicated intrinsic connection. We provide a new short-term intense rainfall prediction model that use two graph generators to model data correlations under distinct semantics, followed by a graph convolution module for information integration to fully extract data spatial-temporal information. Finally, a variant of recurrent neural network is employed to extract the temporal dependence. The experimental results on both datasets show that the model can model the spatial and temporal dependence across the data more effectively than the baseline model, and further improve the model’s predictive performance for short-term intense rainfall.},
booktitle = {Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing},
pages = {74–80},
numpages = {7},
keywords = {Graph Convolution, Short-term intense rainfall, spatial-temporal correlation},
location = {Sanya, China},
series = {MLNLP '22}
}

@inproceedings{10.1145/3447548.3467275,
author = {Han, Liangzhe and Du, Bowen and Sun, Leilei and Fu, Yanjie and Lv, Yisheng and Xiong, Hui},
title = {Dynamic and Multi-faceted Spatio-temporal Deep Learning for Traffic Speed Forecasting},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467275},
doi = {10.1145/3447548.3467275},
abstract = {Dynamic Graph Neural Networks (DGNNs) have become one of the most promising methods for traffic speed forecasting. However, when adapting DGNNs for traffic speed forecasting, existing approaches are usually built on a static adjacency matrix (no matter predefined or self-learned) to learn spatial relationships among different road segments, even if the impact of two road segments can be changeable dynamically during a day. Moreover, the future traffic speed cannot only be related with the current traffic speed, but also be affected by other factors such as traffic volumes. To this end, in this paper, we aim to explore these dynamic and multi-faceted spatio-temporal characteristics inherent in traffic data for further unleashing the power of DGNNs for better traffic speed forecasting. Specifically, we design a dynamic graph construction method to learn the time-specific spatial dependencies of road segments. Then, a dynamic graph convolution module is proposed to aggregate hidden states of neighbor nodes to focal nodes by message passing on the dynamic adjacency matrices. Moreover, a multi-faceted fusion module is provided to incorporate the auxiliary hidden states learned from traffic volumes with the primary hidden states learned from traffic speeds. Finally, experimental results on real-world data demonstrate that our method can not only achieve the state-of-the-art prediction performances, but also obtain the explicit and interpretable dynamic spatial relationships of road segments.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {547–555},
numpages = {9},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@article{10.1145/3759440,
author = {E, Subha and V, Jothi Prakash and S, Arul Antran Vijay},
title = {A Graph-Based Framework for Temporal and Causal Analysis of Sentiments},
year = {2025},
issue_date = {November 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3759440},
doi = {10.1145/3759440},
abstract = {This research aims to develop a novel framework that uncovers the causal influence of global events on public sentiment through temporal graph modeling and neural causal inference. Global events, such as pandemics, elections, and economic crises, profoundly affect public sentiments, shaping social behaviors and economic outcomes. Traditional models often fall short in capturing the complex, dynamic, and non-linear relationships between these events and sentiments. This article presents the Neural Temporal Causal Graph Network (NTCGN), a unified framework that integrates temporal graph neural networks with a Causal Attention Network (CAN) to model and interpret these relationships. NTCGN constructs a temporal graph from event data and sentiment-labeled texts, learning dependencies and causal influences through advanced neural architectures. A thorough comparative analysis with state-of-the-art models such as Logistic Regression, SVM, LSTM, and transformer-based models demonstrates NTCGN’s superior performance. Experimental evaluation using the Sentiment140 and Global Database of Events, Language and Tone (GDELT) 2.0 datasets shows NTCGN achieving an accuracy of 0.798 and an F1 score of 0.795, outperforming these baseline models. The model’s causal inference capabilities are validated using the Causal Impact Score (CIS) and Causal Discovery Precision (CDP), highlighting its reliability in identifying true causal links. Visualizations of attention maps and causal pathways enhance interpretability, demonstrating how specific events influence public sentiments. This work provides a robust and interpretable tool for analyzing event-driven sentiment dynamics in real-world applications.},
journal = {ACM Trans. Web},
month = oct,
articleno = {47},
numpages = {31},
keywords = {Temporal graph neural networks, causal inference, sentiment analysis, event-sentiment dynamics, attention mechanisms, causal graphs, deep learning, interpretability}
}

@inproceedings{10.1145/3366423.3380296,
author = {Wu, Xian and Huang, Chao and Zhang, Chuxu and Chawla, Nitesh V.},
title = {Hierarchically Structured Transformer Networks for Fine-Grained Spatial Event Forecasting},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380296},
doi = {10.1145/3366423.3380296},
abstract = {Spatial event forecasting is challenging and crucial for urban sensing scenarios, which is beneficial for a wide spectrum of spatial-temporal mining applications, ranging from traffic management, public safety, to environment policy making. In spite of significant progress has been made to solve spatial-temporal prediction problem, most existing deep learning based methods based on a coarse-grained spatial setting and the success of such methods largely relies on data sufficiency. In many real-world applications, predicting events with a fine-grained spatial resolution do play a critical role to provide high discernibility of spatial-temporal data distributions. However, in such cases, applying existing methods will result in weak performance since they may not well capture the quality spatial-temporal representations when training triple instances are highly imbalanced across locations and time. To tackle this challenge, we develop a hierarchically structured Spatial-Temporal ransformer network (STtrans) which leverages a main embedding space to capture the inter-dependencies across time and space for alleviating the data imbalance issue. In our STtrans framework, the first-stage transformer module discriminates different types of region and time-wise relations. To make the latent spatial-temporal representations be reflective of the relational structure between categories, we further develop a cross-category fusion transformer network to endow STtrans with the capability to preserve the semantic signals in a fully dynamic manner. Finally, an adversarial training strategy is introduced to yield a robust spatial-temporal learning under data imbalance. Extensive experiments on real-world imbalanced spatial-temporal datasets from NYC and Chicago demonstrate the superiority of our method over various state-of-the-art baselines.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {2320–2330},
numpages = {11},
keywords = {Deep neural networks, Spatial-temporal data mining},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@article{10.1145/3725893,
author = {Souli, Nikolas and Katzanis, Panagiotis and Kardaras, Panayiotis and Grigoriou, Yiannis and Stavrinides, Stavros G. and Kolios, Panayiotis and Ellinas, Georgios},
title = {An Onboard UAV Multi-task System for Trajectory Prediction and State Estimation Employing Transformer- and Reservoir-based Networks},
year = {2025},
issue_date = {December 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
url = {https://doi.org/10.1145/3725893},
doi = {10.1145/3725893},
abstract = {With the increasing technological advancements and deployment of unmanned aerial vehicles (UAVs) in different applications (e.g., delivery services, surveillance, critical infrastructure monitoring, military operations, and search-and-rescue operations), a robust, lightweight, and accurate system for UAV state identification and trajectory prediction is becoming a mandate. This work introduces an onboard real-time multi-task learning framework that combines Transformer neural networks and reservoir computing (RC) architectures to enhance outdoor UAV operations. The proposed system employs the Transformer-based architecture to capture the temporal dependencies in sequential data for long-term horizons, while RC-based networks are utilized to ensure robust and real-time performance. Specifically, custom multi-task models are implemented and fine-tuned to collect multi-modal sensor measurements, aiming to enhance the two-fold objective of simultaneous UAV state identification and trajectory prediction through shared feature learning. A dataset comprised of measurements collected from real-world UAV operations (in 3D space) under various conditions is employed to train and evaluate the proposed system. Furthermore, a prototype onboard UAV system is implemented and tested in real-world field experiments. Extensive evaluations of the experimental results demonstrate that the onboard framework achieves accuracy close to the ground truth in both state identification and trajectory prediction, consequently showcasing its potential for practical applications.},
journal = {ACM J. Auton. Transport. Syst.},
month = jun,
articleno = {18},
numpages = {33},
keywords = {Machine learning, multi-task learning, trajectory prediction, state identification, UAV applications, Transformers, Reservoir Computing}
}

@inproceedings{10.1145/3583780.3614810,
author = {Wang, XiaoYu and Guo, YongHui and Ma, Xiaoyang and Huang, Dongbo and Xu, Lan and Tan, Haisheng and Zhou, Hao and Li, Xiang-Yang},
title = {CLOCK: Online Temporal Hierarchical Framework for Multi-scale Multi-granularity Forecasting of User Impression},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614810},
doi = {10.1145/3583780.3614810},
abstract = {User impression forecasting underpins various commercial activities, from long-term strategic decisions to short-term automated operations. As a representative that involves both kinds, the highly profitable Guaranteed Delivery (GD) advertising focuses mainly on promoting brand effect by allowing advertisers to order target impressions weeksin advance and get allocatedonline at the scheduled time. Such a business mode naturally incurs three issues making existing solutions inferior: 1) Timescale-granularity dilemma of coherently supporting the sales of day-level impressions of the distant future and the corresponding fine-grained allocation in real-time. 2) High dimensionality due to the Cartesian product of user attribute combinations. 3) Stability-plasticity dilemma of instant adaptation to emerging patterns of temporal dependency withoutcatastrophic forgetting of repeated ones facing the non-stationary traffic.To overcome the obstacles, we propose an online temporal hierarchical framework that functions analogously to a CLOCK and hence its name. Long-timescale, coarse-grained temporal data (e.g., the daily impression of one quarter) and short-timescale but fine-grained ones are handled separately by dedicated models, just like the hour/minute/second hands. Each tier in the hierarchy is triggered for forecasting and updating by need at different frequencies, thus saving the maintenance overhead. Furthermore, we devise a reconciliation mechanism to coordinate tiers by aggregating the separately learned local variance and global trends tier by tier. CLOCK solves the dimensionality dilemma by subsuming the autoencoder design to achieve an end-to-end, nonlinear factorization of streaming data into a low-dimension latent space, where a neural predictor produces predictions for the decoder to project them back to the high dimension. Lastly, we regulate the CLOCK's continual refinement by combining the complementary Experience Replay (ER) and Knowledge Distillation (KD) techniques to consolidate and recall previously learned temporal patterns. We conduct extensive evaluations on three public datasets and the real-life user impression log from the Tencent advertising system, and the results demonstrate CLOCK's efficacy.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {2544–2553},
numpages = {10},
keywords = {display advertising, hierarchical forecasting, multivariate time series, online learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3539618.3591784,
author = {Zhang, Zhao and Guan, Zhanpeng and Zhang, Fuwei and Zhuang, Fuzhen and An, Zhulin and Wang, Fei and Xu, Yongjun},
title = {Weighted Knowledge Graph Embedding},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591784},
doi = {10.1145/3539618.3591784},
abstract = {Knowledge graph embedding (KGE) aims to project both entities and relations in a knowledge graph (KG) into low-dimensional vectors. Indeed, existing KGs suffer from the data imbalance issue, i.e., entities and relations conform to a long-tail distribution, only a small portion of entities and relations occur frequently, while the vast majority of entities and relations only have a few training samples. Existing KGE methods assign equal weights to each entity and relation during the training process. Under this setting, long-tail entities and relations are not fully trained during training, leading to unreliable representations. In this paper, we propose WeightE, which attends differentially to different entities and relations. Specifically, WeightE is able to endow lower weights to frequent entities and relations, and higher weights to infrequent ones. In such manner, WeightE is capable of increasing the weights of long-tail entities and relations, and learning better representations for them. In particular, WeightE tailors bilevel optimization for the KGE task, where the inner level aims to learn reliable entity and relation embeddings, and the outer level attempts to assign appropriate weights for each entity and relation. Moreover, it is worth noting that our technique of applying weights to different entities and relations is general and flexible, which can be applied to a number of existing KGE models. Finally, we extensively validate the superiority of WeightE against various state-of-the-art baselines.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {867–877},
numpages = {11},
keywords = {bilevel optimization, knowledge graph embedding, link prediction},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3459637.3482413,
author = {Uddin, Ajim and Tao, Xinyuan and Yu, Dantong},
title = {Attention Based Dynamic Graph Learning Framework for Asset Pricing},
year = {2021},
isbn = {9781450384469},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3459637.3482413},
doi = {10.1145/3459637.3482413},
abstract = {Recent studies suggest that financial networks play an essential role in asset valuation and investment decisions. Unlike road networks, financial networks are neither given nor static, posing significant challenges in learning meaningful networks and promoting their applications in price prediction. In this paper, we first apply the attention mechanism to connect the "dots" (firms) and learn dynamic network structures among stocks over time. Next, the end-to-end graph neural networks pipeline diffuses and propagates the firms' accounting fundamentals into the learned networks and ultimately predicts stock future returns. The proposed model reduces the prediction errors by 6\% compared to the state-of-the-art models. Our results are robust with different assessment measures. We also show that portfolios based on our model outperform the S&amp;P-500 index by 34\% in terms of Sharpe Ratio, suggesting that our model is better at capturing the dynamic inter-connection among firms and identifying stocks with fast recovery from major events. Further investigation on the learned networks reveals that the network structure aligns closely with the market conditions. Finally, with an ablation study, we investigate different alternative versions of our model and the contribution of each component.},
booktitle = {Proceedings of the 30th ACM International Conference on Information \&amp; Knowledge Management},
pages = {1844–1853},
numpages = {10},
keywords = {asset pricing, diffusion recurrent convolution, fintech, graph attention, graph neural networks, stock price prediction},
location = {Virtual Event, Queensland, Australia},
series = {CIKM '21}
}

@inproceedings{10.1145/3477314.3507035,
author = {Lucchese, Claudio and Callegher, Gianmarco and Modenese, Mirko and Dassi\`{e}, Silvia},
title = {A comparison of spatio-temporal prediction methods: a parking availability case study},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507035},
doi = {10.1145/3477314.3507035},
abstract = {In this paper, we present a comparative analysis of Statistical, Machine Learning and Deep Learning spatio-temporal models for parking occupancy prediction1. We evaluate such models on three public datasets, which are enriched by a set of hand-crafted features to take into account the temporal and spatial components when they are not natively handled by a model. Two approaches for this regression task are investigated: a univariate one and a multivariate one. In the former, we build a separate model for each parking lot. In the latter, a single model is used to predict the availability of all parking lots so as to learn the interactions and the co-movements among all time-series. All models exhibit similar performance. However, we highlight the higher effectiveness of gradient boosted methods when encompassing both temporal and spatial awareness in the feature space and of deep-learning models that take into account the spatial structure of the data.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {1013–1020},
numpages = {8},
keywords = {GAM, GBDT, GCNN, RNN, VAR, parking occupancy},
location = {Virtual Event},
series = {SAC '22}
}

@inproceedings{10.1145/3637528.3671929,
author = {Ma, Xiaoxiao and Li, Ruikun and Liu, Fanzhen and Ding, Kaize and Yang, Jian and Wu, Jia},
title = {Graph Anomaly Detection with Few Labels: A Data-Centric Approach},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671929},
doi = {10.1145/3637528.3671929},
abstract = {Anomalous node detection in a static graph faces significant challenges due to the rarity of anomalies and the substantial cost of labeling their deviant structure and attribute patterns. These challenges give rise to data-centric problems, including extremely imbalanced data distributions and intricate graph learning, which significantly impede machine learning and deep learning methods from discerning the patterns of graph anomalies with few labels. While these issues remain crucial, much of the current research focuses on addressing the induced technical challenges, treating the shortage of labeled data as a given. Distinct from previous efforts, this work focuses on tackling the data-centric problems by generating auxiliary training nodes that conform to the original graph topology and attribute distribution. We categorize this approach as data-centric, aiming to enhance existing anomaly detectors by training them on our synthetic data. However, the methods for generating nodes and the effectiveness of utilizing synthetic data for graph anomaly detection remain unexplored in the realm. To answer these questions, we thoroughly investigate the denoising diffusion model. Drawing from our observations on the diffusion process, we illuminate the shifts in graph energy distribution and establish two principles for designing denoising neural networks tailored to graph anomaly generation. From the insights, we propose a diffusion-based graph generation method to synthesize training nodes, which can be promptly integrated to work with existing anomaly detectors. The empirical results on eight widely-used datasets demonstrate our generated data can effectively enhance the nine state-of-the-art graph detectors' performance.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2153–2164},
numpages = {12},
keywords = {generative graph diffusion, graph anomaly detection},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3649142,
author = {Chen, April and Rossi, Ryan A. and Park, Namyong and Trivedi, Puja and Wang, Yu and Yu, Tong and Kim, Sungchul and Dernoncourt, Franck and Ahmed, Nesreen K.},
title = {Fairness-Aware Graph Neural Networks: A Survey},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3649142},
doi = {10.1145/3649142},
abstract = {Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. We categorize these techniques by whether they focus on improving fairness in the pre-processing, in-processing (during training), or post-processing phases. We discuss how such techniques can be used together whenever appropriate and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics, including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {138},
numpages = {23},
keywords = {Fairness, Bias, Graph Neural Networks}
}

@inproceedings{10.1145/3448016.3457564,
author = {Wang, Xuhong and Lyu, Ding and Li, Mengjian and Xia, Yang and Yang, Qi and Wang, Xinwen and Wang, Xinguang and Cui, Ping and Yang, Yupu and Sun, Bowen and Guo, Zhenyu},
title = {APAN: Asynchronous Propagation Attention Network for Real-time Temporal Graph Embedding},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457564},
doi = {10.1145/3448016.3457564},
abstract = {To capture higher-order structural features, most GNN-based algorithms learn node representations incorporating k-hop neighbors' information. Due to the high time complexity of querying k-hop neighbors, most graph algorithms cannot be deployed in a giant dense temporal network to execute millisecond-level inference. This problem dramatically limits the potential of applying graph algorithms in certain areas, especially financial fraud detection. Therefore, we propose Asynchronous Propagation Attention Network, an asynchronous continuous time dynamic graph algorithm for real-time temporal graph embedding. Traditional graph models usually execute two serial operations: first graph querying and then model inference. Different from previous graph algorithms, we decouple model inference and graph computation to alleviate the damage of the heavy graph query operation to the speed of model inference. Extensive experiments demonstrate that the proposed method can achieve competitive performance while greatly improving the inference speed. The source code is published at a Github repository.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {2628–2638},
numpages = {11},
keywords = {dynamic graph, graph neural networks, network embedding},
location = {Virtual Event, China},
series = {SIGMOD '21}
}

@article{10.1145/3643748,
author = {Huang, Haiyu and Zhang, Xiaoyu and Chen, Pengfei and He, Zilong and Chen, Zhiming and Yu, Guangba and Chen, Hongyang and Sun, Chen},
title = {TraStrainer: Adaptive Sampling for Distributed Traces with System Runtime State},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643748},
doi = {10.1145/3643748},
abstract = {Distributed tracing has been widely adopted in many microservice systems and plays an important role in monitoring and analyzing the system. However, trace data often come in large volumes, incurring substantial computational and storage costs. To reduce the quantity of traces, trace sampling has become a prominent topic of discussion, and several methods have been proposed in prior work. To attain higher-quality sampling outcomes, biased sampling has gained more attention compared to random sampling. Previous biased sampling methods primarily considered the importance of traces based on diversity, aiming to sample more edge-case traces and fewer common-case traces. However, we contend that relying solely on trace diversity for sampling is insufficient, system runtime state is another crucial factor that needs to be considered, especially in cases of system failures. In this study, we introduce TraStrainer, an online sampler that takes into account both system runtime state and trace diversity. TraStrainer employs an interpretable and automated encoding method to represent traces as vectors. Simultaneously, it adaptively determines sampling preferences by analyzing system runtime metrics. When sampling, it combines the results of system-bias and diversity-bias through a dynamic voting mechanism. Experimental results demonstrate that TraStrainer can achieve higher quality sampling results and significantly improve the performance of downstream root cause analysis (RCA) tasks. It has led to an average increase of 32.63\% in Top-1 RCA accuracy compared to four baselines in two datasets.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {22},
numpages = {21},
keywords = {biased sampling, distributed tracing, microservice}
}

@article{10.1145/3715908,
author = {Li, Jia and Tao, Chongyang and Li♂, Jia and Li, Ge and Jin, Zhi and Zhang, Huangzhao and Fang, Zheng and Liu, Fang},
title = {Large Language Model-Aware In-Context Learning for Code Generation},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715908},
doi = {10.1145/3715908},
abstract = {Large Language Models (LLMs) have shown impressive In-Context Learning (ICL) ability in code generation. LLMs take a prompt context consisting of a few demonstration examples and a new requirement as input, and output new programs without any parameter update. Existing studies have found that the performance of ICL-based code generation heavily depends on the quality of demonstration examples and thus arises research on selecting demonstration examples: given a new requirement, a few demonstration examples are selected from a candidate pool, where LLMs are expected to learn the pattern hidden in these selected demonstration examples. Existing approaches are mostly based on heuristics or randomly selecting examples. However, the distribution of randomly selected examples usually varies greatly, making the performance of LLMs less robust. The heuristics retrieve examples by only considering textual similarities of requirements, leading to sub-optimal performance.To fill this gap, we propose a Large language model-Aware selection approach for In-context-Learning-based code generation named LAIL. LAIL uses LLMs themselves to select examples. It requires LLMs themselves to label a candidate example as a positive example or a negative example for a requirement. Positive examples are helpful for LLMs to generate correct programs, while negative examples are trivial and should be ignored. Based on the labeled positive and negative data, LAIL trains a model-aware retriever to learn the preference of LLMs and select demonstration examples that LLMs need. During the inference, given a new requirement, LAIL uses the trained retriever to select a few examples and feed them into LLMs to generate desired programs. We apply LAIL to four widely used LLMs and evaluate it on five code generation datasets. Extensive experiments demonstrate that LAIL outperforms the State-of-the-Art (SOTA) baselines by 11.58\%, 3.33\%, and 5.07\% on CodeGen-Multi-16B, 1.32\%, 2.29\%, and 1.20\% on CodeLlama-34B, and achieves 4.38\%, 2.85\%, and 2.74\% improvements on Text-davinci-003 in terms of Pass@1 at MBJP, MBPP, and MBCPP, respectively. In addition to function-level code generation, LAIL improves the performance of LLMs on DevEval, a repository-level code generation dataset, which achieves 10.04\%, 8.12\%, and 4.63\% improvements compared to the SOTA baselines at Pass@1, 3, and 5 on CodeLlama-7B. Human evaluation further verifies that the generated programs of LAIL are superior in correctness, code quality, and maintainability. Besides, LAIL has satisfactory transferability across different LLMs and datasets, where the retriever learned on one LLM (dataset) can be transferred to other LLMs (datasets).},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {190},
numpages = {33},
keywords = {Code generation, in-context-learning, large language model}
}

@inproceedings{10.1145/3605573.3605583,
author = {Tairin, Suraiya and Shen, Haiying and Zhang, Zeyu},
title = {Embracing Uncertainty for Equity in Resource Allocation in ML Training},
year = {2023},
isbn = {9798400708435},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605573.3605583},
doi = {10.1145/3605573.3605583},
abstract = {To reduce the Deep Learning (DL) model training time and hence resource consumption, it is critical to avoid stragglers. However, the dynamics and uncertainty features of resource availability pose a challenge to avoiding stragglers caused. To handle this challenge, we propose a Straggler-Avoiding job Scheduling approach (SAS), which smartly ensures that the tasks of a job receive resources with similar dynamics and uncertainty so that the tasks can complete at approximately the same time. Specifically, SAS uses an ML method to predict available resource amounts with probability in future times, groups nodes with similar available resource amounts and probabilities, and then assigns each job to one node group with the objective of minimizing job completion time (JCT). To reduce the decision making time, we also propose a reinforcement learning (RL) based scheduling approach (SAS-RL) that assigns each job to a node group. In addition, we propose a distributed parameter server (PS) load reassignment method to handle PS stragglers. Our trace-driven real experiments show that SAS reduce up to 45\% JCT and 63\% stragglers compared with existing job schedulers, and our PS load reassignment reduces up to 48\% JCT compared with the previous PS load distribution scheme.},
booktitle = {Proceedings of the 52nd International Conference on Parallel Processing},
pages = {423–432},
numpages = {10},
location = {Salt Lake City, UT, USA},
series = {ICPP '23}
}

@article{10.1145/3478099,
author = {Huang, Huiqun and Yang, Xi and He, Suining},
title = {Multi-Head Spatio-Temporal Attention Mechanism for Urban Anomaly Event Prediction},
year = {2021},
issue_date = {Sept 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
url = {https://doi.org/10.1145/3478099},
doi = {10.1145/3478099},
abstract = {Timely forecasting the urban anomaly events in advance is of great importance to the city management and planning. However, anomaly event prediction is highly challenging due to the sparseness of data, geographic heterogeneity (e.g., complex spatial correlation, skewed spatial distribution of anomaly events and crowd flows), and the dynamic temporal dependencies.In this study, we propose M-STAP, a novel Multi-head Spatio-Temporal Attention Prediction approach to address the problem of multi-region urban anomaly event prediction. Specifically, M-STAP considers the problem from three main aspects: (1) extracting the spatial characteristics of the anomaly events in different regions, and the spatial correlations between anomaly events and crowd flows; (2) modeling the impacts of crowd flow dynamic of the most relevant regions in each time step on the anomaly events; and (3) employing attention mechanism to analyze the varying impacts of the historical anomaly events on the predicted data. We have conducted extensive experimental studies on the crowd flows and anomaly events data of New York City, Melbourne and Chicago. Our proposed model shows higher accuracy (41.91\% improvement on average) in predicting multi-region anomaly events compared with the state-of-the-arts.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {104},
numpages = {21},
keywords = {anomaly event prediction, crowd flow, multi-head self-attention}
}

@article{10.1145/3469437,
author = {Zhao, Qi and Chen, Chuqiao and Liu, Guangcan and Liu, Qingshan and Chen, Shengyong},
title = {Parallel Connected LSTM for Matrix Sequence Prediction with Elusive Correlations},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3469437},
doi = {10.1145/3469437},
abstract = {This article is about a challenging problem called matrix sequence prediction, which is motivated from the application of taxi order prediction. Remarkably, the problem differs greatly from previous sequence prediction tasks in the sense that the time-wise correlations are quite elusive; namely, distant entries could be strongly correlated and nearby entries are unnecessarily related. Such distinct specifics make prevalent convolution-recurrence-based methods inadequate to apply. To remedy this trouble, we propose a novel architecture called Parallel Connected LSTM (PcLSTM), which integrates two new mechanisms, Multi-channel Linearized Connection (McLC) and Adaptive Parallel Unit (APU), into the framework of LSTM. Benefiting from the strengths of McLC and APU, our PcLSTM is able to handle well both the elusive correlations within each timestamp and the temporal dependencies across different timestamps, achieving state-of-the-art performance in a set of experiments demonstrated on synthetic and real-world datasets.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = aug,
articleno = {51},
numpages = {16},
keywords = {Sequence prediction, long short-term memory, attention mechanism, temporal dependencies}
}

@inproceedings{10.1145/3447548.3467157,
author = {Schwabe, Amray and Persson, Joel and Feuerriegel, Stefan},
title = {Predicting COVID-19 Spread from Large-Scale Mobility Data},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467157},
doi = {10.1145/3447548.3467157},
abstract = {To manage the COVID-19 epidemic effectively, decision-makers in public health need accurate forecasts of case numbers. A potential near real-time predictor of future case numbers is human mobility; however, research on the predictive power of mobility is lacking. To fill this gap, we introduce a novel model for epidemic forecasting based on mobility data, called mobility marked Hawkes model. The proposed model consists of three components: (1) A Hawkes process captures the transmission dynamics of infectious diseases. (2) A mark modulates the rate of infections, thus accounting for how the reproduction number R varies across space and time. The mark is modeled using a regularized Poisson regression based on mobility covariates. (3) A correction procedure incorporates new cases seeded by people traveling between regions. Our model was evaluated on the COVID-19 epidemic in Switzerland. Specifically, we used mobility data from February through April 2020, amounting to approximately 1.5 billion trips. Trip counts were derived from large-scale telecommunication data, i.e., cell phone pings from the Swisscom network, the largest telecommunication provider in Switzerland. We compared our model against various state-of-the-art baselines in terms of out-of-sample root mean squared error. We found that our model outperformed the baselines by 15.52\%. The improvement was consistently achieved across different forecast horizons between 5 and 21 days. In addition, we assessed the predictive power of conventional point of interest data, confirming that telecommunication data is superior. To the best of our knowledge, our work is the first to predict the spread of COVID-19 from telecommunication data. Altogether, our work contributes to previous research by developing a scalable early warning system for decision-makers in public health tasked with controlling the spread of infectious diseases.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \&amp; Data Mining},
pages = {3531–3539},
numpages = {9},
keywords = {COVID-19, Hawkes process, epidemic forecasting, mobility data, telecommunication data},
location = {Virtual Event, Singapore},
series = {KDD '21}
}

@inproceedings{10.1145/3474085.3475495,
author = {Cheng, Yingying and Zhang, Fan and Hu, Gang and Wang, Yiwen and Yang, Hanhui and Zhang, Gong and Cheng, Zhuo},
title = {Block Popularity Prediction for Multimedia Storage Systems Using Spatial-Temporal-Sequential Neural Networks},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475495},
doi = {10.1145/3474085.3475495},
abstract = {Predicting block popularity is of crucial importance for data placement in multi-tiered multimedia storage systems. Traditional methods, such as least recently used and exponential smoothing, are commonly employed to predict future block access frequencies and fail to achieve good performance for complex and changing access patterns. Recently, deep neural networks have brought great success to pattern recognition and prediction, which motivates us to introduce deep learning to solve the problem of block popularity prediction. In this paper, we first analyze and verify the temporal and spatial correlations among the multimedia I/O traces. Then, we design a multi-dimension feature to capture such correlations, which serves as the input of the designed deep neural network. A spatial-temporal-sequential neural network (STSNN) and its variants that capture the locality information, time dependency information, and block sequential information are proposed to predict the block popularity. We systematically evaluate our STSNN models against six baseline models from three different categories, i.e., heuristic methods, regression methods and neural network-based methods. Experiment results show that our proposed STSNN models are very promising for predicting block access frequencies under some of Huawei and Microsoft datasets and particularly achieve 2-6 times better performance compared with the baselines in terms of the I/O hit ratio, I/O recall rate and I/O prediction ratio under the Microsoft 64 MB-block dataset.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {3390–3398},
numpages = {9},
keywords = {block popularity prediction, deep neural networks, hot data prediction, multi-tiered multimedia storage},
location = {Virtual Event, China},
series = {MM '21}
}

@inproceedings{10.1145/3442381.3450116,
author = {Hsieh, Tsung-Yu and Sun, Yiwei and Tang, Xianfeng and Wang, Suhang and Honavar, Vasant G.},
title = {SrVARM: State Regularized Vector Autoregressive Model for Joint Learning of Hidden State Transitions and State-Dependent Inter-Variable Dependencies from Multi-variate Time Series},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3450116},
doi = {10.1145/3442381.3450116},
abstract = {Many applications, e.g., healthcare, education, call for effective methods methods for constructing predictive models from high dimensional time series data where the relationship between variables can be complex and vary over time. In such settings, the underlying system undergoes a sequence of unobserved transitions among a finite set of hidden states. Furthermore, the relationships between the observed variables and their temporal dynamics may depend on the hidden state of the system. To further complicate matters, the hidden state sequences underlying the observed data from different individuals may not be aligned relative to a common frame of reference. Against this background, we consider the novel problem of jointly learning the state-dependent inter-variable relationships as well as the pattern of transitions between hidden states from multi-variate time series data. To solve this problem, we introduce the State-Regularized Vector Autoregressive Model (SrVARM) which combines a state-regularized recurrent neural network to learn the dynamics of transitions between discrete hidden states with an augmented autoregressive model which models the inter-variable dependencies in each state using a state-dependent directed acyclic graph (DAG). We propose an efficient algorithm for training SrVARM by leveraging a recently introduced reformulation of the combinatorial problem of optimizing the DAG structure with respect to a scoring function into a continuous optimization problem. We report results of extensive experiments with simulated data as well as a real-world benchmark that show that SrVARM outperforms state-of-the-art baselines in recovering the unobserved state transitions and discovering the state-dependent relationships among variables.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {2270–2280},
numpages = {11},
keywords = {Bayesian Networks, Deep Neural Networks, Dynamic structure learning, State space model, State-regularized vector autoregressive model},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@article{10.1109/TCBB.2022.3144008,
author = {Hua, Yang and Song, Xiaoning and Feng, Zhenhua and Wu, Xiao-Jun and Kittler, Josef and Yu, Dong-Jun},
title = {CPInformer for Efficient and Robust Compound-Protein Interaction Prediction},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3144008},
doi = {10.1109/TCBB.2022.3144008},
abstract = {Recently, deep learning has become the mainstream methodology for Compound-Protein Interaction (CPI) prediction. However, the existing compound-protein feature extraction methods have some issues that limit their performance. First, graph networks are widely used for structural compound feature extraction, but the chemical properties of a compound depend on functional groups rather than graphic structure. Besides, the existing methods lack capabilities in extracting rich and discriminative protein features. Last, the compound-protein features are usually simply combined for CPI prediction, without considering information redundancy and effective feature mining. To address the above issues, we propose a novel CPInformer method. Specifically, we extract heterogeneous compound features, including structural graph features and functional class fingerprints, to reduce prediction errors caused by similar structural compounds. Then, we combine local and global features using dense connections to obtain multi-scale protein features. Last, we apply ProbSparse self-attention to protein features, under the guidance of compound features, to eliminate information redundancy, and to improve the accuracy of CPInformer. More importantly, the proposed method identifies the activated local regions that link a CPI, providing a good visualisation for the CPI state. The results obtained on five benchmarks demonstrate the merits and superiority of CPInformer over the state-of-the-art approaches.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jan,
pages = {285–296},
numpages = {12}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

