"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Simple Contrastive Representation Learning for Time Series Forecasting","X. Zheng; X. Chen; M. Schürch; A. Mollaysa; A. Allam; M. Krauthammer",University of Zürich; ETH Zürich; University of Zürich; University of Zürich; University of Zürich; University of Zürich,"ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","18 Mar 2024","2024","","","6005","6009","Contrastive learning methods have shown an impressive ability to learn meaningful representations for image or time series classification. However, these methods are less effective for time series forecasting, as optimization of instance discrimination is not directly applicable to predicting the future state from the historical context. To address these limitations, we propose SimTS, a simple representation learning approach for improving time series forecasting by learning to predict the future from the past in the latent space. SimTS exclusively uses positive pairs and does not depend on negative pairs or specific characteristics of a given time series. In addition, we show the shortcomings of the current contrastive learning framework used for time series forecasting through a detailed ablation study. Overall, our work suggests that SimTS is a promising alternative to other contrastive learning approaches for time series forecasting.","2379-190X","979-8-3503-4485-1","10.1109/ICASSP48485.2024.10446875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446875","Contrastive Learning;Time Series Forecasting;Representation Learning","Representation learning;Time series analysis;Self-supervised learning;Predictive models;Signal processing;Data augmentation;Acoustics","","18","","26","IEEE","18 Mar 2024","","","IEEE","IEEE Conferences"
"MORL: A Multi-Objective Representation Learning Modeling for Time Series Forecasting","J. Zhai; Z. Kan","School of Computer and Big Data, Heilongjiang University, Harbin, China; School of Computer and Big Data, Heilongjiang University, Harbin, China",2025 10th International Conference on Intelligent Computing and Signal Processing (ICSP),"28 Jul 2025","2025","","","1214","1218","Time series representation learning has a wide range of applications, including forecasting, classification, and anomaly detection. The primary challenge in the forecasting task is to learn high-quality representations from raw data using appropriate pre-training methods. This ensures that the model performs well without sacrificing generalization and robustness, making it useful for subsequent tasks. In this context, we introduce MORL, a simple yet effective approach for time series forecasting. MORL is based on three key components, drawing from the principles of representation learning. (i) Our approach utilizes an online knowledge distillation neural network, (ii) a novel data augmentation module, and (iii) a unified optimization mechanism that caters to both contrastive learning and similarity learning objective tasks. We have experimentally validated our method on four real-world time series datasets and one ECG signal dataset, and proves better results than previous methods, demonstrating superior performance compared to existing techniques. MORL achieves significant reductions in MSE by up to 20.9% and MAE by up to 22.1% in energy series datasets, marking notable improvements.","","979-8-3315-3626-8","10.1109/ICSP65755.2025.11086755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11086755","Time series forecasting;Representation learning;Multi-Objective Joint optimization","Representation learning;Time series analysis;Contrastive learning;Predictive models;Signal processing;Semisupervised learning;Robustness;Forecasting;Optimization;Similarity learning","","","","20","IEEE","28 Jul 2025","","","IEEE","IEEE Conferences"
"Dynamic Hypergraph Structure Learning for Multivariate Time Series Forecasting","S. Wang; Y. Zhang; X. Lin; Y. Hu; Q. Huang; B. Yin","Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China; Beijing Key Laboratory of Multimedia and Intelligent Software Technology, Beijing Artificial Intelligence Institute, Faculty of Information Technology, Beijing University of Technology, Beijing, China",IEEE Transactions on Big Data,"11 Jul 2024","2024","10","4","556","567","Multivariate time series forecasting plays an important role in many domain applications, such as air pollution forecasting and traffic forecasting. Modeling the complex dependencies among time series is a key challenging task in multivariate time series forecasting. Many previous works have used graph structures to learn inter-series correlations, which have achieved remarkable performance. However, graph networks can only capture spatio-temporal dependencies between pairs of nodes, which cannot handle high-order correlations among time series. We propose a Dynamic Hypergraph Structure Learning model (DHSL) to solve the above problems. We generate dynamic hypergraph structures from time series data using the K-Nearest Neighbors method. Then a dynamic hypergraph structure learning module is used to optimize the hypergraph structure to obtain more accurate high-order correlations among nodes. Finally, the hypergraph structures dynamically learned are used in the spatio-temporal hypergraph neural network. We conduct experiments on six real-world datasets. The prediction performance of our model surpasses existing graph network-based prediction models. The experimental results demonstrate the effectiveness and competitiveness of the DHSL model for multivariate time series forecasting.","2332-7790","","10.1109/TBDATA.2024.3362188","National Key R&D Program of China(grant numbers:2021ZD0111902); National Natural Science Foundation of China(grant numbers:62072015,62172023,U21B2038,61632006,61876012,61902053); Natural Science Foundation of Beijing(grant numbers:4222021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10420432","Graph neural network;hypergraph structure learning;multivariate time series forecasting","Time series analysis;Forecasting;Correlation;Predictive models;Data models;Adaptation models;Recurrent neural networks","","24","","37","IEEE","5 Feb 2024","","","IEEE","IEEE Journals"
"Adaptive Graph Structure Learning Neural Rough Differential Equations for Multivariate Time Series Forecasting","Y. Su; T. Ma; H. Rong; M. M. A. Wahab","School of Computer Science, School of Cyber Science and Engineering, Nanjing University of Information Science & Technology, Nanjing, China; School of Computer Engineering, Jiangsu Ocean University, Jiangsu, China; School of Artificial Intelligence (School of Future Technology), Nanjing University of Information Science & Technology, Nanjing, China; Faculty of Science, Cairo University, Cario, Egypt",IEEE Transactions on Big Data,"3 Sep 2025","2025","11","5","2710","2723","Multivariate time series forecasting has extensive applications in urban computing, such as financial analysis, weather prediction, and traffic forecasting. Using graph structures to model the complex correlations among variables in time series, and leveraging graph neural networks and recurrent neural networks for temporal aggregation and spatial propagation stage, has shown promise. However, traditional methods’ graph structure node learning and discrete neural architecture are not sensitive to issues such as sudden changes, time variance, and irregular sampling often found in real-world data. To address these challenges, we propose a method called Adaptive Graph structure Learning neural Rough Differential Equations (AGLRDE). Specifically, we combine dynamic and static graph structure learning to adaptively generate a more robust graph representation. Then we employ a spatio-temporal encoder-decoder based on Neural Rough Differential Equations (Neural RDE) to model spatio-temporal dependencies. Additionally, we introduce a path reconstruction loss to constrain the path generation stage. We conduct experiments on six benchmark datasets, demonstrating that our proposed method outperforms existing state-of-the-art methods. The results show that AGLRDE effectively handles aforementioned challenges, significantly improving the accuracy of multivariate time series forecasting.","2332-7790","","10.1109/TBDATA.2025.3552334","National Natural Science Foundation of China(grant numbers:62372243); National Natural Science Foundation of China(grant numbers:62102187,42175194); STDF Egypt(grant numbers:43088); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938288","Graph structure learning;neural ordinary differential equations;multivariate time series forecasting","Time series analysis;Forecasting;Predictive models;Mathematical models;Adaptation models;Correlation;Data models;Graph neural networks;Computational modeling;Accuracy","","2","","40","IEEE","24 Mar 2025","","","IEEE","IEEE Journals"
"EGENN: An Efficient Graph-Enhanced Neural Network for Multivariate Time Series Forecasting","H. Xu; H. Zhu; Y. Chen; C. Yi; B. Wei; F. Jiang","Faculty of Computing, Harbin Institute of Technology, Harbin, China; School of Medicine and Health, Harbin Institute of Technology, Harbin, China; School of Computer Science, University of Nottingham Malaysia, Semenyih, Malaysia; School of Medicine and Health, Harbin Institute of Technology, Harbin, China; School of Medicine and Health, Harbin Institute of Technology, Harbin, China; School of Medicine and Health, Harbin Institute of Technology, Harbin, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Graph Neural Network (GNN) has been widely applied in multivariate time series forecasting due to its excellent relationship modeling capabilities. However, current methods still face limitations in computational efficiency or time series expression capabilities. To address these issues, we propose an Efficient Graph-Enhanced Neural Network (EGENN), which consists of an adjacency matrix generator, GNN, and projection module. Firstly, EGENN designs a spectral similarity-based graph construction method and further enhances the expressive power of temporal features. Secondly, we introduce an inter-layer attention graph convolutional network, which adaptively aggregates information from different network depths to better capture complex patterns. Finally, a predictive projection strategy fusing wavelet convolutions and patch-wise transformation is proposed to produce compact parameterization and extended receptive fields. Experiments on five datasets from different domains show that our model achieves state-of-the-art prediction performance while maintaining low computational resource consumption.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10890196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10890196","Multivariate Time Series Forecasting;Graph Neural Network;Spectral Graph Construction;Compact Parameterization","Wavelet transforms;Adaptation models;Convolution;Graph convolutional networks;Computational modeling;Time series analysis;Predictive models;Computational efficiency;Forecasting;Speech processing","","","","20","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"High-dimensional Multivariate Time Series Forecasting using Self-Organizing Maps and Fuzzy Time Series","M. C. dos Santos; F. G. Guimarães; P. C. de Lima e Silva","Machine Intelligence and Data Science Laboratory (MINDS) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Machine Intelligence and Data Science Laboratory (MINDS) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Instituto Federal do Norte de Minas Gerais, IFNMG, Januaria, Brazil",2021 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),"5 Aug 2021","2021","","","1","6","Machine learning models that follow the FTS (Fuzzy Time Series) approach stand out as data-driven non-parametric models of easy implementation and high accuracy, which can be applied to uni-variate and multivariate time series. However, this approach encounters difficulties when dealing with databases of many variables, given the explosion of rules that are generated for the construction of models. Usually filter and wrapper techniques (e.g. Boruta test) and data projection techniques (e.g. Principal Component Analysis) are used. The present work proposes a methodology for tackling this issue by projecting the original high-dimensional data into a low dimensional embedding space using self-organizing Kohonnen maps and later using the Weighted Multivariate FTS method (WMVFTS) for rule discovery and forecasting. The results obtained showed good values of RMSE and MAPE, illustrating the validity and potential of the method.","1558-4739","978-1-6654-4407-1","10.1109/FUZZ45933.2021.9494496","National Council for Scientific and Technological Development (CNPq); Coordination for the Improvement of Higher Education (CAPES); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9494496","fuzzy time series;self-organizing maps;high-dimension databases;multivariate time series;time series forecasting","Self-organizing feature maps;Reactive power;Databases;Time series analysis;Machine learning;Predictive models;Explosions","","3","","26","IEEE","5 Aug 2021","","","IEEE","IEEE Conferences"
"Core: Transferable Long-Range Time Series Forecasting Enhanced by Covariates-Guided Representation","X. -Y. Li; P. -N. Zhong; D. Chen; Y. -B. Yang","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; General Development Dept, Huawei Technologies Co. Ltd., Dongguan, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China","ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","5 May 2023","2023","","","1","5","In recent years, long-range time series forecasting has been actively studied and has shown promising results. However, since these methods mainly focus on predicting time series with a fixed dimension, they are inapplicable to the large-scale and ever-changing datasets that are common in real-world applications. Additionally, existing methods only take a window of the near past as input, which prevents the models from learning persistent historical patterns. To tackle these problems, we propose CoRe, a novel transferable long-term forecasting method enhanced by Covariates-guided Representation. By encoding the input series into a dense vector, CoRe is able to extract instance-wise global features. Specifically, the representation is learned by modeling the correlation between the target series and constructed auxiliary covariates, which is implemented by our proposed cross-dependency network. Comprehensive experiments on six real-world datasets show that CoRe achieves overall state-of-the-art results and can transfer to unseen data with stable performance.","2379-190X","978-1-7281-6327-7","10.1109/ICASSP49357.2023.10096231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10096231","Time series forecasting;representation learning;temporal dependency;encoder-decoder","Correlation;Time series analysis;Signal processing;Predictive models;Feature extraction;Encoding;Acoustics","","1","","19","IEEE","5 May 2023","","","IEEE","IEEE Conferences"
"W-Transformers: A Wavelet-based Transformer Framework for Univariate Time Series Forecasting","L. Sasal; T. Chakraborty; A. Hadid","Sorbonne Center for Artificial Intelligence, Sorbonne University Abu Dhabi, Abu Dhabi, UAE; Sorbonne Center for Artificial Intelligence, Sorbonne University Abu Dhabi, Abu Dhabi, UAE; Sorbonne Center for Artificial Intelligence, Sorbonne University Abu Dhabi, Abu Dhabi, UAE",2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA),"23 Mar 2023","2022","","","671","676","Deep learning utilizing transformers has recently achieved a lot of success in many vital areas such as natural language processing, computer vision, anomaly detection, and recommendation systems, among many others. Among several merits of transformers, the ability to capture long-range temporal dependencies and interactions is desirable for time series forecasting, leading to its progress in various time series applications. In this paper, we build a transformer model for non-stationary time series. The problem is challenging yet crucially important. We present a novel framework for univariate time series representation learning based on the wavelet-based transformer encoder architecture and call it W-Transformer. The proposed W-Transformers utilize a maximal overlap discrete wavelet transformation (MODWT) to the time series data and build local transformers on the decomposed datasets to vividly capture the nonstationarity and long-range nonlinear dependencies in the time series. Evaluating our framework on several publicly available benchmark time series datasets from various domains and with diverse characteristics, we demonstrate that it performs, on average, significantly better than the baseline forecasters for long-term forecasting, even for datasets that consist of only a few hundred training samples.","","978-1-6654-6283-9","10.1109/ICMLA55696.2022.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10069146","Transformers;time series forecasting;deep learning;wavelet decomposition","Training;Representation learning;Deep learning;Computer vision;Time series analysis;Transformers;Natural language processing","","23","","43","IEEE","23 Mar 2023","","","IEEE","IEEE Conferences"
"Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting","L. Chen; D. Chen; Z. Shang; B. Wu; C. Zheng; B. Wen; W. Zhang","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",IEEE Transactions on Knowledge and Data Engineering,"14 Sep 2023","2023","35","10","10748","10761","Multivariate time series (MTS) forecasting plays an important role in the automation and optimization of intelligent applications. It is a challenging task, as we need to consider both complex intra-variable dependencies and inter-variable dependencies. Existing works only learn temporal patterns with the help of single inter-variable dependencies. However, there are multi-scale temporal patterns in many real-world MTS. Single inter-variable dependencies make the model prefer to learn one type of prominent and shared temporal patterns. In this article, we propose a multi-scale adaptive graph neural network (MAGNN) to address the above issue. MAGNN exploits a multi-scale pyramid network to preserve the underlying temporal dependencies at different time scales. Since the inter-variable dependencies may be different under distinct time scales, an adaptive graph learning module is designed to infer the scale-specific inter-variable dependencies without pre-defined priors. Given the multi-scale feature representations and scale-specific inter-variable dependencies, a multi-scale temporal graph neural network is introduced to jointly model intra-variable dependencies and inter-variable dependencies. After that, we develop a scale-wise fusion module to effectively promote the collaboration across different time scales, and automatically capture the importance of contributed temporal patterns. Experiments on six real-world datasets demonstrate that MAGNN outperforms the state-of-the-art methods across various settings.","1558-2191","","10.1109/TKDE.2023.3268199","National Key Research and Development Program of China(grant numbers:2018YFB0505000); Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10105527","Multivariate time series forecasting;multi-scale modeling;graph neural network;graph learning","Forecasting;Time series analysis;Predictive models;Graph neural networks;Adaptive systems;Adaptation models;Power demand","","125","","46","IEEE","19 Apr 2023","","","IEEE","IEEE Journals"
"TimeDRL: Disentangled Representation Learning for Multivariate Time-Series","C. Chang; C. -T. Chan; W. -Y. Wang; W. -C. Peng; T. -F. Chen","National Yang Ming Chiao Tung University, Hsinchu, Taiwan; National Yang Ming Chiao Tung University, Hsinchu, Taiwan; National Yang Ming Chiao Tung University, Hsinchu, Taiwan; National Yang Ming Chiao Tung University, Hsinchu, Taiwan; National Yang Ming Chiao Tung University, Hsinchu, Taiwan",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","625","638","Multivariate time-series data in numerous real-world applications (e.g., healthcare and industry) are informative but challenging due to the lack of labels and high dimensionality. Recent studies in self-supervised learning have shown their potential in learning rich representations without relying on labels, yet they fall short in learning disentangled embeddings and addressing issues of inductive bias (e.g., transformation-invariance). To tackle these challenges, we propose TimeDRL, a generic multivariate time-series representation learning frame-work with disentangled dual-level embeddings. TimeDRL is characterized by three novel features: (i) disentangled derivation of timestamp-level and instance-level embeddings from patched time-series data using a [CLS] token strategy; (ii) utilization of timestamp-predictive and instance-contrastive tasks for disentangled representation learning, with the former optimizing timestamp-level embeddings with predictive loss, and the latter optimizing instance-level embeddings with contrastive loss; and (iii) avoidance of augmentation methods to eliminate inductive biases, such as transformation-invariance from cropping and masking. Comprehensive experiments on 6 time-series forecasting datasets and 5 time-series classification datasets have shown that TimeDRL consistently surpasses existing representation learning approaches, achieving an average improvement of forecasting by 58.02% in MSE and classification by 1.48% in accuracy. Further-more, extensive ablation studies confirmed the relative contribution of each component in TimeDRL's architecture, and semi-supervised learning evaluations demonstrated its effectiveness in real-world scenarios, even with limited labeled data. The code is available at https://github.com/blacksnail789521/TimeDRL.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597874","Representation Learning;Multivariate Time-Series;Self-Supervised Learning;Time-Series Forecasting;Time-Series Classification","Industries;Accuracy;Large language models;Disentangled representation learning;Self-supervised learning;Medical services;Semisupervised learning","","11","","52","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Toward Digital Twin: Leveraging Pre-training Approaches for Multivariate Time Series Forecasting","L. Yan; Z. Zhang; X. Wang; Y. Zhang; Y. Gu","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",2023 IEEE 6th International Conference on Electronic Information and Communication Technology (ICEICT),"22 Sep 2023","2023","","","1106","1111","Time series forecasting has been an active research area, particularly in the context of Digital Twin (DT) systems. Despite the excellent results yielded by pre-trained models in Natural Language Processing (NLP) and Computer Vision (CV), only a few studies have researched pre-training strategies for time series forecasting networks within DT systems. Recent studies demonstrate that transfer learning across multiple time series datasets does not always provide promising results, making self-supervised pre-training directly on the downstream dataset a temporarily considered optimal solution. To the best of our knowledge, the only general pre-training task in the time series field is the Masked Autoencoder. However, this approach may lead to redundant representations for downstream forecasting within DT systems. Therefore, we propose three pre-training tasks specially designed for time series forecasting within DT frameworks: Inverse Forecasting (IF), Coarser Forecasting (CF), and Anomaly Forecasting (AF). These tasks are respectively designed to capture bidirectional dependency, reduce noise, and augment data, all crucial aspects in enhancing the predictive capabilities of DT systems. By integrating the three tasks, we obtain a composite pre-training task which generally improves the forecasting results of time series models within DT systems across multiple datasets. This work contributes to the ongoing efforts to improve the accuracy and efficiency of DT systems, paving the way for more robust and reliable digital representations of physical systems.","2836-7782","979-8-3503-9905-9","10.1109/ICEICT57916.2023.10245025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10245025","time series forecasting;digital twin;self-supervised learning;pre-training","Time series analysis;Transfer learning;Neural networks;Predictive models;Natural language processing;Digital twins;Information and communication technology","","2","","32","IEEE","22 Sep 2023","","","IEEE","IEEE Conferences"
"LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting","Y. Ren; X. Yu","Department of Electrical Engineering, Tsinghua University, Beijing, China; Department of Electrical Engineering, Tsinghua University, Beijing, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Modern Internet of Things (IoT) systems generate massive, heterogeneous multivariate time series data. Accurate Multivariate Time Series Forecasting (MTSF) of such data is critical for numerous applications. However, existing methods almost universally employ a shared embedding layer that processes all channels identically, creating a representational bottleneck that obscures valuable channel-specific information. To address this challenge, we introduce a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into a shared base component capturing common patterns and channel-specific auxiliary components modeling unique deviations. Within this decomposition, we empirically observe that the auxiliary components tend to exhibit low-rank and clustering characteristics, a structural pattern that is significantly less apparent when using purely independent embeddings. Consequently, we design LightSAE, a parameter-efficient embedding module that operationalizes these observed characteristics through low-rank factorization and a shared, gated component pool. Extensive experiments across 9 IoT-related datasets and 4 backbone architectures demonstrate LightSAE’s effectiveness, achieving MSE improvements of up to 22.8% with only 4.0% parameter increase. Code is available at https://github.com/EDM314/LightSAE.","2327-4662","","10.1109/JIOT.2025.3631505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11240137","Multivariate time series forecasting;channel heterogeneity;embedding mechanisms;parameter efficiency;deep learning","Internet of Things;Time series analysis;Forecasting;Predictive models;Scalability;Costs;Transformers;Statistical distributions;Standards;Representation learning","","","","","IEEE","11 Nov 2025","","","IEEE","IEEE Early Access Articles"
"Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting","J. Kim; H. Lee; S. Yu; U. Hwang; W. Jung; K. Yoon","Department of Electronic Engineering, Hanyang University, Seoul, South Korea; Department of Electronic Engineering, Hanyang University, Seoul, South Korea; Department of Electronic Engineering, Hanyang University, Seoul, South Korea; Department of Electronic Engineering, Hanyang University, Seoul, South Korea; Department of Electronic Engineering, Hanyang University, Seoul, South Korea; Department of Electronic Engineering, Hanyang University, Seoul, South Korea",IEEE Access,"30 Oct 2023","2023","11","","118386","118394","Multivariate time series is prevalent in many scientific and industrial domains. Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions–both direct and indirect. To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them. Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data. Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies. The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks. The results consistently showcase the superiority of our model, achieving an average 23% reduction in mean squared error (MSE) compared to existing models.","2169-3536","","10.1109/ACCESS.2023.3325041","National Research Foundation of Korea (NRF)(grant numbers:NRF-2021R1F1A1045390); Brain Convergence Research Program(grant numbers:NRF-2021M3E5D2A01023887); Bio and Medical Technology Development Program of NRF(grant numbers:RS-2023-00226494); Institute of Information & Communications Technology Planning & Evaluation (IITP) Grant (Artificial Intelligence Graduate School Program, Hanyang University); Korean Government [Ministry of Science and ICT (MSIT)](grant numbers:2020-0-01373); Technology Innovation Program (Development of Industrial Intelligent Technology for Manufacturing, Process, and Logistics); Ministry of Trade, Industry & Energy (MOTIE, South Korea)(grant numbers:20013726); Samsung Electronics Company Ltd.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286512","Time series analysis;long sequence time series forecast;graph neural network;structure learning;self-attention","Time series analysis;Forecasting;Predictive models;Computational modeling;Graph neural networks;Signal resolution;Complexity theory","","4","","35","CCBYNCND","16 Oct 2023","","","IEEE","IEEE Journals"
"A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting","C. Wan; C. Xie; L. Liu; D. Wu; Y. Li","Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Science, Shenzhen, China","ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","7 Mar 2025","2025","","","1","5","Continuous blood pressure (BP) monitoring is essential for timely diagnosis and intervention in critical care settings. However, BP varies significantly across individuals, this inter-patient variability motivates the development of personalized models tailored to each patient’s physiology. In this work, we propose a personalized BP forecasting model mainly using electrocardiogram (ECG) and photoplethysmogram (PPG) signals. This time-series model incorporates 2D representation learning to capture complex physiological relationships. Experiments are conducted on datasets collected from three diverse scenarios with BP measurements from 60 subjects total. Results demonstrate that the model achieves accurate and robust BP forecasts across scenarios within the Association for the Advancement of Medical Instrumentation (AAMI) standard criteria. This reliable early detection of abnormal fluctuations in BP is crucial for at-risk patients undergoing surgery or intensive care. The proposed model provides a valuable addition for continuous BP tracking to reduce mortality and improve prognosis.","2379-190X","979-8-3503-6874-1","10.1109/ICASSP49660.2025.10889293","Research and Development; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10889293","blood pressure forecasting;time series prediction;multi-signal processing;multi-scenario;personalized modeling","Representation learning;Time series analysis;Mortality;Predictive models;Blood pressure;Biomedical monitoring;Forecasting;Prognostics and health management;Standards;Monitoring","","1","","24","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Time Series Forecasting Based on Structured Decomposition and Variational Autoencoder","Z. Zhang; X. Yao","College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China; College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","Time series forecasting based on decomposition method usually decomposes a complex time series into some simple components, such as long-term and seasonal trends, which are more easy to be predicted. Though long-term and seasonal trends are vital in time series foreasting, it may be insufficient for those not having such obvious characters. This paper proposes a time series forecasting model named SD-VAE based on structured decomposition and variational autoencoder(VAE). The structured decomposition module decomposes a time series into long-term component, seasonal component, short-term component and co-evolving component, and the VAE module learns the representation of them, through which the future value of each decomposed component are predicted and then fused by a neural network. To get a better decoupled representation of each decomposed component, mutual information constraints are added in the latent space of VAE. Extensive experiments prove that our model performs the best in 3 out of 4 public datasets, with the other one ranking second, against the most representation learning and end-to-end forecasting models.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10650587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650587","structured decomposition;Variational Autoencoder;time series forecasting;decoupling;mutual information","Representation learning;Time series analysis;Neural networks;Predictive models;Market research;Forecasting;Mutual information","","1","","26","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"FusionBC: Contrastive Graph and Information Bottleneck Fusion Learning for Time Series Forecasting","H. Xu; Y. Shi; Y. Zhan; H. Jin; Q. Ren; Z. Li","Department of Computer Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science and Technology, Heilongjiang University, Harbin, China; Department of Computer Science and Technology, Heilongjiang University, Harbin, China",2025 IEEE International Conference on High Performance Computing and Communications (HPCC),"31 Oct 2025","2025","","","162","169","Graph contrastive learning has demonstrated its effectiveness in time series modeling. However, existing approaches often face significant challenges, including sensitivity to noise, incompleteness in data, and the difficulty of balancing performance across long- and short-term forecasting tasks. To overcome these limitations, we propose a novel fusion-based framework, Contrastive Graph and Information Bottleneck Fusion Learning (FusionBC), tailored for robust multivariate time series forecasting. By integrating Contrastive Graph Learning with the Information Bottleneck principle, our method selectively filters out irrelevant or redundant information during the learning process, leading to refined, noise-resilient representations that enhance forecasting accuracy. Specifically, the FusionBC framework employs adaptive graph augmentation, intelligently dropping edges or nodes to optimize graph structures and reinforce robustness. Additionally, it combines scale-wise temporal convolution with dual-flow spatial attentive graph convolution, effectively capturing both inter-variable dynamics and multi-scale intra-variable dependencies. Extensive evaluations on real-world datasets show that FusionBC consistently outperforms state-of-the-art methods, achieving a 4.0% improvement in RSE on multivariate forecasting benchmarks. This improvement underscores FusionBC's ability to deliver enhanced, noise-resilient forecasting results that are robust across a range of time series scenarios.","","979-8-3315-6874-0","10.1109/HPCC67675.2025.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11207273","Time series forecasting;Contrastive graph learning;Temporal convolution;Information bottleneck","Sensitivity;Filters;Accuracy;Convolution;High performance computing;Time series analysis;Noise;Robustness;Forecasting;Faces","","","","33","IEEE","31 Oct 2025","","","IEEE","IEEE Conferences"
"Mitigating Channel Redundancy for Multivariate Time Series Forecasting","G. Xiao; B. Qin; Y. Chen; W. Yang","Hunan University, Changsha, China; Hunan University, Changsha, China; Central South University, Changsha, China; Hunan University, Changsha, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Transformer-based methods have been widely used in multivariate time series forecasting (MTSF), typically following either channel-independent (CI) or channel-dependent (CD) mod-eling approaches. However, CI methods overlook inter-channel information, while CD methods struggle with the complexity and redundancy of channel relationships, leading to suboptimal performance and high computational costs. In this paper, we propose a novel Channel Aggregation Network, dubbed CANet, to efficiently model both intra and inter-channel dependencies. Specifically, CANet embeds input sequences into patch tokens and uses probabilistic masking in the Channel Aggregator to effectively filter out redundant and noisy information. The refined inter-channel features are then injected into the temporal dimension, allowing CANet to focus on temporal attention while efficiently leveraging cross-channel information. After that, the Temporal Sampler selects key temporal tokens along the time axis, enhancing long-range dependency modeling and accelerating global representation learning. Extensive experiments on multiple real-world datasets demonstrate that CANet achieves state-of-the-art performance with superior accuracy and significantly reduced computational complexity.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228045","multivariate time series forecasting;Transformer;inter-channel dependency;redundancy","Representation learning;Computational modeling;Time series analysis;Redundancy;Transformers;Probabilistic logic;Information filters;Noise measurement;Forecasting;Computational complexity","","","","21","IEEE","14 Nov 2025","","","IEEE","IEEE Conferences"
"Semi4TSF: End-to-End Semi-Supervised Contrastive Representation Learning for Time Series Forecasting","Y. Wu; X. Meng; J. Zhang; Y. Dong; D. Lu","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Industrial Informatics,"17 Oct 2025","2025","21","11","8791","8801","Learning time series representations with sparse labels presents notable challenges. The surge in unsupervised contrastive learning has garnered increasing interest due to its immense advancements in deriving meaningful representations in semi-supervised settings, typically involving a two-stage process: pretraining on large unlabeled data followed by fine-tuning with few labeled samples. However, this approach has inherent drawbacks: poor knowledge transfer, reduced generalizability, and failure to directly utilize unsupervised contrastive loss from pretraining and valuable supervised loss guided by ground truth to impact the downstream tasks. In response, we introduce a novel end-to-end semi-supervised framework, Semi4TSF, for time series forecasting (TSF). It optimizes unsupervised loss on massive unlabeled data and integrates supervised contrastive and forecasting losses on limited labeled data, enabling the model to see other unlabeled embeddings meanwhile learning useful labeled embeddings, improving generalization. The three losses are jointly to refine the encoder and forecaster. Specifically, the unsupervised learning module applies two instance-wise augmentation banks over the entire series to capture long-term dependencies, suggests a learnable Fourier layer, and fuses temporal and frequency information to uncover intricate temporal-frequency correlations through cross-domain interactions to capture nuanced representations. Extensive experiments on five benchmarks demonstrate that Semi4TSF is an effective and superior end-to-end framework that fills the gap in semi-supervised TSF.","1941-0050","","10.1109/TII.2025.3588582","Zhejiang Provincial Science and Technology Plan(grant numbers:2024C03261); Specialized Research Projects of Huanjiang Laboratory(grant numbers:XYY-128102-E52201); Key Scientific Research Base for Digital Conservation of Cave Temples; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105503","Contrastive learning;data augmentation;end-to-end;semi-supervised learning;time series forecasting (TSF)","Time series analysis;Forecasting;Contrastive learning;Semisupervised learning;Data models;Training;Predictive models;Representation learning;Data augmentation;Time-frequency analysis","","1","","36","IEEE","31 Jul 2025","","","IEEE","IEEE Journals"
"Dwtformer: Wavelet decomposition Transformer with 2D Variation for Long-Term Series Forecasting","Y. Cao; X. Zhao",Wuhan University of Technology; Wuhan University of Technology,"2023 IEEE 6th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)","30 Mar 2023","2023","6","","1548","1558","Benefiting from the boom in deep learning and natural language processing, RNNs, CNNs and Transformers have significantly improved the accuracy of multivariate long time series prediction, which focus on how to discover the long-term dependence of long time series and how to capture the overall trend of time series. But They ignore the complex intrinsic features of the series (the characteristics of intra-period and inter-period variations). Based on the observation of the multi-periodicity of time series, this study extends the analysis of time series to a higher space by decomposing a complex 1D time series into a set of 2D tensors based on multiple frequencies. Through this transformation, we connect the time series prediction to the computer vision so we can get more effective techniques which can be employed to extract complex temporal variations from the transformed 2D tensors. To address these issues, this paper proposes to combine the Transformer with a wavelet decomposition-based 2D feature learning module. The 2D feature learning module captures the complex period variations of the time series and the Transformer captures the long-term historical details. To more fully learn the periodic features, this paper proposes Dwtformer by referring to the auto-correlation mechanism in Autoformer. Experiments on four benchmark datasets show that compared to state-of-the-art methods, Dwtformer can reduce multivariate time series prediction errors by 14.9%.","2693-3128","978-1-6654-6004-0","10.1109/ITNEC56291.2023.10082078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10082078","time series forecasting;time series decomposition;transformer;deep learning","Representation learning;Time-frequency analysis;Tensors;Time series analysis;Predictive models;Network architecture;Transformers","","3","","37","IEEE","30 Mar 2023","","","IEEE","IEEE Conferences"
"A Data-Level Augmentation Framework for Time Series Forecasting With Ambiguously Related Source Data","R. Ye; Q. Dai","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China",IEEE Transactions on Knowledge and Data Engineering,"5 Jun 2025","2025","37","7","3855","3868","Many practical time series forecasting (TSF) tasks are plagued by data limitations. To alleviate this challenge, we design a data-level augmentation framework. It involves a time series generation (TSG) module and a source data selection (Sel-src) module. TSG aims to achieve better generation results by considering both the global profile and temporal dynamics of series. However, when only few target data is available, TSG module may tend to simulate the limited target samples, leading to poor generalization performance. A natural idea for this problem is to seek help from related source domain, which can provide additional useful information for TSG module. Here we consider a more complex situation, where the relevance between source and target domains is ambiguous. That is, irrelevant samples may exist in the source domain. Blindly using all the source data may lead to counterproductive results. To meet this challenge, Sel-src module is designed to select effective source samples by Inter-Representation Learning (Inter-RL) and Intra-Representation Learning (Intra-RL). Effectiveness of this algorithm is underpinned from two aspects: the quality of the augmented data and the accuracy improvement upon the augmentation.","1558-2191","","10.1109/TKDE.2025.3555530","National Natural Science Foundation of China(grant numbers:62476126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10949281","Time series forecasting;time series generation;data augmentation","Time series analysis;Generative adversarial networks;Data augmentation;Data models;Forecasting;Market research;Decoding;Transfer learning;Synthetic data;Representation learning","","1","","43","IEEE","4 Apr 2025","","","IEEE","IEEE Journals"
"TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations","J. Hao; Q. Shi; Y. Ye; W. Zeng","Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",IEEE Transactions on Visualization and Computer Graphics,"25 Dec 2023","2024","30","1","1183","1193","Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely TimeTuner, designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual explanations to connect the relationships among time-series representations, multivariate features and model predictions. Next, we design multiple coordinated views including a partition-based correlation matrix and juxtaposed bivariate stripes, and provide a set of interactions that allow users to step into the transformation selection process, navigate through the feature space, and reason the model performance. We instantiate TimeTuner with two transformation methods of smoothing and sampling, and demonstrate its applicability on real-world time-series forecasting of univariate sunspots and multivariate air pollutants. Feedback from domain experts indicates that our system can help characterize time-series representations and guide the feature engineering processes.","1941-0506","","10.1109/TVCG.2023.3327389","National Natural Science Foundation of China(grant numbers:62172398); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515011700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10297593","Time-series forecasting;counterfactual explanation;visual analytics","Forecasting;Predictive models;Data visualization;Biological system modeling;Data models;Task analysis;Measurement","","7","","67","IEEE","26 Oct 2023","","","IEEE","IEEE Journals"
"A Multistep Multivariate Fuzzy-Based Time-Series Forecasting on Internet of Things Data","H. V. Bitencourt; P. d. O. Lucas; O. Orang; P. C. L. Silva; F. G. Guimarães","Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Federal Institute of Northern Minas Gerais, Salinas, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil; Federal Institute of Northern Minas Gerais, Januária, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil",IEEE Internet of Things Journal,"11 Jun 2025","2025","12","12","21679","21690","Multistep ahead time series forecasting is essential in Internet of Things (IoT) applications in smart cities and smart homes to make accurate future predictions and precise decision making. Thus, this study introduces a novel multiple-input single-output (MISO) forecasting method called Multistep Embedding-based fuzzy time series (MS-EFTS), designed to predict high-dimensional nonstationary time series data. As a first-order approach, it employs a direct strategy that integrates an embedding transformation with a weighted multivariate FTS (WMVFTS) model. This combination allows for effective predictions over long-term horizons within low-dimensional, learned continuous representations. The effectiveness of the proposed MS-EFTS is assessed using three high-dimensional IoT time series in this investigation. The obtained results showcase the superior performance of the proposed method compared to some deep learning forecasting methods, including LSTM, BiLSTM, TCN, and CNN-LSTM, in terms of accuracy, parsimony, and efficiency.","2327-4662","","10.1109/JIOT.2025.3549715","National Council for Scientific and Technological Development (CNPq), Brazil(grant numbers:312991/2020-7); Coordination for the Improvement of Higher Education Personnel (CAPES) through the Academic Excellence Program (PROEX), Brazil; RDI Agreement between UFMG and Fundep – Research Development Foundation: “Federated Machine Learning Program for Connected Vehicles.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918737","Embedding transformation;fuzzy time series;multistep-ahead time-series forecasting;smart buildings;smart cities","Forecasting;Time series analysis;Internet of Things;Predictive models;Accuracy;Buildings;Adaptation models;Smart cities;Data models;Training","","2","","61","IEEE","10 Mar 2025","","","IEEE","IEEE Journals"
"STNet: Spatial-Temporal Transformers are Effective for Multivariate Time Series Forecasting","K. Yang; X. Wang; Z. Wang; C. Chi; C. Deng; J. Feng","JIUTIAN Team, China Mobile Research Institute, Beijing, China; JIUTIAN Team, China Mobile Research Institute, Beijing, China; JIUTIAN Team, China Mobile Research Institute, Beijing, China; JIUTIAN Team, China Mobile Research Institute, Beijing, China; JIUTIAN Team, China Mobile Research Institute, Beijing, China; JIUTIAN Team, China Mobile Research Institute, Beijing, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","The recent boom of Transformer-based models have enhanced state-of-the-art results of multivariate time series (MTS) forecasting. However, MTS forecasting remains a challenging problem, primarily because of the intricate temporal patterns and obscured spatial correlations. Existing models are not only computationally expensive in modeling long-term temporal dependencies, but more importantly, fail to adequately capture the interrelations among variables. To address these problems, we propose STNet, a Spatial-Temporal Transformer Network with self-supervised pre-training scheme for MTS forecasting. In STNet, the MTS are formalized as a data-driven graph structure, which is learned through the training process to extract the latent patterns within the spatial dependencies of the data. Then we encode the structural information of the graph into the spatial Transformer encoder to help STNet better model refined spatial dependencies. A patch-level Transformer encoder is implemented to efficiently enhance locality and comprehensively capture semantic information pertaining to temporal dependencies. Moreover, the pre-training model generates rich contextual information, which consistently leads to reliable outcomes in transfer performance for downstream tasks. Extensive experiments conducted on five real-world benchmark datasets show the proposed STNet improves the prediction accuracy by 5.0%-25.2% compared to previous state-of-the-arts.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228192","Multivariate time series forecasting;Transformer;Self-supervised learning","Training;Correlation;Current transformers;Computational modeling;Time series analysis;Semantics;Self-supervised learning;Predictive models;Feature extraction;Forecasting","","","","38","IEEE","14 Nov 2025","","","IEEE","IEEE Conferences"
"RecVAE-GBRT: Memory-Fused XGBoost for Time-Series Forecasting","X. Zheng; S. A. Bagloee; M. Sarvi","FEIT, University of Melbourne, Melbourne, Australia; FEIT, University of Melbourne, Melbourne, Australia; FEIT, University of Melbourne, Melbourne, Australia",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","Time series forecasting is a crucial task for control and decision in various fields. Recent efforts focus on integrating complex deep learning techniques, such as RNN or Transformer, into sequential models. However, these solutions are often criticized due to their excessive complexity. Inspired by the effectiveness of Gradient Boosted Regression Trees (GBRT) methods (such as XGBoost) on tabular datasets, this study proposes a hybrid method for time series forecasting. In this method, we design a memory mechanism for GBRT, namely, Recursive Variational AutoEncoder (RecVAE), which can generate compressed representations of historical sequences by recursively summarizing a section of input time series and preceding internal outputs into current internal outputs. This compensates for the limitation of the GBRT in incorporating long historical sequences for time series forecasting. The resulting memory-fused forecasting model, namely, RecVAE-GBRT, is tested on 4 real-world time series datasets. The results indicate that it generates competitive results compared to Transformer-based time series forecasting methods, all happening at the same level of computation efficiency or better.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10650508","University of Melbourne; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10650508","GBRT;VAE;time series forecasting;Transformer;XGBoost","Deep learning;Design methodology;Computational modeling;Time series analysis;Neural networks;Predictive models;Transformers","","2","","47","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Late Meta-learning Fusion Using Representation Learning for Time Series Forecasting","T. L. v. Zyl","Institute for Intelligent Systems University of Johannesburg, Johannesburg, South Africa",2023 26th International Conference on Information Fusion (FUSION),"25 Aug 2023","2023","","","1","8","Meta-learning, decision fusion, hybrid models, and representation learning are topics of investigation with significant traction in time-series forecasting research. Of these two specific areas have shown state-of-the-art results in forecasting: hybrid meta-learning models such as Exponential Smoothing- Recurrent Neural Network (ES-RNN) and Neural Basis Expansion Analysis (N-BEATS) and feature-based stacking ensembles such as Feature-based FORecast Model Averaging (FFORMA). However, a unified taxonomy for model fusion and an empirical comparison of these hybrid and feature-based stacking ensemble approaches is still missing. This study presents a unified taxonomy encompassing these topic areas. Furthermore, the study empirically evaluates several model fusion approaches and a novel combination of hybrid and feature stacking algorithms called Deep-learning FORecast Model Averaging (DeFORMA). The taxonomy contextualises the considered methods. Furthermore, the empirical analysis of the results shows that the proposed model, DeFORMA, can achieve state-of-the-art results in the M4 data set. DeFORMA, increases the mean Overall Weighted Average (OWA) in the daily, weekly and yearly subsets with competitive results in the hourly, monthly and quarterly subsets. The taxonomy and empirical results lead us to argue that significant progress is still to be made by continuing to explore the intersection of these research areas.","","979-8-89034-485-4","10.23919/FUSION52260.2023.10224217","Nedbank; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10224217","Meta-learning;Decision fusion;Model fusion;Hybrid models;Representation learning","Representation learning;Metalearning;Deformable models;Analytical models;Taxonomy;Stacking;Transfer learning","","3","","57","","25 Aug 2023","","","IEEE","IEEE Conferences"
"Time Series Forecasting with Multi-scale Decomposition and Fourier Neural Operators","R. Long; H. Xie; D. Lian","School of Data Science, University of Science and Technology of China, Hefei, China; School of Data Science, University of Science and Technology of China, Hefei, China; State Key Laboratory of Cognitive Intelligence, University of Science and Technology of China, Hefei, China",2024 7th International Conference on Computer Information Science and Application Technology (CISAT),"2 Oct 2024","2024","","","952","957","Time series forecasting has a wide range of applications in weather forecasting, energy price prediction, and many other fields. However, real-world time series data are often inherently non-stationary, which makes modeling time series data challenging. Existing research methods typically use seasonal-trend decomposition to disentangle time series data, and then leverage Transformer and other model structures to learn complex, evolving temporal variations.However, we observe that single seasonal-trend decomposition is often insufficient, and time series data exhibit different pattern regularities at different sampling scales. To address this, we propose a novel method that performs multi-scale seasonal-trend decomposition and aggregates features from fine to coarse scales to fully exploit semantic information. Furthermore, we draw inspiration from ensemble learning and employ Fourier neural operator-based backbone networks at different scales, with the predictions from multiple scales aggregated as the final output prediction. Extensive experiments demonstrate that our proposed model achieves superior prediction performance than state-of-the-art models on multiple public datasets.","","979-8-3503-7510-7","10.1109/CISAT62382.2024.10695364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10695364","Time series forecasting;Fourier Neural Operator;Series Decomposition;Multi-scale","Time series analysis;Semantics;Neural networks;Weather forecasting;Predictive models;Transformers;Data models;Ensemble learning;Forecasting;Periodic structures","","","","18","IEEE","2 Oct 2024","","","IEEE","IEEE Conferences"
"Learning Time-Aware Graph Structures for Spatially Correlated Time Series Forecasting","M. Ma; J. Hu; C. S. Jensen; F. Teng; P. Han; Z. Xu; T. Li","School of Computing and Artificial Intelligence, Southwest Jiaotong University, China; East China Normal University, China; Aalborg University, Denmark; School of Computing and Artificial Intelligence, Southwest Jiaotong University, China; University of Electronic Science and Technology of China, China; Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates; School of Computing and Artificial Intelligence, Southwest Jiaotong University, China",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","4435","4448","Spatio-temporal forecasting of future values of spatially correlated time series is important across many cyber-physical systems (CPS). Recent studies offer evidence that the use of graph neural networks to capture latent correlations between time series holds a potential for enhanced forecasting. However, most existing methods rely on predefined or self-learning graphs, which are either static or unintentionally dynamic, and thus cannot model the time-varying correlations that exhibit trends and periodicities caused by the regularity of the underlying processes in CPS. To tackle such limitation, we propose Time-aware Graph Structure Learning (TagSL), which extracts time-aware correlations among time series by measuring the interaction of node and time representations in high-dimensional spaces. Notably, we introduce time discrepancy learning that utilizes contrastive learning with distance-based regularization terms to constrain learned spatial correlations to a trend sequence. Additionally, we propose a periodic discriminant function to enable the capture of periodic changes from the state of nodes. Next, we present a Graph Convolution-based Gated Recurrent Unit (GCGRU) that jointly captures spatial and temporal dependencies while learning time-aware and node-specific patterns. Finally, we introduce a unified framework named Time-aware Graph Convolutional Recurrent Network (TGCRN), combining TagSL, and GCGRU in an encoder-decoder architecture for multi-step spatiotemporal forecasting. We report on experiments with TGCRN and popular existing approaches on five real-world datasets, thus providing evidence that TGCRN is capable of advancing the state-of-the-art. We also cover a detailed ablation study and visualization analysis, offering detailed insight into the effectiveness of time-aware structure learning.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00338","National Natural Science Foundation of China(grant numbers:62176221,62276215); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598092","Time series forecasting;spatiotemporal graph neural networks;time-aware graph structure learning","Correlation;Time series analysis;Logic gates;Market research;Extraterrestrial measurements;Time measurement;Graph neural networks","","11","","38","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping","L. Wang; L. Bai; Z. Li; R. Zhao; F. Tsung","Interdisciplinary Programs Office, The Hong Kong University of Science and Technology, Hong Kong SAR; The Shanghai AI Laboratory, Shanghai, China; Information System, University of Cologne, Cologne, NRW, Germany; SenseTime Reasearch and Qing Yuan Research Institute of Shanghai Jiao Tong University, Shanghai, China; The Hong Kong University of Science and Technology and The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",2023 IEEE 19th International Conference on Automation Science and Engineering (CASE),"28 Sep 2023","2023","","","1","7","Correlated time series analysis plays an important role in many real-world industries. Learning an efficient representation of this large-scale data for further downstream tasks is necessary but challenging. In this paper, we propose a time-step-level representation learning framework for individual instances via bootstrapped spatiotemporal representation prediction. We evaluated the effectiveness and flexibility of our representation learning framework on correlated time series forecasting and cold-start transferring the forecasting model to new instances with limited data. A linear regression model trained on top of the learned representations demonstrates our model performs best in most cases. Especially compared to representation learning models, we reduce the RMSE, MAE, and MAPE by 37%, 49%, and 48% on the PeMS-BAY dataset, respectively. Furthermore, in real-world metro passenger flow data, our framework demonstrates the ability to transfer to infer future information of new cold-start instances, with gains of 15%, 19%, and 18%. The source code will be released under the GitHub https://github.com/bonaldli/Spatiotemporal-TS-Representation-Learning.","2161-8089","979-8-3503-2069-5","10.1109/CASE56687.2023.10260640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10260640","","Representation learning;Source coding;Time series analysis;Self-supervised learning;Predictive models;Data models;Spatiotemporal phenomena","","5","","35","IEEE","28 Sep 2023","","","IEEE","IEEE Conferences"
"TravelNet: A Recursive Decomposition-Based Time Series Forecasting Framework for Bus Travel Time Estimation","B. Chen; Y. Li; R. Li; W. Wu; M. Shi; B. Tan","Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China; Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China; Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China; Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China; Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China; Chongqing Key Laboratory of Secure Computing for Biology, Chongqing Institute of Green and Intelligent Technology, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Public transportation is an indispensable part of daily life, and predicting bus travel times has long been a focus in public transportation research. In recent years, the development of time series forecasting methods based on machine learning and deep learning has provided new solutions to this problem. However, the complexity of historical data generated during the bus travel process makes it challenging for existing methods to effectively capture meaningful patterns, thereby limiting their ability to achieve more accurate estimations. To address this issue, this paper proposes TravelNet, a recursive decomposition-based time series forecasting framework that integrates extraction of key components and multi-time scale analysis to enhance the accuracy of bus travel time estimation (BTTE). Specifically, TravelNet achieves significant average MAPE improvements of 72.23% on ARIMA, 48.96% on GRU, 5.66% on Transformer, and 6.48% on TCN, which are considered baselines, using real-world data from Chongqing, China. For more advanced models, such as DLinear and iTransformer, TravelNet also achieves notable improvements of 13.56% and 4.81%, respectively.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11228543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228543","representation learning;time series forecasting;recursive decomposition;public transportation","Representation learning;Accuracy;Time series analysis;Neural networks;Estimation;Predictive models;Transformers;Robustness;Forecasting;Public transportation","","","","41","IEEE","14 Nov 2025","","","IEEE","IEEE Conferences"
"Robust Time Series Contrastive Representation Learning via Explicit Seasonal-Trend Disentanglement","F. Li; B. Jin","Dalian University of Foreign Languages, Dalian, China; Dalian University of Technology, Dalian, China",IEEE Access,"20 Oct 2025","2025","13","","178681","178692","We address universal self-supervised representation learning for time series under label scarcity and distribution shifts. A key challenge is that prevalent encode-then-decompose pipelines only implicitly separate seasonal and trend signals, which mixes noise across components and degrades robustness, especially with sudden jumps or stochastic movements. In this work, we propose an explicit, decomposition-aware contrastive framework: original time series are split via a Fourier transform into seasonal (high-frequency) and trend (low-frequency) components. Seasonality is modeled by a frequency-enhanced attention encoder with amplitude-induced augmentations; trend is captured by a tree-structured causal convolution encoder with random perturbations to handle non-stationary drift. The two views are trained contrastively and then fused with lightweight fine-tuning, delivering state-of-the-art accuracy, improved robustness to jumps, and interpretable attributions.","2169-3536","","10.1109/ACCESS.2025.3621317","National Natural Science Foundation of China(grant numbers:62172074); Program of Introducing Talents of Discipline to Universities (Plan 111)(grant numbers:B20070); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11202913","Contrastive learning;seasonal-trend decomposition;time-series representation learning","Market research;Time series analysis;Forecasting;Noise;Contrastive learning;Feature extraction;Costs;Transformers;Representation learning;Data augmentation","","","","48","CCBY","14 Oct 2025","","","IEEE","IEEE Journals"
"Domain Generalization for Time-Series Forecasting via Extended Domain-Invariant Representations","Y. Shi; W. Li; A. Y. Zomaya","Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Australia; Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Australia; Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Australia",2024 IEEE Annual Congress on Artificial Intelligence of Things (AIoT),"20 Sep 2024","2024","","","110","116","Time-series forecasting is crucial for IoT applications, but generalizing across domains is challenging due to distinct data distributions and dynamics. Most domain generalization methods work well for image processing and classification, but they struggle with time-series forecasting. This is because they solely learn domain-invariant representations of input data, ignoring variations in the output space across domains. This oversight can lead to inaccurate forecasts when outputs in new domains exhibit different distributions or temporal patterns. In this work, we present a new approach to improve the time-series forecasting model generalization by extracting domain-invariant representations from both input and output data. Experiments demonstrate the effectiveness of our approach, achieving significant improvements in forecasting accuracy across multiple test domains. Compared to state-of-the-art methods, our approach delivers up to an 8% increase in accuracy.","","979-8-3503-9229-6","10.1109/AIoT63253.2024.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10677579","Domain generalization;Time series forecasting","Bridges;Accuracy;Image processing;Time series analysis;Predictive models;Data models;Internet of Things","","1","","34","IEEE","20 Sep 2024","","","IEEE","IEEE Conferences"
"IL-DiffTSF: Invertible Latent Diffusion for Probabilistic Time Series Forecasting","V. K. Z. Koh; S. Lin; Y. Li; Z. Lin; B. Wen","School of Electrical and Electronic Engineering, Nanyang Technological University, 50 Nanyang Ave, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, 50 Nanyang Ave, Singapore; Xylem Water Solutions Singapore Pte Ltd, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, 50 Nanyang Ave, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, 50 Nanyang Ave, Singapore",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Internet of Things (IoT) devices generate large volumes of time series data that are often volatile and complex, making probabilistic time series forecasting (TSF) essential for modeling the distribution of future outcomes. Recently, diffusion-based TSF methods have gained attention for their ability to learn complex distributions. However, they typically apply the diffusion process directly in the time domain, which may struggle to capture complex temporal dependencies, thus limiting the full potential of the diffusion process. Besides, they obtain probabilistic forecasts by sampling multiple plausible outcomes from the learned distribution, which is time-consuming and less effective. To solve these problems, we propose Invertible Latent Diffusion for probabilistic Time Series Forecasting (IL-DiffTSF), a novel approach based on a latent diffusion model. Specifically, we design an invertible latent projection between time series and latent space, where a conditional diffusion process is applied. This design ensures bidirectional consistency and minimal information loss, enabling more accurate TSF. Moreover, instead of sampling-based probabilistic forecasting, IL-DiffTSF represents uncertainties by directly learning a mapping from latent representations to prediction errors, achieving faster and more reliable uncertainty estimates. Experiments on univariate and multivariate benchmarks validate the efficiency and effectiveness of IL-DiffTSF. The code for this project is available at https://github.com/vanerkz/IL-DiffTSF.","2327-4662","","10.1109/JIOT.2025.3636872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11267410","Time series forecasting;latent diffusion model;invertible latent diffusion","Probabilistic logic;Diffusion processes;Predictive models;Time-domain analysis;Time series analysis;Internet of Things;Training;Diffusion models;Accuracy;Limiting","","","","","IEEE","25 Nov 2025","","","IEEE","IEEE Early Access Articles"
"iBACon: imBalance-Aware Contrastive Learning for Time Series Forecasting","J. Zhang; Q. Dai; R. Ye","College of Information Science and Technology & Artificial Intelligence, Nanjing Forestry University, Nanjing, China; College of Artificial Intelligence, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Artificial Intelligence, Nanjing Agricultural University, Nanjing, China",IEEE Transactions on Knowledge and Data Engineering,"12 Sep 2025","2025","37","10","5967","5982","Time series forecasting (TSF) has gained significant attention as a widely explored research area in diverse applications. Existing methods, which focus on improvements in the most common scenarios, focus little on performance in rare cases. Despite their scarce occurrences in the data, these rare samples are more challenging and easily overlooked by models, significantly contributing to the total loss. In this paper, we propose a novel approach (dubbed iBACon) that overcomes this limitation by employing imbalance-aware contrastive learning and trend-seasonal decomposition architecture, specifically designed to solve TSF. To this end, we first introduce the Input-Output Difference (IOD) metric as a pseudo-label and reveal the data imbalance phenomenon in TSF. This label continuity inherently provides a meaningful distance between targets, implying a similarity between nearby targets in both label and feature spaces. Based on this similarity, the proposed imbalance-aware contrastive loss aims to reshape feature embeddings to facilitate knowledge dissemination among challenging samples and learn specific predictive features. Finally, when combined with our trend-seasonal decomposition network, iBACon significantly improves TSF accuracy. Experiments show that iBACon enhances overall average accuracy and substantially improves the 1-3% most challenging samples.","1558-2191","","10.1109/TKDE.2025.3589693","National Natural Science Foundation of China(grant numbers:62476126); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11081860","Time series forecasting;data imbalance;contrastive learning","Time series analysis;Forecasting;Contrastive learning;Predictive models;Accuracy;Artificial intelligence;Market research;Data models;Transformers;Data augmentation","","","","53","IEEE","16 Jul 2025","","","IEEE","IEEE Journals"
"Data-driven Latent Graph Structure Learning for Diagnosis of Alzheimer’s Syndrome","J. Wang; C. Wu","School of Computer Engineering and Science, Shanghai Institute for Advanced Communication and Data Science, Shanghai University; School of Computer Engineering and Science, Shanghai University, Shanghai, China",2022 26th International Conference on Pattern Recognition (ICPR),"29 Nov 2022","2022","","","3138","3144","Complex systems often have a latent graph structure. Studying the underlying graph structure will help us to analyze the mechanisms of complex phenomena. However, it is a challenging problem to learn effective graph structures from the data and apply them to downstream tasks. In this paper, we propose an end-to-end graph learning approach for Alzheimer’s syndrome diagnosis based on functional magnetic resonance imaging (fMRI) data of brain regions, which is completely data-driven. The interactions between time-series of each brain region are represented as graph structures, and a multi-head attention mechanism is used to update the representations of the nodes. Then, the graph structures are obtained from the feature sampling of the edges. Finally, the learned graph structure is combined with the left-out time-series data features and the node prior to completing the classification task of the brain network. In comparison with the latest research methods, our approach achieves higher classification accuracy.","2831-7475","978-1-6654-9062-7","10.1109/ICPR56361.2022.9956713","Shanghai University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9956713","","Image edge detection;Functional magnetic resonance imaging;Pattern recognition;Task analysis;Alzheimer's disease;Complex systems","","","","32","IEEE","29 Nov 2022","","","IEEE","IEEE Conferences"
"SFLGNN: Power Load Forecasting Based on Spectral-Frequency Learning and Graph Neural Network","X. Li; X. Wei; Z. Liu; S. Xie; J. Sun; H. Qin; Z. Wei","State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China; State Grid Jinan Power Supply Company, Jinan, China",2024 4th International Conference on Computer Systems (ICCS),"19 Dec 2024","2024","","","23","27","With the continuous development of modern power systems, accurate power load forecasting has gradually become a key issue in energy management. Compared to deep learning models, existing statistical-based prediction models are not well suited to learn how to represent power load data and mine the rich information in the data. In addition, power load data needs to consider both intra-series temporal correlation and inter-series correlation. Recently, attempts have been made to capture both correlations simultaneously, but most of the studies capture only temporal correlations in the time domain and use predefined a priori as inter-sequence relationships. In this paper, SFLGNN (Spectral-Frequency Learning Based Graph Neural Network) is designed for power load forecasting. SFLGNN effectively solves the problem by capturing both variable correlation and inter-sequence correlation using graph neural networks, and extracts important features through CP decomposition with multi-attention mechanism. In addition, SFLGNN enhances representation learning through Spectral-Frequency Learning. We performed comparative experiments, ablation experiments, and hyper-parameter sensitivity experiments on our collected dataset. The experiments demonstrate the effectiveness of our proposed model in the power load forecasting task.","","979-8-3503-6634-1","10.1109/ICCS62594.2024.10795826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10795826","power load forecasting;graph neural network;representation learning;tensor factorization","Representation learning;Correlation;Load forecasting;Computational modeling;Time series analysis;Predictive models;Feature extraction;Graph neural networks;Data models;Load modeling","","","","15","IEEE","19 Dec 2024","","","IEEE","IEEE Conferences"
"Contrastive Representation Learning for Time Series via Compound Consistency and Hierarchical Contrasting","T. Zheng; G. Cao; L. Chen; K. Hao","Engineering Research Center of Digitized Textile & Apparel Technology, Ministry of Education, Donghua University, Shanghai, P. R. China; Engineering Research Center of Digitized Textile & Apparel Technology, Ministry of Education, Donghua University, Shanghai, P. R. China; Engineering Research Center of Digitized Textile & Apparel Technology, Ministry of Education, Donghua University, Shanghai, P. R. China; Engineering Research Center of Digitized Textile & Apparel Technology, Ministry of Education, Donghua University, Shanghai, P. R. China",2023 IEEE 12th Data Driven Control and Learning Systems Conference (DDCLS),"7 Jul 2023","2023","","","1623","1628","In this paper, a novel contrastive representation learning framework for time series data is proposed. The framework is designed to learn general representations of time series at various semantic levels and is capable of transferring across different datasets. The framework incorporates two key components. Firstly, a hierarchical contrasting method is used to consider both the temporal and instance dimensions of the time series and captures information at different levels through maximum pooling at corresponding timestamps, enabling the model to learn fine-grained and multi-scale time-stamped representations for time series prediction tasks. Secondly, a compound consistency constraint is leveraged, which combines transformation consistency and temporal-frequency consistency, to effectively learn a universal representation of the time series, thereby ensuring its transferability across different datasets. Additionally, the framework considers both the temporal and frequency information of the time series, and uses an adaptive wavelet transform to obtain the frequency domain representation while maintaining temporal alignment, facilitating the contrast of temporal-frequency consistency. Finally, the proposed framework is evaluated through extensive experiments on time series prediction tasks and compared with existing models on four public datasets. The results show that the linear regressor trained with the representations learned by the proposed model outperforms existing time series prediction models in terms of prediction accuracy and transferability.","2767-9861","979-8-3503-2105-0","10.1109/DDCLS58216.2023.10166246","Natural Science Foundation of Shanghai(grant numbers:19ZR1402300,20ZR1400400); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10166246","Contrastive Learning;Time Series;Time-Frequency Consistency;Hierarchical Contrasting","Wavelet transforms;Representation learning;Time-frequency analysis;Adaptation models;Wavelet domain;Time series analysis;Predictive models","","","","19","IEEE","7 Jul 2023","","","IEEE","IEEE Conferences"
"SimEXT: Self-supervised Representation Learning for Extreme Values in Time Series","A. H. Galib; P. -N. Tan; L. Luo","Dept of Computer Science and Engineering, Michigan State University; Dept of Computer Science and Engineering, Michigan State University; Dept of Geography, Environment, and Spatial Sciences, Michigan State University",2023 IEEE International Conference on Data Mining (ICDM),"5 Feb 2024","2023","","","1031","1036","Forecasting extreme values in time series is an important but challenging problem as the extreme values are rarely observed even when a large amount of historical data is available. The modeling of extreme values requires a specific focus on estimating the tail distribution of the time series, whose statistical properties may differ from the distribution of its non-extreme values. To overcome this challenge, we present a novel self-supervised learning framework, SimEXT, to learn a robust representation of the time series that preserves the fidelity of its tail distribution. The framework employs a combination of contrastive learning and a reconstruction-based autoencoder architecture to facilitate robust representation learning of the temporal patterns associated with the extreme events. SimEXT also incorporates a wavelet-based data augmentation technique with a distribution-based loss function to prioritize the learning of extreme value distribution. We provide probabilistic guarantees on the wavelet-based augmentation that enables the wavelet coefficients to be perturbed during data augmentation without significantly altering the extreme values of the time series. Experimental results on real-world datasets show that SimEXT can effectively learn a robust representation of the time series to boost the performance of downstream tasks for forecasting block maxima values.","2374-8486","979-8-3503-0788-7","10.1109/ICDM58522.2023.00119","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415790","forecasting;time series;extreme values","Representation learning;Time series analysis;Self-supervised learning;Tail;Data augmentation;Forecasting;Wavelet coefficients","","","","18","IEEE","5 Feb 2024","","","IEEE","IEEE Conferences"
"Transformer-PLM Enhanced Multimodal Time Series Forecasting via Decoupled Dual-Temporal Graph Adaptation","J. Lei; W. Zhang; Q. Yang; X. Zhang; H. Tang","School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Shenzhen, Guangdong, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, Hubei, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",IEEE Signal Processing Letters,"","2025","PP","99","1","5","With the proliferation of multimodal data in real-world applications, integrating time series with auxiliary modalities has become critical for accurate forecasting. Although Transformers and pre-trained language model (PLM) have enabled initial explorations of multi-domain multimodal time series analysis, several pressing challenges still remain. Specifically, coarse-grained alignment may hinder long-range semantic capture, while distribution shifts in intra-modality introduce fluctuating noise. Inspired by GNNs' capability to model spatio-temporal dependencies and contextual interactions, we propose Decoupled Dual Adaptive Temporal Graph (DDATG), a universal GNN plugin for Transformer-PLM based adaptive text-time series bimodal learning. Our framework: (1) Reconstructs global temporal patterns from decoupled local residual terms in temporal modality, enhancing local-global semantic discovery and diversifying attention mechanisms; (2) Explicitly constructs pointwise contextual connections and strengthens aggregation in textual modality, facilitating inter-modal semantic alignment. Extensive experiments across Transformer variants and domain-specific datasets demonstrate the effectiveness of DDATG. Code is available at https://github.com/DDATG.","1558-2361","","10.1109/LSP.2025.3630087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11230812","Multimodal Time Series Forecasting;Graph Structure Adaptation;Multimodal Representation Learning","Transformers;Time series analysis;Forecasting;Adaptation models;Semantics;Modeling;Market research;Predictive models;Graph neural networks;Electronic mail","","","","","IEEE","6 Nov 2025","","","IEEE","IEEE Early Access Articles"
"GTformer: Graph-Based Temporal-Order-Aware Transformer for Long-Term Series Forecasting","A. Liang; X. Chai; Y. Sun; M. Guizani","School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; Machine Learning Department, Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE",IEEE Internet of Things Journal,"24 Sep 2024","2024","11","19","31467","31478","In the production environment of the Internet of Things (IoT), sensors of various qualities generate a large amount of multivariate time series (MTS) data. The long-term prediction of time series data generated by various IoT devices provides longer foresight and helps execute necessary resource scheduling or fault alarms in advance, thus improving the efficiency of system operation and ensuring system security. In recent years, deep learning models like Transformers have achieved advanced performance in multivariate long-term time series forecasting (MLTSF) tasks. However, many previous research attempts either overlooked the interseries dependencies or ignored the need to model the strict temporal order of MTS data. In this article, we introduce GTformer, a graph-based temporal-order-aware transformer model. We propose an adaptive graph learning method specifically designed for MTS data to capture both uni-directional and bi-directional relations. In addition, we generate positional encoding in a sequential way to emphasize the strict temporal order of time series. By adopting these two components, our model can have a better understanding of the interseries and intraseries dependencies of MTS data. We conducted extensive experiments on eight real-world data sets, and the results show that our model achieves better predictions compared with state-of-the-art methods.","2327-4662","","10.1109/JIOT.2024.3419768","National Natural Science Foundation of China(grant numbers:62272052,62172051); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10574288","Interseries dependencies;long-term time series forecasting;multivariate time series (MTS);strict temporal order;transformer","Time series analysis;Transformers;Predictive models;Forecasting;Data models;Task analysis;Internet of Things","","12","","45","IEEE","27 Jun 2024","","","IEEE","IEEE Journals"
"Representation Learning and Knowledge Distillation for Lightweight Domain Adaptation","S. R. Bin Shah; S. Subhash Putty; A. Schwung","Department of Electrical Power Engineering, South Westphalia University of Applied Sciences, Soest, Germany; Department of Electrical Power Engineering, South Westphalia University of Applied Sciences, Soest, Germany; Department of Electrical Power Engineering, South Westphalia University of Applied Sciences, Soest, Germany",2024 IEEE Conference on Artificial Intelligence (CAI),"30 Jul 2024","2024","","","1202","1207","In industrial machine learning applications, insufficient data, lack of labeling, distribution shift between subsets, varying operational conditions, etc. result in poor generalizing performance by pre-trained neural network models across domains. In contrast to image detection tasks, time series dataset contain critical domain-specific characteristics that must be learned by the corresponding networks. Naively aligning the learned representations during the adaptation process increases the risk of losing these key information, thus resulting in poor performance. This paper proposes a lightweight domain adaptation method involving representation learning and knowledge distillation (RepLKD). A separate network is pre-trained to learn valuable information from the target data in its latent space with the help of a reconstructor. In the adaptation stage, we use maximum mean discrepancy to minimize the difference in distributions between the source and target latent space. Additionally, we implement knowledge distillation to encourage the target network to generate source-like latent embedding and penalize only when an upper-bound condition is not fulfilled to prevent over-regularization and loss of domain-specific features. Finally, we test our proposed method on 12 cross-domain scenarios with the C-MAPSS dataset and compare the efficacy of our method against existing literature methods.","","979-8-3503-5409-6","10.1109/CAI59869.2024.00214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10605466","Unsupervised domain adaptation;maximum mean discrepancy;knowledge distillation;representation learning;remaining useful lifetime estimation;C-MAPSS","Representation learning;Knowledge engineering;Adaptation models;Time series analysis;Neural networks;Data models;Labeling","","","","24","IEEE","30 Jul 2024","","","IEEE","IEEE Conferences"
"A Review for Pre-Trained Transformer-Based Time Series Forecasting Models","Y. E. Midilli; S. Parshutin","Information Technology Dept., Riga Technical University, Riga, Latvia; Information Technolgy Dept., Riga Technical University, Riga, Latvia",2023 IEEE 64th International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS),"17 Nov 2023","2023","","","1","8","Transformer-based models have proven their superiority against recurrent networks in time series forecasting. Enhancing transformer-based forecasting models via pretraining tasks is a novel approach in the literature. In this paper, we are reviewing the most recent papers about pretraining aspects of time series as well as pretraining tasks that are used in transformer-based architectures.","2771-6937","979-8-3503-7029-4","10.1109/ITMS59786.2023.10317721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10317721","pretraining;transformer;forecasting;contrastive learning;masked auto-encoder","Training;Computational modeling;Time series analysis;Computer architecture;Predictive models;Transformers;Probabilistic logic","","","","38","IEEE","17 Nov 2023","","","IEEE","IEEE Conferences"
"Multivariate Segment Expandable Encoder-Decoder Model for Time Series Forecasting","Y. Li; D. C. Anastasiu","Computer Science and Engineering Department, Santa Clara University, Santa Clara, CA, USA; Computer Science and Engineering Department, Santa Clara University, Santa Clara, CA, USA",IEEE Access,"13 Dec 2024","2024","12","","185012","185026","Accurate time series forecasting is critical in a variety of fields, including transportation, weather prediction, energy management, infrastructure monitoring, and finance. Forecasting highly skewed and heavy-tailed time series, particularly in multivariate environments, is still difficult. In these cases, accurately capturing the relationships between variables is critical for successful model design. This is especially true when dealing with extreme events like droughts or floods in streamflow forecasting, which can have severe consequences on public safety and social well-being. We present the Multivariate Segment-Expandable Encoder Decoder (MSEED), a novel framework designed to address the challenges of extreme-adaptive multivariate time series forecasting. MSEED features a hierarchical encoder-decoder architecture, a short-term-enhanced subnet, and a feature assembling layer that integrates spatial and temporal information across multivariate inputs. By capturing quantile distributions across segmented subsequences at multiple scales, the model is able to detect complex patterns, enhancing both the accuracy and robustness of forecasts. Additionally, MSEED incorporates a simple vanilla encoder-decoder model for strengthening rolling predictions. The framework has been tested on four challenging real-world datasets, focusing on two critical forecasting scenarios: long-term predictions (three days ahead) and rolling predictions (every four hours) to simulate real-time decision-making in water resource management. MSEED consistently outperforms state-of-the-art models, showing improvements in forecasting accuracy ranging from 18% to 74%.","2169-3536","","10.1109/ACCESS.2024.3513256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10781401","Deep learning;representation learning;oversampling policy;streamflow prediction;hydrologic prediction;LSTM;time series","Time series analysis;Forecasting;Predictive models;Accuracy;Transformers;Rain;Data models;Kurtosis;Heavily-tailed distribution;Deep learning","","1","","48","CCBY","9 Dec 2024","","","IEEE","IEEE Journals"
"Improving Time-Series Classification Accuracy Based on Temporal Feature Representation Learning Using CRU-LSTM Autoencoder","D. Kim; S. Sim; B. Yoon; L. Liu; H. Bae","Dept. Industrial Engineering, Major in Industrial Data Science & Engineering, Pusan National University, Busan, South Korea; Dept. Industrial Management & Big Data Engineering, Dong-Eui University, Busan, South Korea; Dept. Industrial Management & Big Data Engineering, Dong-Eui University, Busan, South Korea; College of Computing, Georgia Institute of Technology, Georgia, USA; Dept. Industrial Engineering, Major in Industrial Data Science & Engineering, Pusan National University, Busan, South Korea",2023 IEEE 5th International Conference on Cognitive Machine Intelligence (CogMI),"19 Feb 2024","2023","","","175","183","Time-series data consists of a sequence of observations recorded in chronological order, where the data changes over time. This type of data exhibits various characteristics, such as temporal volatility, trends, and seasonality. Recently, a new layer structure called Correlation Recurrent Units (CRU) has been proposed to capture not only temporal variability but also trends and seasonality in time-series data. In this study, we propose an end-to-end model that utilizes a CRU autoencoder to learn temporal feature representations and address time-series classification problems simultaneously. To validate the performance of our proposed model, we conducted comparative experiments using 30 time-series classification datasets from six different types. The experimental results showed that the proposed model outperformed the baseline models in 20 out of the 30 time-series datasets. This indicates that the proposed approach effectively captures various temporal features in time-series data and improves the performance of time-series classification tasks.","","979-8-3503-2383-2","10.1109/CogMI58952.2023.00033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10431541","Time-series Classification;Time-series Data;Temporal Feature Representation Learning;Correlation Recurrent Units Autoencoder","Representation learning;Time series analysis;Feature extraction;Market research;Data models;Task analysis;Machine intelligence","","1","","29","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"A Deep Learning Framework for Non-stationary Time Series Prediction","L. Li; S. Huang; Z. Ouyang; N. Li","College of Computer Science and Technology, Changchun University, Changchun, China; College of Computer Science and Technology, Changchun University, Changchun, China; College of Computer Science and Technology, Changchun University, Changchun, China; College of Computer Science and Technology, Changchun University, Changchun, China","2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA)","18 Jul 2022","2022","","","339","342","In non-stationary time series, there are data bursts, which brings challenges to accurately predict data. This paper proposes a deep learning framework for non-stationary time series prediction. In this framework, the first-order and second-order difference and decomposition of the original time series are first made respectively, so as to generate five new time series, which are as the input of the framework. Then, a prediction model is constructed sequentially by GRU (gated recurrent unit) and FCN (fully-connected network) networks to predict and fit data. Finally, a two-stage training mode is designed, which first predicts the trend and component, and then fits with the cycle to produce the prediction data. The experiments are tested on the public air quality dataset, and the results show that our approach can accurately predict the non-stationary time series, especially overcomes the lag, and achieves better performance than typical statistics methods and deep learning models.","","978-1-6654-5911-2","10.1109/CVIDLICCEA56201.2022.9824863","Natural Science Foundation of Jilin Province; Jilin Scientific and Technological Development Program; Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9824863","non-stationary time series;deep learning;data prediction;gated recurrent unit networks;convolutional neural networks","Deep learning;Training;Representation learning;Atmospheric modeling;Time series analysis;Neural networks;Predictive models","","11","","17","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Attentive Neural Controlled Differential Equations for Time-series Classification and Forecasting","S. Y. Jhin; H. Shin; S. Hong; M. Jo; S. Park; N. Park; S. Lee; H. Maeng; S. Jeon","Yonsei University, Seoul, South Korea; Yonsei University, Seoul, South Korea; Yonsei University, Seoul, South Korea; Yonsei University, Seoul, South Korea; Yonsei University, Seoul, South Korea; Yonsei University, Seoul, South Korea; Socar Co. Ltd., Seoul, South Korea; Socar Co. Ltd., Seoul, South Korea; Socar Co. Ltd., Seoul, South Korea",2021 IEEE International Conference on Data Mining (ICDM),"24 Jan 2022","2021","","","250","259","Neural networks inspired by differential equations have proliferated for the past several years, of which neural ordinary differential equations (NODEs) and neural controlled differential equations (NCDEs) are two representative examples. In theory, NCDEs exhibit better representation learning capability for time-series data than NODEs. In particular, it is known that NCDEs are suitable for processing irregular time-series data. Whereas NODEs have been successfully extended to adopt attention, methods to integrate attention into NCDEs have not yet been studied. To this end, we present $\underline{\mathrm{A}}$ttentive $\underline{\mathrm{N}}$eural $\underline{\mathrm{C}}$ontrolled $\underline{\mathrm{D}}$ifferential $\underline{\mathrm{E}}$quations (ANCDEs) for time-series classification and forecasting, where dual NCDEs are used: one for generating attention values, and the other for evolving hidden vectors for a downstream machine learning task. We conduct experiments on three real-world time-series datasets and ten baselines. After dropping some values, we also conduct experiments on irregular time-series. Our method consistently shows the best accuracy in all cases by non-trivial margins. Our visualizations also show that the presented attention mechanism works as intended by focusing on crucial information.","2374-8486","978-1-6654-2398-4","10.1109/ICDM51629.2021.00035","Yonsei University; Yonsei University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679144","time-series data;neural controlled differential equations;attention","Representation learning;Neural networks;Data visualization;Focusing;Ordinary differential equations;Mathematical models;Data models","","8","","49","IEEE","24 Jan 2022","","","IEEE","IEEE Conferences"
"MTAP-DK: Multivariate Time-Series Anomaly Prediction with Domain Knowledge","L. Xue; Z. Peng; J. Zhang; F. Wang; Y. Wang","Shandong University, Qingdao, China; Shandong University, Qingdao, China; Shandong University, Qingdao, China; Shandong University, Qingdao, China; Shandong University, Qingdao, China",2022 International Joint Conference on Neural Networks (IJCNN),"30 Sep 2022","2022","","","1","8","Predicting anomalies of mobile equipment plays an important role in performing preventive maintenance, alleviating major economic losses and personal safety issues. Previous studies basically adopted data-driven models for anomaly prediction or detection of industrial equipment, ignoring the importance of domain knowledge. The domain knowledge can more accurately and theoretically capture the complex relationship among features. However, building the deep learning models incorporating domain knowledge is very difficult due to the following challenges. First, the domain knowledge is often different from the actual state of the equipment, so it is difficult to obtain knowledge information that conforms to the real situation. Second, domain knowledge is difficult to directly and effectively be applied to deep learning models due to its diverse representations. In this paper, we propose a Multivariate Time-Series Anomaly Prediction with Domain Knowledge (MTAP-DK) to address these issues. Specifically, we firstly propose a knowledge extraction module, which can extract the domain equations that conform to the actual situation with the domain knowledge and historical data. Secondly, we design a domain guidance module to guide and constrain the graph neural network from the knowledge level, to improve its capabilities to express the relationship among features. Thirdly, we predict future data based on the graph incorporating knowledge information. Finally, the prediction is reconstructed by the multi-scale convolution reconstruction method, and the abnormal information is inferred according to the reconstruction error.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892923","National Natural Science Foundation of China(grant numbers:62072282); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892923","Anomaly Prediction;Domain Knowledge;Multivariate Time-Series Prediction","Deep learning;Biological system modeling;Time series analysis;Predictive models;Reconstruction algorithms;Feature extraction;Mathematical models","","","","26","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"Characterizing Disease Spreading via Visibility Graph Embedding","K. Ni; J. Xu; S. Roach; T. -C. Lu; A. Kopylov","HRL Laboratories, Malibu, CA, USA; HRL Laboratories, Malibu, CA, USA; HRL Laboratories, Malibu, CA, USA; HRL Laboratories, Malibu, CA, USA; HRL Laboratories, Malibu, CA, USA",2021 IEEE International Conference on Big Data (Big Data),"13 Jan 2022","2021","","","2656","2661","Gaining timely insights on real-world emergency events, such as infectious disease outbreaks, is critical for developing appropriate response strategies. In this work, we propose a data-driven approach to study the spreading dynamics of the global Covid-19 pandemic. Specifically, we aim to identify a set of most “similar” geographic regions as proxies for making predictions on a targeted location. Example predictions include the number of new cases, number of hospitalizations, and number of deaths. Such predictions can be made at different levels of regional granularities, including city, county, and state levels. Our approach starts by transforming regional time series into graph representations using the natural visibility graph (NVG) model in order to capture their intrinsic trends and properties. These graphs are then projected onto a common embedding space using graph-level network embedding techniques. Essentially, each time series is converted as a data point in a feature embedding space, where spatial proximity indicates similarity among time series. Given a targeted region, our approach can identify the most “relevant” geographic regions by finding its k-nearest neighbors in the embedding space. Subsequently, appropriate response strategies and policies (e.g., school shutdown, indoor dining restriction) can be adapted based on the success or failure experiences from relevant regions. Our approach will potentially provide valuable insights in mitigating the spreading of infectious disease.","","978-1-6654-3902-2","10.1109/BigData52589.2021.9671810","United States Air Force; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9671810","Natural Visibility Graph;Graph Embedding;Forecast;Covid-19","COVID-19;Infectious diseases;Pandemics;Conferences;Time series analysis;Urban areas;Big Data","","","","21","IEEE","13 Jan 2022","","","IEEE","IEEE Conferences"
"Long Sequence Multivariate Time-Series Forecasting for Industrial Processes Using SASGNN","Y. Wang; X. Wang; J. Zhou; C. Yang; Y. Yang","School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China; School of Automation, Central South University, Changsha, China",IEEE Transactions on Industrial Informatics,"7 Oct 2024","2024","20","10","12407","12417","In process industries, the processes are usually very long, which results in long residence of the material in the process. In addition, in many processes, the quality of the final product cannot be detected online, making it challenging to achieve timely and effective control. Therefore, in many processes, middle-state variables are observed and used for control. In many cases, these middle-state variables cannot be measured online. Long sequence multivariate time series forecasting (MTSF) reveals the changes in the process in advance and allows us to make timely adjustments in predictive control mode. However, many current MTSF methods do not consider the relationships between variables adequately, making it difficult to achieve satisfactory results for long sequence forecasting. To address this problem, a novel sparse attention spectral graph neural network (SASGNN) is proposed. In SASGNN, a graph structure learning module is first developed to establish relationships between different variables by combining prior knowledge with a sparse attention mechanism. Then, a long sequence forecasting module transforms the constructed graph into the spectral domain to extract the latent temporal pattern of each variable and the correlation feature between different variables. Besides, considering the temporal information loss during modeling, SASGNN uses a variant GRU to extract the long-term dependencies from the historical data. Experimental results show the superior and stable performance for long sequence forecasting using the SASGNN.","1941-0050","","10.1109/TII.2024.3424214","National Natural Science Foundation of China(grant numbers:62073342,62394340); High Performance Computing Center of Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10601562","Froth flotation;graph neural network (GNN);industrial process;multivariate time-series forecasting (MTSF);sparse attention","Forecasting;Tungsten;Accuracy;Industries;Indexes;Graph neural networks;Feature extraction","","3","","30","IEEE","17 Jul 2024","","","IEEE","IEEE Journals"
"Wind Power Forecasting Based on a Spatial–Temporal Graph Convolution Network With Limited Engineering Knowledge","L. Yang; F. Tsung; K. Wang; J. Zhou","Department of Industrial Engineering, Tsinghua University, Beijing, China; Department of Industrial Engineering and Decision Analytics, Hong Kong University of Science and Technology, Hong Kong, China; Department of Industrial Engineering and the Vanke School of Public Health, Tsinghua University, Beijing, China; Control Engineering and Protection Department, Research and Development Center, Goldwind Science & Technology Company Ltd., Beijing, China",IEEE Transactions on Instrumentation and Measurement,"22 Mar 2024","2024","73","","1","13","Wind power forecasting is critical for ensuring the reliability of wind power systems. A wind turbine consists of several subsystems, each containing various sensors that collect multivariate time series. These subsystems can naturally classify the turbines into clusters. This clustering strongly correlates variables within the same cluster, and the correlation between two clusters can be derived from engineering knowledge. In this study, we propose a hierarchical multivariate time series forecasting method based on a spatial–temporal graph convolution network (HMTGCN) to forecast wind power by leveraging engineering knowledge. The model uses a spatial–temporal graph neural network (GNN) containing a graph learning module to extract features from each time-series cluster. These features are concatenated to form graph data at the cluster level, which are subsequently processed by a graph convolution network. We evaluated the performance using simulation experiments and a real-life wind power dataset, and the results showed that the proposed method improved the prediction performance by 8.99% on average, which demonstrated the effectiveness and superiority of our approach.","1557-9662","","10.1109/TIM.2024.3374321","National Natural Science Foundation of China(grant numbers:71932006,72371271); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462162","Engineering knowledge;graph neural network (GNN);hierarchical data;multivariate time-series forecasting;wind power forecasting","Time series analysis;Wind turbines;Forecasting;Wind power generation;Sensors;Wind forecasting;Knowledge engineering","","8","","24","IEEE","7 Mar 2024","","","IEEE","IEEE Journals"
"A Large-Scale Ensemble Learning Framework for Demand Forecasting","Y. -J. Park; D. Kim; F. Odermatt; J. Lee; K. -M. Kim","MIT, Cambridge, MA, USA; Seoul National University, Seoul, South Korea; ETH Zürich, Zürich, Switzerland; Superpetual Inc., Seoul, South Korea; NAVER CLOVA & NAVER AI Lab, Seongnam, South Korea",2022 IEEE International Conference on Data Mining (ICDM),"1 Feb 2023","2022","","","378","387","Demand forecasting is a crucial component of supply chain management for revenue optimization and inventory planning. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful ensemble framework capable of accurately predicting future demand for a diverse range of items. Forchestra consists of two parts: 1) base predictors and 2) a neural conductor. For a given time series, each base predictor outputs its respective forecast based on historical observations. On top of the base predictors, the neural conductor adaptively assigns the importance weight for each predictor by looking at the representation vector provided by a representation module. Finally, Forchestra aggregates the predictions by the weights and constructs a final prediction. In contrast to previous ensemble approaches, the neural conductor and all base predictors of Forchestra are trained in an end-to-end manner; this allows each base predictor to modify its reaction to different inputs, while supporting other predictors and constructing a final prediction jointly. We empirically show that the model size is scalable to up to 0.8 billion parameters ($\approx$400-layer LSTM). The proposed method is evaluated on our proprietary E-Commerce (100K) and the public M5(30K) datasets, and it outperforms existing forecasting models with a significant margin. In addition, we observe that our framework generalizes well to unseen data points when evaluated in a zeroshot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional ensemble approaches. The code is available at https://github.com/young-j-parld22-ICDM-Forchestra.","2374-8486","978-1-6654-5099-7","10.1109/ICDM54844.2022.00048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10027662","","Analytical models;Supply chain management;Time series analysis;Demand forecasting;Predictive models;Conductors;Planning","","2","","37","IEEE","1 Feb 2023","","","IEEE","IEEE Conferences"
"CoGenT: A Unified Contrastive-Generative Framework for Time Series Classification","Z. Liu; A. Alavi; M. Li; X. Zhang","School of Computing Technologies, RMIT, Melbourne, VIC, Australia; School of Computing Technologies, RMIT, Melbourne, VIC, Australia; School of Computing Technologies, RMIT, Melbourne, VIC, Australia; Department of Computer Science at the University of North Carolina at Charlotte, NC, USA",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","10","Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at distinguishing between different examples, and generative approaches that learn the overall data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive-Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. Co-GenT addresses fundamental limitations of both approaches: it overcomes contrastive learning’s sensitivity to high intra-class similarity in temporal data while reducing generative methods’ dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2& and 14.27& F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the CoGenT preserves high accuracy while acquiring structural reliability. These findings establish a foundation for hybrid SSL in time series analysis. Code at https://github.com/DL4mHealth/cogent/.","2691-4581","","10.1109/TAI.2025.3637168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11269359","self-supervised learning;time series;contrastive learning;masked autoencoder","Time series analysis;Contrastive learning;Artificial intelligence;Representation learning;Image reconstruction;Data models;Autoencoders;Training;Adaptation models;Accuracy","","","","","IEEE","26 Nov 2025","","","IEEE","IEEE Early Access Articles"
"CNN-Based Time Series Decomposition Model for Video Prediction","J. Lee; G. Kim","School of Software, Soongsil University, Seoul, South Korea; School of Software, Soongsil University, Seoul, South Korea",IEEE Access,"24 Sep 2024","2024","12","","131205","131216","Video prediction presents a formidable challenge, requiring effectively processing spatial and temporal information embedded in videos. While recurrent neural network (RNN) and transformer-based models have been extensively explored to address spatial changes over time, recent advancements in convolutional neural networks (CNNs) have yielded high-performance video prediction models. CNN-based models offer advantages over RNN and transformer-based models due to their ease of parallel processing and lower computational complexity, highlighting their significance in practical applications. However, existing CNN-based video prediction models typically treat the spatiotemporal channels of videos similarly to the channel axis of static images. They stack frames in temporal order to construct a spatiotemporal axis and employ standard  $1\times 1$  convolution operations. Nevertheless, this approach has its limitations. Applying  $1\times 1$  convolution directly to the spatiotemporal axis results in a mixture of temporal and spatial information, which may lead to computational inefficiencies and reduced accuracy. Additionally, this operation needs to improve in processing temporal data. This study introduces a CNN-based time series decomposition model for video prediction. The proposed model first divides the  $1\times 1$  convolution operation within the channel aggregation module to independently process the temporal and spatial dimensions. To capture evolving features, the temporal axis is segregated into trend and residual components, followed by applying a time series decomposition forecasting method. To assess the performance of the proposed technique, experiments were conducted using the moving MNIST, KTH, and KITTI-Caltech benchmark datasets. In the experiments on moving MNIST, despite a reduction of approximately 55% in the number of parameters and 37% in computational cost, the proposed method improved accuracy by up to 7% compared to the previous approach.","2169-3536","","10.1109/ACCESS.2024.3458460","Innovative Human Resource Development for Local Intellectualization program through the Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government [Ministry of Science and ICT (MSIT)](grant numbers:(IITP-2024-RS-2022-00156360)); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10676971","Convolutional neural networks;deep learning architecture;spatiotemporal representation learning;time series forecasting;video prediction","Predictive models;Convolutional neural networks;Spatiotemporal phenomena;Time series analysis;Forecasting;Transformers;Data models;Deep learning","","1","","51","CCBYNCND","11 Sep 2024","","","IEEE","IEEE Journals"
"TC-GATN: Temporal Causal Graph Attention Networks With Nonlinear Paradigm for Multivariate Time-Series Forecasting in Industrial Processes","J. Li; Y. Shi; H. Li; B. Yang","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China",IEEE Transactions on Industrial Informatics,"24 May 2023","2023","19","6","7592","7601","Multivariate time-series (MTS) forecasting plays an important role in industrial process monitoring, control, and optimization. Usually, hierarchical interactive behaviors among industrial MTS have formed complex nonlinear causal characteristics, which greatly hinders the applications of the existing predictive models. It is found that graph attention networks (GATs) provide technical ideas to meet this challenge. However, the unknown directed graph and linear conversions of node information make conventional GATs less popular for the industrial fields. In this article, we propose a novel prediction model termed as temporal causal graph attention networks with nonlinear paradigms (TC-GATN) to adequately capture inherent dependencies on industrial MTS. Specifically, the graph learning algorithm concerning the Granger causality is exploited to extract potential relationships among multiple variables for guiding directional edge connections of the hierarchy. Then, parallel gated recurrent unit encoders located in the graph neighborhood space are introduced to perform the nonlinear interaction of node features, which accomplishes the adaptive transformation and transmission. The self-attention mechanism is further employed to aggregate encoder hidden states across all the stages. Finally, a temporal module is supplemented to process information from the graph layer, achieving satisfactory predictions. The feasibility and effectiveness of the TC-GATN are validated by two actual datasets from the methanol production and the chlorosilane distillation","1941-0050","","10.1109/TII.2022.3211330","China Scholarship Council(grant numbers:202006885028); National Natural Science Foundation of China(grant numbers:72201021); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9907826","Gated recurrent unit (GRU);Granger causality (GC);graph attention networks (GATs);multivariate time-series (MTS) prediction","Time series analysis;Predictive models;Informatics;Forecasting;Production;Directed graphs;Biological system modeling","","31","","29","IEEE","3 Oct 2022","","","IEEE","IEEE Journals"
"Fourier-driven Lightweight Token Mixing Model for Efficient Time Series Forecasting","J. Kumari; A. Mondal; J. Mathew","Department of Computer Science and Engineering, Indian Institute of Technology Patna, India; Department of Computer Science and Engineering, Indian Institute of Technology Patna, India; Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",IEEE Transactions on Artificial Intelligence,"","2025","PP","99","1","14","Time-series forecasting is crucial in a wide range of real-world applications, such as weather prediction, energy planning, and financial risk management. Although previous Transformer-based models have performed well in forecasting over long time horizons using self-attention mechanisms and stacked architectures, challenges remain in effectively learning complex temporal patterns while minimizing trainable parameters and computational costs. This paper introduces Fourier-driven Network (F-Net), a novel architecture for multivariate time series forecasting that replaces the traditional attention mechanism with Fourier-driven Representation Learning (FdRL). F-Net is extended to Efficient F-Net (EF-Net) to further enhance computational efficiency by incorporating a Latent Mapping Model (LMM). Experimental results demonstrate that F-Net outperforms state-of-the-art (SoTA) methods by an average margin of 28.18%, surpassing the conventional attention-based vanilla transformer by 27%. F-Net is exceptionally lightweight, with ~103 parameters, achieving a reduction of more than a thousand times compared to existing SoTA approaches. Adding the LMM with F-Net further enhances its efficiency, cutting inference time by an average of 72% across benchmark datasets while maintaining a similar parameter count, making it ideal for real-time applications. EF-Net also gives comparative accuracy and outperforms various SoTAs.","2691-4581","","10.1109/TAI.2025.3584693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11060930","Deep Learning;Forecasting;Time Series","Forecasting;Time series analysis;Computational modeling;Transformers;Accuracy;Attention mechanisms;Computational efficiency;Real-time systems;Predictive models;Computer architecture","","1","","","IEEE","1 Jul 2025","","","IEEE","IEEE Early Access Articles"
"From Uniform Models To Generic Representations: Stock Return Prediction With Pre-training","J. You; T. Han; L. Shen","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",2022 International Joint Conference on Neural Networks (IJCNN),"30 Sep 2022","2022","","","1","8","The emergence of deep learning has cast new light on the century-old problem of stock return prediction. For single stock return prediction, incorporating peripheral data such as cross sectional information has become the de facto standard for target horizons denoted in hours and above. However, such approach is not directly applicable to predicting short-term stock returns due to their strong stochastic nature. Little has been reported in public domain on how to utilize the rich exogenous data in short-term scenarios effectively. We propose a representation learning solution based on a pretrain-finetune framework. To help models learn high-quality feature extractors, we further propose to use triplet loss as a novel pre-train task. We present a new sample selection criterion and three versions of triplet selection in this context: “easy sample”, “multiple samples”, and “hard sample”. Experiment results using the proposed method demonstrate significant improvement over standard approaches. We also share some insight on how to apply triplet loss effectively in the context of short-term stock return prediction. Specifically, we demonstrate that using regression labels to select triplets is more effective than using embedding similarity. The proposed training framework is model-agnostic and shows great performance improvements in various settings.","2161-4407","978-1-7281-8671-9","10.1109/IJCNN55064.2022.9892697","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9892697","representation learning;stock return prediction;triplet loss","Training;Representation learning;Deep learning;Neural networks;Stochastic processes;Predictive models;Feature extraction","","3","","38","IEEE","30 Sep 2022","","","IEEE","IEEE Conferences"
"IProbeTrans: A Long-Term Series Forecasting Method Based on Self-Supervised Learning","X. Zuo; J. Wu; X. Yang; H. Zhao; B. Huang","College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China; College of Big Data and Internet, Shenzhen Technology University, Shenzhen, China",2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT),"10 Jun 2025","2024","","","1048","1053","Long-term time series forecasting (LTSF) is essential for domains like meteorology and finance, requiring accurate predictions over many time points. While Transformer-based models have shown promise in capturing long-term dependencies, they face challenges due to potential information loss and quadratic scaling of time complexity, impacting efficiency. Thus, this work proposes a forecasting method called iProbTrans, which uses inverted embedding and probsparse self-attention to capture temporal representations and correlations between variables. It outperforms transformer-based methods on multivariate datasets, reducing MSE and MAE by 9.6% and 6.6%, respectively, compared to the FEDformer baseline. A self-supervised learning approach is proposed, decomposing time series into patches and applying random masking to reduce computational costs. This model, trained on mean squared error loss for mask reconstruction, improves upon supervised learning by reducing MSE and MAE by 26.3% and 27.5%. It excels in capturing long-term dependencies, enhancing generalization, and offers a solution to the limitations of Transformer-based methods in LTSF.","","979-8-3315-1709-0","10.1109/ACAIT63902.2024.11021826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11021826","long-term time series forecasting;deep learning;transformer;self-supervised learning","Correlation;Time series analysis;Supervised learning;Self-supervised learning;Predictive models;Transformers;Forecasting;Time complexity;Optimization;Meteorology","","","","24","IEEE","10 Jun 2025","","","IEEE","IEEE Conferences"
"TimesFNP: Contrastive Learning for Financial Domain with Noise-Resilient Prediction","S. Shen; Q. Li; Y. Chen; R. Cheng; Y. Zheng","School of Finance, Southwestern University of Finance and Economics, Chengdu, China; Research Institute for Digital Economy and Interdisciplinary Sciences Southwestern University of Finance and Economics, Chengdu, China; School of Finance, Southwestern University of Finance and Economics, Chengdu, China; School of Finance, Southwestern University of Finance and Economics, Chengdu, China; School of Finance, Southwestern University of Finance and Economics, Chengdu, China",2025 11th International Conference on Computing and Artificial Intelligence (ICCAI),"11 Aug 2025","2025","","","697","704","Long-term time series forecasting is a long-standing research topic in financial scenarios. Recent studies have shown that Transformer models have great potential in time series forecasting. However, time series in financial scenarios contain complex noise disturbances. To address this issue, we propose a new framework called TimesFNP, which aims to improve the noise resistance of long-term time series forecasting in financial scenarios based on contrastive learning methods. Specifically, first, we introduce a noise-based data augmentation method to simulate the noise components in financial scenarios. Second, we fully consider the potential correlations between different companies in long-term time series forecasting tasks and represent the time series features at the company level. Remarkably, our framework demonstrates significant improvements over state-of-the-art algorithms in time series forecasting, achieving performance enhancements of at least $\mathbf{8. 5 7 \%}$ in MSE and $\mathbf{4. 4 2 \%}$ in MAE","","979-8-3315-2491-3","10.1109/ICCAI66501.2025.00111","National Natural Science Foundation of China; Southwestern University of Finance and Economics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11106073","Time Series;Contrastive Learning;NoiseResilient Prediction","Resistance;Time-frequency analysis;Time series analysis;Noise;Contrastive learning;Companies;Predictive models;Transformers;Prediction algorithms;Forecasting","","","","47","IEEE","11 Aug 2025","","","IEEE","IEEE Conferences"
"Ranking Neighborhood and Class Prototype Contrastive Learning for Time Series","C. Wei; J. Yuan; Y. Zhang; Z. Yu; Y. Liu; H. Liu","School of Data Science and Intelligent Media, Communication University of China, Beijing, China; Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing, China; Ant Group, Hangzhou, China; Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing, China; Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing, China; Key Laboratory of Big Data & Artificial Intelligence in Transportation, Ministry of Education, Beijing, China",IEEE Transactions on Big Data,"10 Jul 2025","2025","11","4","1907","1917","Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. Existing contrastive learning methods conduct augmentations and maximize their similarity. However, they ignore the similarity of adjacent timestamps and suffer from the problem of sampling bias. In this paper, we propose a self-supervised framework for learning generalizable representations of time series, called $\mathbf {R}$Ranking n$\mathbf {E}$E ighborhood and cla$\mathbf {S}$Ss prototyp$\mathbf {E}$E contr$\mathbf {A}$Astive $\mathbf {L}$Learning (RESEAL). It exploits information about similarity ranking to learn an embedding space, ensuring that positive samples are ranked according to their temporal order. Additionally, RESEAL introduces a class prototype contrastive learning module. It contrasts time series representations and their corresponding centroids as positives against truly negative pairs from different clusters, mitigating the sampling bias issue. Extensive experiments conducted on several multivariate and univariate time series tasks (i.e., classification, anomaly detection, and forecasting) demonstrate that our representation framework achieves significant improvement over existing baselines of self-supervised time series representation.","2332-7790","","10.1109/TBDATA.2024.3495509","Fundamental Research Funds for the Central Universities(grant numbers:2022JBMC011); National Key R&D Program of China(grant numbers:2022YFE0200400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10748408","Contrastive learning;multivariate time series;representation learning","Time series analysis;Contrastive learning;Prototypes;Big Data;Representation learning;Forecasting;Time-frequency analysis;Semantics;Data augmentation;Computational modeling","","1","","49","IEEE","8 Nov 2024","","","IEEE","IEEE Journals"
"Dynamic Personalized Graph Neural Ordinary Differential Equation Network for Multivariate Time Series Prediction of Chemical Processes","N. Wang; Y. Cao; L. Wang; F. Luo; X. Li; Y. Han; X. Hu","Key Laboratory of Oil & Gas Business Chain Optimization, CNPC PetroChina Planning and Engineering Institute, Beijing, China; Key Laboratory of Oil & Gas Business Chain Optimization, CNPC PetroChina Planning and Engineering Institute, Beijing, China; PetroChina Dalian Petrochemical Company, Liaoning, China; Key Laboratory of Oil & Gas Business Chain Optimization, CNPC PetroChina Planning and Engineering Institute, Beijing, China; Research Center of Intelligent PSE, Ministry of Education in China, College of Information Science and Technology, Beijing University of Chemical Technology Engineering, Beijing, China; Research Center of Intelligent PSE, Ministry of Education in China, College of Information Science and Technology, Beijing University of Chemical Technology Engineering, Beijing, China; Research Center of Intelligent PSE, Ministry of Education in China, College of Information Science and Technology, Beijing University of Chemical Technology Engineering, Beijing, China",2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS),"5 Aug 2024","2024","","","2044","2049","The prediction of multivariate time series (MTS) has increasingly captured substantial interest in practical domains such as chemical process flow and data analysis, which representing a profoundly challenging task. Numerous traditional MTS forecasting models demand substantial computational resources and may fall short of fulfilling real-time requirements. In this paper, given the intricate interdependencies within and between variables, a novel Multivariate Time Graph Neural Network (MTGNN) integrated with an ordinary differential equation (ODE) (MTGNN-ODE) approach is proposed to address the challenges of MTS prediction in chemical engineering. First, MTGNN represents the dependencies among variables in MTS data using the adjacency matrix to learn of spatio-temporal features. Then, The ODE is utilized to achieve the continuous propagation of the graph structure to a deeper level, and solves the problem of over-smoothing. In comparison with the baselines on a petrochemical process dataset, proposed method demonstrates a 15.6% enhancement in RSE and a 5.1% improvement in CORR. The prediction of key points in the chemical process is of great significance to achieve closed-loop control and real-time optimization of product quality.","2767-9861","979-8-3503-6167-4","10.1109/DDCLS61622.2024.10606557","National Natural Science Foundation of China(grant numbers:62273025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606557","Multivariate time series forecasting;Graph structure learning;Graph convolutional networks;multi-scale modeling","Training;Time series analysis;Predictive models;Ordinary differential equations;Real-time systems;Product design;Chemical processes","","1","","16","IEEE","5 Aug 2024","","","IEEE","IEEE Conferences"
"A Novel Approach of ESN Reservoir Structure Learning for Improved Predictive Performance","S. Bouazizi; E. Benmohamed; H. Ltifi","Research Groups in Intelligent Machines Lab, Sfax, Tunisia; Research Groups in Intelligent Machines Lab, Sfax, Tunisia; Research Groups in Intelligent Machines Lab, Sfax, Tunisia",2023 IEEE Symposium on Computers and Communications (ISCC),"28 Aug 2023","2023","","","232","237","This paper presents a novel method to enhance the predictive performance of the Echo State Network (ESN) model by adopting reservoir topology learning. ESNs are a type of Recurrent Neural Network (RNN) that have demonstrated considerable potential in various applications, but they can be challenging to train and optimize due to their random initialization. To improve the learning capabilities of ESNs and enhance their effectiveness in a broad range of predictive tasks, we utilize a structure learning algorithm. The proposed approach modifies the ESN reservoir's connectivity by applying techniques such as reversing, deleting, and adding new connections. We evaluate our proposal performance using both synthetic and real datasets, and our results indicate that it can substantially improve predictive accuracy compared to traditional ESNs.","2642-7389","979-8-3503-0048-2","10.1109/ISCC58397.2023.10218132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10218132","Echo State Network;Reservoir Computing;Structure Learning;K2 algorithm","Adaptation models;Recurrent neural networks;Computational modeling;Neurons;Transfer learning;Weather forecasting;Predictive models","","1","","44","IEEE","28 Aug 2023","","","IEEE","IEEE Conferences"
"SEED: An Effective Model for Highly-Skewed Streamflow Time Series Data Forecasting","Y. Li; J. Xu; D. C. Anastasiu","Computer Science and Engineering, Santa Clara University, Santa Clara, CA, USA; Santa Clara Valley Water District, Santa Clara, CA, USA; Computer Science and Engineering, Santa Clara University, Santa Clara, CA, USA",2023 IEEE International Conference on Big Data (BigData),"22 Jan 2024","2023","","","728","737","Accurate time series forecasting is crucial in various domains, but predicting highly-skewed and heavy-tailed univariate series poses challenges. We introduce the Segment-Expandable Encoder-Decoder (SEED) model, designed for such time series. SEED incorporates segment representation learning, Kullback-Leibler divergence regularization, and an importance-enhanced sampling policy. We tested our model on the 3-day ahead single-shot prediction task on four hydrologic datasets. Experimental results demonstrate SEED’s effectiveness in optimizing the forecasting process (10-30% of root mean square error reductions over state-of-the-art methods), underlining its notable potential for practical applications in univariate, skewed, long-term time series prediction tasks.","","979-8-3503-2445-7","10.1109/BigData59044.2023.10386959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10386959","deep learning;representation learning;sampling policy;streamflow prediction;time series","Representation learning;Heavily-tailed distribution;Time series analysis;Predictive models;Big Data;Data models;Forecasting","","3","","41","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"Multivariate Time-Series Modeling and Forecasting With Parallelized Convolution and Decomposed Sparse-Transformer","S. Ma; Y. -B. Zhao; Y. Kang; P. Bai","Institute of Advanced Technology, USTC, Shushan, Hefei, Anhui, China; Institute of Advanced Technology and the Department of Automation, USTC, Shushan, Hefei, Anhui, China; Institute of Advanced Technology and the Department of Automation, USTC, Shushan, Hefei, Anhui, China; Department of Automation, USTC, Shushan, Hefei, Anhui, China",IEEE Transactions on Artificial Intelligence,"16 Oct 2024","2024","5","10","5232","5243","Many real-world scenarios require accurate predictions of time series, especially in the case of long sequence time-series forecasting (LSTF), such as predicting traffic flow and electricity consumption. However, existing time-series prediction models encounter certain limitations. First, they struggle with mapping the multidimensional information present in each time step to high dimensions, resulting in information coupling and increased prediction difficulty. Second, these models fail to effectively decompose the intertwined temporal patterns within the time series, which hinders their ability to learn more predictable features. To overcome these challenges, we propose a novel end-to-end LSTF model with parallelized convolution and decomposed sparse-Transformer (PCDformer). PCDformer achieves the decoupling of input sequences by parallelizing the convolutional layers, enabling the simultaneous processing of different variables within the input sequence. To decompose distinct temporal patterns, PCDformer incorporates a temporal decomposition module within the encoder–decoder structure, effectively separating the input sequence into predictable seasonal and trend components. Additionally, to capture the correlation between variables and mitigate the impact of irrelevant information, PCDformer utilizes a sparse self-attention mechanism. Extensive experimentation conducted on five diverse datasets demonstrates the superior performance of PCDformer in LSTF tasks compared to existing approaches, particularly outperforming encoder–decoder-based models.","2691-4581","","10.1109/TAI.2024.3410934","National Natural Science Foundation of China(grant numbers:62173317); Key Research and Development Program of Anhui(grant numbers:202104a05020064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10552140","Decomposed sparse-Transformer;long sequence time-series forecasting (LSTF);parallelized convolution","Feature extraction;Predictive models;Forecasting;Time series analysis;Transformers;Convolution","","","","38","IEEE","7 Jun 2024","","","IEEE","IEEE Journals"
"Grouped Graph Neural Networks for Anomaly Detection in Time Series","Z. Guo; W. Kong; Y. Liu","Sun Yat-Sen University, GuangZhou, China; Sun Yat-Sen University, GuangZhou, China; Sun Yat-Sen University, GuangZhou, China",2024 International Joint Conference on Neural Networks (IJCNN),"9 Sep 2024","2024","","","1","8","Anomaly detection in time series data (e.g., sensor data) is becoming a fundamental research problem that has various applications. Due to the complex inter-sensor relationships, it is challenging to detect anomalous events such as system faults and attacks hidden the high-dimensional time series. Recent advancements in deep learning approaches such as Graph Neural Networks (GNN) have greatly improved anomaly detection performance in time series data. However, existing methods do not learn the dependence relationships between sensors and groups of sensors and may not efficiently detect anomalous events in time series. In this paper, we propose a novel approach GGNN (short for Grouped Graph Neural Networks) that combines a structure learning approach with graph neural networks. In particular, GGNN learns the graph structure containing groups of sensors, which are represented by virtual nodes. In addition, we use the learned graph structure and attention weights to explain the detected anomalies. The experiments on three real world datasets show our superiority in detection accuracy, anomaly diagnosis, and model interpretation compared with state-of-the-art methods.","2161-4407","979-8-3503-5931-2","10.1109/IJCNN60899.2024.10649927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10649927","Grouped Graph Nerual Network;Anomaly Detection","Training;Deep learning;Accuracy;Soft sensors;Time series analysis;Graph neural networks;Anomaly detection","","1","","25","IEEE","9 Sep 2024","","","IEEE","IEEE Conferences"
"Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects","K. Zhang; Q. Wen; C. Zhang; R. Cai; M. Jin; Y. Liu; J. Y. Zhang; Y. Liang; G. Pang; D. Song; S. Pan","Huzhou Institute of Zhejiang University, Huzhou, China; Alibaba Group, China; School of Computer Science and Technology, Zhejiang Normal University, Jinhua, Zhejiang, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; Ant Group, Hangzhou, Zhejiang, China; INTR & DSA Thrust, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing, University of Connecticut, Storrs, CT, USA; School of Information and Communication Technology, Griffith University, Southport, Qld, Australia",IEEE Transactions on Pattern Analysis and Machine Intelligence,"6 Sep 2024","2024","46","10","6775","6794","Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.","1939-3539","","10.1109/TPAMI.2024.3387317","Key R&D Project of Zhejiang Province(grant numbers:2024C01172); National Key R&D Program of China(grant numbers:2021YFB2012300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10496248","Deep learning;representation learning;self-supervised learning;time series analysis","Time series analysis;Task analysis;Reviews;Surveys;Taxonomy;Self-supervised learning;Natural language processing","","115","","217","IEEE","10 Apr 2024","","","IEEE","IEEE Journals"
"Scaling Up Multivariate Time Series Pre-Training with Decoupled Spatial-Temporal Representations","R. Zha; L. Zhang; S. Li; J. Zhou; T. Xu; H. Xiong; E. Chen","School of Computer Science, University of Science and Technology of China; Business Intelligence Lab, Baidu Research; School of Computer Science, University of Science and Technology of China; Business Intelligence Lab, Baidu Research; School of Computer Science, University of Science and Technology of China; The Hong Kong University of Science and Technology (Guangzhou); School of Computer Science, University of Science and Technology of China",2024 IEEE 40th International Conference on Data Engineering (ICDE),"23 Jul 2024","2024","","","667","678","Data scale has been acknowledged as a crucial factor for enhancing the generalization and effectiveness of pre-training models. While existing methods of multivariate time series pre-training are primarily limited to a single specific dataset, scaling to a larger scenario that includes multiple diverse datasets (e.g., multi-region data) remains a substantial challenge. In this paper, we present a novel Decoupled Spatial-Temporal Representation Learning (DeSTR) framework to serve as the backbone network for investigating the data scaling capability of multivariate time series pre-training architectures. Specifically, DeSTR utilizes two separate encoders to capture both the temporal dynamics within each time series and the spatial correlations among multiple variables. The obtained representations of distinct modalities are then fed into a Spatial-Guided Temporal Transformer to equip the temporal features with spatial discriminative information. Moreover, we employ masked autoencoding as the foundational pre-training framework and introduce spacetime-agnostic augmentation to improve robustness and facilitate implicit spatiotemporal modeling. Finally, we successfully pre-train a unified time series representation learning framework on real-world datasets from three different cities. Extensive experiments are carried out on various downstream tasks to validate the performance of DeSTR, compared with three categories of state-of-the-art baselines: deep sequential models, spatial-temporal graph neural networks, and time series representation learning methods. The results clearly demonstrate the advantages of scaling multivariate time series pre-training to multiple datasets, highlighting the effectiveness of DeSTR as a general spatiotemporal learner.","2375-026X","979-8-3503-1715-2","10.1109/ICDE60146.2024.00057","National Natural Science Foundation of China(grant numbers:62222213,U22B2059,U23A20319,62072423); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598155","multivariate time series pre-training;spatiotemporal data;data scalability","Representation learning;Scalability;Time series analysis;Urban areas;Predictive models;Propulsion;Transformers","","5","","54","IEEE","23 Jul 2024","","","IEEE","IEEE Conferences"
"Hybrid Deep Learning and XGBoost Models for Enhanced Energy Forecasting: A Comparative Analysis","S. Nageshwaran; V. Nageshwaran","NVIDIA, Santa Clara, USA; Senior Data Engineer, Business Insider, New York, USA",2025 IEEE Technology and Engineering Management Society Conference - Global (TEMSCON Global),"25 Nov 2025","2025","","","1","5","Energy forecasting is vital for the optimization of power distribution and, subsequently, the management of grids. This paper examines a range of time series forecasting approaches for energy data that include classical statistical methods (ARIMA), gradient boosting-XGBoost, deep learning architectures (CycleNet, xLSTMTime), and the novel hybrid combinations proposed. Using a comprehensive dataset from the U.S. Energy Information Administration (125,000 records over two years), we implement and compare such models over several performance metrics. Our novel contribution is a weighted ensemble methodology that optimal combines deep learning and gradient boosting predictions. The proposed hybrid model combines XGBoost and LSTM predictions and therefore achieves a $\mathrm{R}^{2}$ score of 0.9842 (0.9821-0.9863), 5.3% improvements in RMSE compared to the isolated modeling and 3.7% over current benchmarks. This work further proves while deep learning is clearly adept at grasping temporal dependencies, gradient boosting brings a good deal to the picture when used in an integrated modality due to their multifactorial advantages. The applicability and practicability of hybrid models by means of a detailed analysis of computational efficiencies and deployment considerations.","","979-8-3315-4274-0","10.1109/TEMSCONGlobal64363.2025.11238333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11238333","energy forecasting;deep learning;XGBoost;LSTM;hybrid models;time series analysis;CycleNet","Deep learning;Analytical models;Energy consumption;Statistical analysis;Computational modeling;Time series analysis;Predictive models;Boosting;Forecasting;Long short term memory","","","","13","IEEE","25 Nov 2025","","","IEEE","IEEE Conferences"
"A Neural Network Architecture for Spatiotemporal PM2.5 Forecasting","J. Jenish; M. Prabu","Department of Computer Science and Engineering, SRM Institute of Science and Technology, Chennai, Ramapuram, India; Department of Computer Science and Engineering, SRM Institute of Science and Technology, Chennai, Ramapuram, India","2022 International Conference on Computing, Communication, Security and Intelligent Systems (IC3SIS)","15 Sep 2022","2022","","","1","6","PM2.5 concentrations have been increasing at an alarming rate, making it critical to precisely estimate their regional and temporal distributions. The task is complicated by the non-linear property of PM2.5 and the large number of geological and climatic elements that influence PM2.5 concentrations, as well as the difficulty inherent in modelling their varying spatiotemporal association. Conventional physical and statistical forecasting techniques fail at incorporating several variables and discovering intricate correlations, essential for reliable predictions. This paper proposes a graph neural network capable of modelling PM2.5 concentrations on real-world data by leveraging PM2.5 transport, domain knowledge and considering spatial correlation, by reworking PM2.5 historical data, meteorological and weather forecast data into graph data and employing graph isomorphism networks, similar to the Weisfeiler Lehman graph isomorphism test for powerful graph representation learning, an attention mechanism, and a dedicated recurrent neural network to model temporal distributions, to provide accurate forecasting.","","978-1-6654-6883-1","10.1109/IC3SIS54991.2022.9885669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9885669","graph neural network;attention mechanism;PM2.5;spatio-temporal correlation;recurrent neural network","Representation learning;Correlation;Urban areas;Weather forecasting;Predictive models;Data models;Graph neural networks","","","","10","IEEE","15 Sep 2022","","","IEEE","IEEE Conferences"
"Research on Financial Time Series Risk Assessment Model Based on Computer Deep Learning","X. Huang","School of Economics and Management, Shanghai University of Political Science and Law, Shanghai, China","2024 2nd International Conference on Mechatronics, IoT and Industrial Informatics (ICMIII)","10 Sep 2024","2024","","","450","453","Financial risk assessment plays a crucial role in the financial market, as it enables risk quantification and management, further risk identification and warning, and provides reference for investment decision support and systematic risk prevention. In the current trend of big data, it has become possible to collect a large amount of financial time series data, which contains a lot of useful features that need to be mined and analyzed. Therefore, based on the research of multivariate financial time series, this article proposes a financial time series risk identification method based on GCN-LSTM-CLUSTING. Specifically, we perform patch segmentation on multivariate time series to extract relationships between different patch nodes using GCN, followed by extracting long time series dependencies using LSTM, and utilizing end-to-end regression models to extract features from small time series. Finally, clustering methods are used to cluster the potential features of the time series and identify anomalous financial time series. The experimental results show that the method proposed in this paper has a good recognition rate and can effectively identify abnormal financial time series.","","979-8-3503-8663-9","10.1109/ICMIII62623.2024.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659991","GCN;Deep Learning;abnormal recognition;financial time series","Deep learning;Systematics;Mechatronics;Prevention and mitigation;Time series analysis;Feature extraction;Market research","","","","12","IEEE","10 Sep 2024","","","IEEE","IEEE Conferences"
"GRL-ITransformer: An Intelligent Method for Multi-Wind-Turbine Wake Analysis Based on Graph Representation Learning With Improved Transformer","K. Han; L. Xu","College of Mathematics and Physics, Shanghai University of Electric Power, Shanghai, China; College of Mathematics and Physics, Shanghai University of Electric Power, Shanghai, China",IEEE Access,"14 Mar 2025","2025","13","","43572","43592","The importance of examining the wake effect of wind farms for optimizing their layout and augmenting their power generation efficiency is immense. Considering that the establishment of extensive wind farms often leads to a significant number of turbines being positioned downstream of preceding ones, it significantly diminishes their power generation efficiency. In our study, we propose a graph representation learning model with improved Transformer (GRL-ITransformer) to better integrate feature information, so that the model can capture the dynamic time relationship of different variables and establish its spatial relationship, striving to enhance the precision in predicting wind turbine wake field. Different from the previous way involving handling reduced-order and separating prediction process, we combine the reduced-order technique with the proposed model to make the model more efficiently and intelligently determine the number of modes required for model prediction. After that, the data driven method is employed to update the parameters, and the superiority of GRL-ITransformer is highlighted by analyzing and comparing with the existing five classical intelligent algorithms (belongs to four categories). The comprehensive results show that GRL-ITransformer has excellent performance in wind turbine wake field prediction and reconstruction, and always possesses the lowest error for a series of error evaluation indexes among all models.","2169-3536","","10.1109/ACCESS.2025.3549035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916666","Wind turbine wakes;reduced-order model;improved transformer;attention mechanism;graph representation learning;series forecasting algorithm","Wind turbines;Predictive models;Transformers;Wind farms;Prediction algorithms;Representation learning;Neural networks;Wind speed;Data models;Accuracy","","","","45","CCBYNCND","6 Mar 2025","","","IEEE","IEEE Journals"
"Empowering PHM Applications with Time Series Foundation Models: A Unified Multi-Task Learning Approach","Y. Yu; F. Zhu; D. Wang; F. Tsung","Thrust of Data Science and Analytics, Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Thrust of Data Science and Analytics, Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Department of Industrial Engineering and Management, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Thrust of Data Science and Analytics, Information Hub, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",2025 IEEE 21st International Conference on Automation Science and Engineering (CASE),"23 Sep 2025","2025","","","3300","3305","Currently, small, task-specific models dominate the development of Prognostics and Health Management (PHM) applications. However, these isolated models often struggle to address the diverse and fragmented requirements present in real industrial environments. The emergence of time-series foundation models has attracted considerable attention, providing a more flexible and effective approach for PHM applications. This study explores how time-series foundation models can enhance PHM applications. Using a typical aero-engine degradation dataset as the research context, we propose a novel unified multi-task learning approach that leverages pre-trained time-series foundation models. Specifically, we utilize these foundation models as the basis for time-series representation learning to tackle various PHM tasks. To accommodate the diverse requirements of these tasks, we design specialized output heads tailored for multi-task learning objectives. The pre-trained foundation model is then fine-tuned with specific datasets to develop localized task-specific models. We validate our approach through case studies using the C-MAPSS datasets. The experimental results demonstrate the feasibility and effectiveness of foundation models for the development of PHM applications.","2161-8089","979-8-3315-2246-9","10.1109/CASE58245.2025.11163911","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11163911","","Representation learning;Degradation;Computer aided software engineering;Foundation models;Databases;Time series analysis;Multitasking;Data models;Prognostics and health management;Engines","","","","21","IEEE","23 Sep 2025","","","IEEE","IEEE Conferences"
"Financial Time Series Prediction With Multi-Granularity Graph Augmented Learning","P. Zhu; Y. Li; Q. Liu; D. Cheng; C. Jiang","School of Computer Science and Technology, Tongji University, Shanghai, China; School of Computer Science and Technology, Tongji University, Shanghai, China; School of Computer Science and Technology, Tongji University, Shanghai, China; School of Computer Science and Technology, Tongji University, Shanghai, China; School of Computer Science and Technology, Tongji University, Shanghai, China",IEEE Transactions on Knowledge and Data Engineering,"8 Oct 2025","2025","37","11","6436","6449","Financial time series prediction is an important and challenging data mining task for quantitative investment. The inherent non-linearity, high noise, and susceptibility to various factors, such as macroeconomic conditions and market sentiment in the stock market, increase the difficulty of prediction. Existing financial industries mainly employ time series models or fundamental analysis methods for prediction. However, these methods fail to effectively capture the complex interrelationships between equity. In recent years, graph neural networks (GNNs), due to their powerful relational modeling capabilities, have been applied to stock prediction. However, with the advances of recent digital power, such as widely-used high-frequency trading techniques, existing graph-based methods still have shortcomings in effectively learning multi-granularity temporal relations as they cannot effectively learn the patterns in different frequencies, e.g., minute-level, daily, weekly, etc. Therefore, in this paper, we propose a multi-granularity graph augmented learning framework for interrelated financial time series forecasting. We first construct a temporal return relationship graph with multi-granularity financial time series, including weekly, daily, and minute-level, to comprehensively capture the dynamic relations of equities, including both medium-term trends and short-term fluctuations. Then, to further augment the node relations, we devise an attentional graph augment module to improve the graph learning with fundamental data, which are jointly optimized in the prediction layer. We conduct extensive empirical studies on multiple datasets from both the Chinese and U.S. stock markets. The results demonstrate that our proposed model consistently outperforms existing baseline methods across four key financial metrics, including ARR, ASR, CR, and IR, thereby validating its effectiveness and superiority. The model has been applied and empirically tested in commercial-grade trading platforms, further demonstrating its efficiency and robustness in real-world trading environments.","1558-2191","","10.1109/TKDE.2025.3607005","National Key R&D Program of China(grant numbers:2022YFB4501704); National Natural Science Foundation of China(grant numbers:62472317); Fundamental Research Funds for the Central Universities and the Shanghai Science and Technology Innovation Action Plan Project(grant numbers:22YS1400600,24692118300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11153061","Multi-granularity graph;augmented learning framework;temporal return relationship graph;jointly optimized","Time series analysis;Data models;Predictive models;Market research;Fluctuations;Data mining;Biological system modeling;Stock markets;Computational modeling;Forecasting","","","","58","IEEE","8 Sep 2025","","","IEEE","IEEE Journals"
"Knowledge Enhanced Deep Learning: Application to Pandemic Prediction","J. A. Miller; N. H. Barna; S. Rana; I. B. Arpinar; N. Liu","School of Computing, University of Georgia, Athens, Georgia, USA; School of Computing, University of Georgia, Athens, Georgia, USA; School of Computing, University of Georgia, Athens, Georgia, USA; School of Computing, University of Georgia, Athens, Georgia, USA; School of Computing, University of Georgia, Athens, Georgia, USA",2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC),"19 Feb 2024","2023","","","42","51","Deep Learning has been successfully applied to many problem domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known M Competitions, until recently, hybrids of traditional statistical or machine learning (e.g., gradient boosting) techniques were the top performers. With the recent architectural advances in deep learning being applied to time series forecasting, such as encoder-decoders with attention, transformers, representation learning, and graph neural networks, deep learning has begun to show its advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, ignorance of accumulated scientific knowledge, and interpretability of the model. Today, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject knowledge into deep learning models. The state-of-the-art approaches are reviewed and suggestions for further work are provided. Recommendations for how this can be applied to future pandemics are given.","","979-8-3503-3912-3","10.1109/CIC58953.2023.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429928","Time series;pandemic;deep learning","Deep learning;Training;Pandemics;Time series analysis;Predictive models;Transformers;Forecasting","","1","","97","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"Earthquake Magnitude Prediction using Spatia-temporal Features Learning Based on Hybrid CNN- BiLSTM Model","P. Kavianpour; M. Kavianpour; E. Jahani; A. Ramezani","Department of Civil Engineering, University of Mazandaran, Babolsar, Iran; Department of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Department of Civil Engineering, University of Mazandaran, Babolsar, Iran; Department of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran",2021 7th International Conference on Signal Processing and Intelligent Systems (ICSPIS),"11 Mar 2022","2021","","","1","6","Earthquakes are a very catastrophic natural event that occurs due to sudden changes in the earth's crust, leading to human, financial, and environmental losses in society. Therefore, employing an efficient and dependable method for earthquake prediction can significantly reduce casualties. In this regard, we proposed a deep neural network called the hybrid convolutional neural network and bi-directional long-short-term memory (HC-BiLSTM) to predict the mean magnitude of the future earthquake in a specific area of Japan. To achieve this goal, we suggest a strategy based on four key steps: the division of areas, the preprocessing, the spatial and temporal feature learning, and the prediction. In the division of areas step, The part of Japan is divided into 49 smaller areas to better predict the next earthquake's location. The preprocessing step uses the zero-order hold method in the time series of the mean magnitude of the earthquake. In the next step, the learning spatial and temporal characteristics between earthquake data include three layers of CNN and pooling and two layers of LSTM. Finally, the prediction step has two fully connected layers that combine information supplied by HC-BiLSTMs to predict the mean magnitude for the earthquake next month. As a result, using a comparative method, this study demonstrates the superiority of the proposed method over other common earthquake prediction methods.","","978-1-6654-0938-4","10.1109/ICSPIS54653.2021.9729358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729358","Earthquake prediction;Convolution neural network;Bidirectional LSTM;Time series prediction;Deep neural network","Representation learning;Earthquakes;Neural networks;Time series analysis;Predictive models;Signal processing;Market research","","12","","24","IEEE","11 Mar 2022","","","IEEE","IEEE Conferences"
"STCA-LLM: Spatial–Temporal Cross-Attention Large Language Model for Wind Speed Forecasting","C. Zhou; Y. Wang; J. Ma; Q. Jin","School of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Faculty of Computer and Information Sciences, Hosei University, Chiyoda, Japan; Department of Human Informatics and Cognitive Sciences, Waseda University, Shinjuku, Japan",IEEE Internet of Things Journal,"24 Oct 2025","2025","12","21","45411","45422","Accurately forecasting wind speed is crucial for efficiently utilizing the renewable energy, stabilizing the energy system and advancing the progress of the decarbonization of our society. However, due to its inherently temporal volatility and intermittency, accurate wind speed forecasting in a wind farm is challenging. Recently, large language models (LLMs) have demonstrated notable performance in abundant natural language processing and computer vision tasks. However, the conventional LLMs fail to learn the complex spatial and temporal correlations of the wind speed data at multiple turbines in a wind farm, which makes wind speed forecasting cannot fully benefit from the significant breakthroughs of LLM. To fill in this gap, we propose a novel spatial–temporal cross-attention LLM framework for wind speed forecasting, namely, spatial–temporal cross-attention LLM (STCA-LLM), composed of alignment phase, and fine-tuning phase. In detail, our contributions are given as follows. First, the alignment phase aligns the general-purpose LLM with task-specific data, i.e., training the LLM with wind speed data. Second, in the fine-tuning phase, two representation learning modules, i.e., convolution network and graph neural network (GNN) are, respectively used to extract temporal features of intra time series in each turbine, and the correlation of inter time-series at multiple turbines in a wind farm. Moreover, the cross-attention module is innovatively proposed to establish the connections between spatial and temporal embeddings. Then, the spatial–temporal representation modules and the aligned LLM are fine-tuned in two-stage way. Finally, thorough experiments on real wind speed dataset demonstrate that our proposed STCA-LLM outperforms state-of-the-art time series forecasting models, including Transformer-based models, spatial–temporal GNN-based models, and pertained LLM-based models. Our code is available at: https://github.com/Justinzzcj/STCA-LLM.","2327-4662","","10.1109/JIOT.2025.3599836","JiangSu Provincial Key Research and Development Program(grant numbers:BE2020084-1); QingLan Project of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11129036","graph attention network (GAT);large language model (LLM);spatial–temporal cross-attention;wind speed forecasting","Forecasting;Wind speed;Time series analysis;Predictive models;Transformers;Feature extraction;Correlation;Wind forecasting;Data models;Wind farms","","","","37","IEEE","18 Aug 2025","","","IEEE","IEEE Journals"
"NRL4AQF: Noise-Resistant Learning for Long-Sequence Air Quality Forecasting using Cross-Time Embedding","V. Nguyen; T. Vo","Thu Dau Mot University, Binh Duong, Vietnam; Faculty of Information Technology, Nguyen Tat Thanh University, Ho Chi Minh City, Vietnam",2024 International Conference on Advanced Technologies for Communications (ATC),"7 Mar 2025","2024","","","779","784","Recently, deep learning (DL) has greatly advanced data analysis, including time-series forecasting. Recurrent neural networks (RNNs) are commonly used for DL-based forecasting, but they face limitations in capturing complex, long-range dependencies, especially with cross-dimensional input data. To address these challenges, transformer-based architectures have been introduced, offering improved performance for long-range predictions. However, they still struggle with modeling long input sequences and managing noise in temporal feature learning. To overcome these issues, we propose the NRL4AQF (Noise-Resistant Learning for Air Quality Forecasting) model, a novel denoising transformer-based approach for time-series forecasting. By combining cross-dimensional transformer-based embeddings with a radial basis function neural network (RBFNN), NRL4AQF effectively reduces noise and captures more accurate temporal patterns. Applied to long-sequence air quality forecasting, the model achieves superior results compared to traditional and state-of-the-art DL techniques, as demonstrated by experiments on a real-world dataset.","2162-1039","979-8-3503-5398-3","10.1109/ATC63255.2024.10908270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10908270","air quality forecasting;transformer-based models;time-series forcasting;cross-time embedding;noise-resistant","Representation learning;Recurrent neural networks;Atmospheric modeling;Noise;Noise reduction;Radial basis function networks;Predictive models;Air quality;Transformers;Forecasting","","1","","18","IEEE","7 Mar 2025","","","IEEE","IEEE Conferences"
"Is Single Enough? A Joint Spatiotemporal Feature Learning Framework for Multivariate Time Series Prediction","K. Yuan; K. Wu; J. Liu","Guangzhou Institute of Technology, Xidian University, Guangzhou, China; School of Artificial Intelligence, Xidian University, Xi’an, China; Guangzhou Institute of Technology, Xidian University, Guangzhou, China",IEEE Transactions on Neural Networks and Learning Systems,"4 Apr 2024","2024","35","4","4985","4998","A fuzzy cognitive map (FCM) is a simple but effective tool for modeling and predicting time series. This article focuses on the problem of multivariate time series prediction (TSP), which is essential and challenging in data mining. Although several FCM-based approaches have been designed to solve this problem, their feature extraction module designed for single mode falls short in capturing the nonlinear spatiotemporal dependencies among variates, thereby resulting in low prediction accuracy in forecasting multivariate time series, which shows that the single mode learning is not enough. Therefore, in this article, we propose a joint spatiotemporal feature learning framework for multivariate TSP, where a mix-resolution spatial module consisting of multiple sparse autoencoders (SAEs) is designed to extract the feature series with different spatial resolutions, and a mix-order spatiotemporal module concluding multiple high-order FCMs (HFCMs) is designed to model the spatiotemporal dynamics of these feature series. Finally, the outputs of the two modules are concatenated to predict future values. We refer to this framework as the spatiotemporal FCM (STFCM). Especially, an efficient learning algorithm is designed to update the integral weights of STFCM based on the batch gradient descent algorithm when it deems necessary. We validate the performance of the STFCM on four real-world datasets. Compared with the existing state-of-the-art (SOTA) methods, the experimental results not only show the advantages of the two designed modules in the STFCM but also show the excellent performance of the STFCM.","2162-2388","","10.1109/TNNLS.2022.3216107","Key Project of Science and Technology Innovation 2030 through the Ministry of Science and Technology of China(grant numbers:2018AAA0101302); National Natural Science Foundation of China(grant numbers:62206205); Zhejiang Laboratory’s International Talent Fund for Young Professionals; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9938413","Fuzzy cognitive maps (FCMs);fuzzy neural network;multivariate time series prediction (TSP);sparse autoencoder (SAE);spatiotemporal feature","Time series analysis;Feature extraction;Spatiotemporal phenomena;Correlation;Representation learning;Predictive models;Prediction algorithms","","14","","55","IEEE","3 Nov 2022","","","IEEE","IEEE Journals"
"A Survey on Time-Series Pre-Trained Models","Q. Ma; Z. Liu; Z. Zheng; Z. Huang; S. Zhu; Z. Yu; J. T. Kwok","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China",IEEE Transactions on Knowledge and Data Engineering,"12 Nov 2024","2024","36","12","7536","7555","Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difficult due to data annotation costs. Recently, pre-trained models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Specifically, we first briefly introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments involving 27 methods, 434 datasets, and 679 transfer learning scenarios are conducted to analyze the advantages and disadvantages of transfer learning strategies, Transformer-based models, and representative TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future work.","1558-2191","","10.1109/TKDE.2024.3475809","National Natural Science Foundation of China(grant numbers:62272173); Natural Science Foundation of Guangdong Province(grant numbers:2024A1515010089,2022A1515010179); Science and Technology Planning Project of Guangdong Province(grant numbers:2023A0505050106); Fundamental Research Funds for the Central Universities(grant numbers:2024ZYGXZR104); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10706809","Time-series mining;pre-trained models;deep learning;transfer learning;transformer","Time series analysis;Data models;Deep learning;Transformers;Forecasting;Surveys;Transfer learning;Convolutional neural networks;Computational modeling;Predictive models","","40","","196","IEEE","7 Oct 2024","","","IEEE","IEEE Journals"
"CATS: Contrastive learning for Anomaly detection in Time Series","J. R. Ky; B. Mathieu; A. Lahmadi; R. Boutaba","Orange Innovation Lannion; Orange Innovation Lannion; Université de Lorraine, CNRS, Nancy, France; David R. Cheriton School of Computer Science, University of Waterloo",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","1352","1359","Anomaly detection (AD) plays a critical role in a wide variety of big data applications, including cybersecurity, monitoring, and network systems. It consists in finding patterns in time series data that indicate unexpected events such as faults or defects. Traditional AD approaches, predominantly based on reconstruction techniques, often yield suboptimal performance, particularly when anomalies are present in the training set. Conversely, contrastive learning (CL) has shown significant performance in image processing tasks and is increasingly applied in time series data classification and forecasting. However, traditional CL frameworks are not well-adapted for time series AD due to two key challenges. First, AD is typically performed only on normal instances, and thus CL does not benefit from knowledge about anomalous instances. Second, the temporal nature of time series data is often neglected when computing time series similarity, thereby hindering the effective learning of time series representation.To overcome these limitations, we propose CATS, a novel approach that leverages a temporal similarity measure to learn time series representations. Moreover, through negative data augmentation, CATS generates a more realistic distribution of anomalies, which enables anomaly-informed CL. Extensive experiments conducted on six real-world datasets demonstrate that CATS outperforms existing AD methods. Our results highlight the efficacy of CATS in enhancing time series AD performance in big data environment across various application domains.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825476","anomaly detection;time series;cloud gaming;contrastive learning","Training;Time series analysis;Contrastive learning;Data augmentation;Time measurement;Forecasting;Anomaly detection;Monitoring;Image reconstruction;Network systems","","1","","42","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Intraday Wind Power Forecasting by Ensemble of Overlapping Historical Numerical Weather Predictions","Y. Zhao; S. Pan; Y. Chen; H. Liao; Y. Zheng; L. Ye","College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China",IEEE Transactions on Sustainable Energy,"21 Mar 2025","2025","16","2","1315","1328","The numerical weather prediction (NWP) is crucial to improve intraday wind power forecasting (WPF) accuracy. However, conventional WPF methods relied solely on a latest reported single NWP, overlooking hidden information from sequentially reported multiple historical NWPs that are partially overlapped over time. Additionally, it's challenging to tackle intraday WPF as it involves both ultra-short-term and short-term horizons with different characteristics. Therefore, a novel spatio-temporal representation learning network is proposed for intraday WPF by ensemble of overlapping historical NWPs. Initially, an integrated mask-reconstruction representation learning pretraining strategy is employed to extract hidden representations of historical wind power measurements and overlapping historical NWPs, providing contextual information for the subsequent intraday WPF task. Then, the output layer is trained and end-to-end fine-tuning of the entire network is conducted to adapt to the specific forecasting task. Moreover, a multi-task learning strategy based on hard parameter sharing is adopted to ensure balanced predictive accuracy across each of forecasted wind farms. Case study and detailed ablation tests based on 5 real-world wind farms demonstrate that the proposed method enhances the forecasting accuracy of most wind farms by leveraging spatio-temporal correlation, achieving the best average performance across all time horizons compared to the baseline models.","1949-3037","","10.1109/TSTE.2024.3521384","National Natural Science Foundation of China(grant numbers:52207144); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10812675","Intraday wind power forecasting;spatio-temporal correlation;overlapping historical NWPs;representation learning","Wind power generation;Correlation;Wind farms;Accuracy;Power measurement;Forecasting;Wind speed;Wind forecasting;Representation learning;Spatiotemporal phenomena","","2","","42","IEEE","23 Dec 2024","","","IEEE","IEEE Journals"
"Self-Supervised Generative Pre-Trained Model with a Learnable Mask Network for Industrial Time Series Prediction","C. Wang; H. Wang; Q. Liu","College of Electronic and Information Engineering, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China; College of Electronic and Information Engineering, Tongji University, Shanghai, China","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","1901","1906","Industrial time series prediction (ITSP) is an indispensable part of predictive control in modern industry. Recently, supervised deep learning-based methods have provided solutions with sufficient annotated data. However, there is massive unlabeled data with complex temporal features in modern industrial production, resulting in poor performance of these methods. To address this problem, a self-supervised generative pre-trained model with a learnable mask network (SSGPM-LMN) is proposed in this paper. First, the multivariate time series are made into patches channel-independently. Then, these patches are fed into a Transformer encoder with the learnable mask-reconstruction paradigm, drawing mask indices with high temporal features by calculating the cosine similarity in low-dimensional feature space to better learn general representations. Furthermore, a two-step fine-tuning strategy, including linear probing and full fine-tuning, is adopted for various downstream scenarios. Finally, extensive experimental results on case studies of ITSP and transfer learning indicate that our SSGPM-LMN achieves superior performance.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831502","National Natural Science Foundation of China(grant numbers:62273261); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831502","","Representation learning;Industries;Time series analysis;Transfer learning;Self-supervised learning;Production;Predictive models;Transformers;Data models;Predictive control","","","","22","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"Self-Supervised Time Series Classification Method Based on FRFT Cross-Channel Fusion","Z. Sun; Y. Wang; M. Wang; C. Jiang; Y. Wan","School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, China",2025 International Joint Conference on Neural Networks (IJCNN),"14 Nov 2025","2025","","","1","8","Recently, self-supervised representation learning has been widely applied to various time series tasks (e.g., electric device classification). However, building models for large-scale time series classification remains challenging due to the high cost of labeling time series data, which requires specialized expertise. Additionally, many datasets consist solely of unlabeled data or contain only a small number of labeled samples. Existing solutions for traditional time series tasks are not directly applicable to modern complex temporal problems due to two unique characteristics: (i) long-term temporal dependencies and (ii) complex cross-channel interactions. To address these challenges, we propose TC-FrC, a self-supervised time series classification model that leverages seasonal-trend decomposition for data augmentation and incorporates contrastive losses based on both temporal features and the Fractional Fourier Transform (FRFT). Specifically, we: (i) design a sparse attention mechanism within the temporal contrastive module to enhance feature extraction and improve robustness in long-term time series data, (ii) introduce a seasonal-trend decomposition approach to mitigate inter-class feature confusion, and (iii) develop a cross-channel FRFT-based feature fusion module, which transforms contextual features from the time domain to the fractional domain. We extensively evaluate TC-FrC on seven publicly available datasets, including HAR, Sleep-EDF, and Epilepsy, among others. Experimental results demonstrate that our method outperforms state-of-the-art baselines across various evaluation metrics.","2161-4407","979-8-3315-1042-8","10.1109/IJCNN64981.2025.11229038","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11229038","self-supervised learning;time series classification;FRFT;contrastive learning;cross-channel fusion","Adaptation models;Time-frequency analysis;Time series analysis;Contrastive learning;Feature extraction;Brain modeling;Robustness;Data models;Human activity recognition;Time-domain analysis","","","","33","IEEE","14 Nov 2025","","","IEEE","IEEE Conferences"
"Multi-Dimensional Series Forecasting for Multi-Node Microservices: Leveraging Specialized Embedding in LLMs","L. Cheng; J. Ge; Q. Lv; T. Li; B. Wu","Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",2025 IEEE International Conference on High Performance Computing and Communications (HPCC),"31 Oct 2025","2025","","","80","86","Currently, time series prediction in microservice systems suffers from inaccurate forecasts due to the complex interdependencies and highly dynamic workload characteristics. Traditional small-scale models struggle to understand the temporal patterns embedded within multi-dimensional metrics, leading to suboptimal performance. The advent of large language models (LLMs) offers a promising solution, as their powerful representation learning capabilities can effectively capture these complex temporal patterns. In this study, we propose a novel approach tailored for multi-dimensional time series forecasting in microservice environments. Our method leverages specialized embedding techniques that combine dynamic receptive field convolution and adaptive attention masks to capture temporal dependencies and feature relationships across multiple nodes. Additionally, we fine-tune a pre-trained LLaMA model to enhance its applicability for time series forecasting within microservice contexts. Experimental results demonstrate that our approach achieves higher prediction accuracy compared to baseline methods in different datasets. This research's achievements in time series forecasting provide new insights for downstream tasks such as resource allocation and fault prediction.","","979-8-3315-6874-0","10.1109/HPCC67675.2025.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11207479","microservice;workloads prediction;time series forecast;large language model;fine-tuning;embedding","Representation learning;Measurement;Convolution;Large language models;High performance computing;Time series analysis;Microservice architectures;Predictive models;Resource management;Forecasting","","","","23","IEEE","31 Oct 2025","","","IEEE","IEEE Conferences"
"Adaptive Graph Convolution Neural Differential Equation for Spatio-Temporal Time Series Prediction","M. Han; Q. Wang","Key Laboratory of Intelligent Control and Optimization for Industrial Equipment of Ministry of Education, Dalian University of Technology, Dalian, Liaoning, China; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, Liaoning, China",IEEE Transactions on Knowledge and Data Engineering,"1 May 2025","2025","37","6","3193","3204","Multivariate time series prediction has aroused widely research interests during decades. However, the spatial heterogeneity and temporal evolution characteristics bring much challenges for high-dimensional time series prediction. In this paper, a novel adaptive graph convolution module is introduced to automatically learn the spatial correlation of multivariate time series and a Koopman-based neural differential equation is proposed to simulate the nonlinear system state evolution. In detail, the correlation between multivariate time series is revealed by the consine similarity of node embedding to infer the potential relationship between nodes and the spatio-temporal feature fusion module is utilized. The LSTM-based network is adopted as Koopman operator to reveal the latent states of spatio-temporal time series and the reversible assumption is imposed on the Koopman operator. Furthermore, the Euler-trapezoidal integration are utilized to simulate the temporal dynamics and multiple-step prediction is carried out in the latent space from the perspective of dynamical differential equation. The proposed model could explicitly discover the spatial correlation by adaptive graph convolution and reveal the temporal dynamics by neural differential equation, which make the modeling more interpretable. Simulation results show the effectiveness on spatio-temporal dynamic discovery and prediction performance.","1558-2191","","10.1109/TKDE.2024.3383895","National Natural Science Foundation of China(grant numbers:62173063); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10487888","Multivariate time series;dynamical system;spatial-temporal fusion;graph structure learning","Time series analysis;Predictive models;Feature extraction;Mathematical models;Convolution;Correlation;Data mining","","3","","42","IEEE","2 Apr 2024","","","IEEE","IEEE Journals"
"Research on Commodities Constraint Optimization Based on Graph Neural Network Prediction","Z. Yang; Z. Zhihan; L. Haiying; Z. Weiyi; D. Qian; T. Mingjie","China Tobacco Si Chuan Industrial Company Ltd., Chengdu, China; Southwestern University of Finance and Economics, Chengdu, China; Zhong ke Zhidao Technology Company Ltd., Beijing, China; China Tobacco Si Chuan Industrial Company Ltd., Chengdu, China; China Tobacco Si Chuan Industrial Company Ltd., Chengdu, China; Sichuan University, Chengdu, China",IEEE Access,"29 Aug 2023","2023","11","","90131","90142","Business intelligence makes good sale prediction crucial in any commercial activity as it has a significant impact on production and supply plan. However, practical commercial data presents explicit constraints, that how to get the optimal forecasts of commodity sales under the constraints is a vital problem many researchers face. The present research proposes a prediction model which combines graph convolution neural network and node bipartite graph. Firstly, the node bipartite graph algorithm is used to merge the constraint graph and the store graph, obtaining the “store-constraint bipartite graph”. Secondly, a graph convolutional neural network integrating GRU and AR is utilized to extract temporal features (X). Finally, a fully connected network is applied to predict the optimal solution (Y) after constraint optimization. The former can effectively learn complex features of stores, meanwhile, the later combines the constraint conditions with the store, which can effectively predict the sales of goods under the constraint conditions. In terms of model performance, we compared the proposed model with the classical method such as SVR, LSTM, ARIMA. RMSE, MSE, MAE and MAPE are used for evaluation indexes, and the results show that MAPE for one month’s sales of some product from both datasets is 7.75%.","2169-3536","","10.1109/ACCESS.2023.3302923","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10210412","Graph convolutional networks;constraint optimization;graph representation learning;sales prediction;business intelligence","Convolution;Predictive models;Optimization;Data models;Constraint optimization;Linear programming;Feature extraction;Graph neural networks;Convolutional neural networks;Representation learning;Business intelligence","","1","","27","CCBYNCND","7 Aug 2023","","","IEEE","IEEE Journals"
"SMCL: Towards Semi-Supervised Automatic Modulation Recognition via Semantic Mask Contrastive Learning","Y. Li; H. Tan; H. Miao; Z. Zhang; X. Shi; F. Zhou","School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; School of Aeropace Science and Technology, Xidian University, Xi’an, China",IEEE Internet of Things Journal,"","2025","PP","99","1","1","Automatic modulation recognition (AMR) is essential for ensuring the physical-layer security for Internet of things (IoT) networks. Despite advancements in deep learning, most current AMR methods rely heavily on a large number of labeled samples to achieve high recognition accuracy. However, acquiring labeled samples can be costly and impractical in many real-world scenarios due to privacy concerns and economic constraints. In contrast, unlabeled data is often abundant and readily available. This paper presents a novel semi-supervised AMR framework that addresses the challenge of label scarcity by leveraging semantic mask contrastive learning (SMCL). Through a self-supervised modulation semantic mask contrastive prediction task within IQ sequence, our method learns subtle modulation features directly from unlabeled radio signals. It is important to note that SMCL requires neither data augmentation nor representation domain transformation. Sufficient experiments on public datasets have demonstrated our method outperforms existing semi-supervised and supervised methods when using the same number of labeled samples. SMCL effectively enables the representation learning of unlabeled radio signals, overcoming the limitations posed by the lack of sufficient labeled data and providing a solid technical foundation for the development of signal-based IoT large language models (IoT-LLMs).","2327-4662","","10.1109/JIOT.2025.3630897","Postdoctoral Science Research Projects of Shaanxi Province(grant numbers:2018BSHEDZZ39); Joint Fund of Ministry of Education(grant numbers:6141A02022367); China Postdoctoral Science Foundation(grant numbers:2016M602775); Fundamental Research Runds for the Central Universities(grant numbers:XJS210210); National Natural Science Foundation of China(grant numbers:62001350); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11235940","Modulation recognition;cognitive radio;contrastive learning;semi-supervised learning;semantic mask;representation learning","Internet of Things;Contrastive learning;Training;Data augmentation;Semantics;Accuracy;Time series analysis;Predictive models;Feature extraction;Representation learning","","","","","IEEE","10 Nov 2025","","","IEEE","IEEE Early Access Articles"
"A Novel Discrete Time Series Representation With De Bruijn Graphs for Enhanced Forecasting Using TimesNet","M. Onur Cakiroglu; H. Kurban; E. Buxton; M. Dalkilic","Department of Computer Science, Indiana University Bloomington, Bloomington, IN, USA; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Department of Computer Science, University of Illinois Springfield, Springfield, IL, USA; Department of Computer Science, Indiana University Bloomington, Bloomington, IN, USA",IEEE Access,"22 Jul 2025","2025","13","","123182","123198","In this paper, we present a novel method for advancing time series forecasting by representing discretized time series data through de Bruijn Graphs (dBGs). This method harnesses the capability of dBGs to encapsulate and project future states from historical sequences, thus enhancing predictive analytics in time series. Our approach is multi-faceted, involving: 1) encoding time series data as a dBG; 2) the application of graph representation learning, specifically struct2vec, to distill salient features from dBG constructed from time series and 3) the seamless integration of these extracted features into the state of the art TimesNet model to bolster short-term forecasting accuracy. Empirical evaluations conducted on the M4 datasets illustrate that our approach not only maintains the intrinsic dynamics of the time series but also achieves notable improvements in forecasting performance across diverse datasets. All the code developed for this study can be found at: https://github.com/KurbanIntelligenceLab/dBGTime-Series-Library","2169-3536","","10.1109/ACCESS.2025.3588507","Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11079555","Time series analysis;De Bruijn graph;TimesNet;graph embeddings","Time series analysis;Forecasting;Feature extraction;Predictive models;Data models;Transformers;Encoding;Computational modeling;Accuracy;Training","","","","56","CCBY","14 Jul 2025","","","IEEE","IEEE Journals"
"A Multilevel Deep Fusion Framework for FeO Content Prediction in Sintering Process","S. Wei; X. Zhang; R. Hu; B. He; C. Yang; Z. Song","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",2024 China Automation Congress (CAC),"13 Feb 2025","2024","","","3423","3428","Iron ore sintering is a critical procedure in steel production, and the content of ferrous oxide (FeO) in the finished sinter directly reflects sintering quality. This key indicator is commonly obtained by data-driven soft sensor modeling technology. However, existing methods struggle to fully utilize the multisource and heterogeneous characteristics of the sintering dataset, and this may limit the improvement of FeO prediction accuracy. To address this issue, this paper proposes a multilevel deep fusion framework (MDFF) for detecting FeO content in the sintering process. This novel framework integrates a multilevel fusion of multisource heterogeneous data, i.e., data-level, feature-level, and decision-level. First, shallow features are extracted from images based on expert experience for data-level fusion. Then, multiscale encoding network and shared representation learning network are used for feature extraction and fusion. Finally, the prediction results of shared representations and modality-specific features are combined at the decision level to realize real-time sensing of FeO content. The proposed MDFF fully exploits the intrinsic correlations between multisource information at multiple levels, and experimental results on real sintering datasets further prove its accuracy and stability.","2688-0938","979-8-3503-6860-4","10.1109/CAC63892.2024.10864891","National Natural Science Foundation of China(grant numbers:61933013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10864891","multisource heterogeneous data fusion;soft sensor;ferrous oxide content prediction;iron ore sintering process","Representation learning;Accuracy;Soft sensors;Time series analysis;Sintering;Predictive models;Feature extraction;Stability analysis;Real-time systems;Steel","","","","19","IEEE","13 Feb 2025","","","IEEE","IEEE Conferences"
"Energy usage prediction with ensemble graph convolutional recurrent neural networks: case study of Greek islands","G. Vontzos; V. Laitsos; P. Paraschoudis; D. Bargiotas","Department of Electrical and Computer Engineering, University of Thessaly, Volos, Greece; Department of Electrical and Computer Engineering, University of Thessaly, Volos, Greece; Department of Energy Systems, University of Thessaly, Larissa, Greece; Department of Electrical and Computer Engineering, University of Thessaly, Volos, Greece","14th Mediterranean Conference on Power Generation Transmission, Distribution and Energy Conversion (MEDPOWER 2024)","6 Mar 2025","2024","2024","","324","329","This study investigates the use of graph convolutional and recurrent neural networks to forecast energy consumption on five Greek islands. The model is trained on historical energy usage data, using graph convolutional networks (GCNs) with graphs constructed from power production and their geographical location which their results are averaged. The evaluation metrics mean absolute error (MAE), mean squared error (MSE), and mean absolute percentage error (MAPE) were utilised to measure the accuracy of the proposed prediction algorithms. The results show that all the suggested EGCRNN models with LSTM, Bi-LSTM, and GRU demonstrated excellent performance, strong model fit, and enhanced predictions of energy consumption. In particular, models which utilise long-short term memory (LSTM) and gated recurrence units (GRU) followed with better prediction in one model each, Thira and Rhodes, respectively.","","978-1-83724-268-9","10.1049/icp.2024.4680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10916301","","","","","","","","6 Mar 2025","","","IET","IET Conferences"
"Multi-attention based Feature Embedding for Irregular Asynchronous Time Series Modelling","S. B. Roy; M. Yuan","Agency for Science, Technology and Research, Advanced Remanufacturing & Technology Centre, Singapore, Republic of Singapore; Agency for Science, Technology and Research, Advanced Remanufacturing & Technology Centre, Singapore, Republic of Singapore",IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society,"16 Nov 2023","2023","","","1","6","Forecasting time series values based on historic covariates has been an active area of research in statistics and machine learning. With the availability of computation resources and big data infrastructure supporting massive volume, velocity and variety, the algorithms have evolved from classic statistical learning to neural-network driven loss minimisation techniques. While state of the art attention and self-attention-transformers have shown promise of improved performance with sufficient training data, most of them fail to generalise to different problems of time-series modelling (such as classification and extremum forecasting) with asynchronously sampled covariates. This paper introduces the concept of a generalised time series embedding and transfer learning for time series (analogous to token-to-vector or image-to-vector embeddings in language and vision models respectively) that allow joint training with a unified interface. The major benefit of this work is a unified embedding model employing multi-attention for feature representation which enables benchmark performance against state of the art models from recent literature.","2577-1647","979-8-3503-3182-0","10.1109/IECON51785.2023.10312633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10312633","","Training;Industrial electronics;Machine learning algorithms;Time series analysis;Transfer learning;Statistical learning;Training data;Predictive models;Minimization;Forecasting","","","","24","IEEE","16 Nov 2023","","","IEEE","IEEE Conferences"
"Kolmogorov—Arnold Networks: Overview of Architectures and Use Cases","S. Essahraui; I. Lamaakal; K. E. Makkaoui; I. Ouahbi; M. F. Bouami; Y. Maleh","Multidisciplinary Faculty of Nador, Mohammed Premier University, Oujda, Morocco; Multidisciplinary Faculty of Nador, Mohammed Premier University, Oujda, Morocco; Multidisciplinary Faculty of Nador, Mohammed Premier University, Oujda, Morocco; Multidisciplinary Faculty of Nador, Mohammed Premier University, Oujda, Morocco; Multidisciplinary Faculty of Nador, Mohammed Premier University, Oujda, Morocco; Laboratory LaSTI, ENSAK, Sultan Moulay Slimane University, Khouribga, Morocco","2025 International Conference on Circuit, Systems and Communication (ICCSC)","5 Sep 2025","2025","","","1","6","Kolmogorov-Arnold Networks (KANs) are an emerging class of neural network architectures grounded in the Kolmogorov-Arnold representation theorem, offering a sym-bolic and interpretable approach to modeling complex, high-dimensional functions. By replacing traditional activation functions with learnable univariate splines, KANs deliver enhanced expressiveness, parameter efficiency, and transparency. This survey provides a comprehensive overview of KAN developments, including foundational designs and specialized variants tailored to time series, graphs, scientific computing, image analysis, and biomedicine. We highlight the strengths of KANs in bridging the gap between symbolic reasoning and data-driven learning, while also discussing challenges such as computational overhead and spline optimization complexity. Through detailed architec-tural taxonomy and real-world application examples, this paper positions KANs as a compelling framework for interpretable, high-performance machine learning.","","979-8-3315-6528-2","10.1109/ICCSC66714.2025.11135248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11135248","Kolmogorov-Arnold Networks;Deep Learning;KANs;Machine Learning","Deep learning;Image analysis;Scientific computing;Computational modeling;Time series analysis;Neural networks;Computer architecture;Cognition;Complexity theory;Splines (mathematics)","","","","72","IEEE","5 Sep 2025","","","IEEE","IEEE Conferences"
"AI-based Gas Turbine Multi-Component Health Prognosis via Recurrent Expansion of Gas Path Parameters","T. Berghout; Y. Amirat; A. Bounceur; M. Benbouzid","Laboratory of Automation and Manufacturing Engineering, University of Batna 2, Batna, Algeria; L@bISEN, ISEN Yncréa Ouest, Brest, France; Department of Information and Computer Science, King Fahd University of Petroleum & Minerals, Dahran, Saudi Arabia; UMR CNRS 6027 IRDL, University of Brest, Brest, France","2024 International Conference on Control, Automation and Diagnosis (ICCAD)","18 Jun 2024","2024","","","1","6","Investigating Gas Turbine (GT) degradation based on Gas Path Parameters (GPPs) is essential for its maintenance and operation. Monitoring GPPs is crucial for early detection of degradation, enabling timely maintenance interventions and preventing potential failures. Integrating physics-based thermodynamic models with representation learning significantly improves predictive maintenance studies and provides a solution to challenges posed by expensive and impractical accelerated aging experiments. However, this integration also presents challenges in managing both data complexity and data drift. In this context, this article aims to address these gaps by extending and improving previous research through (i) exclusive use of GPPs; (ii) the implementation of advanced data preprocessing techniques; and (iii) the use of innovative representation learning strategies. Specifically, it introduces ProgMachina, a tool for data quality analysis in prognosis studies that addresses issues related to data complexity in GPPs. Furthermore, to diversify the feature space and improve the adaptability of representation learning to degradation patterns, this paper proposes using Multiverse Recurrent Expansion with Multiple Repeats (MV-REMR) approach, which is based on a series of Recurrent Neural Networks (RNNs). For evaluation, this study incorporates cross-validation and multiple metrics while comparing against multiple RNNs and state-of-the-art works, demonstrating stable and promising performance, making it a suitable choice for GT prognosis tasks.","2767-9896","979-8-3503-6102-5","10.1109/ICCAD60883.2024.10554011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10554011","Deep learning;Diagnosis;Gas path;Gas turbine;Prognosis;Recurrent expansion;Remaining useful life","Representation learning;Degradation;Measurement;Thermodynamics;Recurrent neural networks;Predictive models;Data models","","2","","6","IEEE","18 Jun 2024","","","IEEE","IEEE Conferences"
"Multivariate Time-Series Anomaly Detection Based on Dynamic Graph Neural Networks and Self-Distillation in Industrial Internet of Things","M. Zhao; H. Peng; L. Li","Information Security Center, State Key Laboratory of Networking and Switching Technology, and the National Engineering Laboratory for Disaster Backup and Recovery, Beijing University of Posts and Telecommunications, Beijing, China; Information Security Center, State Key Laboratory of Networking and Switching Technology, and the National Engineering Laboratory for Disaster Backup and Recovery, Beijing University of Posts and Telecommunications, Beijing, China; Information Security Center, State Key Laboratory of Networking and Switching Technology, and the National Engineering Laboratory for Disaster Backup and Recovery, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Internet of Things Journal,"24 Apr 2025","2025","12","9","12181","12192","Time-series anomaly detection is critical to securing the Industrial Internet of Things (IIoT). Although numerous deep learning-based methods have been proposed, these methods fail to consider the interdependencies between different dimensions of the data and often neglect the dynamic changes in these dependencies. Moreover, these methods utilize only the global features from the last layer of the network for anomaly detection. However, local features can capture subtle variations in the data, which are crucial for accurately detecting anomalies. To alleviate these problems, this article proposes a novel framework for detecting time-series anomalies, including four parts, namely, the graph structure learning module, the dynamic graph module, the anomaly scoring module, and the self-distillation. The graph structure learning module generates different graph structures based on the inputs, which will be used in the dynamic graph module. The dynamic graph module employs dynamic graph neural networks to capture the complex relationships within time series from both temporal and spatial dimensions. The anomaly scoring module obtains anomaly scores from predictions and observed values, and the model makes anomaly judgments based on these scores. Additionally, self-distillation enhances model performance by utilizing mutual learning between the teacher and student models, thereby integrating local and global information for better anomaly detection. We carry out a series of experiments on IIoT datasets, which verify the performance of the framework. The experimental results of the proposed method outperform other methods, demonstrating the advantage of our framework.","2327-4662","","10.1109/JIOT.2024.3520362","National Key Research and Development Program of China(grant numbers:2024YFB2906503,2024YFB2906500); National Natural Science Foundation of China(grant numbers:62032002); Higher Education Discipline Innovation Project(grant numbers:B21049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10810265","Anomaly detection;graph neural networks (GNNs);Industrial Internet of Things (IIoT);multivariate time series;self-distillation","Time series analysis;Anomaly detection;Feature extraction;Graph neural networks;Industrial Internet of Things;Training;Data models;Adaptation models;Transformers;Telecommunications","","2","","57","IEEE","19 Dec 2024","","","IEEE","IEEE Journals"
"GNN and Encoder Integrated Model for Distributed Solar and Wind Power Forecasting","Q. Wu; Y. Wang; J. Cao; J. Huang; W. Miao","College of Information Engineering Nanjing University Of Finance and Economics, Nanjing, China; College of Information Engineering Nanjing University Of Finance and Economics, Nanjing, China; College of Information Engineering Nanjing University Of Finance and Economics, Nanjing, China; State Grid Jiangsu Electric Power Co., Ltd, Nanjing, China; State Grid Jiangsu Electric Power Co., Ltd, Nanjing, China",2023 6th International Conference on Software Engineering and Computer Science (CSECS),"16 Feb 2024","2023","","","01","09","The integration of large amount of distributed power generation from renewable resources like solar and wind brings new challenges to power forecasting in both short-term and long-term time scales. Distributed power generating units characterized by increased variability and uncertainty among different sites, necessitates collaborative data analysis. And regional variations and simultaneous predictions for multiple sites should also be accounted. This paper proposes a time series forecasting model based on the combination of graph neural network (GNN) and Transformer-Encoder, which is used for long-term and short-term accurate forecasting of renewable energy. It combines temporal convolutional models, graph convolutional neural network, and Transformer-Encoder. This scheme first uses the temporal convolution model to extract short-term and time-dimensional features of time series data, and then replaces the ordinary graph learning layer with Transformer's Encoder layer to further extract the long-term and global features of time series data, and then converts the generated The adjacency matrix is input into the graph convolution module to extract information about its spatial dimensions. Simulation results on an open-source dataset verify that the model is effective and accurate in short-and long-term renewable energy forecasting.","","979-8-3503-0637-8","10.1109/CSECS60003.2023.10428146","Jiangsu Provincial Key Research and Development Program(grant numbers:BE2020001-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10428146","Graph Neural Network (GNN);Transformer;Temporal Convolutional Network (TCN);Solar Power Forecasting;Wind Power Forecasting","Renewable energy sources;Time series analysis;Predictive models;Feature extraction;Transformers;Graph neural networks;Forecasting","","","","34","IEEE","16 Feb 2024","","","IEEE","IEEE Conferences"
"Medium-Term Jointly Load Forecasting via an Enhanced KAN-Based MTL Framework","S. Wang; Y. Huang; Q. Wang","Queen Mary School Hainan, Beijing University of Posts and Telecommunications, Hainan, China; School of Information Science and Technology, Peking University, Beijing, China; School of Automation Science and Electrical Engineering, University of Science and Technology Beijing, Beijing, China",2024 IEEE PES 16th Asia-Pacific Power and Energy Engineering Conference (APPEEC),"24 Mar 2025","2024","","","1","5","Electricity load forecasting involves predicting future power demand based on historical data and related factors. Accurate forecasting is crucial for energy distribution and system management. This study introduces a novel multi-task learning (MTL) framework that integrates Kolmogorov-Arnold Networks (KAN) with a multi-head self-attention (MHSA) with a both hard and soft parameter sharing strategy to effectively merge different types of inputs for joint load forecasting. The KAN layer is tasked with cross-feature learning and output fitting while the MHSA mechanism captures the temporal information from multiple perspectives, aiming to facilitate comprehensive nonlinear feature learning. Experimental results show that the proposed method can attains better forecasting accuracy, with an average mean absolute percentage error of 3.842% for 10-day medium-term forecasts.","","979-8-3503-8612-7","10.1109/APPEEC61255.2024.10922466","National Natural Science Foundation of China(grant numbers:42401521); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922466","electricity load forecasting;KAN;MHSA MTL;nonlinear integration","Representation learning;Accuracy;Load forecasting;Electricity;Neural networks;Predictive models;Multitasking;Data models;Forecasting;Load modeling","","","","24","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"Long-Term Interpretable Air Quality Trend Forecasting via Directed Interval Fuzzy Cognitive Maps","X. Liu; Y. Zhang; H. Wang; S. Qin; Z. Zhang; Y. Yang; J. Wang","School of Computer Science and Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; School of Computer Science and Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; School of Electronics, Electrical Engineering, and Computer Science, Queen's University Belfast, Belfast, U.K.; School of Computer Science and Technology, Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; School of Astronautics, Beihang University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; Center of Information & Network Technology, Beijing Normal University, Beijing, China",IEEE Transactions on Fuzzy Systems,"2 Dec 2024","2024","32","12","7129","7142","Accurate air quality forecasting is crucial for public health and addressing air pollution. However, the dynamic evolution trends, the cross-interference among different air quality indexes, and the error accumulation in the long-term prediction process are still open problems when establishing air quality forecasting models. Thus, we present a long-term interpretable air quality trend forecasting model to address these challenges via directed interval fuzzy cognitive maps, DE-DIFCM. Specifically, we design a time series trend extraction and representation learning module based on the interval fuzzy granules and the Cramer decomposition theorem in the first phase. Next, we formulate the interval information granules' time series forecasting as a DIFCM. In particular, we employ PM$_{2.5}$ as a benchmark to validate the performance of the proposed DE-DIFCM. Experimental results on six air quality monitoring datasets demonstrate the model's superior and competitive long-term prediction performance by comparison with some representative baselines.","1941-0034","","10.1109/TFUZZ.2024.3482282","National Key Research and Development Program of China(grant numbers:2022YFB2603302); National Natural Science Foundation of China(grant numbers:U2268206); the China Scholarship Council(grant numbers:202307090102); Engineering and Physical Sciences Research Council(grant numbers:EP/V002740/2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720621","Air quality forecasting;PM  $_{2.5}$   forecasting;directed interval fuzzy cognitive map (DIFCM);fuzzy cognitive map (FCM);granular representation","Atmospheric modeling;Forecasting;Predictive models;Market research;Time series analysis;Fuzzy systems;Fuzzy cognitive maps;Data models;Air pollution;Computational modeling","","4","","50","IEEE","16 Oct 2024","","","IEEE","IEEE Journals"
"The New Abnormal: Network Anomalies in the AI Era","F. Soro; T. Favale; D. Giordano; L. Vassio; Z. Ben Houidi; I. Drago","Politecnico di Torino, 10129, Torino, Italy; Politecnico di Torino, 10129, Torino, Italy; Politecnico di Torino, 10129, Torino, Italy; Politecnico di Torino, 10129, Torino, Italy; Huawei Technologies, 92100, Boulogne&#x2010;Billancourt, France; University of Turin, 10149, Torino, Italy",Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning,"","2021","","","261","288","Anomaly detection aims at finding unexpected patterns in data. It has been used in several problems in computer networks, from the detection of port scans and distributed denial‐of‐service (DDoS) attacks to the monitoring of time series collected from Internet monitoring systems. Data‐driven approaches and machine learning have seen widespread application on anomaly detection too, and this trend has been accelerated by the recent developments on Artificial Intelligence (AI) research. This chapter summarizes ongoing recent progresses on anomaly detection research. In particular, we evaluate how developments on AI algorithms bring new possibilities for anomaly detection. We cover new representation learning techniques such as Generative Artificial Networks and Autoencoders, as well as techniques that can be used to improve models learned with machine learning algorithms, such as reinforcement learning. We survey both research works and tools implementing AI algorithms for anomaly detection. We found that the novel algorithms, while successful in other fields, have hardly been applied to networking problems. We conclude the chapter with a case study that illustrates a possible research direction.","","9781119675440","10.1002/9781119675525.ch11","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9536309.pdf&bkn=9536223&pdfType=chapter","","Anomaly detection;Taxonomy;IEEE Sections;Tools;Time series analysis;Telemetry;Reinforcement learning","","","","","","13 Sep 2021","","","IEEE","Wiley-IEEE Press eBook Chapters"
"Vector Representation and Machine Learning for Short-Term Photovoltaic Power Prediction","R. Costa; A. Costa; O. Vilela; T. Ing Ren","Centro de Informática UFPE, Recife, Brazil; Centro de Energias Renováveis UFPE, Recife, Brazil; Centro de Energias Renováveis UFPE, Recife, Brazil; Centro de Informática UFPE, Recife, Brazil","2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","29 Jan 2024","2023","","","1241","1246","Short-term photovoltaic (PV) energy production forecasting is critical for managing grid-connected systems and energy trading. Machine learning models are widely used for accurate prediction, and this study proposes using Time2Vec as an embedding for a transformer-based neural network architecture. Experiments on two PV power plants in India showed significant improvements comparing our proposed architecture to MLP, LSTM, and the persis-tence model, which is a standard baseline prediction in this type of forecasting, with over 20 % improvements in some horizons. These findings demonstrate the effectiveness of the proposed approach for short-term PV forecasting using machine learning models.","2577-1655","979-8-3503-3702-0","10.1109/SMC53992.2023.10394456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10394456","Solar Energy;Machine Learning;Neural Networks;Time Series Prediction","Photovoltaic systems;Radiation effects;Atmospheric modeling;Neural networks;Predictive models;Transformers;Forecasting","","3","","14","IEEE","29 Jan 2024","","","IEEE","IEEE Conferences"
"Anomaly detection for steam turbine based on dual-attention autoencoder","J. Lei; W. Xu","Sichuan Guang'an Power Co., Ltd, Hangzhou, China; Huadian Electric Power Research Institute Co., Ltd, Guang'an, China","12th International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering (QR2MSE 2022)","28 Apr 2023","2022","2022","","1802","1806","Anomaly detection plays an essential role in routine operation and maintenance of steam turbine. Due to vague parameter correlation, various working condition, and nonstationary industry process, there still remain challenges in building representation models to detect abnormal working condition accurately and sensitively. To alleviate this problem, this paper proposes an autoencoder(AE) approach with dual-attention mechanism, including parameter attention and temporal attention, to learn data distribution under the normal working condition. In dual-attention mechanism, parameter attention mechanism exerts varying weight to parameters referring to their current significance, and temporal attention mechanism improves information integration by utilizing the hidden state of gated recurrent unit(GRU) cells. Based on the output of AE, box-cox transformation and three-sigma rule of thumb determine the dynamic threshold. The proposed approach is evaluated through experiments on steam turbine from a real case. The experiment result demonstrates it outperforms the state-of-the-art baselines for advanced alarm time and better stability.","","978-1-83953-836-0","10.1049/icp.2022.3129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10110548","","","","","","","","28 Apr 2023","","","IET","IET Conferences"
"A Regional Short-term Load Forecasting Method Based on Adaptive Graph Construction and Kernel Size Selection","J. Zhao; H. Dai; Z. Zhen; F. Wang","Department of Electrical Engineering, North China Electric Power University, Baoding, China; Department of Electrical Engineering, North China Electric Power University, Baoding, China; Department of Electrical Engineering, North China Electric Power University, Baoding, China; Department of Electrical Engineering, North China Electric Power University, Baoding, China",2024 IEEE/IAS 60th Industrial and Commercial Power Systems Technical Conference (I&CPS),"24 Jun 2024","2024","","","1","6","Accurate Short-Term Load Forecasting is very important for power system operation. However, the existing methods for regional load forecasting often lack consideration of the differentiated load characteristics and the interrelationships between various types of loads. Particularly during extreme weather events, demand responses, and other special occurrences, focusing only on the overall trend of regional load changes can lead to significant forecasting errors. Additionally, under extreme weather conditions, various loads within a region exhibit different response patterns. This paper proposes a multivariate time series forecasting model based on an Adaptive Graph Neural Network (ADAGNN) to treat various load types as nodes in a graph network, adaptively constructing adjacency matrices through a graph construction layer to extract inter-load relational information; it also uses graph convolution and temporal convolution to capture different load change patterns in regional loads. Considering the existence of different scales of cyclical changes in time series, an initial dilated convolution method is proposed, endowing the ADAGNN model with the ability to adaptively select the size of convolution kernels to extract multi-scale features of the original series. Ultimately, the model outputs the forecast data for all categorized loads, and the regional load forecast is obtained by summation. A case study is conducted using regional load data from a province in China. Relative to the optimal model in the control group, the proposed ADAGNN model improved by 1.06%, 43.32%, and 42.24% in the MAPE, MAE, and RMSE metrics, respectively, thus validating its high predictive accuracy and scalability.","2158-4907","979-8-3503-4530-8","10.1109/ICPS60943.2024.10563907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10563907","Inception layer;Adaptive Graph neural network;Regional load;Short term forecasting;Load forecasting","Industries;Adaptation models;Adaptive systems;Accuracy;Load forecasting;Convolution;Predictive models","","","","25","IEEE","24 Jun 2024","","","IEEE","IEEE Conferences"
"Learning Low-Dimensional Representation for O-RAN Testing via Transformer-ESN","J. Dai; R. Zhao; F. Rezazadeh; L. Zheng; H. Wang; L. Liu","Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA; Universitat Politècnica de Catalunya (UPC), Barcelona, Spain; Massachusetts Institute of Technology, Boston, Massachusetts, USA; Virginia Tech, Blacksburg, VA, USA; Virginia Tech, Blacksburg, VA, USA",2025 IEEE 22nd International Conference on Mobile Ad-Hoc and Smart Systems (MASS),"4 Nov 2025","2025","","","127","133","Open Radio Access Network (O-RAN) architectures enhance flexibility for 6G and NextG networks. However, it also brings significant challenges in O-RAN testing with evaluating abundant, high-dimensional key performance indicators (KPIs). In this paper, we introduce a novel two-stage framework to learn temporally-aware low-dimensional representations of O-RAN testing KPIs. To be specific, stage one employs an information-theoretic H-score to train a hybrid self-attentive transformer and echo state network (ESN) reservoir, called Transformer-ESN, capturing temporal dynamics and producing task-aligned 8-dimensional embeddings. Stage two evaluates these embeddings by training a lightweight multilayer perceptron (MLP) predictor exclusively on them for key target KPIs such as reference signal received quality (RSRQ) and spectral efficiency. Using real-world O-RAN testbed data (video streaming with interference), our approach demonstrates a significant advantage specifically when training samples are very limited. In this scenario, the low-dimensional representations learned from the Transformer-ESN yield mean square error (MSE) reductions of up to 41.9% for RSRQ and 29.9% for spectral efficiency compared to predictions from the original high-dimensional data. The framework exhibits high efficiency for O-RAN testing, significantly reducing testing complexities for O-RAN systems.","2155-6814","979-8-3315-6599-2","10.1109/MASS66014.2025.00030","Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11206294","O-RAN;Low-Dimensional Representation;H-score;Transformer;Echo State Network (ESN)","Training;Spectral efficiency;Open RAN;Echo state networks;Mean square error methods;Multilayer perceptrons;Transformers;Smart systems;Reservoirs;Testing","","1","","19","IEEE","4 Nov 2025","","","IEEE","IEEE Conferences"
"Attack Detection and Location Using State Forecasting in Multivariate Time Series of ICS","G. Cao; Y. Wu; D. Yu; Z. Wang","School of Cybersecurity, Northwestern Polytechnical University, Xi'an, China; School of Cybersecurity, Northwestern Polytechnical University, Xi'an, China; School of Artificial Intelligence, OPtics and ElectroNics, Northwestern Polytechnical University, Xi'an, China; School of Cybersecurity, Northwestern Polytechnical University, Xi'an, China",IEEE Transactions on Network Science and Engineering,"26 Jun 2025","2025","12","4","2989","3001","ICS (industrial control systems) security researches have paid a great effort on anomaly detection base on the analyzes of communication protocols, network dataflow, sensor time series. However, few research have been done to recognize cyber attacks as well as the localization, which make active security control impossible. Actually, to recognize cyber attacks is crucial for ICS security control. In this paper, we proposed a novel multivariate time series attack detection and location framework based on adaptive state space formulation and forecasting. To dynamically describe systems' state transition characteristics, a graph structure learning scheme was designed based on Attention mechanism. Furthermore, to achieve state forecasting of systems, an improved Kalman filter with Transformer mechanism was proposed. Experiments on datasets from real industrial scenario demonstrated the effectiveness, and proved that the proposed method achieved higher location accuracy than the state-of-the-art methods.","2327-4697","","10.1109/TNSE.2025.3555764","National Natural Science Foundation of China(grant numbers:61803303); Aeronautical Science Foundation of China(grant numbers:2018ZD53045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10946197","Multivariate time series;attack detection and location;state space model;state forecast;graph structure learning","Time series analysis;Anomaly detection;Mathematical models;Sensors;Correlation;Transformers;Cyberattack;Convolutional neural networks;Noise measurement","","","","47","IEEE","1 Apr 2025","","","IEEE","IEEE Journals"
"Pay Attention to Evolution: Time Series Forecasting With Deep Graph-Evolution Learning","G. Spadon; S. Hong; B. Brandoli; S. Matwin; J. F. Rodrigues-Jr; J. Sun","Institute of Mathematics and Computer Sciences, University of Sao Paulo, São Carlos - SP, Brazil; National Institute of Health Data Science and Institute of Medical Technology, Peking University, Beijing, China; Institute for Big Data Analytics, Dalhousie University, Halifax, NS, Canada; Institute for Big Data Analytics, Dalhousie University, Halifax, NS, Canada; Institute of Mathematics and Computer Sciences, University of Sao Paulo, São Carlos - SP, Brazil; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA",IEEE Transactions on Pattern Analysis and Machine Intelligence,"4 Aug 2022","2022","44","9","5368","5384","Time-series forecasting is one of the most active research topics in artificial intelligence. It has the power to bring light to problems in several areas of knowledge, such as epidemiological studies, healthcare inference, and climate change analysis. Applications in real-world time series should consider two factors for achieving reliable predictions: modeling dynamic dependencies among multiple variables and adjusting the model's intrinsic hyperparameters. An open gap in the literature is that statistical and ensemble learning approaches systematically present lower predictive performance than deep learning methods. The existing applications consistently disregard the data sequence aspect entangled with multivariate data represented in more than one time series. Conversely, this work presents a novel neural network architecture for time-series forecasting that combines the power of graph evolution with deep recurrent learning on distinct data distributions, named after Recurrent Graph Evolution Neural Network (ReGENN). The idea is to infer multiple multivariate relationships between co-occurring time-series by assuming that the temporal data depends not only on inner variables and intra-temporal relationships (i.e., observations from itself) but also on outer variables and inter-temporal relationships (i.e., observations from other-selves). An extensive set of experiments was conducted comparing ReGENN with tens of ensemble methods and classical statistical ones. The results outperformed both statistical and ensemble-learning approaches, showing an improvement of 64.87 percent over the competing algorithms on the SARS-CoV-2 dataset of the renowned John Hopkins University for 188 countries simultaneously. For further validation, we tested our architecture in two other public datasets of different domains, the PhysioNet Computing in Cardiology Challenge 2012 and Brazilian Weather datasets. We also analyzed the Evolution Weights arising from the hidden layers of ReGENN to describe how the variables of the dataset interact with each other; and, as a result of looking at inter and intra-temporal relationships simultaneously, we concluded that time-series forecasting is majorly improved if paying attention to how multiple multivariate data synchronously evolve.","1939-3539","","10.1109/TPAMI.2021.3076155","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior – Brazil; Fundação de Amparo à Pesquisa do Estado de São Paulo(grant numbers:2014/25337-0,2016/17078-0,2017/08376-0,2018/17620-5,2019/04461-9,2020/07200-9); Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:167967/2017-7,305580/2017-5,406550/2018-2); National Science Foundation(grant numbers:IIS-2014438,PPoSS-2028839,IIS-1838042); National Institutes of Health(grant numbers:R01 1R01NS107291-01,R56HL138415); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416768","Time series;graph evolution;representation learning","Forecasting;Time series analysis;COVID-19;Predictive models;Evolution (biology);Climate change;Recurrent neural networks","","50","","60","CCBY","27 Apr 2021","","","IEEE","IEEE Journals"
"WirMAE: Learning Well-Logging Interval Representations via Masked Autoencoders for Gas Hydrate Reservoir Characterization","Z. Li; Z. Zhang; L. Jiang; Z. Liu; H. Zhou; J. Sun; K. Lee; F. Ning","Faculty of Engineering and National Center for International Research on Deep Earth Drilling and Resource Development, China University of Geosciences, Wuhan, China; National Center for International Research on Deep Earth Drilling and Resource Development and the College of Marine Science and Technology, China University of Geosciences, Wuhan, China; School of Computer Science, China University of Geosciences, Wuhan, China; Faculty of Engineering and National Center for International Research on Deep Earth Drilling and Resource Development, China University of Geosciences, Wuhan, China; Faculty of Engineering and National Center for International Research on Deep Earth Drilling and Resource Development, China University of Geosciences, Wuhan, China; Faculty of Engineering and National Center for International Research on Deep Earth Drilling and Resource Development, China University of Geosciences, Wuhan, China; Department of Geoenvironmental Sciences, Yellow Sea Institute of Geoenvironmental Sciences, Kongju National University, Gongju-si, Chungnam, Republic of Korea; Faculty of Engineering and National Center for International Research on Deep Earth Drilling and Resource Development, China University of Geosciences, Wuhan, China",IEEE Transactions on Geoscience and Remote Sensing,"20 Jun 2025","2025","63","","1","16","Reservoir characterization (identification and parameter estimation) is critical for gas hydrate exploration and development. While machine learning (ML) techniques excel at capturing complex relationships in well-logging reservoir characterization, existing research mainly focuses on end-to-end supervised learning approaches relying on costly labeled data and lacking multitask learning capabilities. In this article, we introduce a self-supervised learning (SSL) framework to learn general representations of large-scale unlabeled Well-Logging Interval Representations via Masked Autoencoders (WirMAE). By incorporating channel-based attention mechanisms and a masked reconstruction pretraining strategy for variable tokens, WirMAE effectively extracts intrinsic multivariate correlations within logging data, enabling the generation of various missing log curves. The model is validated on data from globally distributed hydrate with diverse accumulation patterns. Compared to supervised deep learning methods and classical ML models, fine-turned WirMAE achieves superior reservoir identification accuracy (average  $F1$ -score: 0.864) using only 1% labeled data in complex geological settings. Combined with domain expertise, WirMAE yields precise estimation of key reservoir parameters such as hydrate saturation and permeability, outperforming conventional petrophysical methods. Additionally, embedding visualizations and attention analyses reveal the inner workings of the model and its consistency with expert-driven geological interpretations. Our findings highlight the potential of SSL for advancing more accurate and transparent intelligent reservoir characterization using well-log data, indicating that the application of WirMAE could be extended to broader hydrocarbon reservoirs in the future.","1558-0644","","10.1109/TGRS.2025.3577988","National Science Fund for Distinguished Young Scholars(grant numbers:42225207); National Natural Science Foundation of China(grant numbers:42306240,42376220,42372361); fellowship of China Postdoctoral Science Foundation(grant numbers:2024T170853,2022M722942); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029068","Gas hydrate;masked autoencoder (MAE);reservoir characterization;self-supervised learning (SSL);Transformer;well-log data","Reservoirs;Geology;Transformers;Accuracy;Autoencoders;Data models;Representation learning;Predictive models;Training;Decoding","","","","93","IEEE","9 Jun 2025","","","IEEE","IEEE Journals"
"A causal graph-based framework for satellite health monitoring","J. Meng; J. Cai; L. Chang","Innovation Academy for Microsatellites, University of Chinese Academy of Sciences, Shanghai, China; Innovation Academy for Microsatellites, University of Chinese Academy of Sciences, Shanghai, China; Innovation Academy for Microsatellites, University of Chinese Academy of Sciences, Shanghai, China",2023 IEEE International Conference on Prognostics and Health Management (ICPHM),"2 Aug 2023","2023","","","89","98","In satellite operations, one of the essential tasks is to monitor the health status of the systems, which involves forecasting telemetry data that reflects the state of health. The application of data-driven approaches in system monitoring has led to significant improvements in health monitoring and anomaly detection. However, existing methods fail to fully leverage the complex inter-sensor relationships present in satellites. They do not explicitly exploit the structure of these relationships to predict the expected behavior of telemetry time series either. To address these limitations, this paper introduces a novel health monitoring framework for artificial satellites that combines causal graphs and deep learning. In the causality learning phase, we propose a method that integrates mRMR (Maximum Relevance Minimum Redundancy) and PCMCI (Peter-Clark Momentary Conditional Independence) to construct an efficient and accurate causal discovery approach for learning causal graphs for high-dimensional telemetry data. Subsequently, we design a graph attention-based neural network that incorporates these causal graphs into a deep network for prediction. Experimental evaluation on two datasets from satellite attitude control systems and power systems demonstrates the superior performance of our proposed method in accurately predicting health status compared to baseline approaches. Furthermore, the experiments highlight the interpretability-enhancing role of causal graphs, which is beneficial for health monitoring and anomaly detection.","2166-5656","979-8-3503-4625-1","10.1109/ICPHM57936.2023.10194125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10194125","satellite health management;causal discovery;time series prediction;anomaly detection;health assessment","Analytical models;Satellites;Neural networks;Time series analysis;Sensor systems;Sensors;Telemetry","","","","25","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"Deep Collaborative Intelligence-Driven Traffic Forecasting in Green Internet of Vehicles","Z. Guo; K. Yu; K. Konstantin; S. Mumtaz; W. Wei; P. Shi; J. J. P. C. Rodrigues","Chongqing Key Laboratory of Intelligent Perception and BlockChain Technology, National Research Base of Intelligent Manufacturing Services, Chongqing Technology and Business University, Chongqing, China; Graduate School of Science and Engineering, Hosei University, Tokyo, Japan; Department of Physics of Nanoscale Systems, South Ural State University, Chelyabinsk, Russia; Mobile System, Instituto de Telecomunicações, Aveiro, Portugal; School of Computer Science and Engineering, Xi’an University of Technology, Xi’an, China; School of Electrical and Electronic Engineering, University of Adelaide, Adelaide, SA, Australia; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China",IEEE Transactions on Green Communications and Networking,"19 May 2023","2023","7","2","1023","1035","Accompanied with the development of green wireless communication, the green Internet of Vehicles (GIoV) has been a latent solution for future transportation. Among them, intelligent traffic forecasting for key nodes in GIoV is a significant research topic. Much research had been devoted to this issue, and graph learning-based approaches seemed to be a promising solution. However, existing research works concentrated more on graph-structured features in GIoV yet neglected global reliability. To deal with such issue, this work combines both deep embedding and graph embedding together and proposes a deep collaborative intelligence-driven traffic forecasting model in GIoV. By establishing more reliable feature spaces for traffic flow prediction, forecasting efficiency is expected to be promoted. Specifically, deep embedding is utilized to generate more abstract representation for basic features of road networks, and graph embedding is employed to update feature representation for different timestamps. Their collaboration contributes to considerable reliability. In addition, experiments are also conducted on a real-world dataset, and the results indicate that forecasting deviation receives about 15%-25% reduction.","2473-2400","","10.1109/TGCN.2022.3193849","National Natural Science Foundation of China(grant numbers:62106029); Humanities and Social Science Research Project of the Ministry of Education(grant numbers:21YJC630036); Science and Technology Research Program of Chongqing Municipal Education Commission(grant numbers:KJQN202000805); High-Level Talents Research Project of CTBU(grant numbers:1856033,1953013); Japan Society for the Promotion of Science (JSPS) Grants-in-Aid for Scientific Research (KAKENHI)(grant numbers:JP18K18044,JP21K17736); FCT/MCTES through National Funds and when applicable co-funded EU Funds(grant numbers:UIDB/50008/2020); Brazilian National Council for Scientific and Technological Development—CNPq(grant numbers:313036/2020-9); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9841473","Collaborative intelligence;traffic forecasting;green Internet of Vehicles;deep learning","Forecasting;Predictive models;Roads;Intelligent transportation systems;Encoding;Data models;Computational modeling","","62","","38","IEEE","26 Jul 2022","","","IEEE","IEEE Journals"
"Anomaly Detection for Small Hydropower Based on Deep Spatio-Temporal Modeling","Y. Zhan; B. Yang; Y. Ma","School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China; School of Electrical Engineering, Guangxi University, Nanning, China",2025 6th International Conference on Mechatronics Technology and Intelligent Manufacturing (ICMTIM),"30 Jun 2025","2025","","","624","630","Anomaly detection in small hydropower plays a crucial role in small hydropower data-driven condition monitoring systems, contributing to improved equipment durability and reduced operational and maintenance expenses. Benefiting from advancements in the industrial internet, various sensors in small hydropower stations generate co-evolving time-series data with distinct characteristics at any given moment, which are recorded in the small hydropower condition monitoring system. The joint modeling of variable associations and temporal dependencies in small hydropower multivariate time-series data presents significant challenges for anomaly detection tasks. This study characterizes the complex relationships within small hydropower data as a combination of temporal dependencies and inter-feature correlations. To address these, it introduces a novel anomaly detection framework for multivariate time series, integrating adaptive graph structure learning, graph attention mechanisms, and temporal feature pyramid networks to effectively capture spatiotemporal dependencies. The proposed method aims to dynamically capture the most significant relationships, enabling timely detection of potential anomalies for more reliable small hydropower station monitoring. Experimental results on real-world sensor datasets from small hydropower stations show that the proposed method outperforms traditional approaches in anomaly detection, with superior capability in modeling the spatiotemporal dependencies inherent in multivariate time-series data.","","979-8-3315-2661-0","10.1109/ICMTIM65484.2025.11040954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11040954","small hydropower;anomaly detection;multivariate time-series;deep learning","Condition monitoring;Time series analysis;Hydroelectric power generation;Sensor phenomena and characterization;Data models;Sensor systems;Real-time systems;Spatiotemporal phenomena;Anomaly detection;Monitoring","","","","28","IEEE","30 Jun 2025","","","IEEE","IEEE Conferences"
"TransGlow: Attention-augmented Transduction model based on Graph Neural Networks for Water Flow Forecasting","N. S. Roudbari; C. Poullis; Z. Patterson; U. Eicker","Gina Cody School of Engineering and Computer Science Concordia University, Montreal, QC, Canada; Gina Cody School of Engineering and Computer Science Concordia University, Montreal, QC, Canada; Gina Cody School of Engineering and Computer Science Concordia University, Montreal, QC, Canada; Gina Cody School of Engineering and Computer Science Concordia University, Montreal, QC, Canada",2023 International Conference on Machine Learning and Applications (ICMLA),"19 Mar 2024","2023","","","626","632","The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control. However, the task is difficult due to the dynamic nature and limited data of water systems. Highly interconnected water systems can significantly affect hydrometric forecasting. Consequently, it is crucial to develop models that represent the relationships between other system components. In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction. Existing methods are unable to model the influence of adjacent regions between pairs of variables. In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism. The attention layer allows the decoder to access different parts of the input sequence selectively. Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data. Spatiotemporal forecasting relies on historical data. In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions. Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes. Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin.","1946-0759","979-8-3503-4534-6","10.1109/ICMLA58977.2023.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10460026","Encoder-Decoder;Attention;Graph Neural Net-works;Spatiotemporal forecasting","Recurrent neural networks;Water quality;Predictive models;Rivers;Spatiotemporal phenomena;Floods;Forecasting","","3","","36","IEEE","19 Mar 2024","","","IEEE","IEEE Conferences"
"Time Series Prediction Problems Under Covariate Drift","X. Liang; K. Hao; L. Chen; L. Ren","Engineering Research Center of Digitized Textile and Apparel Technology, Ministry of Education, Donghua University, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Ministry of Education, Donghua University, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Ministry of Education, Donghua University, Shanghai, China; Engineering Research Center of Digitized Textile and Apparel Technology, Ministry of Education, Donghua University, Shanghai, China",2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS),"5 Aug 2024","2024","","","414","419","In the real world, time series data are ubiquitous, and the prediction task of time series data is very important. Most real-world time series data do not satisfy the assumption of independent and identical distribution (i.i.d.) due to environmental changes, that is, the distribution of the training datasets is different from the distribution of the test datasets, $P(X_{i})= P(X_{j})$, but the conditional distribution is usually considered to be unchanged, $P(y\vert x_{i})= P(y\vert x_{j})$. In this case, it is defined as covariate drift. However, most of the existing prediction algorithms are based on the assumption of i.i.d., so these algorithms have great limitations in the prediction of time series data under covariant drift. Therefore, the AEIF-MLP model is proposed, a time series data prediction model based on MLP and causal structures. The model mainly consists of two modules. Based on the principle of maximum entropy, we propose an adaptive environment segmentation module to separate different environments in the training datasets. Based on the causal structure, we propose an invariant feature learning module to learn common invariant features in different environments to train the model to deal with test datasets of unknown distribution. In summary, this method solves the problem of time series prediction under covariate drift. The validity of the model is verified by drift data sets in different environments for the first time, and the validity of the model is further verified on two real data sets.","2767-9861","979-8-3503-6167-4","10.1109/DDCLS61622.2024.10606927","Fundamental Research Funds for the Central Universities(grant numbers:2232021A-10); National Natural Science Foundation of China(grant numbers:61903078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606927","covariate drift;adaptive environment segmentation;causal structure;invariant feature learning","Training;Representation learning;Learning systems;Adaptation models;Time series analysis;Predictive models;Prediction algorithms","","","","17","IEEE","5 Aug 2024","","","IEEE","IEEE Conferences"
"Online Topology Identification of Higher-Order Cell Structures","A. Canbolat; R. Money; B. Beferull-Lozano","Simula Metropolitan Center for Digital Engineering, Oslo, Norway; Simula Metropolitan Center for Digital Engineering, Oslo, Norway; Simula Metropolitan Center for Digital Engineering, Oslo, Norway",2025 IEEE 35th International Workshop on Machine Learning for Signal Processing (MLSP),"24 Oct 2025","2025","","","1","6","Topology identification in cellular complexes is a central challenge in Topological Signal Processing, yet existing methods face major limitations: they fail to generalize to graph learning and inadequately capture the connectivity patterns of cellular complexes. Moreover, most approaches are limited to offline learning with batch data, restricting their applicability in dynamic or non-stationary data environments. We propose a unified framework that explicitly distinguishes between simple and general cycles, enabling seamless generalization across graphs, simplicial complexes, and cellular complexes. Our framework also bridges offline and online learning through a state-space formulation. Based on this, we introduce an online topology identification algorithm and demonstrate its effectiveness through preliminary experiments on synthetic datasets.","2161-0371","979-8-3315-7029-3","10.1109/MLSP62443.2025.11204205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11204205","Topological signal processing;cellular complex learning;topology-based modeling;online learning","Bridges;Machine learning algorithms;Heuristic algorithms;Conferences;Signal processing algorithms;Machine learning;Signal processing;Topology;Faces;Synthetic data","","","","21","IEEE","24 Oct 2025","","","IEEE","IEEE Conferences"
"Forecasting Application Counts in Talent Acquisition Platforms: Harnessing Multimodal Signals using LMs","M. A. Kabir; K. Abdelfatah; S. He; M. Korayem; M. Al Hasan","CareerBuilder LLC, USA; CareerBuilder LLC, Canada; CareerBuilder LLC, USA; CareerBuilder LLC, Canada; Indiana University Indianapolis, USA",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2334","2339","As recruitment and talent acquisition have become more and more competitive, recruitment firms have become more sophisticated in using machine learning (ML) methodologies for optimizing their day to day activities. But, most of published ML based methodologies in this area have been limited to the tasks like candidate matching, job to skill matching, job classification and normalization. In this work, we discuss a novel task in the recruitment domain, namely, application count forecasting, motivation of which comes from designing of effective outreach activities to attract qualified applicants. We show that existing auto-regressive based time series forecasting methods perform poorly for this task. Henceforth, we propose a multimodal LM-based model which fuses job-posting metadata of various modalities through a simple encoder. Experiments from large real-life datasets from CareerBuilder LLC show the effectiveness of the proposed method over existing state-of-the-art methods.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825459","","Fuses;Time series analysis;Machine learning;Metadata;Big Data;Feature extraction;Forecasting;Recruitment","","","","15","IEEE","16 Jan 2025","","","IEEE","IEEE Conferences"
"Graph-Time Convolutional Neural Networks: Architecture and Theoretical Analysis","M. Sabbaqi; E. Isufi","Intelligent Systems Department, Delft University of Technology, Delft, CD, The Netherlands; Intelligent Systems Department, Delft University of Technology, Delft, CD, The Netherlands",IEEE Transactions on Pattern Analysis and Machine Intelligence,"3 Nov 2023","2023","45","12","14625","14638","Devising and analysing learning models for spatiotemporal network data is of importance for tasks including forecasting, anomaly detection, and multi-agent coordination, among others. Graph Convolutional Neural Networks (GCNNs) are an established approach to learn from time-invariant network data. The graph convolution operation offers a principled approach to aggregate information and offers mathematical analysis by exploring tools from graph signal processing. This analysis provides insights into the equivariance properties of GCNNs; spectral behaviour of the learned filters; and the stability to graph perturbations, which arise from support perturbations or uncertainties. However, extending the convolutional learning and respective analysis to the spatiotemporal domain is challenging because spatiotemporal data have more intrinsic dependencies. Hence, a higher flexibility to capture jointly the spatial and temporal dependencies is required to learn meaningful higher-order representations. Here, we leverage product graphs to represent the spatiotemporal dependencies in the data and introduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled architecture. We also introduce a parametric product graph to learn the spatiotemporal coupling. The convolution principle further allows a similar mathematical tractability as for GCNNs. In particular, the stability result shows GTCNNs are stable to spatial perturbations. owever, there is an implicit trade-off between discriminability and robustness; i.e., the more complex the model, the less stable. Extensive numerical results on benchmark datasets corroborate our findings and show the GTCNN compares favorably with state-of-the-art solutions. We anticipate the GTCNN to be a starting point for more sophisticated models that achieve good performance but are also fundamentally grounded.","1939-3539","","10.1109/TPAMI.2023.3311912","TU Delft AI Labs; TTW-OTP project GraSPA(grant numbers:19497); Dutch Research Council (NWO); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10239277","Graph convolutional neural networks;graph signal processing;graph-time neural networks;stability to perturbations","Spatiotemporal phenomena;Convolution;Stability analysis;Perturbation methods;Numerical stability;Convolutional neural networks;Data models","","16","","54","IEEE","5 Sep 2023","","","IEEE","IEEE Journals"
"Attention-Based Deep Learning Model for Prediction of Major Adverse Cardiovascular Events in Peritoneal Dialysis Patients","Z. Xu; X. Xu; X. Zhu; K. Niu; J. Dong; Z. He","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Renal Division, Department of Medicine, Peking University First Hospital, Beijing, China; Beijing University of Posts and Telecommunications Hospital, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Renal Division, Department of Medicine, Peking University First Hospital, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Journal of Biomedical and Health Informatics,"5 Feb 2024","2024","28","2","1101","1109","Major adverse cardiovascular events (MACE) encompass pivotal cardiovascular outcomes such as myocardial infarction, unstable angina, and cardiovascular-related mortality. Patients undergoing peritoneal dialysis (PD) exhibit specific cardiovascular risk factors during the treatment, which can escalate the likelihood of cardiovascular events. Hence, the prediction and key factor analysis of MACE have assumed paramount significance for peritoneal dialysis patients. Current pathological methodologies for prognosis prediction are not only costly but also cumbersome in effectively processing electronic health records (EHRs) data with high dimensionality, heterogeneity, and time series. Therefore in this study, we propose the CVEformer, an attention-based neural network designed to predict MACE and analyze risk factors. CVEformer leverages the self-attention mechanism to capture temporal correlations among time series variables, allowing for weighted integration of variables and estimation of the probability of MACE. CVEformer first captures the correlations among heterogeneous variables through attention scores. Then, it analyzes the correlations within the time series data to identify key risk variables and predict the probability of MACE. When trained and evaluated on data from a large cohort of peritoneal dialysis patients across multiple centers, CVEformer outperforms existing models in terms of predictive performance.","2168-2208","","10.1109/JBHI.2023.3338729","National Key Research and Development Program of China(grant numbers:2021YFE0205300); Scientific Research Project of Capital Health Development(grant numbers:2020-2-4079); CAMS Innovation Fund for Medical Sciences(grant numbers:2019-I2M-5-046); National High Level Hospital Clinical Research Funding(grant numbers:2022CR82); National High Level Hospital Clinical Research Funding(grant numbers:2022CX09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10339835","Major adverse cardiovascular events (MACE);peritoneal dialysis;deep learning;attention mechanism;key risk factors","Abdomen;Feature extraction;Time series analysis;Hospitals;Deep learning;Predictive models;Correlation","Humans;Deep Learning;Peritoneal Dialysis;Myocardial Infarction;Risk Factors;Prognosis","5","","28","IEEE","4 Dec 2023","","","IEEE","IEEE Journals"
"Cloudformer: Contrastive Learning Based Cloud Workload Prediction","H. Lu; Y. Zhang; Z. Wu; Z. Wei","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",2024 7th International Conference on Electronics Technology (ICET),"18 Sep 2024","2024","","","534","540","During the last 3 years, researchers have endeavored to extend the efficacy of contrastive learning (CL) towards addressing the challenges inherent in cloud workload prediction, which has demonstrated considerable success in the domains of Computer Vision (CV) and Natural Language Processing(NLP). However, due to the distinctive temporal characteristics of serialized workload information, relying solely on empirical guidance from other domains may prove insufficient for cloud workload prediction. Therefore, we systematically investigated three key components of CL, including: 1) designing backbone encoder for feature extraction, 2) designing methods for extracting negative samples for contrast, and 3) designing the CL loss. We found that inappropriate construction of negative samples may introduce excessive pseudo-negative samples, which neither preserve temporal characteristics nor provide sufficient discriminative features. Additionally, focusing solely on the discrimination between positive and negative samples in the CL loss may not be adequate for enabling the model to learn the temporal patterns of serialized workload information. To address these problems, we propose a novel self-supervised model named Cloudformer. Specifically, we first constructed a CL network based on the Transformer architecture using a pre-train-finetune framework. Following this, we proposed a method to filter pseudo-negative samples based on differential cosine similarity, aimed at assisting the model in more effectively distinguishing between positive and negative samples. Additionally, we introduced the BatchNCE loss, combining MSE loss with InfoNCE loss as a joint optimization objective for CL, effectively enhancing the predictive capability of the model. The experimental results indicate that Cloudformer is capable of learning high-quality patterns in serialized workload sequences and achieves more advanced performance in short sequence prediction tasks.","2768-6515","979-8-3503-6395-1","10.1109/ICET61945.2024.10672804","Research and Development; Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10672804","Cloudformer;cloud;workload prediction;time series;pseudo-negative sample","Learning systems;Analytical models;Prevention and mitigation;Natural languages;Contrastive learning;Predictive models;Feature extraction","","1","","26","IEEE","18 Sep 2024","","","IEEE","IEEE Conferences"
"Causality-Aware Multi-Graph Convolutional Networks With Critical Node Dynamics for Electric Vehicle Charging Station Load Forecasting","Y. Huang; S. Wu; Z. Wang; X. Liu; C. Li; Y. Hu","School of Automation, Central South University, Changsha, China; College of Computer Engineering, Jimei University, Xiamen, China; College of Computer Engineering, Jimei University, Xiamen, China; Department of Technology, Management and Economics, Technical University of Denmark, Lyngby, Denmark; DITEN, University of Genoa, Genova, Italy; College of Computer Engineering, Jimei University, Xiamen, China",IEEE Transactions on Smart Grid,"23 Jun 2025","2025","16","4","3210","3225","Accurately forecasting the load of electric vehicle charging stations (EVCSs) is crucial for optimizing grid operations and facilitating EV integration, yet existing methods struggle to capture the intricate spatio-temporal dependencies and the impact of influential EVCSs within charging networks. To address this, we propose a novel framework, Causality-Aware Dynamic Multi-Graph Convolutional Network (CADGN), a multi-graph convolutional network that integrates causal inference and critical node modeling. It consists of two core modules: the Causality-Aware Graph Learning Module (CAGLM) uncovers and represents causal relationships between EVCSs, while the Critical Relationship Graph Learning Module (CRGLM) dynamically models the evolving connections among critical EVCS nodes. Temporal patterns extracted from these modules are then fused to generate accurate load predictions. Extensive experiments using real-world datasets of hourly charging data from multiple cities demonstrate CADGN’s superiority over state-of-the-art EVCS load forecasting models, particularly for short-term and mid-term horizons. Notably, our model achieves an average 4.7% reduction in Mean Absolute Error (MAE) compared to Graph WaveNet across all datasets and prediction horizons, highlighting the practical benefits of considering both causal and critical relationships for enhanced grid operations and EV integration. These results emphasize the importance of incorporating causality and the identification of critical relationships in the EVCS load forecast to achieve higher accuracy.","1949-3061","","10.1109/TSG.2025.3570955","BEGONIA Project through European Commission(grant numbers:01133306); FAST Community; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11007094","Electric vehicle charging stations;load forecasting;graph convolutional networks;causal inference;time series analysis","Load modeling;Accuracy;Load forecasting;Correlation;Forecasting;Predictive models;Vehicle dynamics;Electric vehicle charging;Cause effect analysis;Transportation","","1","","44","IEEE","19 May 2025","","","IEEE","IEEE Journals"
"Knowledge Base-Guided Modeling of ICS Device Behavior for Status Prediction","L. Li; S. Zhang; X. Liu; D. Liu; R. Wang; F. Zhang; F. Zhao; S. Xu","State Grid Shandong Electric Power Company, Jinan, China; State Grid Shandong Electric Power Company, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Research Institute, Jinan, China",2024 IEEE 9th International Conference on Data Science in Cyberspace (DSC),"4 Feb 2025","2024","","","541","548","Predicting device status in Industrial Control Systems (ICS) is important for ensuring operational efficiency and preventing costly failures. Traditional univariate forecasting models grapple with the complexities inherent in multivariate time series data characterized by high interdependencies among devices. This study pioneers a novel methodology, which can fuse of linear model principles with graph embedding techniques (GCNs), for device behavior modeling. Specifically, we innovatively establish a device behavior knowledge base and exploits graph embedding algorithms to decipher both the spatial-temporal intricacies and underlying correlations embedded within extensive sensor data collections. The behavior knowledge base employs statistical methodologies like Pearson correlation to derive an adjacency matrix, which can facilitate the model’s realization of the static structure and dynamic interaction of device features. Moreover, to enhance predictive precision, we synthesize the strengths of linear model interpretations with the nuanced insights derived from graph-based feature learning. GCNs, serving as the backbone for learning sophisticated inter-device relations within this knowledge base, significantly influence the efficacy of device status prediction. Linear models are strategically utilized to distill time-dependent features from individual device sequences, overcoming scalability limitations associated with Recurrent Neural Networks (RNNs) when handling extended observation periods. Extensive experiments on real word dataset are conducted to validate our model’s performance. Experimental results illustrate that the proposed method achieves high performance on status prediction of ICS device.","","979-8-3503-9136-7","10.1109/DSC63484.2024.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10859044","","Performance evaluation;Recurrent neural networks;Correlation;Fuses;Computational modeling;Knowledge based systems;Time series analysis;Predictive models;Data models;Integrated circuit modeling","","","","22","IEEE","4 Feb 2025","","","IEEE","IEEE Conferences"
"A Dynamic Evolving Fuzzy System for Streaming Data Prediction","Z. Mei; T. Zhao; X. Gu","College of Electrical Engineering, Sichuan University, Chengdu, China; College of Electrical Engineering, Sichuan University, Chengdu, China; Department of Computer Science, University of Surrey, Guildford, U.K.",IEEE Transactions on Fuzzy Systems,"5 Aug 2024","2024","32","8","4324","4337","This article proposes a dynamic evolving fuzzy system (DEFS) for streaming data prediction. DEFS utilizes the enhanced data potential and prediction errors of individual local models as the main criteria for fuzzy rule generation. A vital feature of the proposed system is its novel rule merging scheme that can self-adjust its tolerance toward the degree of similarity between two similar fuzzy rules according to the size of the rule base. To better handle the shifts and drifts in the data patterns, a novel rule quality measure based on both the utility values and the prediction accuracy of individual fuzzy rules is further introduced to help DEFS identify these less activated fuzzy rules with poorer descriptive capabilities and, thereby, maintaining a healthier fuzzy rule base by removing these stale rules. Very importantly, the thresholds used by DEFS are self-adaptive toward the input data. The adaptive thresholds can help DEFS to precisely capture the underlying structure and dynamically changing patterns of streaming data, enabling the system to perform accurate approximation reasoning. Numerical examples based on several popular benchmark problems show the superior performance of DEFS over the state-of-the-art evolving fuzzy systems. The prediction performance of the proposed method is at least 2.88% better than the best-performing comparative EFSs on each individual regression benchmark problem considered in this study, and the average performance improvement across all the numerical experiments is approximately 30%.","1941-0034","","10.1109/TFUZZ.2024.3395643","Sichuan Science and Technology Program(grant numbers:24NSFSC0239); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10517460","Data stream;evolving fuzzy system (EFS);online learning;self-adaptive thresholds","Streams;Fuzzy systems;Fuzzy neural networks;Data models;Merging;Fuzzy logic;Adaptation models","","22","","58","IEEE","1 May 2024","","","IEEE","IEEE Journals"
"Remaining Useful Life Prediction for Bearings Based on Generative Pretrained Transformer","L. Wang; Y. Wang; Q. Wu; B. Zhang; F. Huang","School of Artificial Intelligence and Automation, Wuhan University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Wuhan University of Science and Technology, Wuhan, China; School of Information Engineering, Zhejiang University of Technology, Zhejiang, China; School of Information Engineering, Zhejiang University of Technology, Zhejiang, China; School of Artificial Intelligence and Automation, Wuhan University of Science and Technology, Wuhan, China",2025 IEEE 2nd International Conference on Big Data Science and Engineering (ICBDSE),"4 Nov 2025","2025","","","1","5","Accurate prediction of bearing remaining useful life (RUL) is crucial for ensuring the safe operation of critical equipment. To address the limitations of existing methods, including insufficient generalization capability caused by reliance on single datasets and increased deployment costs due to the requirement for customized prediction heads for different operating conditions, a novel solution is proposed in this paper. Specifically,mixed dataset pre-training dataset is constructed to expand the training scale, enabling the model to learn more generalizable degradation trend representations. Meanwhile, a multi-scale transformer architecture integrated with autoregressive decoding is adopted, where hierarchical temporal feature extraction and iterative residual learning are synergistically optimized to achieve progressive refinement of prediction results. Experimental results demonstrate that the proposed method significantly outperforms baseline models in both prediction accuracy and robustness, with the RMSE metric being reduced by $8.6 \%$ (reaching 0.0317) compared to the suboptimal PatchTST model, while the MAE metric is decreased by $\mathbf{4 9. 9 \%}$ (optimized to $\mathbf{0. 0 2 4 6}$) relative to conventional Transformer architectures.","","979-8-3315-4407-2","10.1109/ICBDSE65491.2025.11220134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11220134","Remaining useful life prediction;Bearing;Time series forecasting;Deep learing","Measurement;Degradation;Vibrations;Training;Technological innovation;Accuracy;Time series analysis;Predictive models;Transformers;Iterative decoding","","","","22","IEEE","4 Nov 2025","","","IEEE","IEEE Conferences"
"Towards Spatio-Temporal Aware Real Location Restoration for Signaling Data","H. Huang; S. Ji; T. Zhu","State Key Laboratory of Complex Critical Software Environment, Beihang University, Beijing, China; State Key Laboratory of Complex Critical Software Environment, Beihang University, Beijing, China; State Key Laboratory of Complex Critical Software Environment, Beihang University, Beijing, China",2024 39th Youth Academic Annual Conference of Chinese Association of Automation (YAC),"24 Jul 2024","2024","","","1597","1602","This study introduces the novel problem of Real Location Restoration, aimed at reconstructing accurate user trajectories from the coarse-grained mobile signaling data. To tackle this problem, we propose the Spatio-Temporal Aware framework for Signaling Data (STASD), a pioneering approach that encodes the complex spatiotemporal relationships of cellular trajectories. Leveraging a unique global transition graph, STASD captures high-order spatial relationships to effectively mitigate the Ping Pong Effect, a common issue in signaling data analysis. Our extensive experiments showcase the framework’s capability to accurately restore real-world trajectories, significantly advancing the field of mobile data analysis by providing a novel method to interpret and utilize signaling data for detailed location insights.","2837-8601","979-8-3503-7922-8","10.1109/YAC63405.2024.10598525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598525","Signaling Data;Graph Embedding;Coarse Trajectory Data;Sequential Modeling;Uneven Time Interval","Personal protective equipment;Data analysis;Automation;Accuracy;Data models;Trajectory;Spatiotemporal phenomena","","","","25","IEEE","24 Jul 2024","","","IEEE","IEEE Conferences"
"Advanced Learning Techniques for Short-Term Atmospheric Predictions: An Overview","S. K. Patel; S. R. Panchal; S. S. Panchal","E&C Engg. School of Engg. & Tech., Dr. Subhash University, Junagadh, Gujarat; E&C Engg. School of Engg. & Tech., Dr. Subhash University, Junagadh, Gujarat; E&C Engg. School of Engg. & Tech., Dr. Subhash University, Junagadh, Gujarat","2023 2nd International Conference on Automation, Computing and Renewable Systems (ICACRS)","26 Jan 2024","2023","","","838","843","Atmospheric Prediction is a complex task influenced by various factors such as temperature, pressure, air movement, moisture, and the earth’s rotation. Achieving accurate forecasts with high geographical resolution poses significant challenges, requiring substantial computational resources. This study focuses on nowcasting meteorological radar images. Deep learning has emerged as a promising approach for unsupervised representation learning, with next-frame prediction being a particularly intriguing research area in computer vision. This approach involves predicting future images based on prior image information, with applications ranging from robot decision-making to autonomous driving. This review presents the latest advancements in next-frame prediction networks specifically tailored for atmosphere data nowcasting. These networks can be categorized into two main approaches: Machine Learners and deep learners. The study comprehensively analyzes and compare various strategies based on their advantages and limitations, highlighting the benefits and drawbacks of each method. Additionally, potential research directions that hold promise for future investigations in this field are discussed. By identifying the most significant challenges and opportunities, the study aims to inspire further advancements in deep learning methods for atmosphere data nowcasting. Overall, this study provides a comprehensive overview of the current state-of-the-art deep learning techniques for nowcasting atmosphere data, shedding light on their potential applications and suggesting avenues for future research.","","979-8-3503-4023-5","10.1109/ICACRS58579.2023.10405022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10405022","Atmosphere Data;Meteorological Data;Network Common Data Form (NetCDF);Support Vector Machine (SVM);Linear Regression;Random Forest;Convolutional Neural Network (CNN);Long Short-Term Memory (LSTM)","Deep learning;Support vector machines;Representation learning;Temperature;Atmosphere;Weather forecasting;Task analysis","","","","21","IEEE","26 Jan 2024","","","IEEE","IEEE Conferences"
"CGF: A Category Guidance Based PM$_{2.5}$ Sequence Forecasting Training Framework","H. Yu; J. Hu; X. Zhou; C. Guo; B. Yang; Q. Li","Department of Computer Science, Aalborg University, Aalborg, Denmark; Department of Computer Science, Aalborg University, Aalborg, Denmark; Key Laboratory of Big Data and Artificial Intelligence in Transportation, Ministry of Education, Beijing Jiaotong University, Beijing, China; East China Normal University, Shanghai, China; East China Normal University, Shanghai, China; Key Laboratory of Big Data and Artificial Intelligence in Transportation, Ministry of Education, Beijing Jiaotong University, Beijing, China",IEEE Transactions on Knowledge and Data Engineering,"14 Sep 2023","2023","35","10","10125","10139","PM$_{2.5}$2.5 concentration forecasting is important yet challenging. First, complicated local fluctuations in PM$_{2.5}$2.5 concentrations disturb modeling global trends. Second, forecasting errors are often accumulated through an autoregressive process. To contend with the two challenges, we propose a Category Guidance based PM${_{2.5}}$2.5 sequence Forecasting training framework (CGF) to enhance the performance of existing PM${_{2.5}}$2.5 concentration forecasting models. CGF contains a Category based Representation Learning (CRL) module and a Category based Self-paced Learning (CSL) module, both of which utilize PM${_{2.5}}$2.5 category information that is easily obtained and publicly available. First, CRL employs category information to guide forecasting models to produce more robust hidden representations that are insensitive to local fluctuations, thus alleviating the negative impact of local fluctuations. Second, CSL adaptively selects real PM${_{2.5}}$2.5 concentration values versus autoregressive PM${_{2.5}}$2.5 forecast values when training forecasting models, helping alleviate error accumulations. The CGF framework is applied to existing PM${_{2.5}}$2.5 forecasting models, and the experimental results on two real-world datasets demonstrate that CGF is able to consistently improve the accuracy of existing forecasting models. Furthermore, to validate the generality of CGF, we conduct extensional experiments in two other time-series prediction tasks, including exchange rate forecasting and electricity forecasting. The experimental results also verify the effectiveness of CGF.","1558-2191","","10.1109/TKDE.2023.3253703","Fundamental Research Funds for the Central Universities(grant numbers:2022JBQY007); National Natural Science Foundation of China(grant numbers:62276019,U2034211); Wuyi University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10064188","Category guidance;PM  $_{2.5}$      2 . 5        concentration forecasting;spatio-temporal;temporal","Forecasting;Predictive models;Training;Fluctuations;Decoding;Market research;Computational modeling","","6","","39","IEEE","8 Mar 2023","","","IEEE","IEEE Journals"
"AI Algorithms in Networks","S. G. Glisic; B. Lorenzo","University of Oulu, Finland; University of Oulu, Finland",Artificial Intelligence and Quantum Computing for Advanced Wireless Networks,"","2022","","","227","360","This chapter presents the application of diverse machine learning (ML) techniques in various key areas of networking across different network technologies. It considers a heterogeneous network with base stations, small base stations, and users distributed according to independent Poisson point processes. The chapter presents different aspects of using ML algorithms for self‐organizing cellular networks. It discusses the data sources and strong drivers for the adoption of the data analytics, and the role of ML and artificial intelligence in making the system intelligent with regard to being self‐aware, self‐adaptive, proactive, and prescriptive. The chapter also discusses a topology‐aware, dynamic, and autonomous system for managing resources in network function virtualization based on the concept of graph neural networks. The chapter also considers network slicing in a more complex setup. Network representation learning aims to learn latent, low‐dimensional representations of network vertices, while preserving network topology structure, vertex content, and other side information.","","9781119790280","10.1002/9781119790327.ch7","","https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=9779381.pdf&bkn=9779336&pdfType=chapter","","Routing;Predictive models;Quality of service;Protocols;Telecommunication traffic;Classification algorithms;Artificial neural networks","","","","","","20 May 2022","","","Wiley","Wiley Telecom eBook Chapters"
"Super Resolution Graph With Conditional Normalizing Flows for Temporal Link Prediction","Y. Yin; Y. Wu; X. Yang; W. Zhang; X. Yuan","Tianjin Key Laboratory of Network and Data Security Technology, College of Computer Science, Nankai University, Tianjin, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Tianjin Key Laboratory of Network and Data Security Technology, College of Computer Science, Nankai University, Tianjin, China",IEEE Transactions on Knowledge and Data Engineering,"5 Feb 2024","2024","36","3","1311","1327","Temporal link prediction on dynamic graphs has attracted considerable attention. Most methods focus on the graph at each timestamp and extract features for prediction. As graphs are directly compressed into feature matrices, the important latent information at each timestamp has not been well revealed. Eventually, the acquisition of dynamic evolution-related patterns is rendered inadequately. In this paper, inspired by the process of Super-Resolution (SR), a novel deep generative model SRG (Super Resolution Graph) is proposed. We innovatively introduce the concepts of the Low-Resolution (LR) graph, which is a single adjacent matrix at a timestamp, and the High-Resolution (HR) graph, which includes the link status of surrounding snapshots. Specifically, two major aspects are considered regarding the construction of the HR graph. For edges, we endeavor to obtain an extensive information transmission description that affects the current link status. For nodes, similar to the SR process, the neighbor relationship among nodes is maintained. In this form, we could predict the link status from a new perspective: Under the supervision of the graph moving average strategy, the conditional normalizing flow effectively realizes the transformation between LR and HR graphs. Extensive experiments on six real-world datasets from different applications demonstrate the effectiveness of our proposal.","1558-2191","","10.1109/TKDE.2023.3295367","National Key R&D Program of China(grant numbers:2018AAA0102100); National Natural Science Foundation of China(grant numbers:U1936206,U22B2048,62206292,62077031,92167109); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10183879","Temporal link prediction;dynamic graphs;super-resolution;conditional normalizing flow","Noise measurement;Feature extraction;Task analysis;Superresolution;Data mining;Predictive models;Information processing","","3","","65","IEEE","14 Jul 2023","","","IEEE","IEEE Journals"
"Design and Development of Deep Learning Framework for Recognition of Calisthenics Movement","L. Zhu","Tianjin Transportation Technical College, Tianjin, China",2025 International Conference on Intelligent Computing and Knowledge Extraction (ICICKE),"22 Sep 2025","2025","","","1","6","Calisthenics movement recognition has also received considerable interest in recent years given its applications to fitness monitoring, coaching, and rehabilitation. Classic systems to recognize exercises like push-ups, pull-ups, and squats typically employ isolated computer vision methods or shallow deep networks such as CNNs. Those current systems have significant disadvantages in representing fine-grained spatiotemporal patterns, leading to poor recognition performance and challenges to cope with variations in movement execution and style. These limitations reduce model generalization and lead to inconsistent recognition with approximate accuracy rates, precision and other performance metrics. To overcome these limitations, in this paper, research introduces a propoed deep learning architecture that combined model, a strong spatiotemporal feature learning. The CNN layers capture dense spatial representations of every video frame, whereas the GRU layer models temporal patterns throughout movement sequences. Comprehensive experiments on a large-scale as well as exercises filtered from the Kinetics-400 action recognition dataset self-collected and publicly available calisthenics dataset, as well as exercises filtered from the Kinetics-400 action recognition dataset, demonstrate that our proposed CNN+GRU architecture substantially enhances recognition performance. Our model recorded an accuracy of 95.8%, precision of 95.5%, recall of 94.9%, and F1-score of 95.2%, outperforming state-of-the-art methods by about 7-9% across all measures. This significant enhancement proves the efficacy of utilizing both convolutional and recurrent architectures for modeling spatiotemporal differences among exercises. In addition, the introduced framework is computationally lightweight and can be implemented for real-time feedback in training and fitness settings.","","979-8-3315-3681-7","10.1109/ICICKE65317.2025.11136632","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11136632","convolutional neural networks recognition performance;gated recurrent units;calisthenics;kinetics 400","Training;Representation learning;Accuracy;Computational modeling;Computer architecture;Performance metrics;Real-time systems;Spatiotemporal phenomena;Convolutional neural networks;Videos","","","","23","IEEE","22 Sep 2025","","","IEEE","IEEE Conferences"
"MetaSTC: A Backbone Agnostic Spatio-Temporal Framework for Traffic Forecasting","K. Xu; Z. Yu; Y. Gao; S. Zhang; J. Fang; X. Gao; G. Chen","Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Didi Chuxing Technology Co., Beijing, China; Didi Chuxing Technology Co., Beijing, China; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, Shanghai Jiao Tong University, Shanghai, China",2024 IEEE International Conference on Data Mining (ICDM),"21 Feb 2025","2024","","","899","904","Traffic flow prediction is a critical issue in transportation engineering and presents distinct challenges when handling large-scale datasets in the real world. Existing complex spatio-temporal forecasting paradigms use the same parameters to fit traffic sequences with varying spatio-temporal features, and tend to train an average performance model over different time series. This approach greatly reduces their accuracy when applied to larger road networks. Moreover, the significant differences in traffic data distribution from one city to another can also pose great challenges. The same model may be excellent for one city and mediocre when applied to another. To this end, we propose a Meta Backbone Agnostic Spatio-Temporal Clustering Framework for Traffic Forecasting on Large-Scale Road Networks named MetaSTC. We tackle the disparities of spatio-temporal features of traffic flow through a spatio-temporal clustering-based strategy. We design meta-learner for large-scale road network that dynamically extracts the shared information across roads in the same sub-task. In this way, the model can represent task-specific details with a simpler model and make quick and accurate predictions. Our paradigm is backbone-agnostic and can be combined with different traffic prediction models, solving the problem caused by the difference in data distribution. Extensive experimental results conducted on real-world traffic dataset demonstrate the high accuracy and computational efficiency of our model over SOTA approaches.","2374-8486","979-8-3315-0668-1","10.1109/ICDM59182.2024.00112","National Natural Science Foundation of China(grant numbers:U23A20309,62272302,62172276,62372296); Shanghai Municipal Science and Technology Major Project(grant numbers:2021SHZDZX0102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884492","Traffic Flow Prediction;Backbone Agnostic;Clustering;Meta-Learning;Spatio-Temporal Data Mining","Metalearning;Accuracy;Roads;Computational modeling;Urban areas;Transportation;Predictive models;Data models;Data mining;Forecasting","","1","","28","IEEE","21 Feb 2025","","","IEEE","IEEE Conferences"
"A Brief Review of Unsupervised Learning Algorithms for Zero-Day Attacks in Intrusion Detection Systems","S. Oluwadare; Z. ElSayed; O. Adekoya","Department of Information Technology, University of Cincinnati, Ohio, United States of America; Department of Information Technology, University of Cincinnati, Ohio, United States of America; Department of Mechanical Engineering, University of Cincinnati, Ohio, United States of America",2024 IEEE 3rd International Conference on Computing and Machine Intelligence (ICMI),"11 Jul 2024","2024","","","1","6","This research paper presents a brief review of ten popular unsupervised algorithms widely utilized in pattern recognition publications. The algorithms are assessed based on their popularity, strengths, limitations, and resource require-ments. Considering these factors, we propose two most-preferred algorithms suitable for adoption in IDS (Intrusion Detection Systems) to address the problems associated with Zero Day exploits or attacks. Our review of the surveyed algorithms facilitated the recommendation of specific algorithms that can enhance IDS capabilities in detecting and mitigating Zero-Day attacks and anomalous intrusion attempts. These algorithms leverage unsupervised learning techniques to overcome the limitations of traditional signature-based approaches. By incorporating these algorithms, IDS can better handle sophisticated and evolving attacks that often evade detection. In conclusion, this research provides valuable insights into the strengths, limitations, and resource requirements of popular unsupervised algorithms used in pattern recognition. It highlights the potential of adopting these algorithms in IDS systems to bolster their ability to detect and respond to Zero-Day attacks. By recommending the integration of these algorithms, we contribute to the development of intelligent IDS solutions that can adapt to dynamic threat landscapes.","","979-8-3503-7297-7","10.1109/ICMI60790.2024.10585925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10585925","Intrusion Detection;Zero-Day Attacks;Machine Learning;Unsupervised Learning;Pattern Recognition","Surveys;Performance evaluation;Reviews;Heuristic algorithms;Intrusion detection;Training data;Real-time systems","","1","","33","IEEE","11 Jul 2024","","","IEEE","IEEE Conferences"
"STGNNM: Spatial-Temporal Graph Neural Network with Mamba for Cellular Traffic Prediction","J. Li; X. Pu; P. Xia","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Cyber Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China",2024 16th International Conference on Wireless Communications and Signal Processing (WCSP),"14 Jan 2025","2024","","","1187","1192","Accurate long-term prediction of cellular traffic is a critical task in the rapidly developing field of intelligent communications. However, due to the high mobility of users and the complex scheduling mechanism within the network, cellular traffic data presents significant spatial-temporal dependencies, which pose a considerable challenge to long-term cellular traffic prediction. Although Transformer-based models perform well in dealing with long-term dependencies, their quadratic computational complexity leads to low efficiency and high overhead. Moreover, existing studies are often insufficient in dealing with the spatial-temporal correlation of cellular network traffic, limiting the further improvement of prediction accuracy. To overcome these challenges, we propose a novel deep learning model, Spatial-Temporal Graph Neural Network with Mamba (STGNNM). First, we introduce a bidirectional Mamba module to capture the dynamic characteristics of the time series. Second, we apply a double-view graph learning module. The Graph Convolutional Network (GCN) captures the characteristics of neighboring base stations, while the Graph Attention Network (GAT) records the relationships between distant base stations. Finally, the bidirectional Mamba module processes spatial-temporal features comprehensively. We conduct extensive experimental evaluations on a real-world cellular traffic dataset. The results show that STGNNM outperforms the current state-of-the-art methods in all evaluation metrics, demonstrating its superior performance and effectiveness in cellular network traffic prediction.","","979-8-3503-9064-3","10.1109/WCSP62071.2024.10827036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10827036","Spatial-Temporal modeling;Mamba;Graph neural network;Cellular traffic prediction","Cellular networks;Wireless communication;Measurement;Base stations;Accuracy;Processor scheduling;Computational modeling;Time series analysis;Predictive models;Transformers","","","","25","IEEE","14 Jan 2025","","","IEEE","IEEE Conferences"
"A Graph SIR Network Based on Dynamic Graph Structures and Residual Learning for Epidemic Prediction","L. Miao; Y. Chen; J. Wang; C. Zhan; X. Zhao","School of Computer, South China Normal University, Guangzhou, China; School of Computer, South China Normal University, Guangzhou, China; School of Computer, South China Normal University, Guangzhou, China; School of Computer, South China Normal University, Guangzhou, China; College of Information Science and Technology, Donghua University, Shanghai, China",IEEE Transactions on Consumer Electronics,"11 Nov 2025","2025","71","3","9185","9187","According to the World Health Organization (WHO), COVID-19 has resulted in approximately 7 million deaths worldwide, posing a severe threat to public health. Accurately predicting COVID-19 infection trends can assist governments in developing strategies to mitigate the impact. This paper introduces a novel hybrid machine learning model, RLG-SIR-Net, proposed for predicting daily confirmed COVID-19 cases. DLinear is used to decompose time series data, obtaining a trend sequence and a residual sequence. The dynamic graph learning module can construct a dynamic graph from the trend sequence. Then, a graph convolutional network is adopted to extract correction information from the dynamic graph and the residual sequence. Finally, the correction information is employed to enhance the predictive performance of the SIR model. COVID-19 datasets containing data on four countries and five baseline models were used to validate the predictive performance of RLG-SIR-Net. Experimental results show that RLG-SIR-Net outperforms the other baseline models in long-term forecasting of COVID-19 infections.","1558-4127","","10.1109/TCE.2025.3587036","Natural Science Foundation of Guangdong Province, China(grant numbers:2023A1515011618); Key Scientific Research Platform and Project of Guangdong Provincial Education Department(grant numbers:2022ZDZX1038,2022ZDZX1040); Educational Science Planning Topic of Guangdong Province(grant numbers:2022GXJK382); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11073150","Time series forecasting;infectious disease modeling;COVID-19;graph convolutional network (GCN)","Predictive models;Market research;Forecasting;Time series analysis;Data mining;Feature extraction;Measurement;Graph convolutional networks;Consumer electronics;Time series analysis;COVID-19","","","","10","IEEE","8 Jul 2025","","","IEEE","IEEE Journals"
"Graph Neural Network-Based Internet Traffic Prediction in 6G Networks with Genetic Algorithm Hyperparameter Optimization","I. Ampratwum; A. Nayak","School of Electrical Engineering and Computer Science, University of Ottawa, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, Canada","2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC)","26 Aug 2025","2025","","","743","748","Accurate internet traffic prediction is a key challenge in managing next-generation networks such as 6G. This paper presents a novel approach based on Graph Neural Networks (GNNs) for predicting internet traffic in 6G networks. The proposed model integrates Graph Attention Networks (GAT) and Transformer architectures to learn spatial and temporal dependencies in traffic data. A K-Nearest Neighbors (KNN)-based graph construction method is utilized to represent spatial relationships between network cells. The model’s performance is enhanced by leveraging a Genetic Algorithm (GA) for hyperparameter optimization. Experimental results demonstrate the effectiveness of the proposed model in achieving superior prediction accuracy, as evidenced by improvements in RMSE, and MAE compared to baseline models. This work offers a scalable solution for traffic prediction in 6G networks.","2836-3795","979-8-3315-7434-5","10.1109/COMPSAC65507.2025.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126759","6G networks;network traffic forecasting;graph neural networks (GNNs);graph attention network (GAT);temporal graph networks (TGN);genetic algorithm (GA)","6G mobile communication;Accuracy;Computer architecture;Predictive models;Hyperparameter optimization;Transformers;Real-time systems;Graph neural networks;Tuning;Genetic algorithms","","","","22","IEEE","26 Aug 2025","","","IEEE","IEEE Conferences"
"A Novel Spatial-Temporal Deep Neural Network for Electricity Price Forecasting","X. Cheng; I. Ilieva; B. Bremdal; S. Redhu; S. Ødegaard Ottesen","Section of Energy Markets, Smart Innovation Norway, Halden, Norway; Section of Energy Markets, Smart Innovation Norway, Halden, Norway; Section of Energy Markets, Smart Innovation Norway, Halden, Norway; Section of Energy Markets, Smart Innovation Norway, Halden, Norway; Section of Energy Markets, Smart Innovation Norway, Halden, Norway",2023 3rd International Conference on Applied Artificial Intelligence (ICAPAI),"2 Aug 2023","2023","","","1","6","Electricity price forecasting is a difficult task because it depends on various factors such as weather, fuel, load, and bidding strategies. These characteristics bring a lot of volatility to electricity prices. In addition, there exist coupling relationships between different price zones in Europe. CNN-based or LSTM-based methods cannot capture the relationship by their structures or there is a need to extract these couplings explicitly manually. In this work, an end-to-end graph neural network is proposed for the first time to learn the coupling between different price zones automatically. The proposed model mainly consists of two parts: a graph learning module and a temporal learning module, which both are designed to learn spatial information of different price zones and temporal information of historical data, respectively. The performance of the proposed model is evaluated on one-year public data collected from the Nord Pool. The results indicate that our model provides a better solution for electricity price forecasting.","","979-8-3503-2892-9","10.1109/ICAPAI58366.2023.10193970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10193970","electricity price forecasting;price zones;cou-pling effect;graph neural network","Couplings;Renewable energy sources;Manuals;Predictive models;Feature extraction;Data models;Convolutional neural networks","","","","25","IEEE","2 Aug 2023","","","IEEE","IEEE Conferences"
"ROI-demand Traffic Prediction: A Pre-train, Query and Fine-tune Framework","Y. Cui; S. Li; W. Deng; Z. Zhang; J. Zhao; K. Zheng; X. Zhou","The Hong Kong University of Science and Technology, Hong Kong SAR, China; Guangzhou University, Guangzhou, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; University of Electronic Science and Technology of China, Chengdu, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China",2023 IEEE 39th International Conference on Data Engineering (ICDE),"26 Jul 2023","2023","","","1340","1352","Traffic prediction has drawn increasing attention due to its essential role in smart city applications. To achieve precise predictions, a large number of approaches have been proposed to model spatial dependencies and temporal dynamics. Despite their superior performance, most existing studies focus datasets that are usually in large geographic scales, e.g., citywide, while ignoring the results on specific regions. However, in many scenarios, for example, route planning on time-dependent road networks, only small regions are of interest. We name the task of answering forecasting requests from any query region of interest (ROI) as ROI-demand traffic prediction (RTP). In this paper, we make a primary observation that existing methods fail to jointly achieve effectiveness and efficiency for RTP. To address this issue, a novel model-agnostic framework based on pre-Training, Querying and fine-Tuning, named TQT, is proposed, which first customizes input data given an ROI, and then makes fast adaptation from pre-trained traffic prediction backbone models by fine-tuning. We evaluate TQT on two real-world traffic datasets, performing both flow and speed prediction tasks. Extensive experiment results demonstrate the effectiveness and efficiency of the proposed method.","2375-026X","979-8-3503-2227-9","10.1109/ICDE55515.2023.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10184520","traffic forecasting;time series forecasting;pre-train;fine-tune","Adaptation models;Smart cities;Roads;Predictive models;Data engineering;Data models;Planning","","9","","47","IEEE","26 Jul 2023","","","IEEE","IEEE Conferences"
"Contrastive Learning for Multivariate Time Series Classification: an Early Fusion Approach","L. Cagliero; S. Buccafusco; F. Vaccarino","Dip. di Automatica e Informatica, Politecnico di Torino, Turin, Italy; Dip. di Scienze Matematiche, Politecnico di Torino, Turin, Italy; Dip. di Scienze Matematiche, Politecnico di Torino, Turin, Italy",2023 IEEE 17th International Conference on Application of Information and Communication Technologies (AICT),"13 Nov 2023","2023","","","1","6","In recent years, the use of contrastive learning methods for time series classification has shown promising results. State-of-the-art approaches leverage self-supervised contrastive learning representations that encode the underlying series’ features. On top of the latent representation, classification is addressed as a downstream task. While the effectiveness of contrastive models in univariate series classification is established, their portability towards a multivariate scenario is still debated. In this work, we explore the use of contrastive time series representations on multivariate data. We compare the performance of state-of-the-art contrastive models on 30 benchmark datasets and explore the use of an early fusion network to combine the input dimensions. The preliminary results show that incorporating a preliminary stage of information fusion is beneficial to improve the performance of state-of-the-art contrastive time series classifiers.","2472-8586","979-8-3503-0356-8","10.1109/AICT59525.2023.10313147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10313147","Time Series Forecasting;Constrastive Learning;Deep Learning","Learning systems;Time series analysis;Benchmark testing;Information and communication technology;Task analysis","","","","30","IEEE","13 Nov 2023","","","IEEE","IEEE Conferences"
"Higher-Order Spatio-Temporal Neural Networks for Covid-19 Forecasting","Y. Chen; S. Batsakis; H. V. Poor",Temple University; University of Huddersfield; Princeton University,"ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","5 May 2023","2023","","","1","5","Coronavirus Disease 2019 (COVID-19) pneumonia started in December 2019 and cases have been reported in 240 countries/regions with more than 570 million confirmed cases and more than 6 million deaths which caused large casualties and huge economic losses. To enhance the understanding of the levels of COVID-19 transmission and infection, and the effects of treatments and interventions, high-quality spatio-temporal COVID-19 datasets and accurate multivariate time-series forecasting models for COVID-19 case prediction play crucial roles. In this paper, we present the COVID-19 spatio-temporal graph (COV19-STG) datasets, i.e., spatio-temporal United States COVID-19 graph datasets on the county-level. By using these datasets, we propose Higher-order Spatio-temporal Neural Networks (HOST-NETs) to further improve the accuracy of predicting COVID-19 trends. Specifically, we incorporate higher-order structure to build a simplicial complex representation learning module, and integrate it into a spatio-temporal neural network architecture, thus leveraging both global and local topological information. Experimental results show that our model consistently outperforms previous state-of-the-art models.","2379-190X","978-1-7281-6327-7","10.1109/ICASSP49357.2023.10095012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10095012","Simplicial Complex;COVID-19;Deep Learning","COVID-19;Representation learning;Biological system modeling;Neural networks;Signal processing;Telecommunications;Spatiotemporal phenomena","","2","","21","IEEE","5 May 2023","","","IEEE","IEEE Conferences"
"Evaluating Time Series Predictability via Transition Graph Analysis","A. Kovantsev; P. Chunaev; K. Bochenina","National Center for Cognitive Research, ITMO University, St Petersburg, Russia; National Center for Cognitive Research, ITMO University, St Petersburg, Russia; National Center for Cognitive Research, ITMO University, St Petersburg, Russia",2021 International Conference on Data Mining Workshops (ICDMW),"20 Jan 2022","2021","","","1039","1046","This study is focused on exploring time series intrinsic predictability using transition graph analysis. The goal is to find out whether a special graph that reproduces system transition along its trajectory in the state space is useful for distinguishing time series of “good” and “bad” predictability. We perform a state space clustering to construct a weighted and directed transition graph and then to calculate different graph characteristics. We train several predictive models (in particular, the well-known auto-regression, singular spectrum analyses, artificial neural network and specific dynamic models of local approximation and maximal similarity) for time series and apply k-means algorithm to divide the set of the series into two parts using the properties of the corresponding transition graph. As a result we have artificial and real-world datasets divided into two clusters in one of which the mean forecasting error is much less than in the other. The F<inf>1</inf>-score value (≈ 0.87) for this clustering shows that our approach performs better than those in some related works. We also train several classification models on a set of artificial series so that they are able to distinguish real-world time series of “good” and “bad” predictability. The results of this work can be used for data engineering in time series forecasting tasks and for predictive model design and evaluation. The datasets, the framework implementation and the results related to our study are publicly available on GitHub.","2375-9259","978-1-6654-2427-1","10.1109/ICDMW53433.2021.00135","Russian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679876","time series;transition graph;predictability","Heuristic algorithms;Time series analysis;Predictive models;Prediction algorithms;Trajectory;Data mining;Forecasting","","5","","20","IEEE","20 Jan 2022","","","IEEE","IEEE Conferences"
"VSNT: Adaptive Network Traffic Forecasting via VMD and Deep Learning with SCI-Block and Attention Mechanism","P. Dong; Y. Zuo; L. Chen; S. Li; L. Zhang","College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China; College of Information Science and Engineering, Hunan Normal University, Changsha, China","2023 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)","11 Apr 2024","2023","","","104","109","As the Internet evolves towards a dense network paradigm, advancements in mobile services have resulted in a consistent have consistently amplified the volume of mobile data. Consequently, precise network traffic forecasting has become critical for effective network planning and resource allocation. The Informer model, based on the Transformer architecture, has been optimized for time-series forecasting recently. However, the Informer tends to accentuate noise within individual time series, which leads to overfitting or decreased robustness, ultimately affecting forecasting performance. To address these challenges, an adaptive network traffic forecasting model named VSNT is introduced. VSNT employs Variational Mode Decomposition (VMD) to adaptively decompose original network traffic into Intrinsic Mode Function (IMF) components. For the preservation of the interrelation among IMF components, comprehensive representation learning is undertaken prior to their input into the neural network. This network utilizes an encoder-decoder structure and integrates tools such as the SCI-Block and attention mechanisms. The SCI-Block is instrumental in extracting multiscale network attributes, while the attention mechanism emphasizes pronounced features. Compared to the intricate Informer model, VSNT reduces the Root Mean Square Error (RMSE) and the Mean Absolute Percentage Error (MAPE) by approximately 51% and 35% respectively. This positions VSNT as a robust solution for accurate network traffic forecasting, providing a fruitful path for research in network traffic forecasting and time-series analysis.","","979-8-3503-2922-3","10.1109/ISPA-BDCloud-SocialCom-SustainCom59178.2023.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491752","Network Traffic Forecasting;Variational Mode Decomposition (VMD);SCI-Block;Attention Mechanism","Deep learning;Adaptation models;Adaptive systems;Time series analysis;Telecommunication traffic;Predictive models;Feature extraction","","4","","26","IEEE","11 Apr 2024","","","IEEE","IEEE Conferences"
"Guest Editorial: Deep Neural Networks for Graphs: Theory, Models, Algorithms, and Applications","M. Li; A. Micheli; Y. G. Wang; S. Pan; P. Lió; G. S. Gnecco; M. Sanguineti","Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Jinhua, China; Department of Computer Science, University of Pisa, Pisa, Italy; Institute of Natural Sciences, Shanghai Jiao Tong University, Shanghai, China; School of Information and Communication Technology, Griffith University, Brisbane, Australia; Department of Computer Science and Technology, University of Cambridge, Cambridge, U.K; AXES Research Unit IMT School for Advanced Studies, Lucca, Italy; Department of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS), University of Genoa, Genova, Italy",IEEE Transactions on Neural Networks and Learning Systems,"4 Apr 2024","2024","35","4","4367","4372","Deep neural networks for graphs (DNNGs) represent an emerging field that studies how the deep learning method can be generalized to graph-structured data. Since graphs are a powerful and flexible tool to represent complex information in the form of patterns and their relationships, ranging from molecules to protein-to-protein interaction networks, to social or transportation networks, or up to knowledge graphs, potentially modeling systems at very different scales, these methods have been exploited for many application domains.","2162-2388","","10.1109/TNNLS.2024.3371592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10492652","","Special issues and sections;Artificial neural networks;Graph neural networks;Algorithm design and analysis;Social networking (online);Transportation;Protein engineering","","146","","10","IEEE","4 Apr 2024","","","IEEE","IEEE Journals"
