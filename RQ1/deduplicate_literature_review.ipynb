{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc72f9b4",
   "metadata": {},
   "source": [
    "# Deduplicate Literature Review CSV Files\n",
    "\n",
    "This notebook:\n",
    "1. Loads three CSV files (ACM, IEEE, Scopus).\n",
    "2. Normalizes titles and DOIs.\n",
    "3. Identifies duplicated records (by DOI and by title).\n",
    "4. Shows the duplicated entries in dataframes.\n",
    "5. Produces a deduplicated dataframe and saves it to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# ---------- Helper Functions ----------\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Lowercase, remove punctuation, collapse spaces.\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"\"\n",
    "    title = title.lower()\n",
    "    title = re.sub(r'[^a-z0-9 ]+', ' ', title)\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    return title\n",
    "\n",
    "def normalize_doi(doi):\n",
    "    if pd.isna(doi):\n",
    "        return \"\"\n",
    "    doi = doi.strip().lower()\n",
    "    doi = doi.replace(\"https://doi.org/\", \"\")\n",
    "    return doi\n",
    "\n",
    "# ---------- Load Files ----------\n",
    "\n",
    "files = [\n",
    "    r\"C:\\Users\\Andre Silva\\Desktop\\Literature Review\\RQ1\\acm.csv\",\n",
    "    r\"C:\\Users\\Andre Silva\\Desktop\\Literature Review\\RQ1\\IEEEexport2025.12.11-16.55.31.csv\",\n",
    "    r\"C:\\Users\\Andre Silva\\Desktop\\Literature Review\\RQ1\\scopus_export_Dec 11-2025_daae2a1c-ddb4-43f4-93f5-6ff62a5fbc23.csv\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    print(f\"Loading {f}\")\n",
    "    df = pd.read_csv(f, dtype=str)\n",
    "    df[\"source_file\"] = Path(f).name\n",
    "    dfs.append(df)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Total records loaded: {len(data)}\")\n",
    "display(data.head())\n",
    "\n",
    "# ---------- Normalize fields ----------\n",
    "if \"doi\" not in data.columns:\n",
    "    data[\"doi\"] = \"\"\n",
    "\n",
    "data[\"norm_doi\"] = data[\"doi\"].apply(normalize_doi)\n",
    "\n",
    "title_col = \"title\" if \"title\" in data.columns else \"Document Title\"  # IEEE/Scopus\n",
    "data[\"norm_title\"] = data[title_col].apply(normalize_title)\n",
    "\n",
    "# ---------- Find duplicates ----------\n",
    "\n",
    "# Duplicates by DOI (ignoring empty DOIs)\n",
    "duplicates_by_doi = data[\n",
    "    (data[\"norm_doi\"] != \"\") & data.duplicated(subset=[\"norm_doi\"], keep=False)\n",
    "]\n",
    "\n",
    "print(f\"\\nNumber of records involved in DOI duplicates: {len(duplicates_by_doi)}\")\n",
    "display(duplicates_by_doi.head(20))\n",
    "\n",
    "# Duplicates by title\n",
    "duplicates_by_title = data[\n",
    "    data.duplicated(subset=[\"norm_title\"], keep=False)\n",
    "]\n",
    "\n",
    "print(f\"\\nNumber of records involved in title duplicates: {len(duplicates_by_title)}\")\n",
    "display(duplicates_by_title.head(20))\n",
    "\n",
    "# ---------- Deduplication Logic ----------\n",
    "# Rule 1: Deduplicate by DOI when present\n",
    "no_duplicate = data.sort_values(\"norm_doi\").drop_duplicates(subset=[\"norm_doi\"], keep=\"first\")\n",
    "\n",
    "# Rule 2: Deduplicate remaining by normalized title\n",
    "no_duplicate = no_duplicate.sort_values(\"norm_title\").drop_duplicates(subset=[\"norm_title\"], keep=\"first\")\n",
    "\n",
    "print(f\"\\nDeduplicated records: {len(no_duplicate)}\")\n",
    "display(no_duplicate.head(20))\n",
    "\n",
    "# ---------- Save Output ----------\n",
    "output_path = r\"C:\\Users\\Andre Silva\\Desktop\\Literature Review\\RQ1\\deduplicated_publications.csv\"\n",
    "no_duplicate.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nDeduplicated file saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
