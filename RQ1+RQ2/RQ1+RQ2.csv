title,abstract,doi,year,citations,source,doi_norm
Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting,,10.1016/j.neunet.2025.108140,2026,0,Scopus,10.1016/j.neunet.2025.108140
Dual Attention Transformer with Multi-scale Perception for Multivariate Time Series Forecasting,,10.1007/978-981-95-3052-6_24,2026,0,Scopus,10.1007/978-981-95-3052-6_24
Enhancing Salesforce Sales Forecasting with Contrastive Learning-Based Time Series Representation,,10.1007/978-3-032-03558-5_29,2026,0,Scopus,10.1007/978-3-032-03558-5_29
M3E: Mixture of Multi-scale Multi-modal Experts for Time Series Forecasting,,10.1007/978-981-95-3398-5_6,2026,0,Scopus,10.1007/978-981-95-3398-5_6
DiM: Improving multivariate time series forecasting with DI embedding and multi-head graph learning mechanism,,10.1016/j.neucom.2025.131777,2026,0,Scopus,10.1016/j.neucom.2025.131777
Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting,,10.1016/j.ins.2025.122647,2026,0,Scopus,10.1016/j.ins.2025.122647
Multi-resolution leak detection based on shared expert MoE forecasting for natural gas pipelines,,10.1016/j.ipm.2025.104353,2026,0,Scopus,10.1016/j.ipm.2025.104353
An Efficient Denoising Transformer-Based Architecture for Long-Ranged Time-Series Air Quality Prediction,,10.1002/cpe.70450,2025,0,Scopus,10.1002/cpe.70450
Adaptive hybrid spatial hypergraph convolution module with data embedding optimization for stock ranking prediction,,10.1016/j.physa.2025.131046,2025,0,Scopus,10.1016/j.physa.2025.131046
MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting,,10.1145/3746252.3761173,2025,0,Scopus,10.1145/3746252.3761173
Structural Entropy-based Multivariate Time Series Forecasting,,10.1145/3746252.3761007,2025,0,Scopus,10.1145/3746252.3761007
TD-IVDM: A multi-scale concept drift detection method for time series forecasting tasks,,10.1016/j.neucom.2025.131120,2025,0,Scopus,10.1016/j.neucom.2025.131120
Financial Time Series Prediction With Multi-Granularity Graph Augmented Learning,,10.1109/tkde.2025.3607005,2025,1,Scopus,10.1109/tkde.2025.3607005
PRformer: Pyramidal recurrent transformer for multivariate time series forecasting,,10.1016/j.neunet.2025.107769,2025,0,Scopus,10.1016/j.neunet.2025.107769
From a multi-period perspective: A periodic dynamics forecasting network for multivariate time series forecasting,,10.1016/j.patcog.2025.111760,2025,1,Scopus,10.1016/j.patcog.2025.111760
LLM-Empowered Kolmogorov-Arnold Frequency Learning for Time Series Forecasting in Power Systems,,10.3390/math13193149,2025,0,Scopus,10.3390/math13193149
Learnable decomposition meets the neuro-fuzzy learning for robust rich spatial–temporal feature representation learning and better stock price forecasting,,10.1007/s00500-025-10898-0,2025,0,Scopus,10.1007/s00500-025-10898-0
DS-SGCHN: dynamic-static synergetic graph convolutional hierarchical network for traffic forecasting,,10.1088/1361-6501/ae014b,2025,0,Scopus,10.1088/1361-6501/ae014b
A Survey on Kolmogorov-Arnold Network,,10.1145/3743128,2025,25,Scopus,10.1145/3743128
A novel deep graph learning-based multivariate clustering method for time series forecasting of complex chemical systems,,10.1016/j.compchemeng.2025.109214,2025,0,Scopus,10.1016/j.compchemeng.2025.109214
Imputation via Domain Adaptation: Rethinking Variable Subset Forecasting from Knowledge Transfer,,10.1145/3711896.3737007,2025,0,Scopus,10.1145/3711896.3737007
Merlin: Multi-View Representation Learning for Robust Multivariate Time Series Forecasting with Unfixed Missing Rates,,10.1145/3711896.3737046,2025,1,Scopus,10.1145/3711896.3737046
Stochastic Diffusion: A Diffusion Based Model for Stochastic Time Series Forecasting,,10.1145/3711896.3737137,2025,2,Scopus,10.1145/3711896.3737137
FAT: Frequency-Aware Pretraining for Enhanced Time-Series Representation Learning,,10.1145/3711896.3736952,2025,1,Scopus,10.1145/3711896.3736952
TSGformer: A Unified Temporal–Spatial Graph Transformer with Adaptive Cross-Scale Modeling for Multivariate Time Series,,10.3390/systems13080688,2025,0,Scopus,10.3390/systems13080688
VCformer: Variable-Centric Multi-Scale Transformer for Multivariate Time Series Forecasting,,10.3390/s25165202,2025,0,Scopus,10.3390/s25165202
SSSLN:Multivariate Time Series Forecasting via Collaborative Dynamic Graph Learning,,10.1016/j.neunet.2025.107485,2025,0,Scopus,10.1016/j.neunet.2025.107485
A temporal graph-based contrastive approach for financial time series forecasting,,10.1016/j.engappai.2025.110834,2025,1,Scopus,10.1016/j.engappai.2025.110834
Heteroscedastic ensemble deep random vector functional link neural network with multiple output layers for High Frequency Volatility Forecasting and Risk Assessment,,10.1016/j.neucom.2025.130078,2025,1,Scopus,10.1016/j.neucom.2025.130078
A dynamic graph-based multiscale spatio-temporal feature enhancement network applied to ENSO prediction,,10.1007/s10489-025-06691-z,2025,0,Scopus,10.1007/s10489-025-06691-z
Popularity-aware dynamic graph neural collaborative filtering with local-global convergence,,10.1016/j.asoc.2025.113289,2025,0,Scopus,10.1016/j.asoc.2025.113289
AGGA-MVFLN: Multivariate Time Series Forecasting via Adaptive Generalized Graph Accompanied with Multi-View Learning in Frequency Domain,,10.1145/3731715.3733272,2025,0,Scopus,10.1145/3731715.3733272
Self-Optimizing Teacher and Auto-Matching Student Framework for Change-Point Representation Learning in Time Series Forecasting,,10.1145/3718091,2025,0,Scopus,10.1145/3718091
Gaze Prediction as a Function of Eye Movement Type and Individual Differences,,10.1145/3715669.3723116,2025,0,Scopus,10.1145/3715669.3723116
Intra and inter-series pattern representations fusion network for multiple time series forecasting,,10.1016/j.asoc.2025.113024,2025,0,Scopus,10.1016/j.asoc.2025.113024
Evolving graph structure learning for multivariate time series forecasting,,10.1016/j.knosys.2025.113190,2025,1,Scopus,10.1016/j.knosys.2025.113190
Beyond spatial neighbors: Utilizing multivariate transfer entropy for interpretable graph-based spatio–temporal forecasting,,10.1016/j.engappai.2025.110161,2025,1,Scopus,10.1016/j.engappai.2025.110161
Ada-STGMAT: An adaptive spatio-temporal graph multi-attention network for intelligent time series forecasting in smart cities,,10.1016/j.eswa.2025.126428,2025,9,Scopus,10.1016/j.eswa.2025.126428
LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters,,10.1145/3719207,2025,25,Scopus,10.1145/3719207
TITD: enhancing optimized temporal position encoding with time intervals and temporal decay in irregular time series forecasting,,10.1007/s10489-025-06293-9,2025,2,Scopus,10.1007/s10489-025-06293-9
Adaptive Non-Stationary Fuzzy Time Series Forecasting with Bayesian Networks,,10.3390/s25051628,2025,1,Scopus,10.3390/s25051628
Knowledge-enhanced data-driven modeling of wastewater treatment processes for energy consumption prediction,,10.1016/j.compchemeng.2024.108982,2025,2,Scopus,10.1016/j.compchemeng.2024.108982
Heterogeneous Graph Transformer Auto-Encoder for multivariate time series forecasting,,10.1016/j.compeleceng.2024.109927,2025,0,Scopus,10.1016/j.compeleceng.2024.109927
Forecasting of exchange rate time series based on event-aware transformer mode,,10.1007/s00500-025-10558-3,2025,1,Scopus,10.1007/s00500-025-10558-3
Fuzzy-Probabilistic Time Series Forecasting Combining Bayesian Network and Fuzzy Time Series Model,,10.3390/sym17020275,2025,1,Scopus,10.3390/sym17020275
Parallel multi-scale dynamic graph neural network for multivariate time series forecasting,,10.1016/j.patcog.2024.111037,2025,10,Scopus,10.1016/j.patcog.2024.111037
A Memory Guided Transformer for Time Series Forecasting,,10.14778/3705829.3705842,2025,3,Scopus,10.14778/3705829.3705842
TSI: A Multi-view Representation Learning Approach for Time Series Forecasting,,10.1007/978-981-96-0348-0_21,2025,0,Scopus,10.1007/978-981-96-0348-0_21
Time-lagged relation graph neural network for multivariate time series forecasting,,10.1016/j.engappai.2024.109530,2025,3,Scopus,10.1016/j.engappai.2024.109530
Mitigating Channel Redundancy for Multivariate Time Series Forecasting,,10.1109/ijcnn64981.2025.11228045,2025,0,Scopus,10.1109/ijcnn64981.2025.11228045
TravelNet: A Recursive Decomposition-Based Time Series Forecasting Framework for Bus Travel Time Estimation,,10.1109/ijcnn64981.2025.11228543,2025,0,Scopus,10.1109/ijcnn64981.2025.11228543
A Hybrid BERT-ELM Framework for Robust Time Series Forecasting of Solar Energy Generation in EU Renewable Power Plants,,10.37394/232016.2025.20.25,2025,0,Scopus,10.37394/232016.2025.20.25
AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting,,,2025,0,Scopus,
Multi-Dimensional Series Forecasting for Multi-Node Microservices: Leveraging Specialized Embedding in LLMs,,10.1109/hpcc67675.2025.00030,2025,0,Scopus,10.1109/hpcc67675.2025.00030
FusionBC: Contrastive Graph and Information Bottleneck Fusion Learning for Time Series Forecasting,,10.1109/hpcc67675.2025.00040,2025,0,Scopus,10.1109/hpcc67675.2025.00040
FreEformer: Frequency Enhanced Transformer for Multivariate Time Series Forecasting,,10.24963/ijcai.2025/401,2025,0,Scopus,10.24963/ijcai.2025/401
Transformer-PLM Enhanced Multimodal Time Series Forecasting via Decoupled Dual-Temporal Graph Adaptation,,10.1109/lsp.2025.3630087,2025,0,Scopus,10.1109/lsp.2025.3630087
DGraFormer: Dynamic Graph Learning Guided Multi-Scale Transformer for Multivariate Time Series Forecasting,,10.24963/ijcai.2025/391,2025,0,Scopus,10.24963/ijcai.2025/391
Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting,,10.1016/j.eswa.2025.129768,2025,0,Scopus,10.1016/j.eswa.2025.129768
Time series forecasting of network traffic with latent domain generalization: Addressing out-of-distribution challenges,,10.1007/s10844-025-01001-y,2025,0,Scopus,10.1007/s10844-025-01001-y
Decomposing masked time series model: a self-supervised time-series forecasting framework,,10.1117/12.3068730,2025,0,Scopus,10.1117/12.3068730
UFGTime: Mining Intertwined Dependencies in Multivariate Time Series via an Efficient Pure Graph Approach,,10.14778/3746405.3746436,2025,0,Scopus,10.14778/3746405.3746436
STCA-LLM: Spatial–Temporal Cross-Attention Large Language Model for Wind Speed Forecasting,,10.1109/jiot.2025.3599836,2025,1,Scopus,10.1109/jiot.2025.3599836
MORL: A Multi-Objective Representation Learning Modeling for Time Series Forecasting,,10.1109/icsp65755.2025.11086755,2025,0,Scopus,10.1109/icsp65755.2025.11086755
Semi4TSF: End-to-End Semi-Supervised Contrastive Representation Learning for Time Series Forecasting,,10.1109/tii.2025.3588582,2025,1,Scopus,10.1109/tii.2025.3588582
Shareformer: A Patch Transformer Model with Shared Attention for Multivariate Time Series Forecasting,,10.1007/978-981-96-9875-2_27,2025,0,Scopus,10.1007/978-981-96-9875-2_27
CRGNet: Learning Causal Relationships for Multivariate Time Series Forecasting,,10.1007/978-981-96-9818-9_15,2025,0,Scopus,10.1007/978-981-96-9818-9_15
A Novel Discrete Time Series Representation With De Bruijn Graphs for Enhanced Forecasting Using TimesNet,,10.1109/access.2025.3588507,2025,0,Scopus,10.1109/access.2025.3588507
A Graph SIR Network Based on Dynamic Graph Structures and Residual Learning for Epidemic Prediction,,10.1109/tce.2025.3587036,2025,0,Scopus,10.1109/tce.2025.3587036
A Survey on Neural Ordinary Differential Equations,,10.1007/978-981-96-8183-9_27,2025,1,Scopus,10.1007/978-981-96-8183-9_27
Fourier-driven Lightweight Token Mixing Model for Efficient Time Series Forecasting,,10.1109/tai.2025.3584693,2025,1,Scopus,10.1109/tai.2025.3584693
EGENN: An Efficient Graph-Enhanced Neural Network for Multivariate Time Series Forecasting,,10.1109/icassp49660.2025.10890196,2025,0,Scopus,10.1109/icassp49660.2025.10890196
GT-LSTM: Integrating High-Resolution Particulate Matter Data for Urban Air Quality Forecasting,,10.1007/978-3-031-95728-4_5,2025,0,Scopus,10.1007/978-3-031-95728-4_5
Two-in-One Models for Event Prediction and Time Series Forecasting. Comparison of Four Deep Learning Approaches to Simulate a Digital Patient Under Anesthesia,,10.1007/978-3-031-91398-3_28,2025,0,Scopus,10.1007/978-3-031-91398-3_28
A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting,,10.1109/icassp49660.2025.10889293,2025,1,Scopus,10.1109/icassp49660.2025.10889293
A Data-Level Augmentation Framework for Time Series Forecasting With Ambiguously Related Source Data,,10.1109/tkde.2025.3555530,2025,1,Scopus,10.1109/tkde.2025.3555530
Adaptive Graph Structure Learning Neural Rough Differential Equations for Multivariate Time Series Forecasting,,10.1109/tbdata.2025.3552334,2025,2,Scopus,10.1109/tbdata.2025.3552334
Scale-Aware Neural Architecture Search for Multivariate Time Series Forecasting,,10.1145/3701038,2024,4,Scopus,10.1145/3701038
VTNet: A multi-domain information fusion model for long-term multi-variate time series forecasting with application in irrigation water level,,10.1016/j.asoc.2024.112251,2024,5,Scopus,10.1016/j.asoc.2024.112251
Contrastive learning enhanced by graph neural networks for Universal Multivariate Time Series Representation,,10.1016/j.is.2024.102429,2024,2,Scopus,10.1016/j.is.2024.102429
Navigating Weight Prediction with Diet Diary,,10.1145/3664647.3680977,2024,3,Scopus,10.1145/3664647.3680977
Dynamic Spatial-Temporal Embedding via Neural Conditional Random Field for Multivariate Time Series Forecasting,,10.1145/3675165,2024,0,Scopus,10.1145/3675165
Breaking the Weak Semantics Bottleneck of Transformers in Time Series Forecasting,,10.3233/faia240645,2024,0,Scopus,10.3233/faia240645
Mining latent patterns with multi-scale decomposition for electricity demand and price forecasting using modified deep graph convolutional neural networks,,10.1016/j.segan.2024.101436,2024,10,Scopus,10.1016/j.segan.2024.101436
Recurrent ensemble random vector functional link neural network for financial time series forecasting,,10.1016/j.asoc.2024.111759,2024,35,Scopus,10.1016/j.asoc.2024.111759
Root cause localization for wind turbines using physics guided multivariate graphical modeling and fault propagation analysis,,10.1016/j.knosys.2024.111838,2024,13,Scopus,10.1016/j.knosys.2024.111838
DPHM-Net:de-redundant multi-period hybrid modeling network for long-term series forecasting,,10.1007/s11280-024-01281-4,2024,2,Scopus,10.1007/s11280-024-01281-4
Distillation enhanced time series forecasting network with momentum contrastive learning,,10.1016/j.ins.2024.120712,2024,6,Scopus,10.1016/j.ins.2024.120712
Toward Using Representation Learning for Cloud Resource Usage Forecasting,,10.1145/3660605.3660942,2024,0,Scopus,10.1145/3660605.3660942
A hybrid forecasting system using convolutional-based extreme learning with extended elephant herd optimization for time-series prediction,,10.1007/s00500-023-09499-6,2024,4,Scopus,10.1007/s00500-023-09499-6
Dynamic multi-fusion spatio-temporal graph neural network for multivariate time series forecasting,,10.1016/j.eswa.2023.122729,2024,16,Scopus,10.1016/j.eswa.2023.122729
Time-aware personalized graph convolutional network for multivariate time series forecasting,,10.1016/j.eswa.2023.122471,2024,11,Scopus,10.1016/j.eswa.2023.122471
A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction,,10.1609/aaai.v38i18.29956,2024,4,Scopus,10.1609/aaai.v38i18.29956
Learning from Polar Representation: An Extreme-Adaptive Model for Long-Term Time Series Forecasting,,10.1609/aaai.v38i1.27768,2024,11,Scopus,10.1609/aaai.v38i1.27768
Attentive neural controlled differential equations for time-series classification and forecasting,,10.1007/s10115-023-01977-5,2024,12,Scopus,10.1007/s10115-023-01977-5
Bayesian network based probabilistic weighted high-order fuzzy time series forecasting,,10.1016/j.eswa.2023.121430,2024,19,Scopus,10.1016/j.eswa.2023.121430
AMGCN: adaptive multigraph convolutional networks for traffic speed forecasting,,10.1007/s10489-024-05301-8,2024,3,Scopus,10.1007/s10489-024-05301-8
Deep joint modelling of mixed asynchronous streams - Proof of concept for data-driven simulation of a digital patient under anaesthesia,,10.1016/j.procs.2024.09.438,2024,1,Scopus,10.1016/j.procs.2024.09.438
Multivariate Segment Expandable Encoder-Decoder Model for Time Series Forecasting,,10.1109/access.2024.3513256,2024,1,Scopus,10.1109/access.2024.3513256
A Novel Discrete Time Series Representation with De Bruijn Graphs for Enhanced Forecasting Using TimesNet (Extended Abstract),,10.1109/dsaa61799.2024.10722826,2024,2,Scopus,10.1109/dsaa61799.2024.10722826
Long-Term Interpretable Air Quality Trend Forecasting via Directed Interval Fuzzy Cognitive Maps,,10.1109/tfuzz.2024.3482282,2024,4,Scopus,10.1109/tfuzz.2024.3482282
Long Sequence Multivariate Time-Series Forecasting for Industrial Processes Using SASGNN,,10.1109/tii.2024.3424214,2024,5,Scopus,10.1109/tii.2024.3424214
FedDGCL: Federated Graph Neural Network with Dual Graph Contrast Learning for Multivariable Time Series Forecasting,,10.1007/978-981-97-5552-3_27,2024,0,Scopus,10.1007/978-981-97-5552-3_27
MLFGCN: short-term residential load forecasting via graph attention temporal convolution network,,10.3389/fnbot.2024.1461403,2024,5,Scopus,10.3389/fnbot.2024.1461403
STGNA: Spatial-Temporal Graph Convolutional Networks with Node Level Attention for Shortwave Communications Parameters Forecasting,,10.1007/978-3-031-72344-5_14,2024,0,Scopus,10.1007/978-3-031-72344-5_14
ESSformer: Transformers with ESS Attention for Long-Term Series Forecasting,,10.1007/978-3-031-72347-6_15,2024,0,Scopus,10.1007/978-3-031-72347-6_15
Time Series Forecasting Based on Structured Decomposition and Variational Autoencoder,,10.1109/ijcnn60899.2024.10650587,2024,0,Scopus,10.1109/ijcnn60899.2024.10650587
CNN-Based Time Series Decomposition Model for Video Prediction,,10.1109/access.2024.3458460,2024,1,Scopus,10.1109/access.2024.3458460
Dynamic Personalized Graph Neural Ordinary Differential Equation Network for Multivariate Time Series Prediction of Chemical Processes,,10.1109/ddcls61622.2024.10606557,2024,0,Scopus,10.1109/ddcls61622.2024.10606557
Generative Representation Learning in Recurrent Neural Networks for Causal Timeseries Forecasting,,10.1109/tai.2024.3446465,2024,2,Scopus,10.1109/tai.2024.3446465
Learning Time-Aware Graph Structures for Spatially Correlated Time Series Forecasting,,10.1109/icde60146.2024.00338,2024,17,Scopus,10.1109/icde60146.2024.00338
TimeDRL: Disentangled Representation Learning for Multivariate Time-Series,,10.1109/icde60146.2024.00054,2024,18,Scopus,10.1109/icde60146.2024.00054
Predictive modeling of Alzheimer's disease progression: Integrating temporal clinical factors and outcomes in time series forecasting,,10.1016/j.ibmed.2024.100159,2024,4,Scopus,10.1016/j.ibmed.2024.100159
A Regional Short-term Load Forecasting Method Based on Adaptive Graph Construction and Kernel Size Selection,,10.1109/icps60943.2024.10563907,2024,1,Scopus,10.1109/icps60943.2024.10563907
GTformer: Graph-Based Temporal-Order-Aware Transformer for Long-Term Series Forecasting,,10.1109/jiot.2024.3419768,2024,11,Scopus,10.1109/jiot.2024.3419768
Time Series Representation Learning: A Survey on Deep Learning Techniques for Time Series Forecasting,,10.1007/978-3-031-60606-9_25,2024,1,Scopus,10.1007/978-3-031-60606-9_25
Kernel Representation Learning with Dynamic Regime Discovery for Time Series Forecasting,,10.1007/978-981-97-2266-2_20,2024,7,Scopus,10.1007/978-981-97-2266-2_20
"Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",,10.1109/tpami.2024.3387317,2024,142,Scopus,10.1109/tpami.2024.3387317
TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting,,10.1007/978-3-031-53468-3_8,2024,13,Scopus,10.1007/978-3-031-53468-3_8
Wind Power Forecasting Based on a Spatial-Temporal Graph Convolution Network with Limited Engineering Knowledge,,10.1109/tim.2024.3374321,2024,16,Scopus,10.1109/tim.2024.3374321
Dynamic Hypergraph Structure Learning for Multivariate Time Series Forecasting,,10.1109/tbdata.2024.3362188,2024,25,Scopus,10.1109/tbdata.2024.3362188
TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations,,10.1109/tvcg.2023.3327389,2024,6,Scopus,10.1109/tvcg.2023.3327389
Time-Series Forecasting Through Contrastive Learning with a Two-Dimensional Self-attention Mechanism,,10.1007/978-981-99-8082-6_12,2024,2,Scopus,10.1007/978-981-99-8082-6_12
Multi-scale Multi-step Dependency Graph Neural Network for Multivariate Time-Series Forecasting,,10.1007/978-981-99-8132-8_8,2024,2,Scopus,10.1007/978-981-99-8132-8_8
Dynamic personalized graph neural network with linear complexity for multivariate time series forecasting,,10.1016/j.engappai.2023.107291,2024,9,Scopus,10.1016/j.engappai.2023.107291
Simple Contrastive Representation Learning for Time Series Forecasting,,10.1109/icassp48485.2024.10446875,2024,6,Scopus,10.1109/icassp48485.2024.10446875
Multi-scale adaptive attention-based time-variant neural networks for multi-step time series forecasting,,10.1007/s10489-023-05057-7,2023,7,Scopus,10.1007/s10489-023-05057-7
TDG4MSF: A temporal decomposition enhanced graph neural network for multivariate time series forecasting,,10.1007/s10489-023-04987-6,2023,6,Scopus,10.1007/s10489-023-04987-6
Long-term multivariate time series forecasting in data centers based on multi-factor separation evolutionary spatial–temporal graph neural networks,,10.1016/j.knosys.2023.110997,2023,7,Scopus,10.1016/j.knosys.2023.110997
Learning and integration of adaptive hybrid graph structures for multivariate time series forecasting,,10.1016/j.ins.2023.119560,2023,11,Scopus,10.1016/j.ins.2023.119560
Spatiotemporal graph neural network for multivariate multi-step ahead time-series forecasting of sea temperature,,10.1016/j.engappai.2023.106854,2023,25,Scopus,10.1016/j.engappai.2023.106854
Learning Visibility Attention Graph Representation for Time Series Forecasting,,10.1145/3583780.3615289,2023,2,Scopus,10.1145/3583780.3615289
FEAT: A general framework for feature-aware multivariate time-series representation learning,,10.1016/j.knosys.2023.110790,2023,14,Scopus,10.1016/j.knosys.2023.110790
Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting,,10.1109/tkde.2023.3268199,2023,155,Scopus,10.1109/tkde.2023.3268199
MrCAN: Multi-relations aware convolutional attention network for multivariate time series forecasting,,10.1016/j.ins.2023.119277,2023,17,Scopus,10.1016/j.ins.2023.119277
TTS-Norm: Forecasting Tensor Time Series via Multi-Way Normalization,,10.1145/3605894,2023,20,Scopus,10.1145/3605894
TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting,,10.1145/3580305.3599533,2023,236,Scopus,10.1145/3580305.3599533
Look Ahead: Improving the Accuracy of Time-Series Forecasting by Previewing Future Time Features,,10.1145/3539618.3592013,2023,1,Scopus,10.1145/3539618.3592013
Num2vec: Pre-Training Numeric Representations for Time Series Forecasting in the Sensing System,,10.1145/3599728,2023,2,Scopus,10.1145/3599728
Spatio-Temporal Meta-Graph Learning for Traffic Forecasting,,10.1609/aaai.v37i7.25976,2023,259,Scopus,10.1609/aaai.v37i7.25976
TC-GATN: Temporal Causal Graph Attention Networks With Nonlinear Paradigm for Multivariate Time-Series Forecasting in Industrial Processes,,10.1109/tii.2022.3211330,2023,29,Scopus,10.1109/tii.2022.3211330
Multivariate long sequence time-series forecasting using dynamic graph learning,,10.1007/s12652-023-04579-9,2023,17,Scopus,10.1007/s12652-023-04579-9
Dynamic graph structure learning for multivariate time series forecasting,,10.1016/j.patcog.2023.109423,2023,91,Scopus,10.1016/j.patcog.2023.109423
Dynamic spatio-temporal graph network with adaptive propagation mechanism for multivariate time series forecasting,,10.1016/j.eswa.2022.119374,2023,52,Scopus,10.1016/j.eswa.2022.119374
Core: Transferable Long-Range Time Series Forecasting Enhanced by Covariates-Guided Representation,,10.1109/icassp49357.2023.10096231,2023,1,Scopus,10.1109/icassp49357.2023.10096231
VSNT: Adaptive Network Traffic Forecasting via VMD and Deep Learning with SCI-Block and Attention Mechanism,,10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00046,2023,4,Scopus,10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00046
GNN and Encoder Integrated Model for Distributed Solar and Wind Power Forecasting,,10.1109/csecs60003.2023.10428146,2023,1,Scopus,10.1109/csecs60003.2023.10428146
Knowledge Enhanced Deep Learning: Application to Pandemic Prediction,,10.1109/cic58953.2023.00016,2023,1,Scopus,10.1109/cic58953.2023.00016
The PSR-Transformer Nexus: A Deep Dive into Stock Time Series Forecasting,,10.14569/ijacsa.2023.0141292,2023,3,Scopus,10.14569/ijacsa.2023.0141292
Contrastive Learning Enhanced by Transformer Block for Time Series Forecasting,,10.1117/12.3012295,2023,0,Scopus,10.1117/12.3012295
SEED: An Effective Model for Highly-Skewed Streamflow Time Series Data Forecasting,,10.1109/bigdata59044.2023.10386959,2023,5,Scopus,10.1109/bigdata59044.2023.10386959
H2-Nets: Hyper-hodge Convolutional Neural Networks for Time-Series Forecasting,,10.1007/978-3-031-43424-2_17,2023,2,Scopus,10.1007/978-3-031-43424-2_17
Higher-Order Spatio-Temporal Neural Networks for Covid-19 Forecasting,,10.1109/icassp49357.2023.10095012,2023,2,Scopus,10.1109/icassp49357.2023.10095012
Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting,,10.1109/access.2023.3325041,2023,6,Scopus,10.1109/access.2023.3325041
MAGNet: Muti-scale Attention and Evolutionary Graph Structure for Long Sequence Time-Series Forecasting,,10.1007/978-3-031-44223-0_18,2023,2,Scopus,10.1007/978-3-031-44223-0_18
SimpleTS: An Efficient and Universal Model Selection Framework for Time Series Forecasting,,10.14778/3611540.3611561,2023,24,Scopus,10.14778/3611540.3611561
Learning Gaussian Mixture Representations for Tensor Time Series Forecasting,,10.24963/ijcai.2023/231,2023,6,Scopus,10.24963/ijcai.2023/231
Graph Construction Method for GNN-Based Multivariate Time-Series Forecasting,,10.32604/cmc.2023.036830,2023,5,Scopus,10.32604/cmc.2023.036830
Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping,,10.1109/case56687.2023.10260640,2023,7,Scopus,10.1109/case56687.2023.10260640
Late Meta-learning Fusion Using Representation Learning for Time Series Forecasting,,10.23919/fusion52260.2023.10224217,2023,2,Scopus,10.23919/fusion52260.2023.10224217
Deep Representation Learning for Cluster-Level Time Series Forecasting †,,10.3390/engproc2022018022,2022,4,Scopus,10.3390/engproc2022018022
Memory Augmented Graph Learning Networks for Multivariate Time Series Forecasting,,10.1145/3511808.3557638,2022,6,Scopus,10.1145/3511808.3557638
Multi-channel fusion graph neural network for multivariate time series forecasting,,10.1016/j.jocs.2022.101862,2022,8,Scopus,10.1016/j.jocs.2022.101862
Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning,,10.1109/tpami.2021.3076155,2022,50,Scopus,10.1109/tpami.2021.3076155
Multivariate Time Series Deep Spatiotemporal Forecasting with Graph Neural Network,,10.3390/app12115731,2022,30,Scopus,10.3390/app12115731
Adaptive Dual-View WaveNet for urban spatial–temporal event prediction,,10.1016/j.ins.2021.12.085,2022,48,Scopus,10.1016/j.ins.2021.12.085
W-Transformers: A Wavelet-based Transformer Framework for Univariate Time Series Forecasting,,10.1109/icmla55696.2022.00111,2022,34,Scopus,10.1109/icmla55696.2022.00111
Regularized Graph Structure Learning with Semantic Knowledge for Multi-variates Time-Series Forecasting,,10.24963/ijcai.2022/328,2022,39,Scopus,10.24963/ijcai.2022/328
MTHetGNN: A heterogeneous graph embedding framework for multivariate time series forecasting,,10.1016/j.patrec.2021.12.008,2022,49,Scopus,10.1016/j.patrec.2021.12.008
Learning knowledge-enriched company embeddings for investment management,,10.1145/3490354.3494390,2021,8,Scopus,10.1145/3490354.3494390
Dependency Learning Graph Neural Network for Multivariate Forecasting,,10.1007/978-3-030-92307-5_14,2021,1,Scopus,10.1007/978-3-030-92307-5_14
Time-series forecasting of mortality rates using deep learning,,10.1080/03461238.2020.1867232,2021,73,Scopus,10.1080/03461238.2020.1867232
Weighted Knowledge Graph Embedding,"Knowledge graph embedding (KGE) aims to project both entities and relations in a knowledge graph (KG) into low-dimensional vectors. Indeed, existing KGs suffer from the data imbalance issue, i.e., entities and relations conform to a long-tail distribution, only a small portion of entities and relations occur frequently, while the vast majority of entities and relations only have a few training samples. Existing KGE methods assign equal weights to each entity and relation during the training process. Under this setting, long-tail entities and relations are not fully trained during training, leading to unreliable representations. In this paper, we propose WeightE, which attends differentially to different entities and relations. Specifically, WeightE is able to endow lower weights to frequent entities and relations, and higher weights to infrequent ones. In such manner, WeightE is capable of increasing the weights of long-tail entities and relations, and learning better representations for them. In particular, WeightE tailors bilevel optimization for the KGE task, where the inner level aims to learn reliable entity and relation embeddings, and the outer level attempts to assign appropriate weights for each entity and relation. Moreover, it is worth noting that our technique of applying weights to different entities and relations is general and flexible, which can be applied to a number of existing KGE models. Finally, we extensively validate the superiority of WeightE against various state-of-the-art baselines.",10.1145/3539618.3591784,2023,,ACM,10.1145/3539618.3591784
Probabilistic Hypergraph Recurrent Neural Networks for Time-series Forecasting,"Leveraging graph structures for time-series forecasting has garnered significant attention due to their effective relationship modeling between nodes and their associated time-series. However, in scenarios entities communicate in a broadcasting manner, graph models fall short of pairwise modeling. Hypergraph models address this by capturing beyond-pairwise interactions among node time-series. Nevertheless, most hypergraph models overlook the dynamics between nodes and their incident hyperedges, assuming constant node-hyperedge connections. In this paper, we introduce a novel model, Probabilistic Hypergraph Recurrent Neural Networks (PHRNN), which leverages node-hyperedge dynamics for accurate time-series forecasting. PHRNN associates each time-series with a node and models node interactions on a hypergraph, capturing beyond-pairwise interactions. Moreover, PHRNN learns a probabilistic hypergraph in which node-hyperedge relations are modeled as probabilistic distributions instead of fixed values, capturing dynamic node-hyperedge relations. PHRNN further integrates a prior knowledge KNN hypergraph as regularization when learning the probabilistic hypergraph structure. To the best of our knowledge, PHRNN is the first time-series forecasting model that incorporates hypergraph modeling and probabilistic relationship modeling. Forecasting results from extensive experiments show that PHRNN outperforms state-of-the-art graph and hypergraph baselines on real-world datasets.",10.1145/3690624.3709202,2025,,ACM,10.1145/3690624.3709202
STLAformer: Segment-based Temporal Lag Attention effective for time series forecasting,"In recent years, Transformer architectures have attracted considerable attention in multivariate time series forecasting due to their powerful sequence modeling capabilities. However, existing methods primarily focus on temporal dependencies while often overlooking complex lagged relationships among variables, where the current state of a variable is mainly influenced by the historical state of other variables at certain previous time steps, indicating strong lagged correlations among them. To address this limitation, we propose STLAformer, a novel model based on a Segment-based Temporal Lag Attention (STLA) mechanism. By partitioning multivariate time series into local segments and introducing a delay-aware attention module, STLAformer effectively captures cross-variable lagged dependencies. Additionally, we design a Temporal Preservation Segmentation Embedding (TPSE) module to independently encode each segment, preserving local dynamic features, and incorporate learnable temporal encoding to enhance the model's representation of temporal structures. Experimental results demonstrate that our approach achieves significant improvements in modeling capability and forecasting accuracy over existing Transformer variants on multiple real-world multivariate time series forecasting tasks, especially exhibiting stronger generalization ability when handling complex lag dependencies.",10.1145/3759928.3759960,2025,,ACM,10.1145/3759928.3759960
Domain Generalization in Time Series Forecasting,"Domain generalization aims to design models that can effectively generalize to unseen target domains by learning from observed source domains. Domain generalization poses a significant challenge for time series data, due to varying data distributions and temporal dependencies. Existing approaches to domain generalization are not designed for time series data, which often results in suboptimal or unstable performance when confronted with diverse temporal patterns and complex data characteristics. We propose a novel approach to tackle the problem of domain generalization in time series forecasting. We focus on a scenario where time series domains share certain common attributes and exhibit no abrupt distribution shifts. Our method revolves around the incorporation of a key regularization term into an existing time series forecasting model: domain discrepancy regularization. In this way, we aim to enforce consistent performance across different domains that exhibit distinct patterns. We calibrate the regularization term by investigating the performance within individual domains and propose the domain discrepancy regularization with domain difficulty awareness. We demonstrate the effectiveness of our method on multiple datasets, including synthetic and real-world time series datasets from diverse domains such as retail, transportation, and finance. Our method is compared against traditional methods, deep learning models, and domain generalization approaches to provide comprehensive insights into its performance. In these experiments, our method showcases superior performance, surpassing both the base model and competing domain generalization models across all datasets. Furthermore, our method is highly general and can be applied to various time series models.",10.1145/3643035,2024,,ACM,10.1145/3643035
FinCast: A Foundation Model for Financial Time-Series Forecasting,"Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities.",10.1145/3746252.3761261,2025,,ACM,10.1145/3746252.3761261
EAPformer: Entropy-Aware Patch Transformer for Multivariate Long-Term Time Series Forecasting,"Multivariate long-term time series forecasting is pivotal across numerous domains, yet precise predictions require a differentiated assessment of historical time segments due to their varying influence on future trends. Patch-based Transformer frameworks show promise for capturing local temporal patterns. However, they face limitations with static patching, which disrupts temporal continuity, fails to adapt to shifts between periodic and volatile patterns, and overlooks dynamic interactions between time segments and variables. To address these limitations, we propose Entropy-Aware Patch Transformer (EAPformer) which dynamically segments time series for differentiated assessments of historical patterns. Specifically, we overcome static patching limitations by leveraging temporal entropy to dynamically adjust patch boundaries through a two-stage policy, achieving interpretable and context-sensitive segmentation. Subsequently, we adapt EAPformer to periodic and volatile dynamics by employing entropy-aware segmentation that captures distinct temporal patterns across diverse segments. Finally, we further capture dynamic interactions across time segments and variables by introducing a multi-dimensional dependency learning architecture. Additionally, a gated fusion mechanism integrates local and global patterns, enhancing robustness. Extensive experiments on eight public benchmarks demonstrate that EAPformer outperforms state-of-the-art models, achieving superior accuracy across all metrics.",10.1145/3746252.3761055,2025,,ACM,10.1145/3746252.3761055
AdaPatch: Adaptive Patch-Level Modeling for Non-Stationary Time Series Forecasting,"Time series forecasting has witnessed significant advancements through deep learning techniques. However, most existing methods struggle in non-stationary environments, where data distributions evolve over time due to concept drift. To address the challenge of non-stationarity in time series, various stabilization techniques have been proposed to mitigate temporal variations. Nonetheless, these methods operate at the instance level, assuming a homogeneous distribution across all time steps within an instance and relying on fixed statistical normalization. This limits their ability to effectively capture fine-grained distributional shifts.In this paper, we introduce AdaPatch, a novel forecasting model specifically designed to tackle non-stationary multivariate time series. AdaPatch addresses intra-instance distributional shifts by adopting an adaptive scheme for patch-level encoding and normalization, which makes the model capture fine-grained temporal variations more effectively. To further enhance the quality of representations, AdaPatch incorporates a patch reconstruction branch and jointly optimizes a reconstruction loss alongside the forecasting objective. This auxiliary path serves as an implicit regularization mechanism, guiding the encoder to retain meaningful local temporal structures. Furthermore, to enable AdaPatch to better model complex local dynamics, we propose a patch-based predictive decoding strategy that leverages the decoder from the reconstruction branch to replace conventional point-wise forecasting with a more structured patch-level prediction mechanism. Extensive experiments conducted on six real-world multivariate time series datasets demonstrate that AdaPatch achieves superior performance compared to several state-of-the-art baselines, highlighting its effectiveness and strong generalization capability. Our code and data are publicly available at https://github.com/iuaku/AdaPatch.",10.1145/3746252.3761360,2025,,ACM,10.1145/3746252.3761360
TS-Fastformer: Fast Transformer for Time-series Forecasting,"Many real-world applications require precise and fast time-series forecasting. Recent trends in time-series forecasting models are shifting from LSTM-based models to Transformer-based models. However, the Transformer-based model has a limited ability to represent sequential relationships in time-series data. In addition, the transformer-based model suffers from slow training and inference speed due to the bottleneck incurred by a deep encoder and step-by-step decoder inference. To address these problems, we propose a time-series forecasting optimized Transformer model, called TS-Fastformer. TS-Fastformer introduces three new optimizations: First, we propose a Sub Window Tokenizer for compressing input in a simple manner. The Sub Window Tokenizer reduces the length of input sequences to mitigate the complexity of self-attention and enables both single and multi-sequence learning. Second, we propose Time-series Pre-trained Encoder to extract effective representations through pre-training. This optimization enables TS-Fastformer to capture both seasonal and trend representations as well as to mitigate bottlenecks of conventional transformer models. Third, we propose the Past Attention Decoder to forecast target by incorporating past long short-term dependency patterns. Furthermore, Past Attention Decoder achieves high performance improvement by removing a trend distribution that changes over a long period. We evaluate the efficiency of our model with extensive experiments using seven real-world datasets and compare our model to six representative time-series forecasting approaches. The results show that the proposed TS-Fastformer reduces MSE by 10.1\% compared to state-of-the-art model and demonstrates 21.6\% faster training time compared to the existing fastest transformer, respectively.",10.1145/3630637,2024,,ACM,10.1145/3630637
Generative Pretrained Hierarchical Transformer for Time Series Forecasting,"Recent efforts have been dedicated to enhancing time series forecasting accuracy by introducing advanced network architectures and self-supervised pretraining strategies. Nevertheless, existing approaches still exhibit two critical drawbacks. Firstly, these methods often rely on a single dataset for training, limiting the model's generalizability due to the restricted scale of the training data. Secondly, the one-step generation schema is widely followed, which necessitates a customized forecasting head and overlooks the temporal dependencies in the output series, and also leads to increased training costs under different horizon length settings.  To address these issues, we propose a novel generative pretrained hierarchical transformer architecture for forecasting, named GPHT. There are two aspects of key designs in GPHT. On the one hand, we advocate for constructing a mixed dataset under the channel-independent assumption for pretraining our model, comprising various datasets from diverse data scenarios. This approach significantly expands the scale of training data, allowing our model to uncover commonalities in time series data and facilitating improved transfer to specific datasets. On the other hand, GPHT employs an auto-regressive forecasting approach, effectively modeling temporal dependencies in the output series. Importantly, no customized forecasting head is required, enablinga single model to forecast at arbitrary horizon settings. We conduct sufficient experiments on eight datasets with mainstream self-supervised pretraining models and supervised models. The results demonstrated that GPHT surpasses the baseline models across various fine-tuning and zero/few-shot learning settings in the traditional long-term forecasting task, providing support for verifying the feasibility of pretraining time series large models. We make our codes publicly availablefootnotehttps://github.com/icantnamemyself/GPHT.",10.1145/3637528.3671855,2024,,ACM,10.1145/3637528.3671855
TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations,"Time series forecasting is critical across various domains, such as weather, finance and real estate forecasting, as accurate forecasts support informed decision-making and risk mitigation. While recent deep learning models have improved predictive capabilities, they often overlook time-lagged cross-correlations between related sequences, which are crucial for capturing complex temporal relationships. To address this, we propose the Time-Lagged Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances forecasting accuracy by effectively integrating time-lagged cross-correlated sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW) algorithm to capture lagged correlations and a contrastive learning-based encoder to efficiently approximate SSDTW distances. Experimental results on weather, finance and real estate time series datasets demonstrate the effectiveness of our framework. On the weather dataset, SSDTW reduces mean squared error (MSE) by 16.01\% compared with single-sequence methods, while the contrastive learning encoder (CLE) further decreases MSE by 17.88\%. On the stock dataset, SSDTW achieves a 9.95\% MSE reduction, and CLE reduces it by 6.13\%. For the real estate dataset, SSDTW and CLE reduce MSE by 21.29\% and 8.62\%, respectively. Additionally, the contrastive learning approach decreases SSDTW computational time by approximately 99\%, ensuring scalability and real-time applicability across multiple time series forecasting tasks.",10.1145/3746252.3761410,2025,,ACM,10.1145/3746252.3761410
TSFM-Bench: A Comprehensive and Unified Benchmark of Foundation Models for Time Series Forecasting,"Time Series Forecasting (TSF) is key functionality in numerous fields, such as financial investment, weather services, and energy management. Although increasingly capable TSF methods occur, many of them require domain-specific data collection and model training and do not generalize well when applied in other domains. Time Series Foundation Models (TSFMs) that are pre-trained on massive heterogeneous time series data aim to overcome these limitations. The prospects for generalizability have spurred the development of a new generation of TSFMs. This study proposes a benchmark, TSFM-Bench, to facilitate comprehensive and unified evaluation of TSFMs. TSFM-Bench covers a wide range of TSFMs, including those based on large language models and those pre-trained on time series data. TSFM-Bench supports multiple forecasting scenarios, including zero-shot, few-shot, and full-shot, enabling assessment across the full range of adaptation strategies. TSFM-Bench also provides a standardized experimental protocols for critical evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, facilitating consistency and fairness. We report on an extensive evaluation of TSFMs across a diverse range of datasets spanning multiple domains and exhibiting varied statistical characteristics. Specifically, we identify pros and cons and inherent limitations of existing TSFMs, and we propose potential directions for new model designs.",10.1145/3711896.3737442,2025,,ACM,10.1145/3711896.3737442
Scalable Transformer for High Dimensional Multivariate Time Series Forecasting,"Deep models for Multivariate Time Series (MTS) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional MTS data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address these issues, we propose STHD, the Scalable Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has three components: a) Relation Matrix Sparsity that limits the noise introduced and alleviates the memory issue; b) ReIndex applied as a training strategy to enable a more flexible batch size setting and increase the diversity of training data; and c) Transformer that handles 2-D inputs and captures channel dependencies. These components jointly enable STHD to manage the high-dimensional MTS while maintaining computational feasibility. Furthermore, experimental results show STHD's considerable improvement on three high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source code and dataset are publicly available https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.",10.1145/3627673.3679757,2024,,ACM,10.1145/3627673.3679757
TF-GAN: Topology-Aware Generative Adversarial Network for Financial Time Series Forecasting,"Financial time series prediction has long been a topic of interest, and with the rise of machine learning, numerous models have been proposed to improve forecasting accuracy. However, existing approaches largely overlook the topological structure inherent in financial data. In this paper, we propose Topology-aware Financial Generative Adversarial Networks (TF-GAN), a topology-aware adversarial forecasting framework that incorporates topological data analysis (TDA) into the training process. Building upon the ForGAN and Fin-GAN frameworks, TF-GAN introduces a novel topology-aware loss function based on persistent homology that encourages generated sequences to preserve the structural patterns of real financial data. To the best of our knowledge, we are among the first to design and implement a differentiable topological loss function with full gradient support in PyTorch, enabling end-to-end training. Experiments on 5-minute interval stock data for Amazon and IBM show that our method significantly improves both prediction accuracy (RMSE, MAE) and financial performance (Sharpe Ratio, cumulative PnL). TF-GAN improves the Sharpe Ratio by up to 318\% compared to the original ForGAN, and achieves up to 295\% higher Sharpe Ratios compared to Fin-GAN across diverse financial loss functions. The proposed TF-GAN framework demonstrates that incorporating topological structure into the adversarial learning loop yields more robust and profitable predictions, offering a new direction for structure-aware financial forecasting.",10.1145/3768292.3770429,2025,,ACM,10.1145/3768292.3770429
Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing,"In recent years, affiliate marketing has emerged as a revenue-sharing strategy where merchants collaborate with promoters to promote their products. It not only increases product exposure but also allows promoters to earn a commission. This paper addresses the pivotal yet under-explored challenge in affiliate marketing: accurately assessing and predicting the contributions of promoters in product promotion. We design a novel metric for evaluating the indirect contributions of the promoter, called propagation scale. Unfortunately, existing time series forecasting techniques fail to deliver accurate predictions due to the propagation scale being influenced by multiple factors and the inherent complexities arising from dynamic scenarios. To address this issue, we decouple the network structure from the node signals and propose a two-stage solution: initially, the basic self-sales and network structure prediction are conducted separately, followed by the synthesis of the propagation scale. Specifically, we design a graph convolution encoding scheme based on descendant neighbors and incorporate hypergraph convolution to efficiently capture complex promotional dynamics. Additionally, three auxiliary tasks are employed: self-sales prediction for base estimations, descendant prediction to synthesize propagation scale, and promoter activation prediction to mitigate high volatility issues. Extensive offline experiments on large-scale industrial datasets validate the superiority of our method. We further deploy our model on Alimama platform with over 100,000 promoters, achieving a 9.29\% improvement in GMV and a 5.89\% increase in sales volume.",10.1145/3746252.3761515,2025,,ACM,10.1145/3746252.3761515
MSOFormer: Multi-scale Transformer with Orthogonal Embedding and Frequency Modeling for Multivariate Time Series Forecasting,"Multivariate Time Series Forecasting (MTSF) plays a critical role in diverse practical applications. Although Transformer-based models have recently achieved impressive results in this field, their performance is still hindered by three core challenges: complex temporal dependencies, diverse inter-variable correlations, and patterns that span multiple time scales. To address these issues, we propose MSOFormer-a Multi-scale Transformer with Orthogonal Embedding and Frequency Modeling. Specifically, the Dynamic Frequency Filter adaptively weights frequency components across variables based on input characteristics, enabling full-spectrum modeling and precise extraction of key frequency patterns. To improve inter-variable representation, we introduce Orthogonal Embedding, a novel projection strategy for queries and keys that enhances feature diversity in channel-wise self-attention. In addition, Multi-scale Patch Embedding captures temporal features across different scales, providing a comprehensive time series representation. To evaluate MTSF in cloud-native environments, we construct the first three Cloud Kafka cluster datasets, specifically curated for elastic message queue scaling scenarios. Extensive experiments across eleven real-world benchmark datasets demonstrate that MSOFormer consistently outperforms existing state-of-the-art methods, highlighting its effectiveness and broad applicability.",10.1145/3746252.3761143,2025,,ACM,10.1145/3746252.3761143
Mitigating Data Redundancy to Revitalize Transformer-based Long-Term Time Series Forecasting System,"Long-term time-series forecasting (LTSF) is fundamental to various real-world applications, where Transformer-based models have become the dominant framework due to their ability to capture long-range dependencies. However, these models often experience overfitting due to data redundancy in rolling forecasting settings, limiting their generalization ability particularly evident in longer sequences with highly similar adjacent data. In this work, we introduce CLMFormer, a novel framework that mitigates redundancy through curriculum learning and a memory-driven decoder. Specifically, we progressively introduce Bernoulli noise to the training samples, which effectively breaks the high similarity between adjacent data points. This curriculum-driven noise introduction aids the memory-driven decoder by supplying more diverse and representative training data, enhancing the decoder’s ability to model seasonal tendencies and dependencies in the time-series data. To further enhance forecasting accuracy, we introduce a memory-driven decoder. This component enables the model to capture seasonal tendencies and dependencies in the time-series data and leverages temporal relationships to facilitate the forecasting process. Extensive experiments on six real-world LTSF benchmarks show that CLMFormer consistently improves Transformer-based models by up to 30\%, demonstrating its effectiveness in long-horizon forecasting.",10.1145/3735651,2025,,ACM,10.1145/3735651
Deep Coupling Network for Multivariate Time Series Forecasting,"Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this article, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines.",10.1145/3653447,2024,,ACM,10.1145/3653447
TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations,"Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance. The code is available at: https://github.com/Luoauoa/TimeCapsule.git.",10.1145/3711896.3737157,2025,,ACM,10.1145/3711896.3737157
Beyond Fixed Variables: Expanding-variate Time Series Forecasting via Flat Scheme and Spatio-temporal Focal Learning,"Multivariate Time Series Forecasting (MTSF) has long been a key research focus. Traditionally, these studies assume a fixed number of variables, but in real-world applications, Cyber-Physical Systems often expand as new sensors are deployed, increasing variables in MTSF. In light of this, we introduce a novel task, Expanding-variate Time Series Forecasting (EVTSF). This task presents unique challenges, specifically (1) handling inconsistent data shapes caused by adding new variables, and (2) addressing imbalanced spatio-temporal learning, where expanding variables have limited observed data due to the necessity for timely operation. To address these challenges, we propose STEV, a flexible spatio-temporal forecasting framework. STEV includes a new Flat Scheme to tackle the inconsistent data shape issue, which extends the graph-based spatio-temporal modeling architecture into 1D space by flattening the 2D samples along the variable dimension, making the model variable-scale-agnostic while still preserving dynamic spatial correlations through a holistic graph. Additionally, we introduce a novel Spatio-temporal Focal Learning strategy that incorporates a negative filter to resolve potential conflicts between contrastive learning and graph representation, and a focal contrastive loss as its core to guide the framework to focus on optimizing the expanding variables. To evaluate the effectiveness of STEV, we benchmark EVTSF performance on three real-world datasets from various domains and compare it against three potential solutions employing state-of-the-art (SOTA) MTSF models tailored for EVSTF. Experimental results show that STEV significantly outperforms its competitors, especially in handling expanding variables. Notably, STEV, with only 5\% of observations during the expanding period, is on par with SOTA MTSF models trained with complete data. Further exploration of various expanding scenarios underscores the generalizability of STEV in real-world applications.",10.1145/3711896.3736854,2025,,ACM,10.1145/3711896.3736854
ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting,"Forecasting complex time series is an important yet challenging problem that involves various industrial applications. Recently, masked time-series modeling has been proposed to effectively model temporal dependencies for forecasting by reconstructing masked segments from unmasked ones. However, since the semantic information in time series is involved in intricate temporal variations generated by multiple time series components, simply masking a raw time series ignores the inherent semantic structure, which may cause MTM to learn spurious temporal patterns present in the raw data. To capture distinct temporal semantics, we show that masked modeling techniques should address entangled patterns through a decomposition approach. Specifically, we propose ST-MTM, a masked time-series modeling framework with seasonal-trend decomposition, which includes a novel masking method for the seasonal-trend components that incorporates different temporal variations from each component. ST-MTM uses a period masking strategy for seasonal components to produce multiple masked seasonal series based on inherent multi-periodicity and a sub-series masking strategy for trend components to mask temporal regions that share similar variations. The proposed masking method presents an effective pre-training task for learning intricate temporal variations and dependencies. Additionally, ST-MTM introduces a contrastive learning task to support masked modeling by enhancing contextual consistency among multiple masked seasonal representations. Experimental results show that our proposed ST-MTM achieves consistently superior forecasting performance compared to existing masked modeling, contrastive learning, and supervised forecasting methods.",10.1145/3690624.3709254,2025,,ACM,10.1145/3690624.3709254
UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting,"Multivariate time series forecasting plays a pivotal role in contemporary web technologies. In contrast to conventional methods that involve creating dedicated models for specific time series application domains, this research advocates for a unified model paradigm that transcends domain boundaries. However, learning an effective cross-domain model presents the following challenges. First, various domains exhibit disparities in data characteristics, e.g., the number of variables, posing hurdles for existing models that impose inflexible constraints on these factors. Second, the model may encounter difficulties in distinguishing data from various domains, leading to suboptimal performance in our assessments. Third, the diverse convergence rates of time series domains can also result in compromised empirical performance. To address these issues, we propose UniTime for effective cross-domain time series learning. Concretely, UniTime can flexibly adapt to data with varying characteristics. It also uses domain instructions and a Language-TS Transformer to offer identification information and align two modalities. In addition, UniTime employs masking to alleviate domain convergence speed imbalance issues. Our extensive experiments demonstrate the effectiveness of UniTime in advancing state-of-the-art forecasting performance and zero-shot transferability.",10.1145/3589334.3645434,2024,,ACM,10.1145/3589334.3645434
ST-Hyper: Learning High-Order Dependencies Across Multiple Spatial-Temporal Scales for Multivariate Time Series Forecasting,"In multivariate time series (MTS) forecasting, many deep learning based methods have been proposed for modeling dependencies at multiple spatial (inter-variate) or temporal (intra-variate) scales. However, existing methods may fail to model dependencies across multiple spatial-temporal scales (ST-scales, i.e., scales that jointly consider spatial and temporal scopes). In this work, we propose ST-Hyper to model the high-order dependencies across multiple ST-scales through adaptive hypergraph modeling. Specifically, we introduce a Spatial-Temporal Pyramid Modeling (STPM) module to extract features at multiple ST-scales. Furthermore, we introduce an Adaptive Hypergraph Modeling (AHM) module that learns a sparse hypergraph to capture robust high-order dependencies among features. In addition, we interact with these features through tri-phase hypergraph propagation, which can comprehensively capture multi-scale spatial-temporal dynamics. Experimental results on six real-world MTS datasets demonstrate that ST-Hyper achieves the state-of-the-art performance, outperforming the best baselines with an average MAE reduction of 3.8\% and 6.8\% for long-term and short-term forecasting, respectively. Code is available at https://anonymous.4open.science/ST-Hyper-83E7.",10.1145/3746252.3761281,2025,,ACM,10.1145/3746252.3761281
Seeing Sequences like Humans: Pattern Classification Driven Time-Series Forecasting via Vision Language Models,"Time-series forecasting is critical to highly data-dependent domains such as energy, healthcare, and transportation. Although Large Language Models have recently been explored for this task, their performance is hindered by a modality gap: numerical sequences poorly align with text-based inputs, and direct alignment often introduces noise. In contrast, human experts rarely predict directly from numbers; they first inspect line charts to recognize overall patterns and then apply simple models for forecasting. Inspired by this workflow, we propose VisMoE, a Vision-Language-Model-driven Mixture-of-Experts framework. In VisMoE, Each sequence is transformed into a line-chart image, enabling a VLM to classify it into distinct temporal regimes. Based on this classification, VisMoE routes the sequence to lightweight specialized experts operating alongside a global predictor, whose outputs are fused for final forecasts. This human-inspired design preserves semantic understanding, reduces modality misalignment, and improves computational efficiency. Extensive experiments across multiple benchmarks demonstrate that VisMoE achieves state-of-the-art forecasting accuracy while remaining highly efficient. Our code is available at https://github.com/Liu905169/VisMoE.",10.1145/3746252.3761199,2025,,ACM,10.1145/3746252.3761199
Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting,"Spatiotemporal time series forecasting plays a key role in a wide range of real-world applications. While significant progress has been made in this area, fully capturing and leveraging spatiotemporal heterogeneity remains a fundamental challenge. Therefore, we propose a novel Heterogeneity-Informed Meta-Parameter Learning scheme. Specifically, our approach implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings, which can be viewed as a clustering process. Then, a novel spatiotemporal meta-parameter learning paradigm is proposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity. Based on these ideas, we develop a &lt;u&gt;H&lt;/u&gt;eterogeneity-&lt;u&gt;I&lt;/u&gt;nformed Spatiotemporal &lt;u&gt;M&lt;/u&gt;eta-&lt;u&gt;Net&lt;/u&gt;work (HimNet) for spatiotemporal time series forecasting. Extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance while exhibiting superior interpretability. Our code is available at &lt;u&gt;https://github.com/XDZhelheim/HimNet&lt;/u&gt;.",10.1145/3637528.3671961,2024,,ACM,10.1145/3637528.3671961
Multiple Time Series Forecasting with Dynamic Graph Modeling,"Multiple time series forecasting plays an essential role in many applications. Solutions based on graph neural network (GNN) that deliver state-of-the-art forecasting performance use the relation graph which can capture historical correlations among time series. However, in real world, it is common that correlations among time series evolve across time, resulting in dynamic relation graph, where the future correlations may be different from those in history. To address this problem, we propose multiple time series forecasting with dynamic graph modeling (MTSF-DG) that is able to learn historical relation graphs and predicting future relation graphs to capture the dynamic correlations. We also propose a causal GNN to extract features from both kinds of relation graphs efficiently. Then we propose a reasoning network to explicitly learn the variant influence from historical timestamps to future timestamps for final forecasting. Extensive experiments on six benchmark datasets show that MTSF-DG consistently outperforms state-of-the-art baselines, and justify our design with dynamic relation graph modeling.",10.14778/3636218.3636230,2023,,ACM,10.14778/3636218.3636230
Weakly Guided Adaptation for Robust Time Series Forecasting,"Robust multivariate time series forecasting is crucial in many cyberphysical and Internet of Things applications. Existing state-of-the-art robust forecasting models decompose time series into independent functions covering trends and periodicities. However, these independent functions fail to capture correlations among multiple time series, thereby reducing prediction accuracy. Moreover, existing robust forecasting models treat certain abrupt but normal changes, e.g., caused by holidays, as outliers because they occur infrequently and have data distributions that resemble those of outliers. This exacerbates model bias and reduces prediction accuracy. This paper aims to capture correlations across multiple time series and abrupt but normal changes, thereby improving prediction accuracy. We employ weak labels to partition the dataset into source and target domains. Then, we propose the Domain Adversarial Robust Forecaster (DARF). This forecasting model is based on adversarial domain adaptation and includes two novel modules: Correlated Robust Forecaster (CORF) and Domain Critic. Specifically, CORF constitutes an encoder-decoder framework proficient at robust multivariate time series forecasting, and Domain Critic works to reduce data bias. Extensive experiments and discussions show that DARF is capable of state-of-the-art forecasting accuracy.",10.14778/3636218.3636231,2023,,ACM,10.14778/3636218.3636231
Graph Deep Factors for Probabilistic Time-series Forecasting,"Effective time-series forecasting methods are of significant importance to solve a broad spectrum of research problems. Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, a relational global model learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, a relational local model not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average. Furthermore, we target addressing the common nature of many time-series forecasting applications where time-series are provided in a streaming version; however, most methods fail to leverage the newly incoming time-series values and result in worse performance over time. In this article, we propose an online incremental learning framework for probabilistic forecasting. The framework is theoretically proven to have lower time and space complexity. The framework can be universally applied to many other machine learning-based methods.",10.1145/3543511,2023,,ACM,10.1145/3543511
APAN: Asynchronous Propagation Attention Network for Real-time Temporal Graph Embedding,"To capture higher-order structural features, most GNN-based algorithms learn node representations incorporating k-hop neighbors' information. Due to the high time complexity of querying k-hop neighbors, most graph algorithms cannot be deployed in a giant dense temporal network to execute millisecond-level inference. This problem dramatically limits the potential of applying graph algorithms in certain areas, especially financial fraud detection. Therefore, we propose Asynchronous Propagation Attention Network, an asynchronous continuous time dynamic graph algorithm for real-time temporal graph embedding. Traditional graph models usually execute two serial operations: first graph querying and then model inference. Different from previous graph algorithms, we decouple model inference and graph computation to alleviate the damage of the heavy graph query operation to the speed of model inference. Extensive experiments demonstrate that the proposed method can achieve competitive performance while greatly improving the inference speed. The source code is published at a Github repository.",10.1145/3448016.3457564,2021,,ACM,10.1145/3448016.3457564
TimelyGPT: Extrapolatable Transformer Pre-training for Long-term Time-Series Forecasting in Healthcare,"Motivation: Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success in Natural Language Processing and Computer Vision domains. However, the development of PTMs on healthcare time-series data is lagging behind. This underscores the limitations of the existing transformer-based architectures, particularly their scalability to handle large-scale time series and ability to capture long-term temporal dependencies.Methods: In this study, we present Timely Generative Pre-trained Transformer (TimelyGPT). TimelyGPT employs an extrapolatable position (xPos) embedding to encode trend and periodic patterns into time-series representations. It also integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies.Materials: We evaluated TimelyGPT on two large-scale healthcare time series datasets corresponding to continuous biosignals and irregularly-sampled time series, respectively: (1) the Sleep EDF dataset consisting of over 1.2 billion timesteps; (2) the longitudinal healthcare administrative database PopHR, comprising 489,000 patients randomly sampled from the Montreal population.Results: In forecasting continuous biosignals, TimelyGPT achieves accurate extrapolation up to 6,000 timesteps of body temperature during the sleep stage transition, given a short look-up window (i.e., prompt) containing only 2,000 timesteps. For irregularly-sampled time series, TimelyGPT with a proposed time-specific inference demonstrates high top recall scores in predicting future diagnoses using early diagnostic records, effectively handling irregular intervals between clinical records. Together, we envision TimelyGPT to be useful in various health domains, including long-term patient health state forecasting and patient risk trajectory prediction. Availability: The open-sourced code is available at Github.",10.1145/3698587.3701364,2024,,ACM,10.1145/3698587.3701364
GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing,"Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90\% of variables are missing, it can still accurately predict the future values of all variables.",10.1145/3637528.3672055,2024,,ACM,10.1145/3637528.3672055
A Distribution Graph Guided Network with Dual Track Self-Supervised Strategy for Tobacco Pest Time Series Forecasting,"Tobacco pest is one of the main factors that harm tobacco quality in tobacco factories, leading to economic losses. Accurate prediction of pest distribution is crucial for the management and production of tobacco factories. Nevertheless, conventional time series forecasting techniques prove inadequate in capturing sufficient information for fine-grained forecasting tasks involving district-variable-level and day-sampling-level tobacco pest datasets. This limitation arises from the lack of consideration for the knowledge pertaining to the migration and reproduction patterns of tobacco pests. In this work, a dual track self-supervised and distribution graph guided network (DTSSDGN) is proposed to handle this problem. First, a distribution graph guided feature extraction module is designed to help capture the internal and external patterns of pest distribution. Subsequently, a two-stage training strategy is devised, comprising a dual-track self-supervised training phase to acquire features that possess a comprehensive understanding of the pest distribution trend, followed by a fine-grained fine-tuning phase that leverages this knowledge to achieve accurate forecasting outcomes. The effectiveness and superiority of the proposed method are illustrated on a real tobacco pest distribution dataset.",10.1145/3704558.3707079,2025,,ACM,10.1145/3704558.3707079
LightCTS: A Lightweight Framework for Correlated Time Series Forecasting,"Correlated time series (CTS) forecasting plays an essential role in many practical applications, such as traffic management and server load control. Many deep learning models have been proposed to improve the accuracy of CTS forecasting. However, while models have become increasingly complex and computationally intensive, they struggle to improve accuracy. Pursuing a different direction, this study aims instead to enable much more efficient, lightweight models that preserve accuracy while being able to be deployed on resource-constrained devices. To achieve this goal, we characterize popular CTS forecasting models and yield two observations that indicate directions for lightweight CTS forecasting. On this basis, we propose the LightCTS framework that adopts plain stacking of temporal and spatial operators instead of alternate stacking that is much more computationally expensive. Moreover, LightCTS features light temporal and spatial operator modules, called L-TCN and GL-Former, that offer improved computational efficiency without compromising their feature extraction capabilities. LightCTS also encompasses a last-shot compression scheme to reduce redundant temporal features and speed up subsequent computations. Experiments with single-step and multi-step forecasting benchmark datasets show that LightCTS is capable of nearly state-of-the-art accuracy at much reduced computational and storage overheads.",10.1145/3589270,2023,,ACM,10.1145/3589270
Multi-Variate Time Series Forecasting on Variable Subsets,"We formulate a new inference task in the domain of multivariate time series forecasting (MTSF), called Variable Subset Forecast (VSF), where only a small subset of the variables is available during inference. Variables are absent during inference because of long-term data loss (eg. sensor failures) or high -&gt; low-resource domain shift between train / test. To the best of our knowledge, robustness of MTSF models in presence of such failures, has not been studied in the literature. Through extensive evaluation, we first show that the performance of state of the art methods degrade significantly in the VSF setting. We propose a non-parametric, wrapper technique that can be applied on top any existing forecast models. Through systematic experiments across 4 datasets and 5 forecast models, we show that our technique is able to recover close to 95\% performance of the models even when only 15\% of the original variables are present.",10.1145/3534678.3539394,2022,,ACM,10.1145/3534678.3539394
TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods,"Time series are generated in diverse domains such as economic, traffic, health, and energy, where forecasting of future values has numerous important applications. Not surprisingly, many forecasting methods are being proposed. To ensure progress, it is essential to be able to study and compare such methods empirically in a comprehensive and reliable manner. To achieve this, we propose TFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB advances the state-of-the-art by addressing shortcomings related to datasets, comparison methods, and evaluation pipelines: 1) insufficient coverage of data domains, 2) stereotype bias against traditional methods, and 3) inconsistent and inflexible pipelines. To achieve better domain coverage, we include datasets from 10 different domains : traffic, electricity, energy, the environment, nature, economic, stock markets, banking, health, and the web. We also provide a time series characterization to ensure that the selected datasets are comprehensive. To remove biases against some methods, we include a diverse range of methods, including statistical learning, machine learning, and deep learning methods, and we also support a variety of evaluation strategies and metrics to ensure a more comprehensive evaluations of different methods. To support the integration of different methods into the benchmark and enable fair comparisons, TFB features a flexible and scalable pipeline that eliminates biases. Next, we employ TFB to perform a thorough evaluation of 21 Univariate Time Series Forecasting (UTSF) methods on 8,068 univariate time series and 14 Multivariate Time Series Forecasting (MTSF) methods on 25 datasets. The results offer a deeper understanding of the forecasting methods, allowing us to better select the ones that are most suitable for particular datasets and settings. Overall, TFB and this evaluation provide researchers with improved means of designing new TSF methods.",10.14778/3665844.3665863,2024,,ACM,10.14778/3665844.3665863
Large Scale Financial Time Series Forecasting with Multi-faceted Model,"Data-driven approaches using deep neural networks have been successful in modeling complex financial time series and generating accurate predictions without requiring extensive domain knowledge. However, most of the existing models that assume independent and identically distributed (i.i.d.) data may not generalize well to novel situations or distributional shifts across or inside financial scenarios. To address this challenge, we introduce an invariant learning-based regularizer with relaxed bounds that expands the range of feasible solutions and mitigates over-convergence issues in Invariant Risk Minimization (IRM). In practice, the regularizer can be incorporated into both linear and nonlinear financial time series forecasting models. Experimental results on real-world large-scale financial datasets show that our proposed method enables more robust and adaptable financial forecasting models, enhancing the overall performance and generalizability of financial forecasting on both in-distribution and out-of-distribution (OOD) samples.",10.1145/3604237.3626868,2023,,ACM,10.1145/3604237.3626868
RPMixer: Shaking Up Time Series Forecasting with Random Projections for Large Spatial-Temporal Data,"Spatial-temporal forecasting systems play a crucial role in addressing numerous real-world challenges. In this paper, we investigate the potential of addressing spatial-temporal forecasting problems using general time series forecasting models, i.e., models that do not leverage the spatial relationships among the nodes. We propose a all-Multi-Layer Perceptron (all-MLP) time series forecasting architecture called RPMixer. The all-MLP architecture was chosen due to its recent success in time series forecasting benchmarks. Furthermore, our method capitalizes on the ensemble-like behavior of deep neural networks, where each individual block within the network behaves like a base learner in an ensemble model, particularly when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby improving the overall performance of the network. Extensive experiments conducted on the largest spatial-temporal forecasting benchmark datasets demonstrate that the proposed method outperforms 14 alternative methods.",10.1145/3637528.3671881,2024,,ACM,10.1145/3637528.3671881
Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Networks,"Accurate traffic forecasting is crucial for the development of Intelligent Transportation Systems (ITS), playing a pivotal role in modern urban traffic management. Traditional forecasting methods, however, struggle with the irregular traffic time series resulting from adaptive traffic signal controls, presenting challenges in asynchronous spatial dependency, irregular temporal dependency, and predicting variable-length sequences. To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) tailored for irregular traffic time series forecasting. Specifically, we first propose an Asynchronous Graph Diffusion Network to capture the spatial dependency between asynchronously measured traffic states regulated by adaptive traffic signals. After that, to capture the temporal dependency within irregular traffic state sequences, a personalized time encoding is devised to embed the continuous time signals. Then, we propose a Transformable Time-aware Convolution Network, which adapts meta-filters for time-aware convolution on the sequences with inconsistent temporal flow. Additionally, a Semi-Autoregressive Prediction Network, comprising a state evolution unit and a semiautoregressive predictor, is designed to predict variable-length traffic sequences effectively and efficiently. Extensive experiments on a newly established benchmark demonstrate the superiority of ASeer compared with twelve competitive baselines across six metrics.",10.1145/3637528.3671665,2024,,ACM,10.1145/3637528.3671665
Deep Extreme Mixture Model for Time Series Forecasting,"Time Series Forecasting (TSF) has been a topic of extensive research, which has many real world applications such as weather prediction, stock market value prediction, traffic control etc. Many machine learning models have been developed to address TSF, yet, predicting extreme values remains a challenge to be effectively addressed. Extreme events occur rarely, but tend to cause a huge impact, which makes extreme event prediction important. Assuming light tailed distributions, such as Gaussian distribution, on time series data does not do justice to the modeling of extreme points. To tackle this issue, we develop a novel approach towards improving attention to extreme event prediction. Within our work, we model time series data distribution, as a mixture of Gaussian distribution and Generalized Pareto distribution (GPD). In particular, we develop a novel Deep eXtreme Mixture Model (DXtreMM) for univariate time series forecasting, which addresses extreme events in time series. The model consists of two modules: 1) Variational Disentangled Auto-encoder (VD-AE) based classifier and 2) Multi Layer Perceptron (MLP) based forecaster units combined with Generalized Pareto Distribution (GPD) estimators for lower and upper extreme values separately. VD-AE Classifier model predicts the possibility of occurrence of an extreme event given a time segment, and forecaster module predicts the exact value. Through extensive set of experiments on real-world datasets we have shown that our model performs well for extreme events and is comparable with the existing baseline methods for normal time step forecasting.",10.1145/3511808.3557282,2022,,ACM,10.1145/3511808.3557282
Blurred Encoding for Trajectory Representation Learning,"Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLU rred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90\%. Our code is available at https://github.com/slzhou-xy/BLUE.",10.1145/3711896.3736861,2025,,ACM,10.1145/3711896.3736861
Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting,"Recent studies have shown great promise in applying graph neural networks for multivariate time series forecasting, where the interactions of time series are described as a graph structure and the variables are represented as the graph nodes. Along this line, existing methods usually assume that the graph structure (or the adjacency matrix), which determines the aggregation manner of graph neural network, is fixed either by definition or self-learning. However, the interactions of variables can be dynamic and evolutionary in real-world scenarios. Furthermore, the interactions of time series are quite different if they are observed at different time scales. To equip the graph neural network with a flexible and practical graph structure, in this paper, we investigate how to model the evolutionary and multi-scale interactions of time series. In particular, we first provide a hierarchical graph structure cooperated with the dilated convolution to capture the scale-specific correlations among time series. Then, a series of adjacency matrices are constructed under a recurrent manner to represent the evolving correlations at each layer. Moreover, a unified neural network is provided to integrate the components above to get the final prediction. In this way, we can capture the pair-wise correlations and temporal dependency simultaneously. Finally, experiments on both single-step and multi-step forecasting tasks demonstrate the superiority of our method over the state-of-the-art approaches.",10.1145/3534678.3539274,2022,,ACM,10.1145/3534678.3539274
Modeling Temporal Patterns with Dilated Convolutions for Time-Series Forecasting,"Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated CNN for time-series forecasting tasks. The core component in HyDCNN is a proposed hybrid module, in which our proposed position-aware dilated CNNs are utilized to capture the sequential non-linear dynamics and an autoregressive model is leveraged to capture the sequential linear dependencies. To further capture the periodic temporal patterns, a novel hop scheme is introduced in the hybrid module. HyDCNN is then composed of multiple hybrid modules to capture the sequential and periodic patterns. Each of these hybrid modules targets on either the sequential pattern or one kind of periodic patterns. Extensive experiments on five real-world datasets have shown that the proposed HyDCNN is better compared with state-of-the-art baselines and is at least 200\% better than RNN baselines. The datasets and source code will be published in Github to facilitate more future work.",10.1145/3453724,2021,,ACM,10.1145/3453724
Dyn-GWN: Time-Series Forecasting using Time-varying Graphs with Applications to Finance and Traffic Prediction,"Spatio-temporal modeling is an essential lens to understand many real-world phenomena from traffic to finance. There has been exciting work that explores spatio-temporal modeling with temporal graph convolutional networks. Often these methods assume that the spatial structure is static. We propose a new model Dyn-GWN&nbsp;for spatio-temporal learning from time-varying graphs. Our model relies on a novel module called the Tensor Graph Convolutional Module&nbsp;(TGCM), which captures dynamic trends in graphs effectively in the time-varying graph representations. This module has two components: (i) it applies temporal dilated convolutions both on the time-varying graph adjacency space and the time-varying features. (ii) it aggregates the higher-level latent representations from both time-varying components through a proposed layer TGCL. Experiments demonstrate the efficacy of these model across time-series data from finance and traffic domains. Dyn-GWN&nbsp; can give up to better out-of-sample performance than prior methods that learn from time-varying graphs, e.g., EvolveGCN and TM-GCN. Interestingly, Dyn-GWN&nbsp; can be ∼ 300 \texttimes{",10.1145/3604237.3626864,2023,,ACM,10.1145/3604237.3626864
Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting,"Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.",10.1145/3534678.3539396,2022,,ACM,10.1145/3534678.3539396
A Transferable Time Series Forecasting Service Using Deep Transformer Model for Online Systems,"Many real-world online systems expect to forecast the future trend of software quality to better automate operational processes, optimize software resource cost and ensure software reliability. To achieve that, all kinds of time series metrics collected from online software systems are adopted to characterize and monitor the quality of software services. To meet relevant software engineers’ requirements, we focus on time series forecasting and aim to provide an event-driven and self-adaptive forecasting service. In this paper, we present TTSF-transformer, a transferable time series forecasting service using deep transformer model. TTSF-transformer normalizes multiple metric frequencies to ensure the model sharing across multi-source systems, employs a deep transformer model with Bayesian estimation to generate the predictive marginal distribution, and introduces transfer learning and incremental learning into the training process to ensure the performance of long-term prediction. We conduct experiments on real-world time series metrics from two different types of game business in Tencent®. The results show that TTSF-transformer significantly outperforms other state-of-the-art methods and is suitable for wide deployment in large online systems.",10.1145/3551349.3560414,2023,,ACM,10.1145/3551349.3560414
CTRL: Collaborative Temporal Representation Learning for Wind Power Forecasting,"Accurate wind power forecasting is crucial for grid stability and renewable energy integration, but existing methods struggle to capture complex temporal dependencies in wind data. This paper introduces Collaborative Temporal Representation Learning (CTRL), a novel deep learning model that leverages collaborative representation learning to enhance forecasting accuracy and robustness. CTRL integrates Reversible Instance Normalization (RevIN), RNN-based hidden state learning, and a specialized collaborative representation unit to capture multi-directional temporal dynamics across different time scales and variables. Experimental results on two real-world wind power datasets demonstrate that CTRL significantly outperforms 20 existing methods, including state-of-the-art deep learning approaches, achieving up to 9.67\% and 10.42\% improvement in forecasting accuracy, respectively. These findings highlight the potential of collaborative representation learning for advancing wind power forecasting and facilitating the effective integration of renewable energy resources.",10.1145/3711129.3711336,2025,,ACM,10.1145/3711129.3711336
TransForeCaster: In-and-Cross Categorized Feature Integration in User Representation Learning,"This paper introduces TransForeCaster, a novel user representation learning approach to improving prediction accuracy in purchase and churn predictions via a two-stage feature integration process: In-Category Integration (ICI) and Cross-Category Integration (CCI). The ICI stage employs a Time-Series Feature Mixer (TSFM) to capture the temporal dynamics of features within the same categories, resulting in compact and continuous category representations. The CCI stage utilizes a Meta-Conditioned Transformer (MCT) to integrate the representations with multi-task learning, capturing complex relationships across categories and improving interpretability through attention mechanisms. Empirical evaluations of real-world datasets demonstrate significant improvements over conventional models, supported by qualitative analyses using feature importance assessments and UMAP visualizations. TransForeCaster's robustness is validated by its superior performance over other models in multiple in-house deployments across various games and applications. The source code is available at https://github.com/bagelcode-data-science-team/TransForeCaster.",10.1145/3701716.3715267,2025,,ACM,10.1145/3701716.3715267
Conditional mutual information-based contrastive loss for financial time series forecasting,"We present a representation learning framework for financial time series forecasting. One challenge of using deep learning models for finance forecasting is the shortage of available training data when using small datasets. Direct trend classification using deep neural networks trained on small datasets is susceptible to the overfitting problem. In this paper, we propose to first learn compact representations from time series data, then use the learned representations to train a simpler model for predicting time series movements. We consider a class-conditioned latent variable model. We train an encoder network to maximize the mutual information between the latent variables and the trend information conditioned on the encoded observed variables. We show that conditional mutual information maximization can be approximated by a contrastive loss. Then, the problem is transformed into a classification task of determining whether two encoded representations are sampled from the same class or not. This is equivalent to performing pairwise comparisons of the training datapoints, and thus, improves the generalization ability of the encoder network. We use deep autoregressive models as our encoder to capture long-term dependencies of the sequence data. Empirical experiments indicate that our proposed method has the potential to advance state-of-the-art performance.",10.1145/3383455.3422550,2021,,ACM,10.1145/3383455.3422550
DS-TPU: Dynamical System for on-Device Lifelong Graph Learning with Nonlinear Node Interaction,"Graph learning on dynamical systems has recently surfaced as an emerging research domain. By leveraging a novel electronic Dynamical System (DS), various graph learning challenges have been effectively tackled through a rapid, spontaneous natural annealing process. This method has attracted increasing attention due to its orders-of-magnitude improvements in speed and energy efficiency compared to traditional Graph Neural Network (GNN) approaches for inference tasks. However, (1) the current DS hardware only supports inference, missing its native solution for training; while relying on conventional hardware is likely more expensive than GNNs. (2) The current DS architecture only allows linear interactions among its nodes, limiting training accuracy.In this work, we present a Dynamical-System Training-Processing Unit (DS-TPU) developed through algorithm-architecture co-design to tackle the two major challenges: (1) An on-device lifelong learning mechanism that leverages feedback electric current as the loss function in response to the observed training data, allowing electron-speed refinement on the present model parameters. (2) A nonlinear DS node interaction mechanism constructed from Chebyshev polynomials to significantly improve the compatibility between the DS hardware and the embedded relation of graph data. Extensive evaluations using six real-world graph learning applications demonstrate that for accuracy, DS-TPU achieves 10.8\% MAE reduction over the best results of five widely used GNNs. In terms of training performance, the 5-Watt DS-TPU architecture achieves on-average 810 \texttimes{",10.1145/3695053.3731091,2025,,ACM,10.1145/3695053.3731091
Lite-Mind: Towards Efficient and Robust Brain Representation Learning,"The limited data availability and the low signal-to-noise ratio of fMRI signals lead to the challenging task of fMRI-to-image retrieval. State-of-the-art MindEye remarkably improves fMRI-to-image retrieval performance by leveraging a large model, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to the final hidden layer of CLIP's Vision Transformer (ViT). However, significant individual variations exist among subjects, even under identical experimental setups, mandating the training of large subject-specific models. The substantial parameters pose significant challenges in deploying fMRI decoding on practical devices. To this end, we propose Lite-Mind, a lightweight, efficient, and robust brain representation learning paradigm based on Discrete Fourier Transform (DFT), which efficiently aligns fMRI voxels to fine-grained information of CLIP. We elaborately design a DFT backbone with Spectrum Compression and Frequency Projector modules to learn informative and robust voxel embeddings. Our experiments demonstrate that Lite-Mind achieves an impressive 94.6\% fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7\% fewer parameters than MindEye. Lite-Mind is also proven to be able to be migrated to smaller fMRI datasets and establishes a new state-of-the-art for zero-shot classification on the GOD dataset.",10.1145/3664647.3681229,2024,,ACM,10.1145/3664647.3681229
Score-based Graph Learning for Urban Flow Prediction,"Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP, a novel probabilistic graph-based framework for UFP. DiffUFP&nbsp;consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP&nbsp;over the state-of-the-art UFP&nbsp;models and the effect of the two specific modules.",10.1145/3655629,2024,,ACM,10.1145/3655629
DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection,"Time series anomaly detection is critical for a wide range of applications. It aims to identify deviant samples from the normal sample distribution in time series. The most fundamental challenge for this task is to learn a representation map that enables effective discrimination of anomalies. Reconstruction-based methods still dominate, but the representation learning with anomalies might hurt the performance with its large abnormal loss. On the other hand, contrastive learning aims to find a representation that can clearly distinguish any instance from the others, which can bring a more natural and promising representation for time series anomaly detection. In this paper, we propose DCdetector, a multi-scale dual attention contrastive representation learning model. DCdetector utilizes a novel dual attention asymmetric design to create the permutated environment and pure contrastive loss to guide the learning process, thus learning a permutation invariant representation with superior discrimination abilities. Extensive experiments show that DCdetector achieves state-of-the-art results on multiple time series anomaly detection benchmark datasets. Code is publicly available at https://github.com/DAMO-DI-ML/KDD2023-DCdetector.",10.1145/3580305.3599295,2023,,ACM,10.1145/3580305.3599295
ST-Norm: Spatial and Temporal Normalization for Multi-variate Time Series Forecasting,"Multi-variate time series (MTS) data is a ubiquitous class of data abstraction in the real world. Any instance of MTS is generated from a hybrid dynamical system with their specific dynamics normally unknown. The hybrid nature of such a dynamical system is a result of complex external impacts, which can be summarized as high-frequency and low-frequency from the temporal view, or global and local if we take the spatial view. These impacts also determine the forthcoming development of MTS making them paramount to capture in a time series forecasting task. However, conventional methods face intrinsic difficulties in disentangling the components yielded by each kind of impact from the raw data. To this end, we propose two kinds of normalization modules -- temporal and spatial normalization -- which separately refine the high-frequency component and the local component underlying the raw data. Moreover, both modules can be readily integrated into canonical deep learning architectures such as Wavenet and Transformer. Extensive experiments on three datasets are conducted to illustrate that, with additional normalization modules, the performance of the canonical architectures can be enhanced by a large margin in the application of MTS and achieves state-of-the-art results compared with existing MTS models.",10.1145/3447548.3467330,2021,,ACM,10.1145/3447548.3467330
DySTAGE: Dynamic Graph Representation Learning for Asset Pricing via Spatio-Temporal Attention and Graph Encodings,"Current GNN-based asset price prediction models often focus on a fixed group of assets and their static relationships within the financial network. However, this approach overlooks the reality that the composition of asset pools and their interrelationships evolves over time, necessitating the development of a flexible framework capable of adapting to this dynamism. Accordingly, we propose DySTAGE, a framework with a universal formulation that transforms asset pricing time series into dynamic graphs, accommodating asset addition, deletion, and changes in correlations. Our framework includes a graph learning model specifically designed for this purpose. In our framework, assets at various historical time steps are structured as a sequence of dynamic graphs, where connections between assets reflect their long-term correlations. DySTAGE effectively captures both topological and temporal patterns. The Topological Module deploys Asset Influence Attention to learn global interrelationships among assets, further enhanced by Asset-wise Importance Encoding, Pair-wise Spatial Encoding, and Edge-wise Correlation Encoding. Meanwhile, the Temporal Module encapsulates node representations across the temporal dimension via the attention mechanism. We validate our approach through extensive experiments using three different real-world stock pricing data, demonstrating that DySTAGE surpasses popular benchmarks in return prediction, and offers profitable investment strategies. The code is publicly available under NJIT FinTech Lab’s GitHub1.",10.1145/3677052.3698680,2024,,ACM,10.1145/3677052.3698680
Hierarchical Spatio-Temporal Graph Learning Based on Metapath Aggregation for Emergency Supply Forecasting,"Integrated Warehousing and Distribution Supply Networks (IWDSN) have shown their high efficiency in E-commerce. Efficient supply capacity prediction is crucial for logistics systems to maintain the delivery capacity to meet users' requirements. However, unforeseen events such as extreme weather and public health emergencies pose challenges in supply forecasting. Previous work mainly infers supply optimization based on the invariant topology of logistic networks, neglecting dynamic routing and distinct node effects reacting to emergencies. To address these challenges, the hierarchical relations among warehouses, sorting centers, and delivery stations in logistic networks are necessary to learn the diverse reactions. In this paper, we propose a hierarchical spatio-temporal graph learning model to predict the emergency supply capacity of IWDSN based on micro and macro graphs. The micro graph shows transportation connectivity while the macro graph shows the geographical correlation. Specifically, it consists of three components. (1) For micro graphs, a metapath aggregation strategy is designed to capture dynamic routing information on both route-view and event-view graphs. (2) For macro graphs, a bipartite graph learning approach to extract spatial representations. (3) For spatio-temporal feature fusion, the spatio-temporal joint forecasting module combines the temporal feature from the time-series encoder with hierarchical spatial features to predict the future supply capacity. The extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model, which achieves state-of-the-art performance compared with advanced baselines.",10.1145/3627673.3679854,2024,,ACM,10.1145/3627673.3679854
METRO: a generic graph neural network framework for multivariate time series forecasting,"Multivariate time series forecasting has been drawing increasing attention due to its prevalent applications. It has been commonly assumed that leveraging latent dependencies between pairs of variables can enhance prediction accuracy. However, most existing methods suffer from static variable relevance modeling and ignorance of correlation between temporal scales, thereby failing to fully retain the dynamic and periodic interdependencies among variables, which are vital for long- and short-term forecasting. In this paper, we propose METRO, a generic framework with multi-scale temporal graphs neural networks, which models the dynamic and cross-scale variable correlations simultaneously. By representing the multivariate time series as a series of temporal graphs, both intra- and inter-step correlations can be well preserved via message-passing and node embedding update. To enable information propagation across temporal scales, we design a novel sampling strategy to align specific steps between higher and lower scales and fuse the cross-scale information efficiently. Moreover, we provide a modular interpretation of existing GNN-based time series forecasting works as specific instances under our framework. Extensive experiments conducted on four benchmark datasets demonstrate the effectiveness and efficiency of our approach. METRO has been successfully deployed onto the time series analytics platform of Huawei Cloud, where a one-month online test demonstrated that up to 20\% relative improvement over state-of-the-art models w.r.t. RSE can be achieved.",10.14778/3489496.3489503,2021,,ACM,10.14778/3489496.3489503
GSL4Rec: Session-based Recommendations with Collective Graph Structure Learning and Next Interaction Prediction,"Users’ social connections have recently shown significant benefits to session-based recommendations, and graph neural networks have demonstrated great success in learning the pattern of information flow among users. However, the current paradigm presumes a given social network, which is not necessarily consistent with the fast-evolving shared interests and is expensive to collect. We propose a novel idea to learn the graph structure among users and make recommendations collectively in a coupled framework. This idea raises two challenges, i.e., scalability and effectiveness. We introduce a novel graph-structure learning framework for session-based recommendations&nbsp;(GSL4Rec) for solving both challenges simultaneously. Our framework has a two-stage strategy, i.e., the coarse neighbor screening and the self-adaptive graph structure learning, to enable the exploration of potential links among all users while maintaining a tractable amount of computation for scalability. We also propose a phased heuristic learning strategy to sequentially and synergistically train the graph learning part and recommendation part of GSL4Rec, thus improving the effectiveness by making the model easier to achieve good local optima. Experiments on five public datasets demonstrate that our proposed model significantly outperforms strong baselines, including state-of-the-art social network-based methods.",10.1145/3485447.3512085,2022,,ACM,10.1145/3485447.3512085
Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection,"The early detection of potential failures in industrial machinery components is paramount for ensuring the reliability and safety of operations, thereby preserving Machine Condition Monitoring (MCM). This research addresses this imperative by introducing an innovative approach to Real-Time Acoustic Anomaly Detection. Our method combines semi-supervised temporal convolution with representation learning and a hybrid model strategy with Temporal Convolutional Networks (TCN) to handle various intricate anomaly patterns found in acoustic data effectively. The proposed model demonstrates superior performance compared to established research in the field, underscoring the effectiveness of this approach. Not only do we present quantitative evidence of its superiority, but we also employ visual representations, such as t-SNE plots, to further substantiate the model’s efficacy.",10.1145/3651671.3651693,2024,,ACM,10.1145/3651671.3651693
Practical Skills Demand Forecasting via Representation Learning of Temporal Dynamics,"Rapid technological innovation threatens to leave much of the global workforce behind. Today's economy juxtaposes white-hot demand for skilled labor against stagnant employment prospects for workers unprepared to participate in a digital economy. It is a moment of peril and opportunity for every country, with outcomes measured in long-term capital allocation and the life satisfaction of billions of workers. To meet the moment, governments and markets must find ways to quicken the rate at which the supply of skills reacts to changes in demand. More fully and quickly understanding labor market intelligence is one route. In this work, we explore the utility of time series forecasts to enhance the value of skill demand data gathered from online job advertisements. This paper presents a pipeline which makes one-shot multi-step forecasts into the future using a decade of monthly skill demand observations based on a set of recurrent neural network methods. We compare the performance of a multivariate model versus a univariate one, analyze how correlation between skills can influence multivariate model results, and present predictions of demand for a selection of skills practiced by workers in the information technology industry.",10.1145/3514094.3534183,2022,,ACM,10.1145/3514094.3534183
A Transformer-based Framework for Multivariate Time Series Representation Learning,"We present a novel framework for multivariate time series representation learning based on the transformer encoder architecture. The framework includes an unsupervised pre-training scheme, which can offer substantial performance benefits over fully supervised learning on downstream tasks, both with but even without leveraging additional unlabeled data, i.e., by reusing the existing data samples. Evaluating our framework on several public multivariate time series datasets from various domains and with diverse characteristics, we demonstrate that it performs significantly better than the best currently available methods for regression and classification, even for datasets which consist of only a few hundred training samples. Given the pronounced interest in unsupervised learning for nearly all domains in the sciences and in industry, these findings represent an important landmark, presenting the first unsupervised method shown to push the limits of state-of-the-art performance for multivariate time series regression and classification.",10.1145/3447548.3467401,2021,,ACM,10.1145/3447548.3467401
"Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand \&amp; Uncertainties","This paper develops a graph reinforcement learning approach to online planning of the schedule and destinations of electric aircraft that comprise an urban air mobility (UAM) fleet operating across multiple vertiports. This fleet scheduling problem is formulated to consider time-varying demand, constraints related to vertiport capacity, aircraft capacity and airspace safety guidelines, uncertainties related to take-off delay, weather-induced route closures, and unanticipated aircraft downtime. Collectively, such a formulation presents greater complexity, and potentially increased realism, than in existing UAM fleet planning implementations. To address these complexities, a new policy architecture is constructed, primary components of which include: graph capsule conv-nets for encoding vertiport and aircraft-fleet states both abstracted as graphs; transformer layers encoding time series information on demand and passenger fare; and a Multi-head Attention-based decoder that uses the encoded information to compute the probability of selecting each available destination for an aircraft. Trained with Proximal Policy Optimization, this policy architecture shows significantly better performance in terms of daily averaged profits on unseen test scenarios involving 8 vertiports and 40 aircraft, when compared to a random baseline and genetic algorithm-derived optimal solutions, while being nearly 1000 times faster in execution than the latter.",10.1145/3605098.3635976,2024,,ACM,10.1145/3605098.3635976
Attention Based Dynamic Graph Learning Framework for Asset Pricing,"Recent studies suggest that financial networks play an essential role in asset valuation and investment decisions. Unlike road networks, financial networks are neither given nor static, posing significant challenges in learning meaningful networks and promoting their applications in price prediction. In this paper, we first apply the attention mechanism to connect the ",10.1145/3459637.3482413,2021,,ACM,10.1145/3459637.3482413
Towards Multi-Scenario Forecasting of Building Electricity Loads with Multimodal Data,"The rapid urbanization process has significantly increased building energy consumption and carbon emissions, making reliable electricity load forecasting crucial for energy management. However, accurate load forecasting faces three key challenges: (1) complex impact of multimodal data, (2) inter-building semantical relationships, and (3) uncertainty modeling of load patterns. To address these, we propose MMLoad, a novel diffusion-based multimodal framework for multi-scenario building load forecasting with three innovations: (i) a Multimodal Data Enhancement Pipeline generating rich building descriptions using LLMs and integrating temporal factors to analyze multimodal impacts; (ii) a Cross-modal Relation Encoder discovering latent interdependencies through hierarchical fusion, projecting buildings into a unified spatio-temporal (ST) embedding space; and (iii) a Scenario-Conditioned Diffusion Generator employing transformer-based denoising with Scenario-Adaptive Normalization (SAN) for diverse trajectory generation with uncertainty quantification. Experiments show MMLoad outperforms state-of-the-art baselines in accuracy while generating plausible future scenarios, establishing a new paradigm for multimodal learning in smart energy systems.",10.1145/3746027.3755775,2025,,ACM,10.1145/3746027.3755775
Telecommunication Traffic Forecasting via Multi-task Learning,"Accurate telecommunication time series forecasting is critical for smart management systems of cellular networks, and has a special challenge in predicting different types of time series simultaneously at one base station (BS), e.g., the SMS, Calls, and Internet. Unlike the well-studied single target forecasting problem for one BS, this distributed multi-target forecasting problem should take advantage of both the intra-BS dependence of different types of time series at the same BS and the inter-BS dependence of time series at different BS. To this end, we first propose a model to learn the inter-BS dependence by aggregating the multi-view dependence, e.g., from the viewpoint of SMS, Calls, and Internet. To incorporate the interBS dependence in time series forecasting, we then propose a Graph Gate LSTM (GGLSTM) model that includes a graph-based gate mechanism to unite those base stations with a strong dependence on learning a collaboratively strengthened prediction model. We also extract the intra-BS dependence by an attention network and use it in the final prediction. Our proposed approach is evaluated on two real-world datasets. Experiment results demonstrate the effectiveness of our model in predicting multiple types of telecom traffic at the distributed base stations.",10.1145/3539597.3570440,2023,,ACM,10.1145/3539597.3570440
Learning Dynamic Graphs from All Contextual Information for Accurate Point-of-Interest Visit Forecasting,"Forecasting the number of visits to Points-of-Interest (POI) in an urban area is critical for planning and decision making in various application domains, from urban planning and transportation management to public health and social studies. Although this forecasting problem can be formulated as a multivariate time-series forecasting task, current approaches cannot fully exploit the ever-changing multi-context correlations among POIs. Therefore, we propose Busyness Graph Neural Network (BysGNN), a temporal graph neural network designed to learn and uncover the underlying multi-context correlations between POIs for accurate visit forecasting. Unlike other approaches where only time-series data is used to learn a dynamic graph, BysGNN utilizes all contextual information and time-series data to learn an accurate dynamic graph representation. By incorporating all contextual, temporal, and spatial signals, we observe a significant improvement in our forecasting accuracy over state-of-the-art forecasting models in our experiments with real-world datasets across the United States.",10.1145/3589132.3625567,2023,,ACM,10.1145/3589132.3625567
Capturing Structural Evolution in Financial Markets with Graph Neural Time Series Models,"This paper proposes a stock price prediction method based on a graph neural network architecture. The method is designed to address key characteristics of the stock market, including high nonlinearity, multivariable dependencies, and dynamically changing structural relationships. It constructs a dynamic stock graph to represent the evolving relationship network among individual stocks over time. A temporal-aware graph neural network module is designed to jointly model node features through structural propagation and temporal dependence. Specifically, the model incorporates multi-source heterogeneous information to build the dynamic graph structure. This enables explicit representation of the time-varying linkages between stocks within the graph. Graph convolution is then applied to extract structural features at each time step. A temporal module is used to model the evolution of these features over time. To validate the effectiveness of the method, the model is compared with existing graph-based and time-series models across multiple evaluation metrics. Ablation studies, robustness tests, and performance assessments under different market conditions are conducted to comprehensively analyze the model's behavior in various scenarios. Experimental results show that the proposed method achieves low prediction error while maintaining strong stability and generalization ability. It significantly improves the accuracy of modeling asset price trends in financial markets. This study provides a unified solution for structural and dynamic aspects of the stock prediction problem and extends the application scope of graph neural networks in financial time series analysis.",10.1145/3767052.3767086,2025,,ACM,10.1145/3767052.3767086
Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation,"A Session-Based Recommendation (SBR) seeks to predict users’ future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model’s ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M3T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M2T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M3T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.",10.1145/3663760,2024,,ACM,10.1145/3663760
Fine-grained Urban Heat Island Effect Forecasting: A Context-aware Thermodynamic Modeling Framework,"Climate change and rapid urbanization have led to the Urban Heat Island (UHI) effect, resulting in higher temperatures in metropolitan areas and negatively impacting urban communities. Accurate UHI forecasting is crucial for identifying high-risk periods and locations, especially in cities with vulnerable populations. Current methods are limited by data granularity and inadequate modeling of regional thermodynamics, which affects both accuracy and spatio-temporal granularity. In this paper, we propose DeepUHI, a data-driven context-aware framework for modeling local thermodynamics based on the heat equation, alongside the SeoulTemp dataset, the first multi-modal dataset for UHI effect predictions at the street level. Our framework utilizes a heat decomposition method to represent urban thermodynamics through thermodynamic cycles and thermal flows, effectively integrating urban environmental data. Extensive experiments show that our framework improves accuracy in UHI effect prediction and warning tasks, outperforming leading models. We have integrated DeepUHI into our SeoUHI platform to provide hourly street-level UHI forecasting for Seoul. The code, platform, and dataset are accessible at https://github.com/CityMind-Lab/DeepUHI.",10.1145/3711896.3736962,2025,,ACM,10.1145/3711896.3736962
On Generalizing Static Node Embedding to Dynamic Settings,"Temporal graph embedding has been widely studied thanks to its superiority in tasks such as prediction and recommendation. Despite the advances in algorithms and novel frameworks such as deep learning, there has been relatively little work on systematically studying the properties of temporal network models and their cornerstones, the graph time-series representations that are used in these approaches. This paper aims to fill this gap by introducing a general framework that extends an arbitrary existing static embedding approach to handle dynamic tasks, and conducting a systematic study of seven base static embedding methods and six temporal network models. Our framework generalizes static node embeddings derived from the time-series representation of stream data to the dynamic setting by modeling the temporal dependencies with classic models such as the reachability graph. While previous works on dynamic modeling and embedding have focused on representing a stream of timestamped edges using a time-series of graphs based on a specific time-scale (eg, 1 month), we introduce the notion of an ε-graph time-series that uses a fixed number of edges for each graph, and show its superiority in practical settings over the standard solution. From the 42 methods that our framework subsumes, we find that leveraging the new ε-graph time-series representation and capturing temporal dependencies with the proposed reachability or summary graph tend to perform well. Furthermore, the new dynamic embedding methods based on our framework perform comparably and on average better than the state-of-the-art embedding methods designed specifically for temporal graphs in link prediction tasks.",10.1145/3488560.3498428,2022,,ACM,10.1145/3488560.3498428
SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding,"Knowledge graphs (KGs) have been increasingly employed for link prediction and recommendation using real-world datasets. However, the majority of current methods rely on static data, neglecting the dynamic nature and the hidden spatio-temporal attributes of real-world scenarios. This often results in suboptimal predictions and recommendations. Although there are effective spatio-temporal inference methods, they face challenges such as scalability with large datasets and inadequate semantic understanding, which impede their performance. To address these limitations, this paper introduces a novel framework - Simple Spatio-Temporal Knowledge Graph (SSTKG), for constructing and exploring spatio-temporal KGs. To integrate spatial and temporal data into KGs, our framework exploited through a new 3-step embedding method. Output embeddings can be used for future temporal sequence prediction and spatial information recommendation, providing valuable insights for various applications such as retail sales forecasting and traffic volume prediction. Our framework offers a simple but comprehensive way to understand the underlying patterns and trends in dynamic KG, thereby enhancing the accuracy of predictions and the relevance of recommendations. This work paves the way for more effective utilization of spatio-temporal data in KGs, with potential impacts across a wide range of sectors.",10.1145/3589334.3645441,2024,,ACM,10.1145/3589334.3645441
Long-Term Forecasting of Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis,"Long-term forecasting of multivariate urban data poses a significant challenge due to the complex spatiotemporal dependencies inherent in such datasets. This paper presents DST, a novel multivariate time-series forecasting model that integrates graph attention and temporal convolution within a Graph Neural Network (GNN) to effectively capture spatial and temporal dependencies, respectively. To enhance model performance, we apply a decomposition-based preprocessing step that isolates trend, seasonal, and residual components of the time series, enabling the learning of distinct graph structures for different time-series components. Extensive experiments on real-world urban datasets—including electricity demand, weather metrics, carbon intensity, and air pollution—demonstrate the effectiveness of DST across a range of forecast horizons, from several days to one month. Specifically, our approach achieves an average improvement of 2.89\% to 9.10\% in long-term forecasting accuracy over state-of-the-art time-series forecasting models.",10.1145/3736425.3770109,2025,,ACM,10.1145/3736425.3770109
Conv-Attention Model Based on Multivariate Time Series Prediction: The Cyanobacteria Bloom Case,"Multivariate time series forecasting problems are an important part of research in various fields at all times, such as financial and stock markets, natural disasters, disease prevention. However, forecasting has always been difficult due to its own reasons or external factors. In this paper, we propose a brand-new Conv-Attention network (CANet) for harmful algal blooms prediction. To capture more spatial dimension feature information, the network extracts the context dependency from each time series, and at the same time obtains the impact score between the interacting time series. In the previous stage of training, the feature factors are acquired through different convolution kernels. Then attention mechanism is adopted to model the processes that depend on mutual influence. To further enhance the robustness of the network, the CANet incorporates simple MLP layer-assisted training. The experimental results show that our proposed network performs well under the evaluation of the performance index.",10.1145/3501409.3501591,2022,,ACM,10.1145/3501409.3501591
On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper),"Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have not yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains, including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality, such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic large learning models (LLMs) can outperform task-specific fully supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image–based urban noise intensity classification, and remote sensing image scene classification), existing FMs still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing an FM for GeoAI is to address the multimodal nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal FM that can reason over various types of geospatial data through geospatial alignments. We conclude this article by discussing the unique risks and challenges to developing such a model for GeoAI.",10.1145/3653070,2024,,ACM,10.1145/3653070
Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay,"Multi-variate Time Series (MTS) forecasting has made large strides (with very negligible errors) through recent advancements in neural networks, e.g., Transformers. However, in critical situations like predicting gaming overindulgence that affects one's mental well-being; an accurate forecast without a contributing evidence (explanation) is irrelevant. Hence, it becomes important that the forecasts are Interpretable - intermediate representation of the forecasted trajectory is comprehensible; as well as Explainable - attentive input features and events are accessible for a personalized and timely intervention of players at risk. While the contributing state of the art research on interpretability primarily focuses on temporally-smooth single-process driven time series data, our online multi-player gameplay data demonstrates intractable temporal randomness due to intrinsic orthogonality between player's game outcome and their intent to engage further. We introduce a novel deep Actionable Forecasting Network (AFN), which addresses the inter-dependent challenges associated with three exclusive objectives - 1) forecasting accuracy; 2) smooth comprehensible trajectory and 3) explanations via multi-dimensional input features while tackling the challenges introduced by our non-smooth temporal data, together in one single solution. AFN establishes a new benchmark via: (i) achieving 25\% improvement on the MSE of the forecasts on player data in comparison to the SOM-VAE based SOTA networks; (ii) attributing unfavourable progression of a player's time series to a specific future time step(s), with the premise of eliminating near-future overindulgent player volume by over 18\% with player specific actionable inputs feature(s) and (iii) proactively detecting over 23\% (100\% jump from SOTA) of the to-be overindulgent, players on an average, 4 weeks in advance.",10.1145/3637528.3671657,2024,,ACM,10.1145/3637528.3671657
Research on the application of artificial intelligence algorithms in drought prediction,"With the aggravation of global warming, drought has caused more and more serious impact on society and national economy, so the accurate prediction of drought is also the most important thing to deal with the frequent drought problem. On the other hand, artificial intelligence technology has shown its advantages in various fields and has a broad application prospects, so it is gradually being used in drought prediction. In this paper, drought prediction algorithms in recent years are reviewed, and existing cases of drought prediction using different arithmetic models for different drought indices are studied. The advantages and disadvantages of different algorithms are compared, the challenges of drought prediction are summarized, and the future of drought prediction is prospected.",10.1145/3573428.3573753,2023,,ACM,10.1145/3573428.3573753
Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution,"Traffic prediction is the cornerstone of intelligent transportation system. Accurate traffic forecasting is essential for the applications of smart cities, i.e., intelligent traffic management and urban planning. Although various methods are proposed for spatio-temporal modeling, they ignore the dynamic characteristics of correlations among locations on road network. Meanwhile, most Recurrent Neural Network based works are not efficient enough due to their recurrent operations. Additionally, there is a severe lack of fair comparison among different methods on the same datasets. To address the above challenges, in this article, we propose a novel traffic prediction framework, named Dynamic Graph Convolutional Recurrent Network (DGCRN). In DGCRN, hyper-networks are designed to leverage and extract dynamic characteristics from node attributes, while the parameters of dynamic filters are generated at each time step. We filter the node embeddings and then use them to generate dynamic graph, which is integrated with pre-defined static graph. As far as we know, we are first to employ a generation method to model fine topology of dynamic graph at each time step. Furthermore, to enhance efficiency and performance, we employ a training strategy for DGCRN by restricting the iteration number of decoder during forward and backward propagation. Finally, a reproducible standardized benchmark and a brand new representative traffic dataset are opened for fair comparison and further research. Extensive experiments on three datasets demonstrate that our model outperforms 15 baselines consistently. Source codes are available at .",10.1145/3532611,2023,,ACM,10.1145/3532611
Mini-Game Lifetime Value Prediction in WeChat,"The LifeTime Value (LTV) prediction, which endeavors to forecast the cumulative purchase contribution of a user to a particular item, remains a vital challenge that advertisers are keen to resolve. A precise LTV prediction system enhances the alignment of user interests with meticulously designed advertisements, thereby generating substantial profits for advertisers. Nonetheless, this issue is complicated by the paucity of data typically observed in real-world advertising scenarios. The purchase rate among registered users is often as critically low as 0.1\%, resulting in a dataset where the majority of users make only several purchases. Consequently, there is insufficient supervisory signal for effectively training the LTV prediction model. An additional challenge emerges from the interdependencies among tasks with high correlation. It is a common practice to estimate a user's contribution to a game over a specified temporal interval. Varying the lengths of these intervals corresponds to distinct predictive tasks, which are highly correlated. For instance, predictions over a 7-day period are heavily reliant on forecasts made over a 3-day period, where exceptional cases can adversely affect the accuracy of both tasks. In order to comprehensively address the aforementioned challenges, we introduce an innovative framework denoted as Graph-Represented Pareto-Optimal LifeTime Value prediction (GRePO-LTV). Graph representation learning is initially employed to address the issue of data scarcity. Subsequently, Pareto-Optimization is utilized to manage the interdependence of prediction tasks. Our method is evaluated using a proprietary offline mini-game recommendation dataset in conjunction with an online A/B test. The implementation of our method results in a significant enhancement within the offline dataset. Moreover, the A/B test demonstrates encouraging outcomes, increasing average Gross Merchandise Value (GMV) by 8.4\%.",10.1145/3711896.3737248,2025,,ACM,10.1145/3711896.3737248
COMET: NFT Price Prediction with Wallet Profiling,"As the non-fungible token (NFT) market flourishes, price prediction emerges as a pivotal direction for investors gaining valuable insight to maximize returns. However, existing works suffer from a lack of practical definitions and standardized evaluations, limiting their practical application. Moreover, the influence of users' multi-behaviour transactions that are publicly accessible on NFT price is still not explored and exhibits challenges. In this paper, we address these gaps by presenting a practical and hierarchical problem definition. This approach unifies both collection-level and token-level task and evaluation methods, which cater to varied practical requirements of investors. To further understand the impact of user behaviours on the variation of NFT price, we propose a general wallet profiling framework and develop a COmmunity enhanced Multi-bEhavior Transaction graph model, named COMET. COMET profiles wallets with a comprehensive view and considers the impact of diverse relations and interactions within the NFT ecosystem on NFT price variations, thereby improving prediction performance. Extensive experiments conducted in our deployed system demonstrate the superiority of COMET, underscoring its potential in the insight toolkit for NFT investors.",10.1145/3637528.3671621,2024,,ACM,10.1145/3637528.3671621
Cost-effective Data Labelling for Graph Neural Networks,"Active learning (AL), that aims to label limited data samples to effectively train the model, stands as a very cost-effective data labelling strategy in machine learning. Given the state-of-the-art performance GNNs have achieved in graph-based tasks, it is critical to design proper AL methods for graph neural networks (GNNs). However, existing GNN-based AL methods require considerable supervised information to guide the AL process, such as the GNN model to use, and initially labelled nodes and labels of newly selected nodes. Such dependency on supervised information limits both flexibility and scalabilty. In this paper, we propose an unsupervised, scalable and flexible AL method - it incurs low memory footprints and time cost, is flexible to the choice of underlying GNNs, and operates without requiring GNN-model-specific knowledge or labels of selected nodes. Specifically, we leverage the commonality of existing GNNs to reformulate the unsupervised AL problem as the Aggregation Involvement Maximization (AIM) problem. The objective of AIM is to maximize the involvement or participation of all nodes during the feature aggregation process of GNNs for nodes to be labelled. In this way, the aggregated features of labelled nodes can be diversified to a large extent, thereby benefiting the training of feature transformation matrices which are major trainable components in GNNs. We prove that the AIM problem is NP-hard and propose an efficient solution with theoretical guarantees. Extensive experiments on public datasets demonstrate the effectiveness, scalability and flexibility of our method. Our study is highly relevant to the track ",10.1145/3589334.3645339,2024,,ACM,10.1145/3589334.3645339
Entropy Causal Graphs for Multivariate Time Series Anomaly&nbsp;Detection,"Many multivariate time series anomaly detection frameworks have been proposed and widely applied. However, most of these frameworks do not consider intrinsic relationships between variables in multivariate time series data, thus ignoring the causal relationship among variables and degrading anomaly detection performance. This work proposes a novel framework called CGAD, an entropy causal graph for multivariate time series Anomaly Detection. CGAD utilizes transfer entropy to construct graph structures that unveil the underlying causal relationships among time series data. Weighted graph convolutional networks combined with causal convolutions are employed to model both the causal graph structures and the temporal patterns within multivariate time series data. Furthermore, CGAD applies anomaly scoring, leveraging median absolute deviation-based normalization to improve the robustness of the anomaly identification process. Extensive experiments demonstrate that CGAD outperforms state-of-the-art methods on real-world datasets with a 9\% average improvement in terms of three different multivariate time series anomaly detection metrics.",10.1145/3757922,2025,,ACM,10.1145/3757922
Ranking on Dynamic Graphs: An Effective and Robust Band-Pass Disentangled Approach,"Ranking is an essential and practical task on dynamic graphs, which aims to prioritize future interaction candidates for given queries. While existing solutions achieve promising ranking performance, they leverage a single listwise loss to jointly optimize candidate sets, which leads to the gradient vanishing issue; and they employ neural networks to model complex temporal structures within a shared latent space, which fails to accurately capture multi-scale temporal patterns due to the frequency aliasing issue. To address these issues, we propose BandRank, a novel and robust band-pass disentangled ranking approach for dynamic graphs in the frequency domain. Concretely, we propose a band-pass disentangled representation (BPDR) approach, which disentangles complex temporal structures into multiple frequency bands and employs non-shared frequency-enhanced multilayer perceptrons (MLPs) to model each band independently. We prove that our BPDR approach ensures effective multi-scale learning for temporal structures by demonstrating its multi-scale global convolution property. Besides, we design a robust Harmonic Ranking (HR) loss to jointly optimize candidate sets and continuously track comparisons between real and virtual candidates, where we theoretically guarantee its ability to alleviate the gradient vanishing issue. Extensive experimental results show that our BandRank achieves an average improvement of 21.31\% against eight baselines while demonstrating superior robustness across different learning scenarios.",10.1145/3696410.3714943,2025,,ACM,10.1145/3696410.3714943
HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting,"Time series forecasting is a critical and challenging task in practical application. Recent advancements in pre-trained foundation models for time series forecasting have gained significant interest. However, current methods often overlook the multi-scale nature of time series, which is essential for accurate forecasting. To address this, we propose HiMTM, a hierarchical multi-scale masked time series modeling with self-distillation for long-term forecasting. HiMTM integrates four key components: (1) hierarchical multi-scale transformer (HMT) to capture temporal information at different scales; (2) decoupled encoder-decoder (DED) that directs the encoder towards feature extraction while the decoder focuses on pretext tasks; (3) hierarchical self-distillation (HSD) for multi-stage feature-level supervision signals during pre-training; and (4) cross-scale attention fine-tuning (CSA-FT) to capture dependencies between different scales for downstream tasks. These components collectively enhance multi-scale feature extraction in masked time series modeling, improving forecasting accuracy. Extensive experiments on seven mainstream datasets show that HiMTM surpasses state-of-the-art self-supervised and end-to-end learning methods by a considerable margin of 3.16-68.54\%. Additionally, HiMTM outperforms the latest robust self-supervised learning method, PatchTST, in cross-domain forecasting by a significant margin of 2.3\%. The effectiveness of HiMTM is further demonstrated through its application in natural gas demand forecasting.",10.1145/3627673.3679741,2024,,ACM,10.1145/3627673.3679741
Fusing Narrative Semantics for Financial Volatility Forecasting,"We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.",10.1145/3768292.3771256,2025,,ACM,10.1145/3768292.3771256
Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask,"Time Series Representation Learning (TSRL) focuses on generating informative representations for various Time Series (TS) modeling tasks. Traditional Self-Supervised Learning (SSL) methods in TSRL fall into four main categories: reconstructive, adversarial, contrastive, and predictive, each with a common challenge of sensitivity to noise and intricate data nuances. Recently, diffusion-based methods have shown advanced generative capabilities. However, they primarily target specific application scenarios like imputation and forecasting, leaving a gap in leveraging diffusion models for generic TSRL. Our work, Time Series Diffusion Embedding (TSDE), bridges this gap as the first diffusion-based SSL TSRL approach. TSDE segments TS data into observed and masked parts using an Imputation-Interpolation-Forecasting (IIF) mask. It applies a trainable embedding function, featuring dual-orthogonal Transformer encoders with a crossover mechanism, to the observed part. We train a reverse diffusion process conditioned on the embeddings, designed to predict noise added to the masked part. Extensive experiments demonstrate TSDE's superiority in imputation, interpolation, forecasting, anomaly detection, classification, and clustering. We also conduct an ablation study, present embedding visualizations, and compare inference speed, further substantiating TSDE's efficiency and validity in learning representations of TS data.",10.1145/3637528.3671673,2024,,ACM,10.1145/3637528.3671673
Temporal Implicit Multimodal Networks for Investment and Risk Management,"Many deep learning works on financial time-series forecasting focus on predicting future prices/returns of individual assets with numerical price-related information for trading, and hence propose models designed for univariate, single-task, and/or unimodal settings. Forecasting for investment and risk management involves multiple tasks in multivariate settings: forecasts of expected returns and risks of assets in portfolios, and correlations between these assets. As different sources/types of time-series influence future returns, risks, and correlations of assets in different ways, it is also important to capture time-series from different modalities. Hence, this article addresses financial time-series forecasting for investment and risk management in a multivariate, multitask, and multimodal setting. Financial time-series forecasting, however, is challenging due to the low signal-to-noise ratios typical in financial time-series, and as intra-series and inter-series relationships of assets evolve across time. To address these challenges, our proposed Temporal Implicit Multimodal Network (TIME) model learns implicit inter-series relationship networks between assets from multimodal financial time-series at multiple time-steps adaptively. TIME then uses dynamic network and temporal encoding modules to jointly capture such evolving relationships, multimodal financial time-series, and temporal representations. Our experiments show that TIME outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management applications.",10.1145/3643855,2024,,ACM,10.1145/3643855
Network Filtering of Spatial-temporal GNN for Multivariate Time-series Prediction,"We propose an architecture for multivariate time-series prediction that integrates a spatial-temporal graph neural network with a filtering module which filters the inverse correlation matrix into a sparse network structure. In contrast with existing sparsification methods adopted in graph neural networks, our model explicitly leverages time-series filtering to overcome the low signal-to-noise ratio typical of complex systems data. We present a set of experiments, where we predict future sales volume from a synthetic time-series sales volume dataset. The proposed spatial-temporal graph neural network displays superior performances to baseline approaches with no graphical information, fully connected, disconnected graphs, and unfiltered graphs, as well as the state-of-the-art spatial-temporal GNN. Comparison of the results with Diffusion Convolutional Recurrent Neural Network (DCRNN) suggests that, by combining a (inferior) GNN with graph sparsification and filtering, one can achieve comparable or better efficacy than the state-of-the-art in multivariate time-series regression.",10.1145/3533271.3561678,2022,,ACM,10.1145/3533271.3561678
TimesBERT: A BERT-Style Foundation Model for Time Series Understanding,"Time series analysis is crucial in diverse scenarios. Beyond forecasting, considerable real-world tasks are categorized into classification, imputation, and anomaly detection, underscoring different capabilities termed time series understanding in this paper. While GPT-style models have been positioned as foundation models for time series forecasting, the BERT-style architecture, which has made significant advances in natural language understanding, has not been fully unlocked for time series understanding, possibly attributed to the undesirable dropout of essential elements of BERT. In this paper, inspired by the shared multi-granularity structure between multivariate time series and multisentence documents, we design TimesBERT to learn generic representations of time series including temporal patterns and variate-centric characteristics. In addition to a natural adaptation of masked modeling, we propose a parallel task of functional token prediction to embody vital multi-granularity structures. Our model is pre-trained on 260 billion time points across diverse domains. Leveraging multi-granularity representations, TimesBERT achieves state-of-the-art performance across four typical downstream understanding tasks, outperforming task-specific models and language pre-trained backbones, positioning it as a versatile foundation model for time series understanding.",10.1145/3746027.3755238,2025,,ACM,10.1145/3746027.3755238
Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools,"Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNing framework with Maskable stOck REpresentation to handle PM with CSPs through one-shot training in a global stock pool (GSP). Specifically, we first introduce a mechanism to mask out the representation of the stocks outside the target pool. Second, we learn meaningful stock representations through a self-supervised masking and reconstruction process. Third, a re-weighting mechanism is designed to make the portfolio concentrate on favorable stocks and neglect the stocks outside the target pool. Through extensive experiments on 8 subset stock pools of the US stock market, we demonstrate that EarnMore significantly outperforms 14 state-of-the-art baselines in terms of 6 popular financial metrics with over 40\% improvement on profit. Code is available in PyTorch1.",10.1145/3589334.3645615,2024,,ACM,10.1145/3589334.3645615
Credit Card Transaction Trend Forecasting Based on Graph Neural Network,"Accurate prediction of customer transaction trend can provide effective technical support for banks in managing their credit card business. Customer transaction behaviors often involve multiple types of consumption, and existing forecasting methods typically concatenate multi-type features into a unified input, which inadequately accounts for structural differences and interactions among different transaction types. To address this issue, this paper proposes TTF-GNN, a credit card transaction trend forecasting model based on graph neural networks. The proposed method effectively explores customer behavioral characteristics in multi-type transaction scenarios by integrating type-aware embedding with time-varying sensitive graph construction. It jointly captures temporal dynamics and interdependencies among multiple transaction types through spatio-temporal graph convolution, thereby enabling accurate prediction of future trends. Experimental results on three public datasets demonstrate that the proposed method significantly outperforms several exiting forecasting models across multiple evaluation metrics, confirming its effectiveness and adaptability.",10.1145/3762249.3762299,2025,,ACM,10.1145/3762249.3762299
Trending Now: Modeling Trend Recommendations,"Modern recommender systems usually include separate recommendation carousels such as ‘trending now’ to list trending items and further boost their popularity, thereby attracting active users. Though widely useful, such ‘trending now’ carousels typically generate item lists based on simple heuristics, e.g., the number of interactions within a time interval, and therefore still leave much room for improvement. This paper aims to systematically study this under-explored but important problem from the new perspective of time series forecasting. We first provide a set of rigorous definitions related to item trendiness and formulate the trend recommendation task as a one-step time series forecasting problem. We then propose a deep latent variable model, dubbed Trend Recommender (TrendRec), to forecast items’ future trends and generate trending item lists. Furthermore, we design associated evaluation protocols for trend recommendation. Experiments on real-world datasets from various domains show that our TrendRec significantly outperforms the baselines, verifying our model’s effectiveness.",10.1145/3604915.3608810,2023,,ACM,10.1145/3604915.3608810
Self-supervised Learning for Accelerometer-based Human Activity Recognition: A Survey,"Self-supervised learning (SSL) has emerged as a promising alternative to purely supervised learning, since it can learn from labeled and unlabeled data using a pre-train-then-fine-tune strategy, achieving state-of-the-art performances across many research areas. The field of accelerometer-based human activity recognition (HAR) can benefit from SSL since unlabeled data can be collected cost-efficiently due to the ubiquitous nature of sensors embedded in smart devices, which is in contrast to labeled data, that require a costly annotation process. Motivated by the success of SSL and the lack of surveys on SSL for HAR, this survey comprehensively examines 52 SSL methods applied to HAR, and categorizes them into four SSL paradigms based on pre-training objectives. We discuss SSL strategies, evaluation protocols, and utilized datasets. We highlight limitations in current methodologies, including little large-scale pre-training, the absence of foundation models, as well as the scarcity of systematic domain shift experiments and domain knowledge utilization. Notably, the diversity in evaluation protocols across papers poses a considerable challenge when comparing methods. Future directions outlined in this survey include the development of an SSL framework for HAR to enable standardized benchmarking and large-scale pre-training, along with integrating domain knowledge to enhance model performance.",10.1145/3699767,2024,,ACM,10.1145/3699767
From News to Returns: A Granger-Causal Hypergraph Transformer on the Sphere,"We propose the Causal Sphere Hypergraph Transformer (CSHT), a novel architecture for interpretable financial time-series forecasting that unifies Granger-causal hypergraph structure, Riemannian geometry, and causally masked Transformer attention. CSHT models the directional influence of financial news and sentiment on asset returns by extracting multivariate Granger-causal dependencies, which are encoded as directional hyperedges on the surface of a hypersphere. Attention is constrained via angular masks that preserve both temporal directionality and geometric consistency. Evaluated on S&amp;P 500 data from 2018 to 2023, including the 2020 COVID-19 shock, CSHT consistently outperforms baselines across return prediction, regime classification, and top-asset ranking tasks. By enforcing predictive causal structure and embedding variables in a Riemannian manifold, CSHT delivers both robust generalisation across market regimes and transparent attribution pathways from macroeconomic events to stock-level responses. These results suggest that CSHT is a principled and practical solution for trustworthy financial forecasting under uncertainty.",10.1145/3768292.3770414,2025,,ACM,10.1145/3768292.3770414
Stock price prediction model integrating autoencoder and bidirectional LSTM——Optimization based on attention mechanism,"In recent years, financial time series forecasting methods based on deep neural network architectures have been proposed one after another, but there is significant heterogeneity in the performance of each model. This research systematically integrates the feature representation advantages of autoencoders (AE) and the time series modeling capabilities of bidirectional long short-term memory networks (BiLSTM) to construct a new framework for predicting stock market price trends. In terms of technical implementation, a data preprocessing mechanism based on stacked denoising autoencoders is first designed to effectively capture the non-stationary characteristics and implicit patterns of financial time series. Secondly, the bidirectional gated recurrent unit is innovatively embedded in the encoding-decoding architecture to achieve bidirectional time series dependency modeling of multi-dimensional market information, and then a parameter adaptive weighting mechanism is introduced to improve the contribution of prediction-related features through dynamic feature importance evaluation. The final prediction result is obtained through nonlinear mapping of the fully connected layer. Experimental results show that the hybrid model significantly outperforms other baseline models on two stock trading datasets.",10.1145/3745133.3745179,2025,,ACM,10.1145/3745133.3745179
Decoupled Progressive Distillation for Sequential Prediction with Interaction Dynamics,"Sequential prediction has great value for resource allocation due to its capability in analyzing intents for next prediction. A fundamental challenge arises from real-world interaction dynamics where similar sequences involving multiple intents may exhibit different next items. More importantly, the character of volume candidate items in sequential prediction may amplify such dynamics, making deep networks hard to capture comprehensive intents. This article presents a sequential prediction framework with Decoupled Progressive Distillation (DePoD), drawing on the progressive nature of human cognition. We redefine target and non-target item distillation according to their different effects in the decoupled formulation. This can be achieved through two aspects: (1) Regarding how to learn, our target item distillation with progressive difficulty increases the contribution of low-confidence samples in the later training phase while keeping high-confidence samples in the earlier phase. And, the non-target item distillation starts from a small subset of non-target items from which size increases according to the item frequency. (2) Regarding whom to learn from, a difference evaluator is utilized to progressively select an expert that provides informative knowledge among items from the cohort of peers. Extensive experiments on four public datasets show DePoD outperforms state-of-the-art methods in terms of accuracy-based metrics.",10.1145/3632403,2023,,ACM,10.1145/3632403
Graph Deep Factors for Forecasting with Applications to Cloud Resource Allocation,"Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, we propose a relational global model that learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, we learn a relational local model that not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average.",10.1145/3447548.3467357,2021,,ACM,10.1145/3447548.3467357
Data Quality-based Gradient Optimization for Recurrent Neural Networks,"Time series forecasting holds significant value in various application scenarios. However, existing forecasting methods primarily focus on optimizing model architecture while neglecting the substantial impact of data quality on model learning. In this study, we aim to enhance model performance by optimizing data utilization based on data quality and propose a Data Quality-based Gradient Optimization (DQGO) method to facilitate training of recurrent neural networks. Firstly, we define sample quality as the matching degree between samples and model, and suggest using the attention entropy to calculate the sample quality through an attention mechanism. Secondly, we optimize the model's gradient vector by giving different weights to samples with different quality. Through experiments conducted on six datasets, the results demonstrate that DQGO significantly improves LSTM's performance. In certain cases, it even surpasses the state-of-the-art models.",10.1145/3589335.3651918,2024,,ACM,10.1145/3589335.3651918
Nowcast-to-Forecast: Token-Based Multiple Remote Sensing Data Fusion for Precipitation Forecast,"Accurate short-term precipitation forecast is of social and economic significance for preventing severe weather damage. Deep learning has been rapidly adopted in nowcasting based on weather radar, which plays a key role in preventing dangerous weather conditions such as torrential rainfall. However, the limited observation range of the radar imposes constraints on shorter forecast lead times. Securing a sufficient lead time for timely flood warnings and emergency responses is crucial. Here, we propose a novel GAN-based framework that combines radar and satellite data to extend forecast lead time. First, we tokenize the satellite image to align with radar dimensions and combine the satellite and radar data. We then apply positional encoding to add positional information. Second, we design the self-conditioned generator to estimate distributions of various rainfall intensities. Finally, we employ Gaussian Fourier features to map the input noise into a continuous representation. The proposed framework realistically and accurately produces time series images of various precipitation types. Furthermore, our multisource data-driven system outperforms numerical weather prediction at forecasts of up to 6 hours in South Korea.",10.1145/3583780.3614702,2023,,ACM,10.1145/3583780.3614702
A Survey on Recommender Systems Using Graph Neural Network,"The expansion of the Internet has resulted in a change in the flow of information. With the vast amount of digital information generated online, it is easy for users to feel overwhelmed. Finding the specific information can be a challenge, and it can be difficult to distinguish credible sources from unreliable ones. This has made recommender system (RS) an integral part of the information services framework. These systems alleviate users from information overload by analyzing users’ past preferences and directing only desirable information toward users. Traditional RSs use approaches like collaborative and content-based filtering to generate recommendations. Recently, these systems have evolved to a whole new level, intuitively optimizing recommendations using deep network models. graph neural networks (GNNs) have become one of the most widely used approaches in RSs, capturing complex relationships between users and items using graphs. In this survey, we provide a literature review of the latest research efforts done on GNN-based RSs. We present an overview of RS, discuss its generalized pipeline and evolution with changing learning approaches. Furthermore, we explore basic GNN architecture and its variants used in RSs, their applications, and some critical challenges for future research.",10.1145/3694784,2024,,ACM,10.1145/3694784
KGDA: A Knowledge Graph Driven Decomposition Approach for Cellular Traffic Prediction,"Understanding and accurately predicting cellular traffic data is vital for communication operators and device users, as it facilitates efficient resource allocation and ensures superior service quality. However, large-scale cellular traffic data forecasting remains challenging due to intricate temporal variations and complex spatial relationships. This article proposes a Knowledge Graph Driven Decomposition Approach (KGDA) for precise cellular traffic prediction. The KGDA breaks down the impact of static environmental factors and dynamic autocorrelations of cellular traffic time series, enabling the capture of overall traffic changes and understanding of traffic dependence on past values. Specifically, we propose an urban knowledge graph to capture the static environmental context of base stations, mapping these entities into the same latent space while retaining static environmental knowledge. The cellular traffic is divided into a regular pattern and fluctuating residual components, with the KGDA comprising four modules: a Knowledge Graph Representation Learning model, a traffic regular pattern prediction module, a traffic residual dynamic prediction module, and an attentional fusion module. The first leverages graph neural networks to extract spatial contexts and predict regular patterns, the second utilizes the Bi-directional Long Short-Term Memory (Bi-LSTM) model to capture autocorrelations of traffic time series, and the final module integrates the patterns and residuals to produce the final prediction result. Comprehensive experiments demonstrate that our proposed model outperforms state-of-the-art models by more than 10\% in forecasting cellular traffic.",10.1145/3690650,2024,,ACM,10.1145/3690650
GeoIndia V2: A Unified Graph and Language Model for Context-Aware Geocoding,"Geocoding in India presents unique challenges due to the unstructured, multilingual and diverse nature of its address systems. While recent advances in geospatial AI have explored the combination of spatial and semantic cues, existing methods often fall short in effectively integrating both dimensions for robust address resolution. In this work, we propose GeoIndia-V2, an enhanced version of GeoIndia [21], that unifies geospatial and semantic modeling through a novel fusion framework. Our unified model combines the Graphormer architecture [27] and a Pre-trained Transformer based Language Model (PTLM) that is trained from scratch on proprietary Indian address data, using our proposed Key Modulated Cross-Attention (KMCA) mechanism. KMCA enables deep cross-modal interaction between geospatial topology and linguistic structure and allows the model to reason contextually across both geographic and textual dimention, effectively handling the semantic intricacies of Indian addresses-including colloquial usage, inconsistent formatting, and multilinguality. We leverage last-mile e-commerce delivery data to construct a fine-grained graph of neighbourhood connectivity, enabling Graphormer to capture rich spatial relationships. Unlike prior methods that rely on self-loops, we generate graphs dynamically at inference time to exploit Graphormer's topological strength. Additionally, we introduce a generative decoding strategy for predicting hierarchical H3 cells. https://www.uber.com/en-IN/blog/h3/, moving beyond conventional bit-wise classification approaches. To the best of our knowledge, this is the first method to explicitly fuse graph-based geospatial learning with language-driven semantic modeling via cross-attention in the Indian geocoding context. Our approach significantly outperforms existing solutions and marks a substantial advancement toward building scalable real-world geocoding systems for complex address ecosystems like India.",10.1145/3746252.3761512,2025,,ACM,10.1145/3746252.3761512
Long-Term Effect Estimation with Surrogate Representation,"There are many scenarios where short- and long-term causal effects of an intervention are different. For example, low-quality ads may increase short-term ad clicks but decrease the long-term revenue via reduced clicks. This work, therefore, studies the the problem of long-term effect where the outcome of primary interest, orprimary outcome, takes months or even years to accumulate. The observational study of long-term effect presents unique challenges. First, the confounding bias causes large estimation error and variance, which can further accumulate towards the prediction of primary outcomes. Second, short-term outcomes are often directly used as the proxy of the primary outcome, i.e., thesurrogate. Nevertheless, this method entails the strong surrogacy assumption that is often impractical. To tackle these challenges, we propose to build connections between long-term causal inference and sequential models in machine learning. This enables us to learnsurrogate representations that account for thetemporal unconfoundedness and circumvent the stringent surrogacy assumption by conditioning on the inferred time-varying confounders. Experimental results show that the proposed framework outperforms the state-of-the-art.",10.1145/3437963.3441719,2021,,ACM,10.1145/3437963.3441719
PRO-MTL: Parameterized Route Optimization Using Multi-Task Learning,"In the current ridesharing scenario, finding a compatible passenger is highly challenging and largely dependent on chance. Existing algorithms prioritize the shortest route without considering future requests or traffic conditions, which reduces the likelihood of matching with another compatible passenger. This uncertainty leads to increased congestion along shortest routes and fewer ridesharing trips overall. This article proposes a route recommendation strategy that goes beyond the shortest route, aiming to address these issues. The proposed strategy results in higher demand, reduced congestion, broader coverage of points of interest, and an increased probability of finding compatible passengers during a trip. To achieve this, we introduce a time-series forecasting method leveraging a multi-task long short-term memory model to predict demand and traffic patterns in city-zone neighborhoods. These predictions are then used to recommend optimized routes. To evaluate our approach, we tested it on three datasets containing trip and traffic details from New York City, Los Angeles, and Shenzhen. Our model demonstrated 96\% accuracy and a 2\% RMSE loss in predicting the expected number of passengers. Furthermore, during route recommendations, we observed a 23\% increase in passenger count for 97\% of trips and a reduction in travel time for the shortest path for 60\% of trips. In light of the above experimentation, we believe that while our approach recommends a longer route than the shortest one (for 40\% of cases), it helps taxi drivers find compatible passengers on most trips which increases the profit of ridesharing services, and reduces the waiting time for passengers. The source code and dataset used in the paper is available at:",10.1145/3718092,2025,,ACM,10.1145/3718092
RCCNet: A Spatial-Temporal Neural Network Model for Logistics Delivery Timely Rate Prediction,"In logistics service, the delivery timely rate is a key experience indicator, which is highly essential to the competitive advantage of express companies. Prediction on it enables intervention on couriers with low predicted results in advance, thus ensuring employee productivity and customer satisfaction. Currently, few related works focus on couriers’ level delivery timely rate prediction, and there are complex spatial correlations between couriers and road districts in the express scenario, which makes traditional real-time prediction approaches hard to utilize. To deal with this, we propose a deep spatial-temporal neural network, RCCNet to model spatial-temporal correlations. Specifically, we adopt Node2vec, which can encode the road network-based graph directly to capture spatial correlations between road districts. Further, we calculate couriers’ historical time-series similarity to build a graph and employ graph convolutional networks to capture the correlation between couriers. We also leverage historical sequential information with long short-term memory networks. We conduct experiments with real-world express datasets. Compared with other competitive baseline methods widely used in industry, the experiment results demonstrate its superior performance over multiple baselines.",10.1145/3690649,2024,,ACM,10.1145/3690649
MARINA: An MLP-Attention Model for Multivariate Time-Series Analysis,"The proliferation of real-time monitoring applications such as Artificial Intelligence for IT Operations (AIOps) and the Internet of Things (IoT) has led to the generation of a vast amount of time-series data. To extract the underlying value of the data, both the industry and the academia are in dire need of efficient and effective methods for time-series analysis. To this end, in this paper, we propose a Multi-layer perceptron (&lt;u&gt;M&lt;/u&gt;LP)-&lt;u&gt;a&lt;/u&gt;ttention based multivariate time-se&lt;u&gt;ri&lt;/u&gt;es a&lt;u&gt;na&lt;/u&gt;lysis model MARINA. MARINA is designed to simultaneously learn the temporal and spatial correlations among multivariate time-series. Also, the model is versatile in that it is suitable for major time-series analysis tasks such as forecasting and anomaly detection. Through extensive comparisons with the representative multivariate time-series forecasting and anomaly detection algorithms, MARINA is shown to achieve state-of-the-art (SOTA) performance in both forecasting and anomaly detection tasks.",10.1145/3511808.3557386,2022,,ACM,10.1145/3511808.3557386
Multi-Temporal Relationship Inference in Urban Areas,"Finding multiple temporal relationships among locations can benefit a bunch of urban applications, such as dynamic offline advertising and smart public transport planning. While some efforts have been made on finding static relationships among locations, little attention is focused on studying time-aware location relationships. Indeed, abundant location-based human activities are time-varying and the availability of these data enables a new paradigm for understanding the dynamic relationships in a period among connective locations. To this end, we propose to study a new problem, namely multi-Temporal relationship inference among locations (Trial for short), where the major challenge is how to integrate dynamic and geographical influence under the relationship sparsity constraint. Specifically, we propose a solution to Trial with a graph learning scheme, which includes a spatially evolving graph neural network (SEENet) with two collaborative components: spatially evolving graph convolution module (SEConv) and spatially evolving self-supervised learning strategy (SE-SSL). SEConv performs the intra-time aggregation and inter-time propagation to capture the multifaceted spatially evolving contexts from the view of location message passing. In addition, SE-SSL designs time-aware self-supervised learning tasks in a global-local manner with additional evolving constraint to enhance the location representation learning and further handle the relationship sparsity. Finally, experiments on four real-world datasets demonstrate the superiority of our method over several state-of-the-art approaches.",10.1145/3580305.3599440,2023,,ACM,10.1145/3580305.3599440
ODGS: Dependency-Aware Scheduling for High-Level Synthesis with Graph Neural Network and Reinforcement Learning,"Scheduling determines the execution order and time of operations in a program. The order is related to operation dependencies, including data and resource dependencies. Data dependency is intrinsic in a program, showing operation data flow. Resource dependency is determined by scheduling methods, resolving operation resource contention. Existing scheduling methods focus on data dependency, rather than building and exploiting operation dependency graph (ODG) with extra resource dependency. As ODG contains all dependencies determining operation execution order, it provides global program information, facilitating efficient scheduling. In this work, we propose ODGS, a dependency-aware scheduling method for high-level synthesis with graph neural network (GNN) and reinforcement learning (RL). We adopt GNN to perceive accurate relations between operations. We use the relations to guide an RL agent in building a complete ODG. We perform feedback-guided iterative scheduling with ODG to converge to a high-quality solution. Experiments show that our method reduces 16.4\% latency and 26.5\% resource usage on average, compared with the latest RL-based method. Moreover, we reduce an average 2.9\% latency over the GNN-based method under the same resource usage. The same resource usage is obtained by improving the GNN-based method with manual resource constraint tuning. Without tuning, its basic version consumes an average 237.6\% more resources than our method.",10.1145/3721289,2025,,ACM,10.1145/3721289
LLGformer: Learnable Long-range Graph Transformer for Traffic Flow Prediction,"Traffic prediction plays a pivotal role in intelligent transportation systems. Most existing studies only predict traffic flow for a specific time period based on traffic data from a short period, such as an hour, overlooking the influence of periodicity present in traffic data. Moreover, most of the existing advanced methods rely on manually constructed spatio-temporal graphs for joint modeling, or use pure spatial and pure temporal modules to separately model spatial and temporal features, which limits the learning of complex spatio-temporal patterns in traffic data due to structural inadequacies in the model. To address these issues, we propose a novel approach by constructing a learnable long-range spatio-temporal graph, which can better capture complex patterns in traffic data. We introduce a new model, LLGformer, which improves upon traditional Transformer-style models, facilitating more efficient learning of traffic flow data by integrating long-range historical information. Leveraging attention mechanisms on a spatiotemporal graph enables direct interaction of information across different time slices and locations. Additionally, we propose two optimization strategies to further boost the speed of training and inference. Extensive experiments on four real-world datasets show that the new model significantly outperforms state-of-the-art methods.",10.1145/3696410.3714596,2025,,ACM,10.1145/3696410.3714596
FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification,"Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the semantically relevant information of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: 1) the frequency component naturally encodes global features, 2) the orthogonal nature of the Fourier basis allows easier isolation and independent modifications of critical and unimportant information, and 3) a compact set of frequency components can preserve semantic integrity. To fully utilize the three properties, we propose the lightweight yet effective Frequency-Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose semantic-aware Identity Modification and semantic-agnostic Self-adaptive Modification to protect semantically relevant information in the critical frequency components and infuse variance into the unimportant ones respectively. Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets, including UCR and UEA archives, as well as five large-scale datasets on diverse applications. FreRA consistently outperforms ten leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets. The code is available at https://github.com/Tian0426/FreRA.",10.1145/3711896.3736969,2025,,ACM,10.1145/3711896.3736969
ROTAN: A Rotation-based Temporal Attention Network for Time-Specific Next POI Recommendation,"The next Point-of-interest recommendation has attracted extensive research interest recently, which predicts users' subsequent movements. The main challenge is how to effectively capture users' personalized sequential transitions in check-in trajectory, and various methods have been developed. However, most existing studies ignore the temporal information when conducting the next POI recommendation. To fill this gap, we investigate a time-specific next POI recommendation task, which additionally incorporates the target time information. We propose a brand new Time2Rotation technique to capture the temporal information. Different from conventional methods, we represent timeslots as rotation vectors and then perform the rotation operations. Based on the Time2Rotation technique, we propose a novel rotation-based temporal attention network, namely ROTAN, for the time-specific next POI recommendation task. The ROTAN begins by building a collaborative POI transition graph, capturing the asymmetric temporal influence in sequential transitions. After that, it incorporates temporal information into the modeling of individual check-in trajectories, extracting separate representations for user preference and POI influence to reflect their distinct temporal patterns. Lastly, the target time is integrated to generate recommendations. Extensive experiments are conducted on three real-world datasets, which demonstrates the advantages of the proposed Time2Rotation technique and ROTAN recommendation model.",10.1145/3637528.3671809,2024,,ACM,10.1145/3637528.3671809
Contrastive Predictive Coding for Human Activity Recognition,"Feature extraction is crucial for human activity recognition (HAR) using body-worn movement sensors. Recently, learned representations have been used successfully, offering promising alternatives to manually engineered features. Our work focuses on effective use of small amounts of labeled data and the opportunistic exploitation of unlabeled data that are straightforward to collect in mobile and ubiquitous computing scenarios. We hypothesize and demonstrate that explicitly considering the temporality of sensor data at representation level plays an important role for effective HAR in challenging scenarios. We introduce the Contrastive Predictive Coding (CPC) framework to human activity recognition, which captures the temporal structure of sensor data streams. Through a range of experimental evaluations on real-life recognition tasks, we demonstrate its effectiveness for improved HAR. CPC-based pre-training is self-supervised, and the resulting learned representations can be integrated into standard activity chains. It leads to significantly improved recognition performance when only small amounts of labeled training data are available, thereby demonstrating the practical value of our approach. Through a series of experiments, we also develop guidelines to help practitioners adapt and modify the framework towards other mobile and ubiquitous computing scenarios.",10.1145/3463506,2021,,ACM,10.1145/3463506
Spatiotemporal Hypergraph Learning for Stock Return Sequence Prediction,"Financial markets are characterized by strong volatility, high noise, and intricate interdependencies among stocks, making accurate stock return prediction a challenging task. In this study, we propose a novel approach called Spatiotemporal Hypergraph Learning (STHL) for stock return sequence prediction. STHL integrates temporal characteristics and correlation-based spatial structures between stocks, enabling better prediction accuracy. We construct hypergraphs and graphs representing stock relationships using prior knowledge and data-driven methods. Hybrid graph learning techniques capture essential features, which, combined with temporal information, enhance prediction performance. The proposed multi-stock recommendation system provides investors with ranked stock recommendations, optimizing their investment decisions.",10.1145/3718751.3718862,2025,,ACM,10.1145/3718751.3718862
SeLeP: Learning Based Semantic Prefetching for Exploratory Database Workloads,"Prefetching is a crucial technique employed in traditional databases to enhance interactivity, particularly in the context of data exploration. Data exploration is a query processing paradigm in which users search for insights buried in the data, often not knowing what exactly they are looking for. Data exploratory tools deal with multiple challenges such as the need for interactivity with no a priori knowledge being present to help with the system tuning. The state-of-the-art prefetchers are specifically designed for navigational workloads only, where the number of possible actions is limited. The prefetchers that work with SQL-based workloads, on the other hand, mainly rely on data logical addresses rather than the data semantics. They fail to predict complex access patterns in cases where the database size is substantial, resulting in an extensive address space, or when there is frequent co-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher that makes prefetching decisions for both types of workloads, based on the encoding of the data values contained inside the accessed blocks. Following the popular path of using machine learning approaches to automatically learn the hidden patterns, we formulate the prefetching task as a time-series forecasting problem and use an encoder-decoder LSTM architecture to learn the data access pattern. Our extensive experiments, across real-life exploratory workloads, demonstrate that SeLeP improves the hit ratio up to 40\% and reduces I/O time up to 45\% compared to the state-of-the-art, attaining 96\% hit ratio and 84\% I/O reduction on average.",10.14778/3659437.3659458,2024,,ACM,10.14778/3659437.3659458
Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting,"Accurate workload forecasting is critical for efficient resource management in cloud computing systems, enabling effective scheduling and autoscaling. Despite recent advances with transformer-based forecasting models, challenges remain due to the non-stationary, nonlinear characteristics of workload time series and the long-term dependencies. In particular, inconsistent performance between long-term history and near-term forecasts hinders long-range predictions. This paper proposes a novel framework leveraging self-supervised multiscale representation learning to capture both long-term and near-term workload patterns. The long-term history is encoded through multiscale representations while the near-term observations are modeled via temporal flow fusion. These representations of different scales are fused using an attention mechanism and characterized with normalizing flows to handle non-Gaussian/non-linear distributions of time series. Extensive experiments on 9 benchmarks demonstrate superiority over existing methods.",10.1145/3627673.3680072,2024,,ACM,10.1145/3627673.3680072
ProST: Prompt Future Snapshot on Dynamic Graphs for Spatio-Temporal Prediction,"Spatio-temporal prediction focuses on jointly modeling spatial correlations and temporal evolution and has a wide range of applications. Due to the heterogeneity of spatio-temporal data, accurate prediction relies on effectively integrating topological structures and sequential patterns. Although recurrent graph learning methods excel at capturing dynamic graph patterns, explicitly inferring future snapshots from historical dynamic graphs remains a significant challenge. Recently, prompt-based graph learning has shown the potential to improve future snapshot inference by leveraging node or task-specific prompts. However, these methods fail to fully capture edge information resulting in incomplete and less accurate representations of future snapshot structures. To bridge this gap, we propose ProST, a framework that Prompts future snapshots on dynamic graphs for Spatio-Temporal prediction, which leverages dynamic graph pre-training to generate a premise graph containing historical graph information and then employs prompts on the premise graph to infer explicit future snapshots. Specifically, this framework comprises three steps: Firstly, dynamic graph pre-training is performed using multi-granularity evolution graph convolution to obtain the premise graph with both local and global features of dynamic graphs. Secondly, prompt subgraphs are used to prompt node pairs and edge features within the premise graph. The subgraph prompt aggregation mechanism propagates this information to generate future snapshots. Finally, we freeze the parameters of the pre-trained model and update the subgraph prompt parameters using meta-learning to adapt to downstream spatio-temporal prediction tasks. Extensive experiments on real-world datasets validate that ProST achieves state-of-the-art performance.",10.1145/3690624.3709273,2025,,ACM,10.1145/3690624.3709273
A Transferable Spatio-temporal Learning Framework for Cross-city Logistics Demand Prediction,"In logistic systems, demand prediction is an essential task providing the basis for improving the quality of terminal services, such as pick-up and delivery efficiency. However, the geographical scope of operations across multiple cities brings challenges due to the sparsity of user behavior data, hindering accurate predictions. Despite cross-city prediction methods potentially solving this problem by relying on the label of overlapping users in different cities, annotating these overlapping users is expensive. Additionally, the dynamic and diverse nature of user behaviors complicates feature transfer between cities. In this work, we define the logistics demand prediction problem as forecasting pick-up and delivery demand for zones, the smallest operational units in logistics systems, in different cities. To address the challenge, we propose TSTL, a Transferable Spatio-Temporal Learning framework for cross-city logistics prediction with sparse user data. TSTL advances existing methods from two aspects: (1) User-level invariant representation module extracts consistent user representations for overlapping and non-overlapping users across cities. (2) User-zone graph aggregation module enhances user embeddings by integrating dynamic interactions, such as logistics behaviors, into inherent user relations. Finally, the multi-city transfer module fine-tunes model parameters for city-invariant knowledge adoption and predicts future logistics demand. We implement and evaluate TSTL on one of the largest logistics systems. Extensive offline experiments and real-world deployment demonstrate the effectiveness of TSTL.",10.1145/3711896.3737186,2025,,ACM,10.1145/3711896.3737186
Analyzing the Impact of Credit Card Fraud on Economic Fluctuations of American Households Using an Adaptive Neuro-Fuzzy Inference System,"Credit card fraud is assuming growing proportions as a major threat to the financial position of American household, leading to unpredictable changes in household economic behavior. To solve this problem, in this paper, a new hybrid analysis method is presented by using the Enhanced ANFIS. The model proposes several advances of the conventional ANFIS framework and employs a multi-resolution wavelet decomposition module and a temporal attention mechanism. The model performs discrete wavelet transformations on historical transaction data and macroeconomic indicators to generate localized economic shock signals. The transformed features are then fed into a deep fuzzy rule library which is based on Takagi-Sugeno fuzzy rules with adaptive Gaussian membership functions. The model proposes a temporal attention encoder that adaptively assigns weights to multi-scale economic behavior patterns, increasing the effectiveness of relevance assessment in the fuzzy inference stage and enhancing the capture of long-term temporal dependencies and anomalies caused by fraudulent activities. The proposed method differs from classical ANFIS which has fixed input–output relations since it integrates fuzzy rule activation with the wavelet basis selection and the temporal correlation weights via a modular training procedure. Experimental results show that the RMSE was reduced by 17.8\% compared with local neuro-fuzzy models and conventional LSTM models.",10.1145/3766918.3766929,2025,,ACM,10.1145/3766918.3766929
DuroNet: A Dual-robust Enhanced Spatial-temporal Learning Network for Urban Crime Prediction,"Urban crime is an ongoing problem in metropolitan development and attracts general concern from the international community. As an effective means of defending urban safety, crime prediction plays a crucial role in patrol force allocation and public safety. However, urban crime data is a macro result of crime patterns overlapped by various irrelevant factors that cause inhomogeneous noises—local outliers and irregular waves. These noises might obstruct the learning process of crime prediction models and result in a deviation of performance. To tackle the problem, we propose a novel paradigm of &lt;underline&gt;Du&lt;/underline&gt;al-&lt;underline&gt;ro&lt;/underline&gt;bust Enhanced Spatial-temporal Learning &lt;underline&gt;Net&lt;/underline&gt;work&nbsp;(DuroNet), an encoder-decoder architecture that possesses an adaptive robustness for reducing the effect of outliers and waves. The robustness is mainly reflected on two aspects. One is a locality enhanced module that employs local temporal context information to smooth the deviation of outliers and dynamic spatial information to assist in understanding normal points. The other is a self-attention-based pattern representation module to weaken the effect of irregular waves by learning attentive weights. Finally, extensive experiments are conducted on two real-world crime datasets before and after adding Gaussian noises. The results demonstrate the superior performance of our DuroNet over the state-of-the-art methods.",10.1145/3432249,2021,,ACM,10.1145/3432249
Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting,"Recent years have witnessed the perfect encounter of deep learning and quantitative trading has achieved great success in stock investment. Numerous deep learning-based models have been developed for forecasting stock returns, leveraging the powerful representation capabilities of neural networks to identify patterns and factors influencing stock prices. These models can effectively capture general patterns in the market, such as stock price trends, volume-price relationships, and time variations. However, the impact of special irrationality factors -- such as market sentiment, speculative behavior, market manipulation, and psychological biases -- has not been fully considered in existing deep stock forecasting models due to their relative abstraction as well as lack of explicit labels and data description. To fill this gap, we propose UMI, a Universal multi-level Market Irrationality factor model to enhance stock return forecasting. The UMI model learns factors that can reflect irrational behaviors in market from both individual stock and overall market levels. For the stock-level, UMI construct an estimated rational price for each stock, which is cointegrated with the stock's actual price. The discrepancy between the actual and the rational prices serves as a factor to indicate stock-level irrational events. Additionally, we define market-level irrational behaviors as anomalous synchronous fluctuations of stocks within a market. Using two self-supervised representation learning tasks, i.e., sub-market comparative learning and market synchronism prediction, the UMI model incorporates market-level irrationalities into a market representation vector, which is then used as the market-level irrationality factor. We also developed a forecasting model that captures both temporal and relational dependencies among stocks, accommodating the UMI factors. Extensive experiments on U.S. and Chinese stock markets with competitive baselines demonstrate our model's effectiveness and the universality of our factors in improving various forecasting models. We provide our code at https://github.com/lIcIIl/UMI.",10.1145/3690624.3709328,2025,,ACM,10.1145/3690624.3709328
Characterizing and Forecasting Urban Vibrancy Evolution: A Multi-View Graph Mining Perspective,"Urban vibrancy describes the prosperity, diversity, and accessibility of urban areas, which is vital to a city’s socio-economic development and sustainability. While many efforts have been made for statically measuring and evaluating urban vibrancy, there are few studies on the evolutionary process of urban vibrancy, yet we know little about the relationship between urban vibrancy evolution and sophisticated spatiotemporal dynamics. In this article, we make use of multi-sourced urban data to develop a data-driven framework, U-Evolve, to investigate urban vibrancy evolution. Specifically, we first exploit the spatiotemporal characteristics of urban areas to create multi-view time-dependent graphs. Then, we analyze the contextual features and graph patterns of multi-view time-dependent graphs in terms of informing future urban vibrancy variations. Our analysis validates the informativeness of multi-view time-dependent graphs for characterizing and informing future urban vibrancy evolution. After that, we construct a feature based model to forecast future urban vibrancy evolution and quantify each feature’s importance. Moreover, to further enhance the forecasting effectiveness, we propose a graph learning based model to capture spatiotemporal autocorrelation of urban areas based on multi-view time-dependent graphs in an end-to-end manner. Finally, extensive experiments on two metropolises, Beijing and Shanghai, demonstrate the effectiveness of our forecasting models. The U-Evolve framework has also been deployed in the production environment to deliver real-world urban development and planning insights for various cities in China.",10.1145/3568683,2023,,ACM,10.1145/3568683
Unsupervised Temporal Encoding for Stock Price Prediction through Dual-Phase Learning,"This paper proposes a two-stage self-supervised pretraining modeling method for stock price sequence prediction in financial markets. The method is designed to address challenges such as limited labeled data, complex structural patterns, and non-stationary temporal features. The framework consists of two phases: pretraining and fine-tuning. In the pretraining phase, two self-supervised tasks are constructed. One captures long-term trends, while the other models short-term fluctuations. In the fine-tuning phase, the learned representations are used for regression prediction to improve the model's ability to fit future price movements. In the encoder design, the method integrates multi-layer temporal sequence modeling units. This enables multi-granularity semantic extraction and structure-aware representation learning. For the experimental part, a dataset is built based on Tesla's historical stock data from 2010 to 2024. The model is systematically evaluated under different time windows, hidden dimensions, sampling frequencies, and perturbation settings. The experimental results show that the proposed method outperforms existing baseline models across multiple metrics. It effectively captures temporal dependencies while maintaining strong prediction stability and robustness. This study validates the effectiveness of the two-stage architecture in financial time series modeling. It also demonstrates the practical potential of self-supervised learning in low-supervision financial prediction tasks.",10.1145/3770177.3770306,2025,,ACM,10.1145/3770177.3770306
An Information Cascade Prediction Algorithm Based on Time Series,"The prediction of information cascades is a crucial task in data mining, which aims to understand the patterns of information diffusion at macroscopic and microscopic levels. The objective of the macro level is to predict the popularity of information cascades in the future. However, the current macro information cascade prediction algorithms produce a fixed popularity prediction value for a specific future time, which lacks flexibility. In this paper, we propose a novel information cascade prediction algorithm, named CasInformer. This algorithm views information cascades as a sequence of cascaded graph snapshots and employs time series prediction to make inferences. CasInformer enhances the selection method of cascaded snapshots and utilizes diverse information to encode supplementary data, which significantly enhances prediction accuracy compared to existing algorithms. CasInformer can predict the cascading popularity at multiple different times to obtain the future trend of information cascading popularity, which is more practical in real scenarios. Experimental results on real datasets show that CasInformer has achieved significant improvement in both prediction accuracy and prediction ability compared to existing research.",10.1145/3696409.3700258,2024,,ACM,10.1145/3696409.3700258
Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals,"Multi-modal time series data is common in web technologies like the Internet of Things (IoT). Existing methods for multi-modal time series representation learning aim to disentangle the modality-shared and modality-specific latent variables. Although achieving notable performances on downstream tasks, they usually assume an orthogonal latent space. However, the modality-specific and modality-shared latent variables might be dependent on real-world scenarios. Therefore, we propose a general generation process, where the modality-shared and modality-specific latent variables are dependent, and further develop a Multi-modAl TEmporal Disentanglement (MATE) model. Specifically, our MATE model is built on a temporally variational inference architecture with the modality-shared and modality-specific prior networks for the disentanglement of latent variables. Furthermore, we establish identifiability results to show that the extracted representation is disentangled. More specifically, we first achieve the subspace identifiability for modality-shared and modality-specific latent variables by leveraging the pairing of multi-modal data. Then we establish the component-wise identifiability of modality-specific latent variables by employing sufficient changes of historical latent variables. Extensive experimental studies on 12 datasets show a general improvement in different downstream tasks, highlighting the effectiveness of our method in real-world scenarios.",10.1145/3696410.3714931,2025,,ACM,10.1145/3696410.3714931
A Co-training Approach for Noisy Time Series Learning,"In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning1.",10.1145/3583780.3614759,2023,,ACM,10.1145/3583780.3614759
Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach,"Dynamic pricing, which suggests the optimal prices based on the dynamic demands, has received considerable attention in academia and industry. On online hotel booking platforms, room demand fluctuates due to various factors, notably hotel popularity and competition. In this paper, we propose a dynamic pricing approach with popularity and competitiveness-aware demand learning. Specifically, we introduce a novel demand function that incorporates popularity and competitiveness coefficients to comprehensively model the price elasticity of demand. We develop a dynamic demand prediction network that focuses on learning these coefficients in the proposed demand function, enhancing the interpretability and accuracy of price suggestion. The model is trained in a multi-task framework that effectively leverages the correlations of demands among groups of similar hotels to alleviate data sparseness in room-level occupancy prediction. Comprehensive experiments conducted on real-world datasets validate the superiority of our method over state-of-the-art baselines in both demand prediction and dynamic pricing. Our model has been successfully deployed on a popular online travel platform, serving tens of millions of users and hoteliers.",10.1145/3637528.3671921,2024,,ACM,10.1145/3637528.3671921
Enhancing Dependency Dynamics in Traffic Flow Forecasting via Graph Risk Bootstrap,"Graph neural networks, as well as attention mechanisms, have gained widespread popularity for traffic flow forecasting due to their capacity to incorporate the complicated interactions behind flow dynamics. However, existing solutions either formulate a graph-based skeleton with narrow (e.g., static) interaction capture or build the spatiotemporal (e.g., dynamic) attention without proper comprehension of diverse risks, which inevitably burdens the generalization of high-accuracy traffic trends. In this study, we introduce Gboot (Graph bootstrap) enhancement framework for traffic flow forecasting. Gboot takes the traffic flow forecasting problem from a dependency dynamic learning perspective by treating each traffic sensor as the graph node while regarding the observed flows at each sensor as the node feature. In addition to exposing the explicit spatial connectivity behind traffic flows, we hierarchically devise temporal-aware and factual-aware graph learning blocks to consider temporal interactive dynamics and factual interactive dynamics. The former shows the trend dependencies behind flow signals and the latter uncovers different views of traffic situations (e.g., current observation vs. historical observation). More importantly, we present a Dual-view Bootstrap (DvBoot) mechanism in Gboot, which includes both risk-free and risk-aware stands. DvBoot attempts to flexibly align these two views in the latent space to enhance the generalization capability of capturing dynamic dependencies. Experiments on several real-world traffic datasets demonstrate the superiority of our Gboot over representative approaches.",10.1145/3678717.3691237,2024,,ACM,10.1145/3678717.3691237
Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series,"Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at .",10.1145/3516367,2022,,ACM,10.1145/3516367
Towards Predicting Urban Land Use Changes: A Dynamic Graph Alignment Perspective,"Urban land use, intrinsically linked to people’s daily activities, undergoes continuous evolution, presenting a complex interplay that remains partially understood. To bridge this gap, our study leverages fine-grained human mobility data to predict these changes, adopting a novel approach that conceptualizes “community-level” land use shifts as a regression problem and represents citywide changes through dynamic graphs. We harness recent advancements in graph neural networks (GNNs), which, despite their success in various applications, face challenges in directly predicting land use changes due to the temporal mismatch between the slow evolution of urban land and the immediacy of human mobility data. Our research stands out by introducing a temporal skeleton for dynamic GNNs to synchronize human activity graphs with urban land use changes, a dynamic heterogeneous GNN approach for integrating diverse human activity data to capture essential temporal dependencies, and a novel algorithm powered by causal inference to elucidate the primary factors influencing land use predictions at the community level, all of which contribute to a training process informed by the generated causal graph. Empirically validated on three real-world datasets, our model demonstrates a performance leap over state-of-the-art baselines, marking a pivotal step toward understanding and predicting the dynamics of urban land use.",10.1145/3712702,2025,,ACM,10.1145/3712702
Research on Long-Term ENSO Prediction Method Based on Adaptive Spatio-Temporal Attention Network Using K-MEANS Clustering Algorithm,The El Ni\~{n,10.1145/3727353.3727401,2025,,ACM,10.1145/3727353.3727401
SrVARM: State Regularized Vector Autoregressive Model for Joint Learning of Hidden State Transitions and State-Dependent Inter-Variable Dependencies from Multi-variate Time Series,"Many applications, e.g., healthcare, education, call for effective methods methods for constructing predictive models from high dimensional time series data where the relationship between variables can be complex and vary over time. In such settings, the underlying system undergoes a sequence of unobserved transitions among a finite set of hidden states. Furthermore, the relationships between the observed variables and their temporal dynamics may depend on the hidden state of the system. To further complicate matters, the hidden state sequences underlying the observed data from different individuals may not be aligned relative to a common frame of reference. Against this background, we consider the novel problem of jointly learning the state-dependent inter-variable relationships as well as the pattern of transitions between hidden states from multi-variate time series data. To solve this problem, we introduce the State-Regularized Vector Autoregressive Model (SrVARM) which combines a state-regularized recurrent neural network to learn the dynamics of transitions between discrete hidden states with an augmented autoregressive model which models the inter-variable dependencies in each state using a state-dependent directed acyclic graph (DAG). We propose an efficient algorithm for training SrVARM by leveraging a recently introduced reformulation of the combinatorial problem of optimizing the DAG structure with respect to a scoring function into a continuous optimization problem. We report results of extensive experiments with simulated data as well as a real-world benchmark that show that SrVARM outperforms state-of-the-art baselines in recovering the unobserved state transitions and discovering the state-dependent relationships among variables.",10.1145/3442381.3450116,2021,,ACM,10.1145/3442381.3450116
Popularity-aware Distributionally Robust Optimization for Recommendation System,"Collaborative Filtering (CF) has been widely applied for personalized recommendations in various industrial applications. However, due to the training strategy of Empirical Risk Minimization, CF models tend to favor popular items, resulting in inferior performance on sparse users and items. To enhance the CF representation learning of sparse users and items without sacrificing the performance of popular items, we propose a novel Popularity- aware Distributionally Robust Optimization (PDRO) framework. In particular, PDRO emphasizes the optimization of sparse users/items, while incorporating item popularity to preserve the performance of popular items through two modules. First, an implicit module develops a new popularity-aware DRO objective, paying more attention to items that will potentially become popular over time. Second, an explicit module that directly predicts the popularity of items to help the estimation of user-item matching scores. We apply PDRO to a micro-video recommendation scenario and implement it on two representative backend models. Extensive experiments on a real-world industrial dataset, as well as two public benchmark datasets, validate the efficacy of our proposed PDRO. Additionally, we perform an offline A/B test on the industrial dataset, further demonstrating the superiority of PDRO in real-world application scenarios.",10.1145/3583780.3615492,2023,,ACM,10.1145/3583780.3615492
Automated Contrastive Learning Strategy Search for Time Series,"In recent years, Contrastive Learning (CL) has become a predominant representation learning paradigm for time series. Most existing methods manually build specific CL Strategies (CLS) by human heuristics for certain datasets and tasks. However, manually developing CLS usually requires excessive prior knowledge about the data, and massive experiments to determine the detailed CL configurations. In this paper, we present an Automated Machine Learning (AutoML) practice at Microsoft, which automatically learns CLS for time series datasets and tasks, namely Automated Contrastive Learning (AutoCL). We first construct a principled search space of size over 3 \texttimes{",10.1145/3627673.3680086,2024,,ACM,10.1145/3627673.3680086
Prospective Multi-Graph Cohesion for Multivariate Time Series Anomaly Detection,"Anomaly detection in high-dimensional time series data is pivotal for numerous industrial applications. Recent advances in multivariate time series anomaly detection (TSAD) have increasingly leveraged graph structures to model inter-variable relationships, typically employing Graph Neural Networks (GNNs). Despite their promising results, existing methods often rely on a single graph representation, which are insufficient for capturing the complex, diverse relationships inherent in multivariate time series. To address this, we propose the Prospective Multi-Graph Cohesion (PMGC) framework for multivariate TSAD. PMGC exploits spatial correlations by integrating a long-term static graph with a series of short-term instance-wise dynamic graphs, regulated through a graph cohesion loss function. Our theoretical analysis shows that this loss function promotes diversity among dynamic graphs while aligning them with the stable long-term relationships encapsulated by the static graph. Additionally, we introduce a ",10.1145/3701551.3703494,2025,,ACM,10.1145/3701551.3703494
A Universal Model for Human Mobility Prediction,,10.1145/3690624.3709236,2025,,ACM,10.1145/3690624.3709236
Improving Streaming Cryptocurrency Transaction Classification via Biased Sampling and Graph Feedback,"We show that knowledge of wallet addresses from the current time state of a blockchain network, such as Bitcoin, increases the performance of illicit activity detection. Based on this finding we introduce two new methods for the sampling of classifier training data so that precedence is given to transaction information from the recent past and the current time state. This sampling enables streaming classification in which a decision on the class of a transaction needs to be made based on data seen to date. Our new approach provides insight into how the dynamics of the blockchain network plays a central role in the detection of illicit transactions, and is independent of the classifier choice. Our proposed sampling methods enable graph convolution network (GCN) and random forest (RF) classifiers to better adapt to changes in the network due to significant events, such as the closure of a large ‘Darknet’ marketplace. We introduce Graphlet spectral correlation analysis for exposing the effect of such network re-organisation due to major events. Finally, based on our analysis, we propose a new two-stage random forest classifier that feeds back intermediate predictions of neighbours to improve the classification decision. Our methodology enables practical streaming classification, even in the scenario of very limited information on the feature space of each transaction.",10.1145/3485832.3485913,2021,,ACM,10.1145/3485832.3485913
Dynamic and Multi-faceted Spatio-temporal Deep Learning for Traffic Speed Forecasting,"Dynamic Graph Neural Networks (DGNNs) have become one of the most promising methods for traffic speed forecasting. However, when adapting DGNNs for traffic speed forecasting, existing approaches are usually built on a static adjacency matrix (no matter predefined or self-learned) to learn spatial relationships among different road segments, even if the impact of two road segments can be changeable dynamically during a day. Moreover, the future traffic speed cannot only be related with the current traffic speed, but also be affected by other factors such as traffic volumes. To this end, in this paper, we aim to explore these dynamic and multi-faceted spatio-temporal characteristics inherent in traffic data for further unleashing the power of DGNNs for better traffic speed forecasting. Specifically, we design a dynamic graph construction method to learn the time-specific spatial dependencies of road segments. Then, a dynamic graph convolution module is proposed to aggregate hidden states of neighbor nodes to focal nodes by message passing on the dynamic adjacency matrices. Moreover, a multi-faceted fusion module is provided to incorporate the auxiliary hidden states learned from traffic volumes with the primary hidden states learned from traffic speeds. Finally, experimental results on real-world data demonstrate that our method can not only achieve the state-of-the-art prediction performances, but also obtain the explicit and interpretable dynamic spatial relationships of road segments.",10.1145/3447548.3467275,2021,,ACM,10.1145/3447548.3467275
DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions,"Prediction of couriers' delivery timely rates in advance is essential to the logistics industry, enabling companies to take preemptive measures to ensure the normal operation of delivery services. This becomes even more critical during anomaly conditions like the epidemic outbreak, during which couriers' delivery timely rate will decline markedly and fluctuates significantly. Existing studies pay less attention to the logistics scenario. Moreover, many works focusing on prediction tasks in anomaly scenarios fail to explicitly model abnormal events, e.g., treating external factors equally with other features, resulting in great information loss. Further, since some anomalous events occur infrequently, traditional data-driven methods perform poorly in these scenarios. To deal with them, we propose a deep spatial-temporal attention model, named DeepSTA. To be specific, to avoid information loss, we design an anomaly spatio-temporal learning module that employs a recurrent neural network to model incident information. Additionally, we utilize Node2vec to model correlations between road districts, and adopt graph neural networks and long short-term memory to capture the spatial-temporal dependencies of couriers. To tackle the issue of insufficient training data in abnormal circumstances, we propose an anomaly pattern attention module that adopts a memory network for couriers' anomaly feature patterns storage via attention mechanisms. The experiments on real-world logistics datasets during the COVID-19 outbreak in 2022 show the model outperforms the best baselines by 12.11\% in MAE and 13.71\% in MSE, demonstrating its superior performance over multiple competitive baselines.",10.1145/3583780.3614671,2023,,ACM,10.1145/3583780.3614671
UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web,"Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1\% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.",10.1145/3589334.3645378,2024,,ACM,10.1145/3589334.3645378
On Hierarchical Disentanglement of Interactive Behaviors for Multimodal Spatiotemporal Data with Incompleteness,"Multimodal spatiotemporal data (MST) consists of multiple simultaneous spatiotemporal modalities that interact with each other in a dynamic manner. Due to the complexity of MST and the recent desire for the explainability of artificial intelligent systems, disentangled representation learning for MST (DisentMST) has become a significant task, which aims to learn disentangled representations that can expose the underlying spatial semantics, temporal dynamic patterns, and inter-modality interaction modes of the complex MST. One limitation of existing approaches is that they might fail to tolerate the real-world incomplete MST data, where missing information might break the cross-modal spatiotemporal dynamics and bring noise and ambiguity to the learning process. Another limitation is that no existing work systematically reveals the structure of different types of disentangled information. To tackle the two limitations, we define a novel two-level hierarchically structured disentanglement task for MST, which reveals informative and structured disentangled representations for MST as well as digests the real-world MST with incompleteness. We propose a new framework, BiDisentMST, which leverages Gaussian Processes and Graph Factorization on the latent space to achieve our purposes. The experimental results demonstrate the effectiveness of our proposed framework compared with baselines with respect to disentanglement and imputation results.",10.1145/3580305.3599448,2023,,ACM,10.1145/3580305.3599448
MentorPDM: Learning Data-Driven Curriculum for Multi-Modal Predictive Maintenance,"Predictive Maintenance (PDM) systems are essential for preemptive monitoring of sensor signals to detect potential machine component failures in industrial assets such as bearings in rotating machinery. Existing PDM systems face two primary challenges: 1) Irregular Signal Acquisition, where data collection from the sensors is intermittent, and 2) Signal Heterogeneity, where the full spectrum of sensor modalities is not effectively integrated. To address these challenges, we propose a Curriculum Learning Framework for Multi-Modal Predictive Maintenance - MentorPDM. MentorPDM consists of 1) a graph-augmented pretraining module that captures intrinsic and structured temporal correlations across time segments via a temporal contrastive learning objective and 2) a bi-level curriculum learning module that captures task complexities for weighing the importance of signal modalities and samples via modality and sample curricula. Empirical results from MentorPDM show promising performance with better generalizability in PDM tasks compared to existing benchmarks. The efficacy of the MentorPDM model will be further demonstrated in real industry testbeds and platforms.",10.1145/3690624.3709388,2025,,ACM,10.1145/3690624.3709388
Graph Anomaly Detection with Few Labels: A Data-Centric Approach,"Anomalous node detection in a static graph faces significant challenges due to the rarity of anomalies and the substantial cost of labeling their deviant structure and attribute patterns. These challenges give rise to data-centric problems, including extremely imbalanced data distributions and intricate graph learning, which significantly impede machine learning and deep learning methods from discerning the patterns of graph anomalies with few labels. While these issues remain crucial, much of the current research focuses on addressing the induced technical challenges, treating the shortage of labeled data as a given. Distinct from previous efforts, this work focuses on tackling the data-centric problems by generating auxiliary training nodes that conform to the original graph topology and attribute distribution. We categorize this approach as data-centric, aiming to enhance existing anomaly detectors by training them on our synthetic data. However, the methods for generating nodes and the effectiveness of utilizing synthetic data for graph anomaly detection remain unexplored in the realm. To answer these questions, we thoroughly investigate the denoising diffusion model. Drawing from our observations on the diffusion process, we illuminate the shifts in graph energy distribution and establish two principles for designing denoising neural networks tailored to graph anomaly generation. From the insights, we propose a diffusion-based graph generation method to synthesize training nodes, which can be promptly integrated to work with existing anomaly detectors. The empirical results on eight widely-used datasets demonstrate our generated data can effectively enhance the nine state-of-the-art graph detectors' performance.",10.1145/3637528.3671929,2024,,ACM,10.1145/3637528.3671929
ASTNet: Asynchronous Spatio-Temporal Network for Large-Scale Chemical Sensor Forecasting,"The chemical industry is faced with the urgent challenge of effectively harnessing the vast amounts of time-series data generated by thousands of sensors, which is essential for forecasting chemical states, achieving accurate real-time control of production processes. Traditional forecasting methods suffer from high computational latency and struggle with the complexity of spatiotemporal dependencies. As a result, modeling this data becomes challenging. This paper introduces a novel approach, referred to as ASTNet, designed to address these challenges. ASTNet integrates an asynchronous spatiotemporal modeling framework that combines temporal and spatial encoders, enabling concurrent learning of temporal and spatial dependencies while reducing computational latency. Additionally, it introduces a gated graph fusion mechanism that adaptively combines static (meta) and evolving (dynamic) sensor graphs, enhancing the handling of heterogeneous sensor data and spatial correlations. Extensive experiments on three real-world chemical sensor datasets demonstrate that ASTNet outperforms SOTA methods in terms of both prediction accuracy and computational efficiency, making ASTNet successfully deployed in chemical engineering industrial scenarios.",10.1145/3711896.3737194,2025,,ACM,10.1145/3711896.3737194
Robust Spatio-Temporal Graph Neural Network for Electricity Consumption Forecasting,"Precise electricity consumption forecasting is pivotal in the energy schedule of new electric power systems. It is also significant for improving robustness of smart power grid. Existing multivariate time series predictions have made effective achievements in modeling sequential tendency and periodicity, but they lack of considering time series noises due to data sensing or transferring. Therefore, we focus on a robust approach to capture intricate correlations of multivariate time series data for forecasting. Specifically, we exploit gated dilated causal convolution as projection layer to capture latent semantic information from a temporal perspective. Furthermore, we combine time series decomposition and adaptive normalization to learn latent representations of each time series. Finally, we devise spatio-temporal modeling for capturing heterogeneous correlations. Extensive experiments are implemented on real-scenario public datasets. The performances show the effectiveness of proposed approach for electricity consumption forecasting.",10.1145/3697355.3697401,2024,,ACM,10.1145/3697355.3697401
Explainable Stock Price Movement Prediction using Contrastive Learning,"Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of ",10.1145/3627673.3679544,2024,,ACM,10.1145/3627673.3679544
No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models,"Modern IoT deployments for environmental sensing produce high volume spatiotemporal data to support downstream tasks such as forecasting, typically powered by machine learning models. While existing filtering and strategic deployment techniques optimize collected data volume at the edge, they overlook how variations in sampling frequencies and spatial coverage affect downstream model performance. In many forecasting models, incorporating data from additional sensors denoise predictions by providing broader spatial contexts. This interplay between sampling frequency, spatial coverage and different forecasting model architectures remain underexplored. This work presents a systematic study of forecasting models - classical models (VAR), neural networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs), and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under varying spatial sensor nodes density and sampling intervals using real-world temperature data in a wireless sensor network. Our results show that STGNNs are effective when sensor deployments are sparse and sampling rate is moderate, leveraging spatial correlations via encoded graph structure to compensate for limited coverage. In contrast, TSFMs perform competitively at high frequencies but degrade when spatial coverage from neighboring sensors is reduced. Crucially, the multivariate TSFM Moirai outperforms all models by natively learning cross-sensor dependencies. These findings offer actionable insights for building efficient forecasting pipelines in spatio-temporal systems. All code for model configurations, training, dataset, and logs are open-sourced for reproducibility.1",10.1145/3736425.3771958,2025,,ACM,10.1145/3736425.3771958
ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for Multivariate Time Series Analysis,"Designing effective models for learning time series representations is foundational for time series analysis. Many previous works explore time series representation modeling approaches and make progress in this area. Despite their effectiveness, they lack adaptive perception of local patterns in temporally dependent basic units and fail to capture the multi-scale dependency among these units. Instead of relying on prevalent methods centered around self-attention mechanisms, we propose ConvTimeNet, a hierarchical pure convolutional model designed for time series analysis. ConvTimeNet introduces a deformable patch layer that adaptively perceives local patterns of temporally dependent basic units in a data-driven manner. Based on the extracted local patterns, hierarchical pure convolutional blocks are designed to capture dependency relationships among the representations of basic units at different scales. Moreover, a large kernel mechanism is employed to ensure that convolutional blocks can be deeply stacked, thereby achieving a larger receptive field. In this way, local patterns and their multi-scale dependencies can be effectively modeled within a single model. Extensive experiments comparing a wide range of different types of models demonstrate that pure convolutional models still exhibit strong viability, effectively addressing the aforementioned two challenges and showing superior performance across multiple tasks. The code is available for reproducibility. https://github.com/Mingyue-Cheng/ConvTimeNet",10.1145/3701716.3715214,2025,,ACM,10.1145/3701716.3715214
Integrating System State into Spatio Temporal Graph Neural Network for Microservice Workload Prediction,"Microservice architecture has become a driving force in enhancing the modularity and scalability of web applications, as evidenced by the Alipay platform's operational success. However, a prevalent issue within such infrastructures is the suboptimal utilization of CPU resources due to inflexible resource allocation policies. This inefficiency necessitates the development of dynamic, accurate workload prediction methods to improve resource allocation. In response to this challenge, we present STAMP, a &lt;u&gt;S&lt;/u&gt;patio &lt;u&gt;T&lt;/u&gt;emporal Gr&lt;u&gt;a&lt;/u&gt;ph Network for &lt;u&gt;M&lt;/u&gt;icroservice Workload &lt;u&gt;P&lt;/u&gt;rediction. STAMP is designed to comprehensively address the multifaceted interdependencies between microservices, the temporal variability of workloads, and the critical role of system state in resource utilization. Through a graph-based representation, STAMP effectively maps the intricate network of microservice interactions. It employs time series analysis to capture the dynamic nature of workload changes and integrates system state insights to enhance prediction accuracy. Our empirical analysis, using three distinct real-world datasets, establishes that STAMP exceeds baselines by achieving an average boost of 5.72\% in prediction precision, as measured by RMSE. Upon deployment in Alipay's microservice environment, STAMP achieves a 33.10\% reduction in resource consumption, significantly outperforming existing online methods. This research solidifies STAMP as a validated framework, offering meaningful contributions to the field of resource management in microservice architecture-based applications.",10.1145/3637528.3671508,2024,,ACM,10.1145/3637528.3671508
BigST: Linear Complexity Spatio-Temporal Graph Neural Network for Traffic Forecasting on Large-Scale Road Networks,"Spatio-Temporal Graph Neural Network (STGNN) has been used as a common workhorse for traffic forecasting. However, most of them require prohibitive quadratic computational complexity to capture long-range spatio-temporal dependencies, thus hindering their applications to long historical sequences on large-scale road networks in the real-world. To this end, in this paper, we propose BigST, a linear complexity spatio-temporal graph neural network, to efficiently exploit long-range spatio-temporal dependencies for large-scale traffic forecasting. Specifically, we first propose a scalable long sequence feature extractor to encode node-wise long-range inputs (e.g., thousands of time-steps in the past week) into low-dimensional representations encompassing rich temporal dynamics. The resulting representations can be pre-computed and hence significantly reduce the computational overhead for prediction. Then, we build a linearized global spatial convolution network to adaptively distill time-varying graph structures, which enables fast runtime message passing along spatial dimensions in linear complexity. We empirically evaluate our model on two large-scale real-world traffic datasets. Extensive experiments demonstrate that BigST can scale to road networks with up to one hundred thousand nodes, while significantly improving prediction accuracy and efficiency compared to state-of-the-art traffic forecasting models.",10.14778/3641204.3641217,2024,,ACM,10.14778/3641204.3641217
Hypergraph Neural Networks to Predict Stock Movements By Exploring Higher-order Relationships,"Predicting stock price movements can be framed as a classification task, where the goal is to anticipate whether a stock will increase, decrease, or remain stable. Most existing approaches rely solely on the movement patterns of individual stocks or stock pairs, overlooking the more complex, higher-order connections that exist among groups of stocks. In practice, stocks are often interrelated in higher orders, for example, by belonging to the same industry sector or being jointly held within the same investment fund. To address this, we compare 4 hypergraph neural network-based approaches to make spatio-temporal predictions for stock movement prediction, which explicitly leverages these higher-order dependencies. We use two heterogeneous hypergraphs, where one hypergraph represents sector-based associations and the other one represents fund-holding relationships among stocks. In general, we found the hierarchical hypergraph attention mechanism and temporal attention to be effective in achieving better performance. A hierarchical hypergraph attention mechanism models these relationships by weighting the contributions of stock nodes, hyperedges, and even the hypergraphs themselves. Temporal attention captures time-dependent dynamics of both stock and sector sequences, effectively accounting for the influence of past states. Experiments on real-world datasets demonstrate that the methods specializing in hypergraph integration achieve superior performance compared to existing methods, both in terms of predictive accuracy and profitability.",10.1145/3768292.3770389,2025,,ACM,10.1145/3768292.3770389
Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion,"Multimodal Knowledge Graphs (MKGs), which organize visual-text factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all images/objects are relevant to text input, which hinders the applicability to diverse real-world scenarios. In this paper, we propose a hybrid transformer with multi-level fusion to address those issues. Specifically, we leverage a hybrid transformer architecture with unified input-output for diverse multimodal knowledge graph completion tasks. Moreover, we propose multi-level fusion, which integrates visual and text representation via coarse-grained prefix-guided interaction and fine-grained correlation-aware fusion modules. We conduct extensive experiments to validate that our MKGformer can obtain SOTA performance on four datasets of multimodal link prediction, multimodal RE, and multimodal NER1. https://github.com/zjunlp/MKGformer.",10.1145/3477495.3531992,2022,,ACM,10.1145/3477495.3531992
Relation-aware Meta-learning for E-commerce Market Segment Demand Prediction with Limited Records,"E-commerce business is revolutionizing our shopping experiences by providing convenient and straightforward services. One of the most fundamental problems is how to balance the demand and supply in market segments to build an efficient platform. While conventional machine learning models have achieved great success on data-sufficient segments, it may fail in a large-portion of segments in E-commerce platforms, where there are not sufficient records to learn well-trained models. In this paper, we tackle this problem in the context of market segment demand prediction. The goal is to facilitate the learning process in the target segments by leveraging the learned knowledge from data-sufficient source segments. Specifically, we propose a novel algorithm, RMLDP, to incorporate a multi-pattern fusion network (MPFN) with a meta-learning paradigm. The multi-pattern fusion network considers both local and seasonal temporal patterns for segment demand prediction. In the meta-learning paradigm, transferable knowledge is regarded as the model parameter initialization of MPFN, which are learned from diverse source segments. Furthermore, we capture the segment relations by combining data-driven segment representation and segment knowledge graph representation and tailor the segment-specific relations to customize transferable model parameter initialization. Thus, even with limited data, the target segment can quickly find the most relevant transferred knowledge and adapt to the optimal parameters. We conduct extensive experiments on two large-scale industrial datasets. The results justify that our RMLDP outperforms a set of state-of-the-art baselines. Besides, RMLDP has been deployed in Taobao, a real-world E-commerce platform. The online A/B testing results further demonstrate the practicality of RMLDP.",10.1145/3437963.3441750,2021,,ACM,10.1145/3437963.3441750
Jointly Modeling Spatio–Temporal Dependencies and Daily Flow Correlations for Crowd Flow Prediction,"Crowd flow prediction is a vital problem for an intelligent transportation system construction in a smart city. It plays a crucial role in traffic management and behavioral analysis, thus it has raised great attention from many researchers. However, predicting crowd flows timely and accurately is a challenging task that is affected by many complex factors such as the dependencies of adjacent regions or recent crowd flows. Existing models mainly focus on capturing such dependencies in spatial or temporal domains and fail to model relations between crowd flows of distant regions. We notice that each region has a relatively fixed daily flow and some regions (even very far away from each other) may share similar flow patterns which show strong correlations among them. In this article, we propose a novel model named Double-Encoder which follows a general encoder–decoder framework for multi-step citywide crowd flow prediction. The model consists of two encoder modules named ST-Encoder and FR-Encoder to model spatial-temporal dependencies and daily flow correlations, respectively. We conduct extensive experiments on two real-world datasets to evaluate the performance of the proposed model and show that our model consistently outperforms state-of-the-art methods.",10.1145/3439346,2021,,ACM,10.1145/3439346
MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction,"Recently, integrated warehouse and distribution logistics systems are widely used in E-commerce industries to adjust to constantly changing customer demands. It makes the prediction of purchase demand and delivery supply capacity a crucial problem to streamline operations and improve efficiency. The interaction between such demand and supply not only relies on their economic relationships but also on consumer psychology caused by daily events, such as epidemics, promotions, and festivals. Although existing studies have made great efforts in the joint prediction of demand and supply considering modeling the demand-supply interactions, they seldom refer to the impacts of diverse events. In this work, we propose MulSTE, a Multi-view Spatio-Temporal learning framework with heterogeneous Event fusion. Firstly, an Event Fusion Representation (EFR) module is designed to fuse the textual, numerical, and categorical heterogeneous information for emergent and periodic events. Secondly, a Multi-graph Adaptive Convolution Recurrent Network (MGACRN) is developed as the spatio-temporal encoder (ST-Encoder) to capture the evolutional features of demand, supply, and events. Thirdly, the Event Gated Demand-Supply Interaction Attention (EGIA) module is designed to model the demand-supply interactions during events. The evaluations are conducted on two real-world datasets collected from JD Logistics and public websites. The experimental results show that our method outperforms state-of-the-art baselines in various metrics.",10.1145/3637528.3672030,2024,,ACM,10.1145/3637528.3672030
Spatiotemporal disease case prediction using contrastive predictive coding,"Time series prediction models have played a vital role in guiding effective policymaking and response during the COVID-19 pandemic by predicting future cases and deaths at the country, state, and county levels. However, for emerging diseases, there is not sufficient historic data to fit traditional supervised prediction models. In addition, such models do not consider human mobility between regions. To mitigate the need for supervised models and to include human mobility data in the prediction, we propose Spatial Probabilistic Contrastive Predictive Coding (SP-CPC) which leverages Contrastive Predictive Coding (CPC), an unsupervised time-series representation learning approach. We augment CPC to incorporate a covariate mobility matrix into the loss function, representing the relative number of individuals traveling between each county on a given day. The proposal distribution learned by the algorithm is then sampled by the Metropolis-Hastings algorithm to give a final prediction of the number of COVID-19 cases. We find that the model applied to COVID-19 data can make accurate short-term predictions, more accurate than ARIMA and simple time-series extrapolation methods, one day into the future. However, for longer-term prediction windows of seven or more days into the future, we find that our predictions are not as competitive and require future research.",10.1145/3557995.3566122,2022,,ACM,10.1145/3557995.3566122
Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting,"Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the predicted time series in terms of both the temporal trending and the complex spatial-temporal dependencies. Compared with traditional approaches that handle step-wise predictive errors independently, our approach can produce more realistic and robust forecasts. Experiments on six benchmark traffic forecasting datasets and theoretical analysis both demonstrate the superiority and the state-of-the-art performance of TrendGCN. Source code is available at https://github.com/juyongjiang/TrendGCN.",10.1145/3583780.3614868,2023,,ACM,10.1145/3583780.3614868
Bloom-LLM: Privacy-Preserving Large Language Model for Load Forecasting,"Accurate energy load forecasting is essential for optimising power systems across buildings, cities, and smart grids. Recently, large language models (LLMs) have shown remarkable capability in capturing complex temporal patterns in energy consumption data, outperforming both traditional and deep learning techniques. However, their reliance on detailed smart meter (SM) data poses significant privacy risks, as such fine-grained information is susceptible to inference attacks. To overcome these challenges, we introduce Privacy-Preserving Time-LLM, an innovative forecasting framework that combines LLM architectures with SM data encoded via Differentially Private Bloom Filters (DP-BF). This encoding safe-guards sensitive consumption data while preserving high predictive performance. Designed for secure cloud deployment, the framework reduces privacy risks associated with honest-but-curious service providers. It employs Low-Rank Adaptation (LoRA) for efficient fine-tuning and utilises Rotary Position Embedding (RoPE) to model temporal dependencies without accessing raw time-series inputs. We benchmark our approach against the widely used differentially private training method DP-SGD. Experimental results demonstrate that the Time-LLM trained on DP-BF-Encoded SM data consistently outperforms its DP-SGD counterpart, reducing forecasting error by approximately 29\% on average, highlighting an improved balance between privacy and utility. Compared to a state-of-the-art CNN baseline, our method achieves nearly 52\% better forecasting accuracy on DP-BF-Encoded data while maintaining up to 99\% membership privacy. Moreover, under adversarial attacks, models trained with DP-BF-Encoding show over 80\% reduced vulnerability relative to models trained on raw data, significantly enhancing robustness and stability. To the best of our knowledge, this is the first differentially private LLM-based framework for energy load forecasting using DP-BF-Encoding. It opens new possibilities for privacy-preserving analytics in smart grid environments, with extensibility to other time-series applications such as occupancy detection and demand disaggregation.",10.1145/3736425.3770103,2025,,ACM,10.1145/3736425.3770103
Generative Imputation with Multi-level Causal Consistency for Variable Subset Forecasting,"Variable Subset Forecasting (VSF) poses critical challenges in time series analysis when entire variables become unavailable during inference. Existing imputation methods relying on inter-variable correlations fail catastrophically in VSF due to two inherent limitations: (1) Missing variable collapse, where the complete absence of certain variables invalidates correlation-based dependency learning, and (2) Temporal covariate shift, where time-evolving data distributions destabilize correlation patterns learned from training data. To address these fundamental issues, we propose Generative Imputation with Multi-level Causal Consistency (GIMCC ), establishing causality-driven imputation as the first principled solution for VSF. Our key innovation lies in enforcing causal invariance through dual consistency constraints: global causal isomorphism ensures the imputed variables preserve the ground-truth causal graph structure of the complete system, while local causal subgraph alignment maintains consistency between observed variables and their causal neighborhood dependencies. By decoupling causality from spurious correlations, GIMCC provides time-invariant imputation signals robust to distribution shifts, which explicitly preserves causal relationships via multivariate spectral convolutions. Extensive experiments across five real-world domains demonstrate that GIMCC achieves average improvements of 20-60\% in MAE/RMSE over correlation-based imputation baselines, remarkably outperforming full-variable training ( Oracle ) in temporal covariate shift scenarios. Our work bridges the critical gap between causal analysis and practical forecasting systems under variable absence, offering theoretically grounded guarantees for real-world deployment.",10.1145/3711896.3736980,2025,,ACM,10.1145/3711896.3736980
NRFormer: Nationwide Nuclear Radiation Forecasting with Spatio-Temporal Transformer,"Nuclear radiation, which refers to the energy emitted from atomic nuclei during decay, poses significant risks to human health and environmental safety. Recently, advancements in monitoring technology have facilitated the effective recording of nuclear radiation levels and related factors, such as weather conditions. The abundance of monitoring data enables the development of accurate and reliable nuclear radiation forecasting models, which play a crucial role in informing decision-making for individuals and governments. However, this task is challenging due to the imbalanced distribution of monitoring stations over a wide spatial range and the non-stationary radiation variation patterns. In this study, we introduce NRFormer, a novel framework tailored for the nationwide prediction of nuclear radiation variations. By integrating a non-stationary temporal attention module, an imbalance-aware spatial attention module, and a radiation propagation prompting module, NRFormer collectively captures complex spatio-temporal dynamics of nuclear radiation. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed framework against 11 baselines. NRFormer has been deployed online to provide 1-24-day nuclear radiation forecasts, empowering individuals and governments with timely, data-driven decisions for emergency response and public safety. Our framework is designed for general applicability and can be readily adapted for deployment in other regions. The deployed system is available at https://NRFormer.github.io and the dataset and code of the predictive model are available at https://github.com/usail-hkust/NRFormer.",10.1145/3711896.3737252,2025,,ACM,10.1145/3711896.3737252
FEDDGCN: A Frequency-Enhanced Decoupling Dynamic Graph Convolutional Network for Traffic Flow Prediction,"As a core task in Intelligent Transportation Systems (ITS), traffic flow prediction is essential for resource allocation and real-time route planning. Effectively capturing complex temporal correlations and dynamic spatial dependencies in traffic flow data is critical yet challenging for accurate prediction. However, existing approaches are still limited by the insufficient capability for spatial-temporal pattern decoupling and the underutilization of frequency domain information. To address these issues, we propose a novel Frequency-Enhanced Dynamic Decoupling Graph Convolutional Network (FEDDGCN), which introduces a gated decoupling mechanism integrating temporal and spatial embeddings to decouple traffic flow into prominent periodic and perturbative component. It also achieves effective pattern separation by incorporating frequency domain analysis with Fourier filters. Furthermore, a dual-branch spatial-temporal learning module, employing a divide-and-conquer strategy, is designed to achieve separate modeling for the two distinct components. Specially, the dynamic graph convolution modules are utilized to learn spatial dependencies and temporal and frequency attention mechanisms further capture complex temporal correlations for prominent periodic and perturbative components.Extensive experiments on multiple real-world datasets demonstrate that FEDDGCN achieves superior predictive performance compared with state-of-the-art methods.",10.1145/3746252.3761048,2025,,ACM,10.1145/3746252.3761048
LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?,"In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities. Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes are publicly available at Github.",10.1145/3637528.3671709,2024,,ACM,10.1145/3637528.3671709
Bi-Modal Learning for Networked Time Series,"Understanding human mobility patterns is a complex challenge that requires modeling both node-oriented time series (e.g., population) and edge-oriented time series (e.g., population flows) within graph topologies across time. While previous methods have focused on either node-oriented time series or interactions, the synergistic integration of these two modalities has proven difficult to achieve. In this paper, we propose BINTS (BI-modal learning for Networked Time Series), a novel bi-modal learning framework that employs soft contrastive learning along the temporal axis. BINTS captures modality similarities and temporal patterns by simultaneously learning from evolving node-oriented time series and interactions, solving the limitations of single-modality approaches. To evaluate our method, we curate comprehensive multi-modal human mobility datasets spanning diverse locations and times. Our experimental results demonstrate that BINTS significantly outperforms existing forecasting models by capturing synergies across different data modalities. Overall, we establish BINTS as a powerful technique for holistically understanding and forecasting complex mobility dynamics. For reproducibility, the source code of our framework is available at https://github.com/kaist-dmlab/BINTS.",10.1145/3711896.3736856,2025,,ACM,10.1145/3711896.3736856
FinD3: A Dual 3D State Space Model with Dynamic Hypergraph for Financial Stock Prediction,"The financial market plays a crucial role in the modern economy by influencing capital allocation, corporate valuation, and investor behavior. However, its complex dependencies and non-stationary dynamics present significant challenges for financial stock prediction. Previous predictive approaches are typically categorized into Univariate Time Series (UTS) and Multivariate Time Series (MTS) paradigms. UTS methods overlook both cross-feature and cross-stock influences, while MTS methods can only capture one of these simultaneously. Although some recent approaches claim to model 3D Multivariate Time Series (3D-MTS) dependencies, they often discard substantial information and fail to capture the dynamics of the stock market. To address these limitations, we propose FinD3, a Financial 3D model using Dual cubic state spaces and Dynamic hypergraphs. To extract the inherent complex relationships in 3D-MTS, we propose a novel Dual Cubic State Space Model (DCSSM) to capture both cross-feature and cross-stock patterns. Furthermore, to more accurately reflect the dynamics of the stock market, we present an Evolving Hypergraph Attention (EHA) module, which captures dynamic changes in financial markets and updates the hypergraph based on a priori hypergraph. Experimental results demonstrate that FinD3 achieves state-of-the-art performance in quantitative trading performance on two real-world stock market datasets, offering a promising solution to practical quantitative trading challenges. The code is available at: https://github.com/decisionintelligence/FinD3.",10.1145/3746252.3761239,2025,,ACM,10.1145/3746252.3761239
Diffusion Graph Model for Time Series Anomaly Detection via Anomaly-aware Graph Sparsification and Augmentation,"Unsupervised methods, particularly reconstruction-based methods have become the dominant approach for multivariate time series anomaly detection (TSAD), which distinguish between normal and abnormal series based on the magnitude of the reconstruction error. However, in this process, the heterophilic connections (normal \l{",10.1145/3701716.3717376,2025,,ACM,10.1145/3701716.3717376
TARNet: Task-Aware Reconstruction for Time-Series Transformer,"Time-series data contains temporal order information that can guide representation learning for predictive end tasks (e.g., classification, regression). Recently, there are some attempts to leverage such order information to first pre-train time-series models by reconstructing time-series values of randomly masked time segments, followed by an end-task fine-tuning on the same dataset, demonstrating improved end-task performance. However, this learning paradigm decouples data reconstruction from the end task. We argue that the representations learnt in this way are not informed by the end task and may, therefore, be sub-optimal for the end-task performance. In fact, the importance of different timestamps can vary significantly in different end tasks. We believe that representations learnt by reconstructing important timestamps would be a better strategy for improving end-task performance. In this work, we propose TARNet, Task-Aware Reconstruction Network, a new model using Transformers to learn task-aware data reconstruction that augments end-task performance. Specifically, we design a data-driven masking strategy that uses self-attention score distribution from end-task training to sample timestamps deemed important by the end task. Then, we mask out data at those timestamps and reconstruct them, thereby making the reconstruction task-aware. This reconstruction task is trained alternately with the end task at every epoch, sharing parameters in a single model, allowing the representation learnt through reconstruction to improve end-task performance. Extensive experiments on tens of classification and regression datasets show that TARNet significantly outperforms state-of-the-art baseline models across all evaluation metrics.",10.1145/3534678.3539329,2022,,ACM,10.1145/3534678.3539329
Towards Spatio-temporal Sea Surface Temperature Forecasting via Dynamic Personalized Graph Network,"Sea surface temperature (SST) is uniquely important to the Earth’s atmosphere since its dynamics are a major force in shaping local and global climate and profoundly affect our ecosystems. Accurate forecasting of SST brings significant economic and social implications, for example, better preparation for extreme weather such as severe droughts or tropical cyclones months ahead. However, such a task faces unique challenges due to the intrinsic complexity and uncertainty of ocean systems. Recently, deep learning techniques, such as graphical neural networks (GNN), have been applied to address this task. While such techniques achieve certain levels of success, they often have significant limitations in exploring dynamic spatio-temporal dependencies between signals. To solve this problem, this paper proposes a novel graph convolution network architecture with static and dynamic learning layers for SST forecasting. Specifically, two adaptive adjacency matrices are firstly constructed to respectively model the stable long-term and short-term evolutionary patterns hidden in the multivariate SST signals. Then, a personalized convolution layer is designed to fuse these information. The developed network can be learned in an end-to-end manner. Our experiments on real SST datasets demonstrate the state-of-the-art performances of the proposed approach on the forecasting task.",10.1145/3582515.3609561,2023,,ACM,10.1145/3582515.3609561
Analyzing Multimodal Sentiment Via Acoustic- and Visual-LSTM With Channel-Aware Temporal Convolution Network,"The emotion of human is always expressed in a multimodal perspective. Analyzing multimodal human sentiment remains challenging due to the difficulties of the interpretation in inter-modality dynamics. Mainstream multimodal learning architectures tend to design various fusion strategies to learn inter-modality interactions, which barely consider the fact that the language modality is far more important than the acoustic and visual modalities. In contrast, we learn inter-modality dynamics in a different perspective via acoustic- and visual-LSTMs where language features play dominant role. Specifically, inside each LSTM variant, a well-designed gating mechanism is introduced to enhance the language representation via the corresponding auxiliary modality. Furthermore, in the unimodal representation learning stage, instead of using RNNs, we introduce ‘channel-aware’ temporal convolution network to extract high-level representations for each modality to explore both temporal and channel-wise interdependencies. Extensive experiments demonstrate that our approach achieves very competitive performance compared to the state-of-the-art methods on three widely-used benchmarks for multimodal sentiment analysis and emotion recognition.",10.1109/taslp.2021.3068598,2021,,ACM,10.1109/taslp.2021.3068598
AMFR: Attentive Multi-Frequency Regressor for High-Precision Numerical Prediction in Large Language Models,"Across diverse benchmarks, large language models set new performance standards., but they are still struggling with high-precision numerical prediction tasks, because large language models are not sensitive to high-precision numbers and often have accuracy problems when faced with thousands of digits. To solve this problem, we propose a novel output layer structure, the Attentional Multi-Frequency Regressor (AMFR). Unlike the traditional linear regression head that simply maps hidden states, AMFR first projects the hidden representation into a multi-frequency space and constructs multi-scale frequency features using learnable sine-cosine basis functions; it then adaptively fuses the frequency components through an integrated attention mechanism to generate more refined high-precision numerical predictions. Experimental results show that AMFR significantly reduces the prediction error in high-precision numerical regression tasks such as molecular property prediction and time series prediction, effectively capturing important information at different frequencies. Our work provides an effective way to improve the performance of large language models in numerical reasoning tasks.",10.1145/3768184.3768253,2025,,ACM,10.1145/3768184.3768253
Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming,"As the financial industry becomes more interconnected and reliant on digital systems, fraud detection systems must evolve to meet growing threats. Cloud-enabled Transformer models present a transformative opportunity to address these challenges. By leveraging the scalability, flexibility, and advanced AI capabilities of cloud platforms, companies can deploy fraud detection solutions that adapt to real-time data patterns and proactively respond to evolving threats. Using the Graph self-attention Transformer neural network module, we can directly excavate gang fraud features from the transaction network without constructing complicated feature engineering. Finally, the fraud prediction network is combined to optimize the topological pattern and the temporal transaction pattern to realize the high-precision detection of fraudulent transactions. The results of anti-fraud experiments on credit card transaction data show that the proposed model outperforms the 7 baseline models on all evaluation indicators: In the transaction fraud detection task, the average accuracy (AP) increased by 20\% and the area under the ROC curve (AUC) increased by 2.7\% on average compared with the benchmark graph attention neural network (GAT), which verified the effectiveness of the proposed model in the detection of credit card fraud transactions.",10.1145/3724154.3724271,2025,,ACM,10.1145/3724154.3724271
LLM4HAR: Generalizable On-device Human Activity Recognition with Pretrained LLMs,"A long-standing challenge for pushing sensor-based human activity recognition (HAR) to industrial usage is the distribution shift between training data and testing data: significant variations in data distribution lead to a notable decline in performance. Recently, Large Language Models (LLMs) have demonstrated exceptional generalization capability, which provides a new opportunity to mitigate the distribution shift problem of HAR. However, since LLMs are inherently designed and trained on textual data, their potential to enhance generalization in HAR applications remains an open question. In this paper, we introduce LLM4HAR, a novel LLM-based model to improve cross-domain HAR. LLM4HAR consists of three main modules: (i) the Sensor Data Adaptation module, which aligns IMU signals with LLMs via sensor embedding(ii) the Sensor Knowledge Learning module, which injects sensor knowledge into LLMs for activity recognition, and (iii) the Efficiency Enhancement module, which employs a partial training strategy and reduces the model size by more than 10 times. Extensive evaluations show that LLM4HAR outperforms the existing methods by 13.82\% in average F1 score, demonstrating the feasibility and effectiveness of transferring knowledge from pretrained LLMs to enhance HAR. Further, LLM4HAR has been adopted by JD Logistics to support downstream applications such as Courier Welfare Improvement and Map Data Generation.",10.1145/3711896.3737226,2025,,ACM,10.1145/3711896.3737226
D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams,"Large quantities of social activity data, such as weekly web search volumes and the number of new infections with infectious diseases, reflect peoples' interests and activities. It is important to discover temporal patterns from such data and to forecast future activities accurately. However, modeling and forecasting social activity data streams is difficult because they are high-dimensional and composed of multiple time-varying dynamics such as trends, seasonality, and interest diffusion. In this paper, we propose D-Tracker, a method for continuously capturing time-varying temporal patterns within social activity tensor data streams and forecasting future activities. Our proposed method has the following properties: (a) Interpretable: it incorporates the partial differential equation into a tensor decomposition framework and captures time-varying temporal patterns such as trends, seasonality, and interest diffusion between locations in an interpretable manner; (b) Automatic: it has no hyperparameters and continuously models tensor data streams fully automatically; (c) Scalable: the computation time of D-Tracker is independent of the time series length. Experiments using web search volume data obtained from GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data Repository show that our method can achieve higher forecasting accuracy in less computation time than existing methods while extracting the interest diffusion between locations. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/D-Tracker.",10.1145/3690624.3709192,2025,,ACM,10.1145/3690624.3709192
SSD-TS: Exploring the Potential of Linear State Space Models for Diffusion Models in Time Series Imputation,"Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability for uncertainty estimation and denoising diffusion probabilistic models (DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1) The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity. 2) The architecture of denoising modules can not handle the dependencies in the time series data effectively. To address the first challenge, we explore the potential of state space model, namely Mamba, as the backbone denoising module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for time series data modeling. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple real-world datasets. Our datasets and code are available at https://github.com/decisionintelligence/SSD-TS/",10.1145/3711896.3737135,2025,,ACM,10.1145/3711896.3737135
CE-FCM: Convolution-Enhanced Fuzzy Cognitive Map for Multivariate Time Series Prediction,"In the realm of time series tasks, fuzzy cognitive maps (FCMs) have demonstrated their potency as a robust model for predicting system states and representing knowledge in an interpretable manner. Recent research efforts have been directed towards enriching the core FCM framework by integrating features like temporal aspects, uncertainty, or fuzzy rules to improve interpretability. Moreover, attempts have been made to integrate fuzzy neural networks or wavelets to enhance the accuracy of time series predictions. However, striking a balance between precision and interpretability in predictions across diverse domains remains a significant challenge. To address the need for capturing spatial relationships between nodes, we introduce graph convolutional networks for predicting multivariate time series. In this work, we propose an innovative extension of FCM, termed fuzzy cognitive map enhanced by deep graph convolution (CE-FCM), and validate its efficacy across four publicly available datasets. Our findings affirm that CE-FCM furnishes pivotal insights for constructing interpretable predictors, thereby offering valuable utility for real-world applications.",10.1145/3679409.3679427,2024,,ACM,10.1145/3679409.3679427
Traffic Flow Prediction Using Spatio-Temporal Graph Neural Networks Based on Hybrid Adaptive Feature Enhancement,"Aiming at the poor adaptation of most current models to dynamic maps and the difficulty in capturing long-term spatio-temporally relevant features, this paper proposes a hybrid adaptive feature-enhanced graph neural network (HAFEGNN) model. To address these challenges, we propose a new approach based on graph neural networks that integrates multiple state-of-the-art enhancement feature representation mechanisms. The model enhances the representation of dynamic spatio-temporal features by integrating multi-scale convolution, channel self-attention and spatial self-attention mechanisms. On top of that, temporal self-attention mechanism is also introduced to focus on learning long-term dependencies, which leads to better understanding of patterns in historical data and making more accurate predictions. The model further incorporates Dynamic Graph Convolutional Recurrent Network (DGCRN) to capture spatio-temporal dynamics. To enhance the adaptability to dynamic graph structures, it integrates spatial location embedding with graph attention mechanisms to form a spatially aware module, which improves the prediction accuracy. Our experimental evaluation on the widely used PeMS04 and PeMS08 datasets demonstrates the effectiveness of the proposed HAFEGNN. The model achieves significant improvements in key metrics such as MAE, RMSE, and MAPE, outperforming existing state-of-the-art methods and validating its ability to handle complex traffic data. This study provides a new solution for traffic flow prediction and demonstrates its potential in handling complex traffic data.",10.1145/3747227.3747240,2025,,ACM,10.1145/3747227.3747240
LENS: Large Pre-trained Transformer for Exploring Financial Time Series Regularities,"Modeling large-scale time series has gained significant attention in recent years. However, its direct application in finance remains challenging due to substantial differences in data characteristics across domains. Specifically, financial systems feature inherent stochasticity and low signal-to-noise ratios, rendering traditional methods and pre-training approaches ineffective. This underscores the urgent need for a foundation model tailored to financial time series. To bridge this gap, we propose LENS, a pre-trained model for this domain. LENS effectively captures the complexity of financial stochastic systems through a carefully crafted model architecture and mitigates noise during pre-training by using an invertible embedding module. We provide a rigorous theoretical explanation of the model’s effectiveness and validate its performance through extensive experiments. Pre-trained on a dataset comprising 100 billion financial observations, LENS achieves exceptional results across a wide range of critical downstream tasks. Moreover, our work offers practical insights into developing pre-trained time series models in high-noise environments, paving the way for further advancements in this pivotal research domain.",10.1145/3768292.3770349,2025,,ACM,10.1145/3768292.3770349
Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback,"In microservice systems, the identification of root causes of anomalies is imperative for service reliability and business impact. This process is typically divided into two phases: (i)constructing a service dependency graph that outlines the sequence and structure of system components that are invoked, and (ii) localizing the root cause components using the graph, traces, logs, and Key Performance Indicators (KPIs) such as latency. However, both phases are not straightforward due to the highly dynamic and complex nature of the system, particularly in large-scale commercial architectures like Microsoft Exchange.In this paper, we propose a new framework that employs Hierarchical Reinforcement Learning from Human Feedback (HRLHF) to address these challenges. Our framework leverages the static topology of the microservice system and efficiently employs the feedback of engineers to reduce uncertainty in the discovery of the service dependency graph. The framework utilizes reinforcement learning to reduce the number of queries required from O(N2) to O(1), enabling the construction of the dependency graph with high accuracy and minimal human effort. Additionally, we extend the discovered dependency graphs to window causal graphs that capture the characteristics of time series over a specified time period, resulting in improved root cause analysis accuracy and robustness. Evaluations on both real datasets from Microsoft Exchange and synthetic datasets with injected anomalies demonstrate superior performance on various metrics compared to state-of-the-art methods. It is worth mentioning that, our framework has been integrated as a crucial component in Microsoft M365 Exchange service.",10.1145/3580305.3599934,2023,,ACM,10.1145/3580305.3599934
HDM-GNN: A Heterogeneous Dynamic Multi-view Graph Neural Network for Crime Prediction,"Smart cities have drawn a lot of interest in recent years, which employ Internet of Things (IoT)-enabled sensors to gather data from various sources and help enhance the quality of residents’ life in multiple areas, e.g. public safety. Accurate crime prediction is significant for public safety promotion. However, the complicated spatial-temporal dependencies make the task challenging, due to two aspects: 1) spatial dependency of crime includes correlations with spatially adjacent regions and underlying correlations with distant regions, e.g. mobility connectivity and functional similarity; 2) there are near-repeat and long-range temporal correlations between crime occurrences across time. Most existing studies fall short in tackling with multi-view correlations, since they usually treat them equally without consideration of different weights for these correlations. In this paper, we propose a novel model for region-level crime prediction named as Heterogeneous Dynamic Multi-view Graph Neural Network (HDM-GNN). The model can represent the dynamic spatial-temporal dependencies of crime with heterogeneous urban data, and fuse various types of region-wise correlations from multiple views. Global spatial dependencies and long-range temporal dependencies can be derived by integrating the multiple GAT modules and Gated CNN modules. Extensive experiments are conducted to evaluate the effectiveness of our method using several real-world datasets. Results demonstrate that our method outperforms state-of-the-art baselines. All the code are available at https://github.com/ZJUDataIntelligence/HDM-GNN.",10.1145/3665141,2024,,ACM,10.1145/3665141
The 10th ACM SIGSPATIAL International Workshop on Analytics for Big Spatial Data (BigSpatial 2022),"Analysis and management of big data are important areas of research for data researchers and scientists. Both the industry and governmental agencies have invested tremendous resources and effort in the area of big data analysis and management in the past decade. Within the realm of big data, spatial and spatio-temporal data are still one of the fastest-growing types of data. With advances in remote sensors, sensor networks, and the proliferation of location sensing devices in daily life activities and common business practices, the generation of disparate, dynamic, and geographically distributed spatiotemporal data has continued to explode in recent years. In addition, significant progress in ground, air, and space-borne sensor technologies has led to unprecedented access to earth science data for scientists from different disciplines. For example, NASA recently collected its 10 millionth Landsat image [4] and the volume of satellite imagery being collected has reached the petabyte scale. Analysis of this large-scale data poses new challenges to researchers.",10.1145/3632268.3632281,2023,,ACM,10.1145/3632268.3632281
LSTM-Copula Hybrid Approach for Forecasting Risk in Multi-Asset Portfolios,"This study proposes a multi-asset portfolio risk prediction model that integrates Long Short-Term Memory (LSTM) networks with Copula functions. The model is designed to capture both the temporal dynamics of financial asset returns and the nonlinear dependencies among assets. LSTM is used to model the marginal distributions of individual asset return series. Copula functions are employed to describe the joint distribution structure across multiple assets. This allows for accurate prediction of key portfolio risk metrics such as Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR). In the experimental design, several baseline models are constructed for performance comparison. Further analyses are conducted to assess the model's risk prediction ability under varying numbers of assets and to evaluate risk coverage across different confidence intervals. The experimental results show that the proposed LSTM-Copula model outperforms mainstream methods across multiple evaluation metrics. It demonstrates higher robustness and predictive accuracy, particularly in high-dimensional and sparse data settings. This approach offers a novel path for financial risk management by combining statistical modeling with deep learning. It provides strong empirical results and holds substantial practical value for applications in complex financial environments.",10.1145/3746972.3746978,2025,,ACM,10.1145/3746972.3746978
DETECTive: Machine Learning-driven Automatic Test Pattern Prediction for Faults in Digital Circuits,"Due to the continuous technology scaling and the ever-increasing complexity and size of the hardware designs, manufacturing defects have become a key obstacle in meeting end-user demand. Despite decades of research, traditional test-generation techniques often struggle to scale to massive and complex designs. Such scalability issues stem from the numerous backtracking the traditional test generation techniques perform before converging to a test pattern. In this work, we present DETECTive that leverages deep learning on graphs to learn fault characteristics and predict test pattern(s) to expose faults without requiring backtracking. DETECTive is trained on small circuits, and its learned knowledge is transferable to predict test patterns for circuits that contain up to 29 \texttimes{",10.1145/3649476.3658696,2024,,ACM,10.1145/3649476.3658696
WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis,"Given its broad applications, time series analysis has gained substantial research attention but remains a very challenging task. Recent years have witnessed the great success of deep learning methods, eg., CNN and RNN, in time series classification and forecasting, but heterogeneity as the very nature of time series has not yet been addressed adequately and remains the performance ",10.1145/3580305.3599549,2023,,ACM,10.1145/3580305.3599549
SolarMAE: A Unified framework for Regional Centralized and Distributed Solar Power Forecasting with Weather Pre-training,"The recent surge in solar plant installations has notably decreased the reliance on fossil fuels while also presenting significant challenges to power grid. Therefore, the accurate forecasting of centralized and distributed solar power has become critically important. Although site-specific forecasting models typically perform better for utility-scale solar power plants, the model maintenance can be troublesome as the number of solar plants grows. Furthermore, the rapid growth and difficulties in real-time data collection associated with distributed solar systems exacerbate the complexity of regional gross solar power forecasting. To address these issues, we propose SolarMAE, a unified regional solar power forecasting framework enabling end-to-end precise forecasting for both centralized and distributed solar systems. It adopts masked autoencoder (MAE) pre-training strategy for numerical weather prediction (NWP) reconstruction at first, aiming to derive spatiotemporal correlations within meteorological variables, and then fine-tunes a temporal convolutional neural network which predicts future solar power generation. Experiments show that this framework outperforms state-of-the-art centralized or distributed solar power forecasting methods in accuracy, and significantly reduces model maintenance cost. It also demonstrates strong few-shot learning capabilities, which is particularly useful for the cold start problem of newly installed solar plants. The unified solar power forecasting system has been deployed in a province in eastern China, serving solar systems with over 73 GW gross installed capacity and more than 400 centralized solar plants.",10.1145/3746252.3761543,2025,,ACM,10.1145/3746252.3761543
Transformer-Based Risk Monitoring for Anti-Money Laundering with Transaction Graph Integration,"This study addresses the growing complexity of transaction behaviors and the highly concealed nature of money laundering paths in current financial AML scenarios. It proposes a Transformer-based risk monitoring model for anti-money laundering. The approach is grounded in transaction sequence modeling and integrates the structural information of transaction graphs. A context-aware classifier is introduced to enable accurate identification and risk scoring of high-risk accounts. The model first applies feature embedding and positional encoding to each transaction. It then uses multiple Transformer layers to capture long-range behavioral dependencies. At the same time, it incorporates account interaction information from the graph structure. This enhances the model's ability to detect abnormal transaction chains across accounts. At the output stage, a classifier that fuses sequential semantics with graph context is used to determine the overall money laundering risk of each account. Multiple experiments were conducted on the publicly available Elliptic dataset. Results show that the proposed method outperforms existing mainstream models on evaluation metrics such as AUC, F1-Score, and Accuracy. It also demonstrates stronger discriminative power and greater stability in identifying high-risk accounts. Further analysis of model depth sensitivity and case-based verification supports the model's effectiveness in real-world complex transaction environments. The proposed method offers a more adaptable technical solution for financial institutions dealing with large-scale suspicious behavior detection tasks.",10.1145/3762249.3762309,2025,,ACM,10.1145/3762249.3762309
DPP: A Dual-Phase Processing Method for Cross-Cultural Humor Detection,"Multimodal humor detection has become an active research area in the field of artificial intelligence. This paper presents the solution for the MuSe-Humor sub-challenge of cross-cultural humor detection. The goal of the MuSe-Humor sub-challenge is to predict whether humor exists in a given dataset, which includes data from various modalities such as text, audio, and video. The training data consists of German recordings and their transcriptions, while the test data is in English. This cross-cultural testing introduces new challenges, distinguishing it from ordinary multimodal humor detection tasks. To address this issue, we propose a method called Dual-Phase Processing (DPP). The proposed method first preprocesses the text data using a large language model to extract more effective features for humor detection from the raw data. It also partially addresses cross-cultural differences through bilingual annotation. Finally, by applying composite temporal smoothing to the results after decision-level fusion of the three modalities, the accuracy of humor prediction is greatly improved. The experimental results on the official test set demonstrate the effectiveness of our model. Our model achieves an impressive AUC score of 0.9366 on the test set, far surpassing the baseline and securing the first-place ranking.",10.1145/3689062.3689080,2024,,ACM,10.1145/3689062.3689080
A Cross Domain Method for Customer Lifetime Value Prediction in Supply Chain Platform,"Accurate customer LifeTime Value (LTV) predictions are crucial for customer relationship management, especially in Supply Chain Platforms (SCP), which involve effectively managing the service resources in business decision-making. Previous LTV prediction methods usually rely on ample historical customer data, which is not available in the early stages of a customer's lifecycle. It makes the modeling of the historical customer data a difficult task due to the data sparsity. Besides, the long-tail distribution of customer LTV also brings new challenges to the prediction of LTV. To tackle the above issues, we propose CDLtvS, a novel Cross Domain method for customer Lifetime value prediction in SCP. It leverages rich cross-domain information from upstream platforms to enhance LTV predictions in downstream platforms. Firstly, CDLtvS pre-trains the customer representations by an LTV modeling framework named LtvS in source and target domains separately. Specifically, LtvS incorporates the Expert Mask Network (ExMN), which not only effectively models the long-tail distribution of LTV in single-domain but also resolves cross-domain learning model bias resulting from this distribution. Then, the various-level alignment mechanism is introduced to keep the consistency of knowledge transferring from source to target domains on both sparse and non-sparse data. Comprehensive experiments on real-world data from JD, one of the world's largest supply chain platforms, demonstrate that CDLtvS achieves a normalized mean average error of 0.3378 in LTV prediction, outperforming 16.3\% to the baseline. Additionally, the improvements of ≥2.3\% across various data sparsity levels (0\% -- 80\%) provide valuable insights into cross-domain LTV modeling.",10.1145/3589334.3645391,2024,,ACM,10.1145/3589334.3645391
Disentangled Dynamic Graph Attention Network for Out-of-Distribution Sequential Recommendation,"Sequential recommendation, leveraging user-item interaction histories to provide personalized and timely suggestions, has drawn significant research interest recently. With the power of exploiting spatio-temporal dynamics, Dynamic Graph Neural Networks (DyGNNs) show great potential in sequential recommendation by modeling the dynamic relationship between users and items. However, spatio-temporal distribution shifts naturally exist in out-of-distribution sequential recommendation, where both user-item relationships and temporal sequences demonstrate pattern shifts. The out-of-distribution scenarios may lead to the failure of existing DyGNNs in handling spatio-temporal distribution shifts in sequential recommendation, given that the patterns they exploit tend to be variant w.r.t labels under distribution shifts. In this article, we propose Disentangled Intervention-based Dynamic graph Attention networks with Invariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in sequential recommendation by discovering and utilizing invariant patterns, i.e., structures and features whose predictive abilities are stable across distribution shifts. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns. By utilizing the disentangled patterns, we design a spatio-temporal intervention mechanism to create multiple interventional distributions and an environment inference module to infer the latent spatio-temporal environments, and minimize the invariance loss to leverage the invariant patterns with stable predictive abilities under distribution shifts. Extensive experiments demonstrate the superiority of our method over state-of-the-art sequential recommendation baselines under distribution shifts.",10.1145/3701988,2024,,ACM,10.1145/3701988
Synthesizing Multimodal Electronic Health Records via Predictive Diffusion Models,"Synthesizing electronic health records (EHR) data has become a preferred strategy to address data scarcity, improve data quality, and model fairness in healthcare. However, existing approaches for EHR data generation predominantly rely on state-of-the-art generative techniques like generative adversarial networks, variational autoencoders, and language models. These methods typically replicate input visits, resulting in inadequate modeling of temporal dependencies between visits and overlooking the generation of time information, a crucial element in EHR data. Moreover, their ability to learn visit representations is limited due to simple linear mapping functions, thus compromising generation quality. To address these limitations, we propose a novel EHR data generation model called EHRPD. It is a diffusion-based model designed to predict the next visit based on the current one while also incorporating time interval estimation. To enhance generation quality and diversity, we introduce a novel time-aware visit embedding module and a pioneering predictive denoising diffusion probabilistic model (P-DDPM). Additionally, we devise a predictive U-Net (PU-Net) to optimize P-DDPM. We conduct experiments on two public datasets and evaluate EHRPD from fidelity, privacy, and utility perspectives. The experimental results demonstrate the efficacy and utility of the proposed EHRPD in addressing the aforementioned limitations and advancing EHR data generation.",10.1145/3637528.3671836,2024,,ACM,10.1145/3637528.3671836
Enhancing Spatial-Temporal Prediction Models with Dynamic Causal Graphs,"Spatial-temporal prediction has become an important task in many applications, such as traffic forecasting. Due to the spatial-temporal nature of data, most state-of-the-art methods heavily depend on graph neural networks to model the inherent spatial relationships. However, most of them process the spatial data by applying the prior adjacency knowledge or learning a static adaptive adjacency matrix. Thus, their prediction performance is limited on dynamic situations where the spatial dependencies change w.r.t time. Furthermore, considering the stochastic training process, learning an adaptive adjacency matrix from scratch also makes it difficult for the neural network to achieve stable parameters and performance. To address the above challenges, this paper proposes three practical extensions that incorporate dynamic causal knowledge into the training of graph convolution networks. We first analyze the dynamic causal graphs between traffic nodes with one dynamic causal discovery algorithm in each extended model. Subsequently, the spatial module employs dynamic causal graphs to reveal the evolving connections among nodes. Extensive experiments demonstrate that our method has successfully enhanced state-of-the-art traffic forecasting models on two benchmarks.",10.1145/3777547,2025,,ACM,10.1145/3777547
A Survey of Learning-based Method Name Prediction,"The choice of method names significantly influences code comprehension and maintenance, posing a considerable challenge, especially for novice developers. Automating the prediction of appropriate method names based on the method code body has emerged as a promising approach to address this challenge. In recent years, numerous machine/deep learning (ML/DL)-based method name prediction (MNP) techniques have been proposed. However, a systematic review of these techniques is currently lacking, hindering future researchers from understanding the research status, development trends, challenges, and opportunities in this field. To fill this gap, in this paper, we conduct a systematic literature review on learning-based MNP studies. Specifically, we first perform a thorough review of the literature concerning publication venue, publication year, and contribution types. This analysis enables us to discern trends in studies related to MNP. Second, we depict the general workflow of learning-based MNP techniques, which involves three consecutive subprocesses: context extraction, context preprocessing, and context-based prediction. Subsequently, we investigate contemporary techniques/solutions applied in the three subprocesses. Third, we scrutinize the widely used experimental databases, evaluation metrics, and replication packages utilized in MNP studies. Moreover, we summarize existing empirical studies on MNP to facilitate a quick understanding of their focus and findings for subsequent researchers. Finally, based on a systematic review and summary of existing work, we outline several open challenges and opportunities in MNP that remain to be addressed in future work.",10.1145/3771999,2025,,ACM,10.1145/3771999
Decomposed Attention Segment Recurrent Neural Network for Orbit Prediction,"As the focus of space exploration shifts from national agencies to private companies, the interest in space industry has been steadily increasing. With the increasing number of satellites, the risk of collisions between satellites and space debris has escalated, potentially leading to significant property and human losses. Therefore, accurately modeling the orbit is critical for satellite operations. In this work, we propose the Decomposed Attention Segment Recurrent Neural Network (DASR) model, adding two key components, Multi-Head Attention and Tensor Train Decomposition, to SegRNN for orbit prediction. The DASR model applies Multi-Head Attention before segmenting at input data and before the input of the GRU layers. In addition, Tensor Train (TT) Decomposition is applied to the weight matrices of the Multi-Head Attention in both the encoder and decoder. For evaluation, we use three real-world satellite datasets from the Korea Aerospace Research Institute (KARI), which are currently operating: KOMPSAT-3, KOMPSAT-3A, and KOMPSAT-5 satellites. Our proposed model demonstrates superior performance compared to other SOTA baseline models. We demonstrate that our approach has 94.13\% higher predictive performance than the second-best model in the KOMPSAT-3 dataset, 89.79\% higher in the KOMPSAT-3A dataset, and 76.71\% higher in the KOMPSAT-5 dataset.",10.1145/3637528.3671546,2024,,ACM,10.1145/3637528.3671546
GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis,"The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series for climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends. We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.",10.1145/3674029.3674059,2024,,ACM,10.1145/3674029.3674059
Prediction of Impacts of Digital Transformation on Business Performance using LSTM model,"The impacts of digital transformation on the business performance of enterprises are examined using the LSTM models in the present work. Corporate giants like Alibaba, Huawei, and Tencent have, by embracing digital transformation and introducing technological solutions like cloud computing and artificial intelligence (AI), improved their decision-making and business efficiency. To predict the impacts of these digital technologies on business performance, the long short-term memory (LSTM) model provides a solution. In the present work, an LSTM model is employed to predict the business performance of some large enterprises in China and it is revealed that the models achieve a high accuracy in prediction, with an R2 of 0.99 and an accuracy of 97\% for the prediction of Huawei at an embedding size of 40. With a focus on the hyperparameter tuning and dropout rates, we find that increasing the units of the LSTM model can improve the prediction accuracy, but the returns reduce when the units are beyond 150. Our LSTM model provides a practical solution for business performance prediction under the impact of digital transformation.",10.1145/3736426.3736434,2025,,ACM,10.1145/3736426.3736434
Loss or Gain: Hierarchical Conditional Information Bottleneck Approach for Incomplete Time Series Classification,"Incomplete time series classification is both practically valuable and challenging as missing values in time series data are prevalent in real-world scenarios. Current approaches suffer from two major limitations. First, they overemphasize the consistency of data reconstruction during missing value imputation while neglecting the task-effectiveness of the imputed results for the classification. Second, they fail to systematically establish a synergistic optimization mechanism between data imputation and feature representation. To address these challenges, we propose a Hierarchical Conditional Information Bottleneck (HCIB) framework, which achieves incomplete time series classification through end-to-end joint optimization. Specifically, at the data imputation level, we re-examine the dual effects of missing data: the loss of critical information (Loss) versus the gain in interference suppression (Gain), elucidating this duality through bias-variance trade-off theory. Building on this analysis, we propose a task-information sufficiency criterion and extend the information bottleneck theory into a task-driven imputation framework by incorporating label information as a conditional constraint. At the feature representation level, we construct a hierarchical information bottleneck architecture to learn compressed yet informative temporal representations from the task-oriented imputed data. Furthermore, we derive the optimizable objective function for HCIB and design specialized neural network architectures for time series. Comprehensive experiments on multivariate and univariate time series datasets across multiple domains consistently demonstrate that the proposed method achieves significant improvements in classification performance compared to SOTA approaches.",10.1145/3711896.3737033,2025,,ACM,10.1145/3711896.3737033
Multi-view Self-Supervised Contrastive Learning for Multivariate Time Series,"Learning semantic-rich representations from unlabeled time series data with intricate dynamics is a notable challenge. Traditional contrastive learning techniques predominantly focus on segment-level augmentations through time slicing, a practice that, while valuable, often results in sampling bias and suboptimal performance due to the loss of global context. Furthermore, they typically disregard the vital frequency information to enrich data representations. To this end, we propose a novel self-supervised general-purpose framework called Temporal-Frequency and Contextual Consistency (TFCC). Specifically, this framework first performs two instance-level augmentation families over the entire series to capture nuanced representations alongside critical long-term dependencies. Then, TFCC advances by initiating dual cross-view forecasting tasks between the original series and its augmented counterpart in both time and frequency domains to learn robust representations. Finally, three specially designed consistency modules 'temporal, frequency, and temporal-frequency' aid in further developing discriminative representations on top of the learned robust representations. Extensive experiments on multiple benchmarks demonstrate TFCC's superiority over the state-of-the-art classification and forecasting methods and exhibit exceptional efficiency in semi-supervised and transfer learning scenarios.",10.1145/3664647.3681095,2024,,ACM,10.1145/3664647.3681095
Fairness-Aware Graph Neural Networks: A Survey,"Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. We categorize these techniques by whether they focus on improving fairness in the pre-processing, in-processing (during training), or post-processing phases. We discuss how such techniques can be used together whenever appropriate and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics, including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.",10.1145/3649142,2024,,ACM,10.1145/3649142
Decoupling Spatio-Temporal Prediction: When Lightweight Large Models Meet Adaptive Hypergraphs,"Spatio-temporal prediction is a pivotal task with broad applications in traffic management, climate monitoring, energy scheduling, etc. However, existing methodologies often struggle to balance model expressiveness and computational efficiency, especially when scaling to large real-world datasets. To tackle these challenges, we propose STH-SepNet (Spatio-Temporal Hypergraph Separation Networks), a novel framework that decouples temporal and spatial modeling to enhance both efficiency and precision. Therein, the temporal dimension is modeled using lightweight large language models, which effectively capture low-rank temporal dynamics. Concurrently, the spatial dimension is addressed through an adaptive hypergraph neural network, which dynamically constructs hyperedges to model intricate, higher-order interactions. A carefully designed gating mechanism is integrated to seamlessly fuse temporal and spatial representations. By leveraging the fundamental principles of low-rank temporal dynamics and spatial interactions, STH-SepNet offers a pragmatic and scalable solution for spatio-temporal prediction in real-world applications. Extensive experiments on large-scale real-world datasets across multiple benchmarks demonstrate the effectiveness of STH-SepNet in boosting predictive performance while maintaining computational efficiency. This work may provide a promising lightweight framework for spatio-temporal prediction, aiming to reduce computational demands and while enhancing predictive performance. Our code is avaliable at https://github.com/SEU-WENJIA/ST-SepNet-Lightweight-LLMs-Meet-Adaptive-Hypergraphs.",10.1145/3711896.3736904,2025,,ACM,10.1145/3711896.3736904
Leveraging LLMs for Semantic Correlation Enhancement in Spatial-temporal Imputation,"Spatial-temporal imputation remains a challenging problem in transportation, environment and healthcare, where the missing value is filled based on spatial, temporal, and cross correlations. Previous research mainly focused on feature-level correlation integration and comprehension with the hand-crafted enhancement strategy. Meanwhile, the recently prevalent large language models (LLMs) provide token-level understanding for language linguistics, and whether they could be applied for spatial-temporal correlation enhancement is under exploration. To this end, we proposed an LLM-native framework STOMA to fully utilize the intrinsic relevance. We designed semantic enhancing methods by converting the complex correlations, e.g. spatial correlation in network, temporal correlation with periodicity and cross correlation from human behavior, into the embedded tokens. Specifically, we reform dynamic time warping as an asymmetric correlation constructor for complex dynamics. We adapt the proposed backbone along with the spatial-temporal fine-tuning technique, and the empirical results demonstrate the effectiveness of our methods over recent LLM-inspired methods evaluating on real-world datasets.",10.1145/3776557,2025,,ACM,10.1145/3776557
Generalizable Recommender System During Temporal Popularity Distribution Shifts,"Many modern recommender systems represent user and item attributes as embedding vectors, relying on them for accurate recommendations. However, entangled embeddings often capture not only intrinsic property factors (e.g., user interest in item property) but also popularity factors (e.g., user conformity to item popularity) indistinguishably. These embeddings, influenced by popularity distribution, may face challenges when the popularity distribution at test time differs from historical distribution. Existing remedies in the literature involve disentangled embedding learning, which aims to separately capture intrinsic and popularity factors, demonstrating plausible generalization during popularity distribution shifts. However, we highlight that these methods often overlook a crucial aspect of popularity shifts-their temporal nature-in both training and inference phases. To address this, we propose Temporal Popularity distribution shift generalizABle recommender system (TPAB), a novel disentanglement framework incorporating temporal popularity. TPAB introduce a new (1) temporal-aware embedding design for users and items. Within this design, (2) popularity coarsening and (3) popularity bootstrapping are proposed to enhance generalization further. We also provide theoretical analysis showing that the bootstrapping loss eliminates the effect of popularity on the learned model. During inference, we infer test-time popularity and corresponding embeddings, using them alongside property embeddings for prediction. Extensive experiments on real-world datasets validate TPAB, showcasing its outstanding generalization ability during temporal popularity distribution shifts.",10.1145/3690624.3709299,2025,,ACM,10.1145/3690624.3709299
Comparative Analysis of Deep Learning-based Anomaly Detection Models for GPS Spoofing Detection,"As autonomous vehicles (AVs) become vital to modern systems, their vulnerability to cyber-attacks, especially GPS spoofing, presents a significant security threat. This study addresses these challenges by applying a suite of machine learning models to enhance the detection of anomalous GPS signals. We concentrate on autoencoder-based architectures, training models like LSTM-VAE, LSTM-AE, MLP-VAE, MLP-AE, Stacked-LSTM-VAE, and Stacked-LSTM-AE exclusively with authentic GPS data. This strategy improves spoofed signal detection by recognizing deviations from normal patterns through reconstruction error analysis. Our comparative analysis highlights the distinct capabilities of these models in distinguishing between authentic and spoofed signals, with the MLP-AE and Stacked-LSTM models showing notable performance differences. The MLP-AE model demonstrated significant detection abilities with an accuracy of 95.40\%, precision of 93.09\%, and ROC-AUC score of 94.35\%. Similarly, Stacked-LSTM models employing deeper learning structures proved highly effective in managing complex noisy data, crucial for high-stakes applications like AV navigation. The results highlight the potential of combining autoencoder models with MLP or Stacked-LSTM to enhance AV security against GPS spoofing, affirming the value of unsupervised learning for anomaly detection.",10.1145/3649601.3698743,2025,,ACM,10.1145/3649601.3698743
Attention-Based Multi-Asset Order Flow Networks for Enhanced Mid-Price Prediction,"Financial markets are complex adaptive systems where assets continuously influence each other through dynamic and nonlinear interactions. Accurate mid-price forecasting in high-frequency trading (HFT) depends on capturing these market-wide dynamics. While order flow imbalance (OFI) features have proven more effective than raw limit order book (LOB) data for short-term forecasting, most existing models remain limited to single-asset dynamics, ignoring informative signals from related instruments. We propose OF-MATNet, a deep learning-based multi-asset forecasting framework that leverages OFI data from multiple Nasdaq-listed assets. Our approach captures nonlinear cross-asset dependencies through a Transformer-based architecture with multi-axis attention mechanisms over time, assets, and order book levels, enhanced with positional encoding. Informative peer assets for each target are selected using rolling-window Granger causality tests conducted during the training phase, enabling the model to exploit statistically validated cross-asset influences. Experiments on 110 assets show that OF-MATNet significantly outperforms both our single-asset baseline (OF-SATNet) and state-of-the-art models such as DeepLOB, BINCTABL, and TLOB. OF-MATNet achieves consistent R2 improvements in over 90\% of cases, with larger gains for assets highly influenced by peers or at longer prediction horizons. Further analysis reveals that temporal attention contributes most to forecasting, but cross-asset and level-wise information are critical in enhancing accuracy. These findings underscore the practical value of modeling nonlinear cross-asset relationships for strategic financial decision-making.",10.1145/3768292.3770430,2025,,ACM,10.1145/3768292.3770430
Coronary Heart Disease Prediction Technique Based on Self-Attention Mechanism and Contrastive Learning,"Cardiovascular disease remains one of the leading causes of mortality worldwide, with coronary heart disease(CHD) being a predominant form of cardiac pathology. Electrocardiogram (ECG) is widely employed for cardiac disease detection; however, accurate interpretation of ECG signals requires substantial clinical expertise. To address this challenge, this paper proposes a novel approach that combines Butterworth filtering and​continuous wavelet transform (CWT) to extract time-frequency domain features from ECG signals. Subsequently, a self-attention mechanism and contrastive learning framework are utilized to pre-train an ECG time-frequency feature extractor, ultimately enabling the development of a dedicated prediction network for CHD diagnosis. The proposed method is rigorously evaluated using ECG data from the publicly available MIMIC-III dataset. Experimental results demonstrate exceptional performance, achieving 90\% accuracy and 90\% F1-score in CHD prediction, outperforming existing models such as convolutional neural networks (CNNs).",10.1145/3745034.3745131,2025,,ACM,10.1145/3745034.3745131
An Ocean Time Series Prediction Framework Based on Improved PSO with Multiscale Learning,"Accurate prediction of marine time series data is of great practical significance for the protection of marine ecosystems and the sustainable utilization of marine resources. Marine time series data, such as those containing marine parameters such as chlorophyll, turbidity, CDOM, etc., are characterized by high complexity and significant time periodicity. In this paper, oriented to the real ocean time series data prediction scenarios, we design an ocean time series prediction framework based on improved PSO and multi-scale learning for the problems of different inter- and intra-series correlations between ocean time series data on different time scales and the need to set the hyper-parameters individually on different datasets. The framework firstly extracts the significant periodicity in ocean time series data by frequency domain analysis technique and decomposes it to multiple time scales. Secondly, an adaptive graph convolutional network is incorporated to allow correlations between sequences to be independently explored and learned at different time scales, while a self-attention mechanism is incorporated to accurately capture correlations and dependencies within the time series. Finally, an adaptive and dynamic particle swarm optimization algorithm (ANDPSO) is proposed, which reduces the risk of the algorithm falling into a local optimal solution and helps the framework to select the key hyperparameters through the dynamic improvement of inertia weights and learning factors as well as the introduction of population diversity judgment mechanism. Experimental results show that the prediction performance of the framework outperforms the baseline model on a real ocean time series dataset, and ablation experiments are conducted to confirm the indispensability of each component, aiming to provide support for real ocean time series prediction scenarios.",10.1145/3705677.3705678,2025,,ACM,10.1145/3705677.3705678
Cyber Social Threats: A Data-centric AI Perspective,"With the proliferation of social media platforms, cyber social threats such as fake news, hate speech, and cyberbullying have increased significantly. With the availability of abundant data for building machine learning models, artificial intelligence (AI) is making a deep impact in almost every domain, including detecting and mitigating cyber social threats on social media platforms. As the role of data in AI has significantly intensified in recent years, the concept of data-centric AI has emerged, gradually shifting the research focus from improving model design to enhancing the quality and quantity of data. In this paper, we first present the limitations of model-centric AI in the context of cyber social threats, then discuss the existing literature that uses data-centric AI techniques to detect and mitigate cyber social threats. We finally present the major challenges that social media data presents to deal with cyber social threats using data-centric AI and describe future research opportunities.",10.1145/3696673.3723071,2025,,ACM,10.1145/3696673.3723071
TF-MERC: Integrating Time-Frequency Information for Multimodal Emotion Recognition in Conversation,"Multimodal emotion recognition in conversations aims to accurately detect emotions by integrating audio, text, and video modalities, playing an important role in various systems. Existing approaches utilize convolutional and recurrent networks to learn short-term emotional information from individual modalities, or employ graph and attention mechanisms to integrate long-term emotional information from multiple modalities. These methods effectively combine emotional information within the conversational content in the time domain.However, psychological research shows that emotional information are not only conveyed in the time domain but also in the frequency domain (e.g., pitch and speech rate). To capture emotions from a more comprehensive perspective, we propose TF-MERC, a framework that integrates both time and frequency domains.TF-MERC uses a multi-domain alignment module to learn modality information within the time or frequency domains. It then employs FATransformer to deeply integrate the multimodal associations between the time and frequency domains, providing a more comprehensive approach for emotion prediction.Experimental results show that TF-MERC outperforms state-of-the-art methods, achieving superior performance across multiple datasets.",10.1145/3731715.3733447,2025,,ACM,10.1145/3731715.3733447
Dynamic Graph Convolutional Transformer for Short-term Wind Speed Forecasting,"Wind speed forecasting is still a challenging problem, especially considering the correlations of spatial and temporal domains. However, the changing properties of spatial dependencies over time are ignored in most existing algorithms. In this paper, we propose a novel spatio-temporal machine learning algorithm, named Dynamic Graph Convolutional Transformer (DGCT), for wind speed forecasting. The key contribution of the proposed method is that graph convolutional networks are embedded into self-attention layers of Transformer to capture spatio-temporal correlations to improve the accuracy of forecasting. For the changing properties of spatial dependencies, we model the spatial dependencies as a mixture of global and localized patterns, which are represented by static and dynamic matrices respectively. Moreover, an auxiliary network is designed to generate the dynamic matrix, which further improve the forecasting accuracy. Experiments on two real-world datasets demonstrate that the proposed method outperformed other existing methods consistently.",10.1145/3594315.3594385,2023,,ACM,10.1145/3594315.3594385
ASTGCL: Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction,"With the rise of intelligent urban systems, traffic flow prediction has emerged as a vital element within intelligent transportation frameworks. Graph neural networks (GNNs) are crucial for traffic flow prediction due to the non-Euclidean nature of traffic networks. Most GNN-based approaches depend on predefined adjacency matrices, frequently failing to model complex global dependencies. Additionally, these methods primarily use supervised learning, which is highly dependent on data quality. However, traffic data often suffers from missing values caused by sensor malfunctions, hindering effective feature extraction. To overcome these limitations, a novel framework called Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction (ASTGCL) is introduced to improve prediction performance. Specifically, ASTGCL implements two data augmentation strategies: first, it employs an adaptive, learnable adjacency matrix to enhance the predefined matrix, enabling the model to capture both local and global topological features; second, it integrates three traffic data augmentation techniques to reduce the influence of data noise on prediction accuracy. The enhanced adjacency matrix and augmented traffic data are then utilized in a spatio-temporal contrastive learning process to extract higher-order spatio-temporal features from the traffic flow data. Experiments conducted on four real-world datasets reveal that ASTGCL surpasses baseline models, confirming the efficacy of the proposed framework.",10.1145/3746709.3746760,2025,,ACM,10.1145/3746709.3746760
ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations,"Neural ordinary differential equations (NODEs) presented a new paradigm to construct (continuous-time) neural networks. While showing several good characteristics in terms of the number of parameters and the flexibility in constructing neural networks, they also have a couple of well-known limitations: i) theoretically NODEs learn homeomorphic mapping functions only, and ii) sometimes NODEs show numerical instability in solving integral problems. To handle this, many enhancements have been proposed. To our knowledge, however, integrating attention into NODEs has been overlooked for a while. To this end, we present a novel method of attentive dual co-evolving NODE (ACE-NODE): one main NODE for a downstream machine learning task and the other for providing attention to the main NODE. Our ACE-NODE supports both pairwise and elementwise attention. In our experiments, our method outperforms existing NODE-based and non-NODE-based baselines in almost all cases by non-trivial margins.",10.1145/3447548.3467419,2021,,ACM,10.1145/3447548.3467419
Context-aware Event Forecasting via Graph Disentanglement,"Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information.To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual information. First, the categorical context provides supplementary fine-grained information to the coarse-grained events. Second and more importantly, the context provides additional information towards specific situation and condition, which is crucial or even determinant to what will happen next. However, it is challenging to properly integrate context into the event forecasting framework, considering the complex patterns in the multi-context scenario. Towards this end, we design a novel framework named Separation and Collaboration Graph Disentanglement (short as SeCoGD) for context-aware event forecasting. In the separation stage, we leverage the context as a prior guidance to disentangle the event graph into multiple sub-graphs, followed by a context-specific module to model the relational-temporal patterns within each context. In the collaboration stage, we design a cross-context module to retain the collaborative associations among multiple contexts. Since there is no available dataset for this novel task, we construct three large- scale datasets based on GDELT. Experimental results demonstrate hat our model outperforms a list of SOTA methods. The dataset and code are released via https://github.com/yecchen/SeCoGD.",10.1145/3580305.3599285,2023,,ACM,10.1145/3580305.3599285
Are Time Series Foundation models good for Energy Anomaly Detection?,"Smart energy meters generate large volumes of fine-grained time series data that captures building’s energy consumption patterns. This data can be leveraged to detect anomalous energy consumption patterns and reduce energy waste in buildings. Traditional anomaly detection methods for smart meter data rely on statistical and machine learning techniques, which often struggle to model complex temporal patterns, require extensive feature engineering, and have poor scalability. Foundation models for time series, which are pretrained on massive volumes of time series data from diverse domains, have recently emerged as a versatile and scalable tool for time series analysis. They are capable of handling multiple tasks, including anomaly detection, and demonstrating superior performance compared to traditional models in various domains. Despite their potential for cross-domain applications, their applicability to the energy domain and their performance compared to traditional machine learning models remain largely unexplored.Therefore, in this paper, we analyze the applicability and performance of Time Series Foundation Models (TSFMs) for unsupervised energy anomaly detection. Specifically, we compare the performance of two widely used state-of-the-art TSFMs, TimeGPT and MOMENT, against existing anomaly detection techniques in the literature: (a) two statistical methods (Interquartile Range (IQR) and Modified Z-Score (mZ-Score)), (b) two unsupervised machine learning techniques (Isolation Forest and Local Outlier Factor), and (c) a deep learning-based technique, Variational Autoencoder (VAE). Our experimental results, conducted using the LEAD 1.0 dataset, which consists of annotated hourly energy readings of 200 buildings, show that MOMENT outperforms both traditional statistical methods and unsupervised machine learning methods. Our results reveal that fine-tuning of MOMENT marginally improves its performance. VAE trained from scratch surpasses TSFMs in performance despite having a smaller model size. We also analyze the trade-off between performance, scalability, and compute requirements of these models. Our analysis also provides new research directions for using TSFMs in the energy domain.",10.1145/3679240.3734633,2025,,ACM,10.1145/3679240.3734633
TransChem: Effective Pre-training Enhances Molecular Property Prediction,"In this paper, we introduce TransChem, a novel architecture designed to tackle a wide range of downstream tasks in chemistry. TransChem leverages a pre-train fine-tune scheme. For pre-training, we utilize 2 million molecules from the ZINC15 database. We evaluate TransChem on six benchmark datasets from MoleculeNet, demonstrating its superior performance over state-of-the-art methods that employ pre-training and models that rely on hand-crafted features. We demonstrate that properly designed pre-training objectives can steer the learning process and allow TransChem to capture subtle relationships between atoms and generate informative representations, even when the pre-training dataset is relatively small.",10.1145/3688671.3688745,2024,,ACM,10.1145/3688671.3688745
A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis,"Time series data, including univariate and multivariate ones, are characterized by unique composition and complex multi-scale temporal variations. They often require special consideration of decomposition and multi-scale modeling to analyze. Existing deep learning methods on this best fit to univariate time series only, and have not sufficiently considered sub-series modeling and decomposition completeness. To address these challenges, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer, which learns to explicitly decompose and represent the input time series in its different layers. To handle the multi-scale temporal patterns and multivariate dependencies, we propose a novel temporal patching approach to model the time series as multi-scale patches, and employ MLPs to capture intra- and inter-patch variations and channel-wise correlations. In addition, we propose a novel loss function to constrain both the mean and the autocorrelation of the decomposition residual for better decomposition completeness. Through extensive experiments on various real-world datasets for five common time series analysis tasks, we demonstrate that MSD-Mixer consistently and significantly outperforms other state-of-the-art algorithms with better efficiency.",10.14778/3654621.3654637,2024,,ACM,10.14778/3654621.3654637
Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space,"Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the &lt;u&gt;D&lt;/u&gt;ynamics-&lt;u&gt;I&lt;/u&gt;nvariant &lt;u&gt;Sk&lt;/u&gt;eleton Neural &lt;u&gt;Net&lt;/u&gt;work (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18\% in terms of long-term prediction accuracy. Code for reproduction is available at: https://github.com/tsinghua-fib-lab/DiskNet.",10.1145/3637528.3671968,2024,,ACM,10.1145/3637528.3671968
Pretraining Large Brain Language Model for Active BCI: Silent Speech,"This paper explores silent speech decoding in active brain-computer interface (BCI) systems, which offer more natural and flexible communication than traditional BCI applications. We collected a new silent speech dataset of over 120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing 24 commonly used English words for language model pretraining and decoding. Following the recent success of pretraining large models with self-supervised paradigms to enhance EEG classification performance, we propose Large Brain Language Model (LBLM) pretrained to decode silent speech for active BCI. To pretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining paradigm to learn effective representations from unlabeled EEG data. Unlike existing EEG pretraining methods that mainly follow a masked-reconstruction paradigm, our proposed FSTP method employs autoregressive modeling in temporal and frequency domains to capture both temporal and spectral dependencies from EEG signals. After pretraining, we finetune our LBLM on downstream tasks, including word-level and semantic-level classification. Extensive experiments demonstrate significant performance gains of the LBLM over fully-supervised and pretrained baseline models. For instance, in the difficult cross-session setting, our model achieves 47.2\% accuracy on semantic-level classification and 42.3\% in word-level classification, outperforming baseline methods substantially. Our research advances silent speech decoding in active BCI systems, offering an innovative solution for EEG language model pretraining and a new dataset for fundamental research.",10.1145/3746027.3754810,2025,,ACM,10.1145/3746027.3754810
Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention,"Forecasting graph-based, time-dependent data has broad practical applications but presents challenges. Effective models must capture both spatial and temporal dependencies in the data, while also incorporating auxiliary information to enhance prediction accuracy. In this article, we identify limitations in current state-of-the-art models regarding temporal dependency handling. To overcome this, we introduce GSA-Forecaster, a new deep learning model designed for forecasting in graph-based, time-dependent contexts. GSA-Forecaster utilizes graph sequence attention, a new attention mechanism proposed in this article, to effectively manage temporal dependencies. GSA-Forecaster integrates the data’s graph structure directly into its architecture, addressing spatial dependencies. Additionally, it incorporates auxiliary information to refine its predictions further. We validate its performance using real-world graph-based, time-dependent datasets, where it demonstrates superior effectiveness compared to existing state-of-the-art models.",10.1145/3721435,2025,,ACM,10.1145/3721435
Experience: A Comparative Analysis of Multivariate Time-Series Generative Models: A Case Study on Human Activity Data,"Human activity recognition (HAR) is an active research field that has seen great success in recent years due to advances in sensory data collection methods and activity recognition systems. Deep artificial intelligence (AI) models have contributed to the success of HAR systems lately, although still suffering from limitations such as data scarcity, the high costs of labelling data instances, and datasets’ imbalance and bias. The temporal nature of human activity data, represented as time series data, impose an additional challenge to using AI models in HAR, because most state-of-the-art models do not account for the time component of the data instances. These limitations have inspired the time-series research community to design generative models for sequential data, but very little work has been done to evaluate the quality of such models. In this work, we conduct a comparative quality analysis of three generative models for time-series data, using a case study in which we aim to generate sensory human activity data from a seed public dataset. Additionally, we adapt and clearly explain four evaluation methods of synthetic time-series data from the literature and apply them to assess the quality of the synthetic activity data we generate. We show experimentally that high-quality human activity data can be generated using deep generative models, and the synthetic data can thus be used in HAR systems to augment real activity data. We also demonstrate that the chosen evaluation methods effectively ensure that the generated data meets the essential quality benchmarks of realism, diversity, coherence, and utility. Our findings suggest that using deep generative models to produce synthetic human activity data can potentially address challenges related to data scarcity, biases, and expensive labeling. This holds promise for enhancing the efficiency and reliability of HAR systems.",10.1145/3688393,2024,,ACM,10.1145/3688393
DisMS-TS: Eliminating Redundant Multi-scale Features for Time Series Classification,"Real-world time series typically exhibit complex temporal variations, making the time series classification task notably challenging. Recent advancements have demonstrated the potential of multi-scale analysis approaches, which provide an effective solution for capturing these complex temporal patterns. However, existing multi-scale analysis-based time series prediction methods fail to eliminate redundant scale-shared features across multi-scale time series, resulting in the model over- or under-focusing on scale-shared features. To address this issue, we propose a novel end-to-end Disentangled Multi-Scale framework for Time Series classification (DisMS-TS). The core idea of DisMS-TS is to eliminate redundant shared features in multi-scale time series, thereby improving prediction performance. Specifically, we propose a temporal disentanglement module to capture scale-shared and scale-specific temporal representations, respectively. Subsequently, to effectively learn both scale-shared and scale-specific temporal representations, we introduce two regularization terms that ensure the consistency of scale-shared representations and the disparity of scale-specific representations across all temporal scales. Extensive experiments conducted on multiple datasets validate the superiority of DisMS-TS over its competitive baselines, with the accuracy improvement up to 9.71\%.",10.1145/3746027.3754842,2025,,ACM,10.1145/3746027.3754842
Interpretable Cascading Mixture-of-Experts for Urban Traffic Congestion Prediction,"Rapid urbanization has significantly escalated traffic congestion, underscoring the need for advanced congestion prediction services to bolster intelligent transportation systems. As one of the world's largest ride-hailing platforms, DiDi places great emphasis on the accuracy of congestion prediction to enhance the effectiveness and reliability of their real-time services, such as travel time estimation and route planning. Despite numerous efforts have been made on congestion prediction, most of them fall short in handling heterogeneous and dynamic spatio-temporal dependencies (e.g., periodic and non-periodic congestions), particularly in the presence of noisy and incomplete traffic data. In this paper, we introduce a Congestion Prediction Mixture-of-Experts, CP-MoE, to address the above challenges. We first propose a sparsely-gated Mixture of Adaptive Graph Learners (MAGLs) with congestion-aware inductive biases to improve the model capacity for efficiently capturing complex spatio-temporal dependencies in varying traffic scenarios. Then, we devise two specialized experts to help identify stable trends and periodic patterns within the traffic data, respectively. By cascading these experts with MAGLs, CP-MoE delivers congestion predictions in a more robust and interpretable manner. Furthermore, an ordinal regression strategy is adopted to facilitate effective collaboration among diverse experts. Extensive experiments on real-world datasets demonstrate the superiority of our proposed method compared with state-of-the-art spatio-temporal prediction models. More importantly, CP-MoE has been deployed in DiDi to improve the accuracy and reliability of the travel time estimation system.",10.1145/3637528.3671507,2024,,ACM,10.1145/3637528.3671507
ST-FLAM: Evaluating Performance of Deep Learning Models on Mobility Patterns for EVD Forecasting based on Spatio-Temporal Feature Learning,"Ebola Virus Disease (EVD) is a highly contagious and fatal disease that poses a serious threat to public health and security. Accurate and timely forecasting of EVD outbreaks is essential for effective prevention and control measures. However, traditional epidemiological models often fail to capture the complex and dynamic nature of human mobility, which plays a key role in EVD transmission. In this paper, we propose a novel framework for EVD forecasting based on spatio-temporal feature learning called ST-FLAM. We use various types of mobility data, such as phone records, Global Positioning System (GPS) traces, and social media posts, to extract meaningful and representative features that reflect the mobility patterns of individuals and populations. Next, we employ ST-FLAM architectures, which incorporate Graph Neural Networks (GNN) and Long Short Term Memory (LSTM), to establish connections and dependencies between mobility features and EVD cases in both space and time. We evaluate the performance of our framework on real-world datasets from the 2014–2016 West Africa EVD outbreak and the 2015–2016 EVD and human mobility in Sierra Leone. We compare our framework with baseline methods to handle traditional epidemiological challenges during an outbreak. We conduct ablation studies and analyse the impact of different mobility data sources, feature extraction methods, and deep learning architectures on EVD forecasting accuracy. Our results show that our framework outperforms the baselines and achieves state-of-the-art performance in EVD forecasting. We also demonstrate that our framework can provide interpretable and actionable insights for EVD prevention and control.",10.1145/3711650.3711665,2025,,ACM,10.1145/3711650.3711665
Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation for Wide-Area SST Prediction,"Accurate prediction of Sea Surface Temperature (SST) is of high importance in marine science, benefiting applications ranging from ecosystem protection to extreme weather forecasting and climate analysis. Wide-area SST usually shows diverse SST patterns in different sea areas due to the changes of temperature zones and the dynamics of ocean currents. However, existing studies on SST prediction often focus on small-area predictions and lack the consideration of diverse SST patterns. Furthermore, SST shows an annual periodicity, but the periodicity is not strictly adherent to an annual cycle. Existing SST prediction methods struggle to adapt to this non-strict periodicity. To address these two issues, we proposed the Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation (RGCN-PSA) model which is equipped with the Cross-Region Graph Convolutional Network module and the Periodicity Shift Adaption module. The Cross-Region Graph Convolutional Network module enhances wide-area SST prediction by learning and incorporating diverse SST patterns. Meanwhile, the periodicity Shift Adaptation module accounts for the annual periodicity and enable the model to adapt to the possible temporal shift automatically. We conduct experiments on two real-world SST datasets, and the results demonstrate that our RGCN-PSA model obviously outperforms baseline models in terms of prediction accuracy. The code of RGCN-PSA model is available at .",10.1145/3735646,2025,,ACM,10.1145/3735646
Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey,"Machine Learning (ML) workflows—spanning data preprocessing and feature engineering, model selection and hyperparameter optimization, and workflow evaluation—are increasingly embedded in complex software systems. Building these workflows manually demands substantial ML expertise, domain knowledge, and engineering effort. Automated ML (AutoML) frameworks address parts of this challenge but often suffer from constrained search spaces, limited adaptability, and low interpretability. Recent advances in Large Language Models (LLMs) have opened new opportunities to automate and enhance ML workflows by leveraging their capabilities in language understanding, reasoning, interaction, and code generation, posing new practical and theoretical challenges for software engineering (SE). This survey provides the first SE-oriented, stage-wise review of LLM-based ML workflow automation. We introduce a taxonomy covering all three workflow stages, systematically compare and analyze state-of-the-art methods, and synthesize both stage-specific and cross-stage trends. Our analysis yields SE-oriented implications, including the need for robust verification, quality management, context-aware deployment, and risk mitigation, alongside ensuring key quality attributes such as usability, modularity, traceability, and performance. The findings also call for adapting development models, rethinking lifecycle boundaries, and formalizing uncertainty handling to address the probabilistic and collaborative nature of LLM-assisted workflow generation. We further identify major open challenges and outline future research directions to guide the reliable and effective adoption of LLMs in ML workflow development. Our artifacts are publicly available at .",10.1145/3773084,2025,,ACM,10.1145/3773084
A Graph-Based Framework for Temporal and Causal Analysis of Sentiments,"This research aims to develop a novel framework that uncovers the causal influence of global events on public sentiment through temporal graph modeling and neural causal inference. Global events, such as pandemics, elections, and economic crises, profoundly affect public sentiments, shaping social behaviors and economic outcomes. Traditional models often fall short in capturing the complex, dynamic, and non-linear relationships between these events and sentiments. This article presents the Neural Temporal Causal Graph Network (NTCGN), a unified framework that integrates temporal graph neural networks with a Causal Attention Network (CAN) to model and interpret these relationships. NTCGN constructs a temporal graph from event data and sentiment-labeled texts, learning dependencies and causal influences through advanced neural architectures. A thorough comparative analysis with state-of-the-art models such as Logistic Regression, SVM, LSTM, and transformer-based models demonstrates NTCGN’s superior performance. Experimental evaluation using the Sentiment140 and Global Database of Events, Language and Tone (GDELT) 2.0 datasets shows NTCGN achieving an accuracy of 0.798 and an F1 score of 0.795, outperforming these baseline models. The model’s causal inference capabilities are validated using the Causal Impact Score (CIS) and Causal Discovery Precision (CDP), highlighting its reliability in identifying true causal links. Visualizations of attention maps and causal pathways enhance interpretability, demonstrating how specific events influence public sentiments. This work provides a robust and interpretable tool for analyzing event-driven sentiment dynamics in real-world applications.",10.1145/3759440,2025,,ACM,10.1145/3759440
Identifying Contemporaneous and Lagged Dependence Structures by Promoting Sparsity in Continuous-time Neural Networks,"Continuous-time dynamics models, e.g., neural ordinary differential equations, enable accurate modeling of underlying dynamics in time-series data. However, employing neural networks for parameterizing dynamics makes it challenging for humans to identify dependence structures, especially in the presence of delayed effects. In consequence, these models are not an attractive option when capturing dependence carries more importance than accurate modeling, e.g., in tsunami forecasting.In this paper, we present a novel method for identifying dependence structures in continuous-time dynamics models. We take a two-step approach: (1) During training, we promote weight sparsity in the model's first layer during training. (2) We prune the sparse weights after training to identify dependence structures. In evaluation, we test our method in scenarios where the exact dependence-structures of time-series are known. Compared to baselines, our method is more effective in uncovering dependence structures in data even when there are delayed effects. Moreover, we evaluate our method to a real-world tsunami forecasting, where the exact dependence structures are unknown beforehand. Even in this challenging scenario, our method still effective learns physically-consistent dependence structures and achieves high accuracy in forecasting.",10.1145/3627673.3679751,2024,,ACM,10.1145/3627673.3679751
A Universal Sets-level Optimization Framework for Next Set Recommendation,"Next Set Recommendation (NSRec), encompassing related tasks such as next basket recommendation and temporal sets prediction, stands as a trending research topic. Although numerous attempts have been made on this topic, there are certain drawbacks: (i) Existing studies are still confined to utilizing objective functions commonly found in Next Item Recommendation (NIRec), such as binary cross entropy and BPR, which are calculated based on individual item comparisons; (ii) They place emphasis on building sophisticated learning models to capture intricate dependency relationships across sequential sets, but frequently overlook pivotal dependency in their objective functions; (iii) Diversity factor within sequential sets is frequently overlooked. In this research, we endeavor to unveil a universal and Sets-level optimization framework for Next Set Recommendation (SNSRec), offering a holistic fusion of diversity distribution and intricate dependency relationships within temporal sets. To realize this, the following contributions are made: (i) We directly model the temporal set in a sequence as a cohesive entity, leveraging the Structured Determinantal Point Process (SDPP), wherein the probabilistic DPP distribution prioritizes collections of structures (sequential sets) instead of individual items; (ii) We introduce a co-occurrence representation to discern and acknowledge the importance of different sets; (iii) We propose a sets-level optimization criterion, which integrates the diversity distribution and dependency relations across the entire sequence of sets, guiding the model to recommend relevant and diversified set. Extensive experiments on real-world datasets show that our approach consistently outperforms previous methods on both relevance and diversity.",10.1145/3627673.3679610,2024,,ACM,10.1145/3627673.3679610
"A Comprehensive Benchmark on Spectral GNNs: The Impact on Efficiency, Memory, and Effectiveness","With recent advancements in graph neural networks (GNNs), spectral GNNs have received increasing popularity by virtue of their ability to retrieve graph signals in the spectral domain. These models feature uniqueness in efficient computation as well as rich expressiveness, which stems from advanced management and profound understanding of graph data. However, few systematic studies have been conducted to assess spectral GNNs, particularly in benchmarking their efficiency, memory consumption, and effectiveness in a unified and fair manner. There is also a pressing need to select spectral models suitable for learning specific graph data and deploying them to massive web-scale graphs, which is currently constrained by the varied model designs and training settings.In this work, we extensively benchmark spectral GNNs with a focus on the spectral perspective, demystifying them as spectral graph filters. We analyze and categorize 35 GNNs with 27 corresponding filters, spanning diverse formulations and utilizations of the graph data. Then, we implement the filters within a unified spectral-oriented framework with dedicated graph computations and efficient training schemes. In particular, our implementation enables the deployment of spectral GNNs over million-scale graphs and various tasks with comparable performance and less overhead. Thorough experiments are conducted on the graph filters with comprehensive metrics on effectiveness and efficiency, offering novel observations and practical guidelines that are only available from our evaluations across graph scales. Different from the prevailing belief, our benchmark reveals an intricate landscape regarding the effectiveness and efficiency of spectral graph filters, demonstrating the potential to achieve desirable performance through tailored spectral manipulation of graph data.",10.1145/3749156,2025,,ACM,10.1145/3749156
Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion,"Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.",10.1145/3589132.3625641,2023,,ACM,10.1145/3589132.3625641
A Multi-Modal Knowledge-Enhanced Framework for Vessel Trajectory Prediction,"Accurate vessel trajectory prediction facilitates improved navigational safety, routing, and environmental protection. However, existing prediction methods are challenged by the irregular sampling time intervals of the vessel tracking data from the global AIS system and the complexity of vessel movement. These aspects complicate model learning and generalization. To address these challenges and improve vessel trajectory prediction, we propose Multi-modAl Knowledge-Enhanced fRamework (MAKER) for vessel trajectory prediction. To contend better with the irregular sampling time intervals, MAKER features a Large language model-guided Knowledge Transfer (LKT) module that leverages pre-trained language models to transfer trajectory-specific contextual knowledge effectively. To enhance the ability to learn complex trajectory patterns, MAKER incorporates a Knowledge-based Self-paced Learning (KSL) module. This module employs kinematic knowledge to progressively integrate complex patterns during training, allowing for adaptive learning and enhanced generalization. Experimental results on two vessel trajectory datasets show that MAKER can improve the prediction accuracy of state-of-the-art methods by 12.08\%—17.86\%.",10.1145/3748777.3748784,2025,,ACM,10.1145/3748777.3748784
Tide: A Time-Wise Causal Debiasing Framework for Generative Dynamic Link Prediction,"Dynamic link prediction aims to predict the future links in dynamic graphs. Existing generative dynamic link prediction studies utilize the global degree distribution for mitigating the over-estimation problem, which can model the time-invariant features while neglecting the time-varying features, resulting in capturing inaccurate evolution patterns. However, such time related features are intrinsically coupled, which makes simultaneously and independently modeling both features infeasible. Motivated by these issues, we propose a Time-wise causal debiasing framework (Tide) for generative dynamic link prediction, which does not resort to any extra trainable modules. Instead, to obtain the time-invariant features, we first utilize a time-invariant deconfounded learning mechanism for decoupling the prediction score with the degree distribution. To leverage the time-varying features, we intervene in the model during the inference stage by a predicted future degree distribution, aiming to make the accurate predictions for dynamic graphs. Experiments conducted on four public datasets under both inductive and transductive settings present that our Tide enhanced models can outperform their corresponding vanilla versions by up to 21.42\% and 27.73\% in terms of NDCG and Jaccard, respectively.",10.1145/3746252.3761182,2025,,ACM,10.1145/3746252.3761182
Long Short-term Dynamic Graph Neural Networks: for short-term intense rainfall forecasting,"In practice, accurate and timely forecasting of short-term intense rainfall is critical, but the problem is extremely difficult because to its complicated spatial-temporal association. Although several spatial-temporal series forecasting methods have been used to rainfall prediction, these models continue to suffer from inadequate modeling of data’s complicated intrinsic connection. We provide a new short-term intense rainfall prediction model that use two graph generators to model data correlations under distinct semantics, followed by a graph convolution module for information integration to fully extract data spatial-temporal information. Finally, a variant of recurrent neural network is employed to extract the temporal dependence. The experimental results on both datasets show that the model can model the spatial and temporal dependence across the data more effectively than the baseline model, and further improve the model’s predictive performance for short-term intense rainfall.",10.1145/3578741.3578757,2023,,ACM,10.1145/3578741.3578757
Transportation Flow Prediction Based on Graph Attention Echo State Network,"Abstract—Traffic flow prediction is of great importance in applications such as traffic management and urban planning. The complex spatial and temporal dependence of traffic flow between different roads poses a great challenge for accurate real-time traffic flow prediction. Traditional traffic flow prediction methods rely on the assumption of data smoothness, and the prediction accuracy decreases significantly in the face of complex, variable and large amount of traffic flow data. Spatio-temporal prediction models based on graph neural networks and recurrent neural networks can achieve better prediction accuracy, but there are still some problems, such as the need for a known static graph structure, inadequate spatial extraction and long training time of the model. To improve traffic flow prediction accuracy and real-time performance, this paper proposes a novel end-to-end deep learning framework called graph attention echo state network (GAESN), which uses attention mechanism and echo state network to extract spatio-temporal features. Experimental results on four real traffic flow datasets show that our proposed model achieves 17.35, 21.34, 24.12 and 17.31 in mean absolute error(MAE); 29.31, 32.67, 37.51and 26.84 in root mean square error(RMSE); 16.76\%, 15.44\%, 10.33\% and 10.94\% in mean absolute percentage error(MAPE), respectively. Compared with other existing models, this model reduces the number of parameters to be trained and the time required for model training, and also improves the accuracy of traffic flow prediction.",10.1145/3603781.3603907,2023,,ACM,10.1145/3603781.3603907
Attention based Deep Hybrid Networks for Traffic Flow Prediction using Google Maps Data,"Accurate traffic flow prediction is a keystone for building intelligent traffic management systems which have gained attention from researchers because of the availability of the massive volume of traffic data and advances in deep learning technologies. However, there are many cities in the world, that suffer from terrible traffic congestion but there are no infrastructure facilities to collect traffic data. To address this problem we develop a tool that collects traffic data from Google Maps without using its paid API. After that, we proposed an Attention-based Deep Hybrid network (ADHN) for traffic flow prediction using Google map data. The proposed ADHN combines two Convolutional Long Short-Term Memory (ConvLSTM) to capture dynamic spatial temporal dependencies of the traffic flow and applies attention mechanism on traffic features. The experiment result shows that our proposed ADHN can provide higher prediction accuracy compared with the other state-of-the-art approaches. Our code and data are available at https://github.com/Moshiurcse13/trafficDataCollectionTool.",10.1145/3589883.3589894,2023,,ACM,10.1145/3589883.3589894
Community Trend Prediction on Heterogeneous Graph in E-commerce,"In online shopping, ever-changing fashion trends make merchants need to prepare more differentiated products to meet the diversified demands, and e-commerce platforms need to capture the market trend with a prophetic vision. For the trend prediction, the attribute tags, as the essential description of items, can genuinely reflect the decision basis of consumers. However, few existing works explore the attribute trend in the specific community for e-commerce. In this paper, we focus on the community trend prediction on the item attribute and propose a unified framework that combines the dynamic evolution of two graph patterns to predict the attribute trend in a specific community. Specifically, we first design a community-attribute bipartite graph at each time step to learn the collaboration of different communities. Next, we transform the bipartite graph into a hypergraph to exploit the associations of different attribute tags in one community. Lastly, we introduce a dynamic evolution component based on the recurrent neural networks to capture the fashion trend of attribute tags. Extensive experiments on three real-world datasets in a large e-commerce platform show the superiority of the proposed approach over several strong alternatives and demonstrate the ability to discover the community trend in advance.",10.1145/3488560.3498522,2022,,ACM,10.1145/3488560.3498522
MSTEM: Masked Spatiotemporal Event Series Modeling for Urban Undisciplined Events Forecasting,"Urban undisciplined events (UUE) are of increasing concern to urban officials because they reduce the quality of life and cause societal disorder. How to accurately predict future occurrences is a key point in preventing these events. However, existing supervised methods struggle to perform well on sparse UUEs while self-supervised MAE-based methods adopt a traditional random masking strategy which leads to limited performance on UUE forecasting. Fortunately, we have designed an innovative spatiotemporal masking strategy and its corresponding pre-training task called &lt;u&gt;M&lt;/u&gt;asked &lt;u&gt;S&lt;/u&gt;patio-&lt;u&gt;T&lt;/u&gt;emporal &lt;u&gt;E&lt;/u&gt;vent Series &lt;u&gt;M&lt;/u&gt;odeling (MSTEM). Through Cluster-assisted region masking, MSTEM efficiently distributes masked regions evenly among different clusters, enhancing the model's ability to capture spatial correlation and heterogeneity while addressing sparse region distribution of UUEs. Frequency-enhanced patch masking helps the model to sufficiently extract the temporal features of UUEs by reconstructing multiple views. Additionally, we propose future merge and cluster label modeling to enhance the extraction of spatiotemporal dependencies, thereby improving the performance of MSTEM on downstream prediction tasks. Experimental evaluations on four real-world datasets including crimes and disorderly conduct show that our masked autoencoder with MSTEM outperforms most of the state-of-the-art baselines.",10.1145/3627673.3679810,2024,,ACM,10.1145/3627673.3679810
Seeing the Unseen: Learning Basis Confounder Representations for Robust Traffic Prediction,"Traffic prediction is essential for intelligent transportation systems and urban computing. It aims to establish a relationship between historical traffic data X and future traffic states Y by employing various statistical or deep learning methods. However, the relations of X → Y are often influenced by external confounders that simultaneously affect both X and Y, such as weather, accidents, and holidays. Existing deep-learning traffic prediction models adopt the classic front-door and back-door adjustments to address the confounder issue. However, these methods have limitations in addressing continuous or undefined confounders, as they depend on predefined discrete values that are often impractical in complex, real-world scenarios. To overcome this challenge, we propose the Spatial-Temporal sElf-superVised confoundEr learning (STEVE) model. This model introduces a basis vector approach, creating a base confounder bank to represent any confounder as a linear combination of a group of basis vectors. It also incorporates self-supervised auxiliary tasks to enhance the expressive power of the base confounder bank. Afterward, a confounder-irrelevant relation decoupling module is adopted to separate the confounder effects from direct X → Y relations. Extensive experiments across four large-scale datasets validate our model's superior performance in handling spatial and temporal distribution shifts and underscore its adaptability to unseen confounders. Our model implementation is available at https://github.com/bigscity/STEVE_CODE.",10.1145/3690624.3709201,2025,,ACM,10.1145/3690624.3709201
Spatio-Temporal Deep Fusion Graph Convolutional Networks for Crime Prediction,"Effective crime prediction plays a key role in sustaining the stability of society. In recent years, researchers have proposed a number of prediction methods that extract spatial and temporal features separately and fuse afterward. However, the strict distinction between spatial feature extraction and temporal feature extraction can result in the loss of useful information. To this end, we propose a spatio-temporal deep fusion graph convolution network (STDGCN), which embodies the intra-region spatio-temporal features and the inter-region spatio-temporal associations on a single graph. STDGCN performs the convolution without distinguishing between space and time to simultaneously extract spatio-temporal features. Our evaluations of two real-world datasets demonstrate the effectiveness of STDGCN.",10.1145/3583788.3583799,2023,,ACM,10.1145/3583788.3583799
Prediction of the Number of Postgraduate Entrance Examination Applicants Based on LSTM and Statistical Analysis Method,"In recent years, with the expansion of higher education institutions year by year, the total number of fresh undergraduates has been rapidly increasing. This paper proposes a prediction algorithm for the number of undergraduates who will enter graduate school through long short-term memory (LSTM) based on the current development trend of graduate school and the number of admissions to graduate school in recent years.Firstly, the parameters that have the greatest influence on the prediction of the number of applicants for the examinations are statistically analyzed, and then a deep learning prediction model based on LSTM is built to predict the number of applicants for the examinations, and the results are displayed in the visualization interface. The experimental results show that the trained LSTM model works better than the Support Vector Machine (SVM) results. The prediction model will be provided to students before registering for the exam, which is of practical significance to facilitate students to make reasonable decisions.",10.1145/3606043.3606045,2023,,ACM,10.1145/3606043.3606045
BiST: A Lightweight and Efficient Bi-Directional Model for Spatiotemporal Prediction,"While existing spatiotemporal prediction models have shown promising performance, they often rely on the assumption of input-label spatiotemporal consistency, and their high complexity raises concerns about scalability. To enhance both efficiency and performance, we integrate label information into the learning process and propose a spatiotemporal dynamic theory that outlines a bi-directional learning paradigm. Building on this paradigm, we design BiST, a lightweight yet effective Bi-directional Spatio-Temporal prediction model. BiST incorporates two key processes: a forward spatiotemporal learning process and a backward correction process. The forward process utilizes MLP layers exclusively to model input correlations and generate base prediction. In the backward process, we implement a spatiotemporal decoupling module, which can learn the residual modeling deviation between input and label representations from a decoupled perspective. After smoothing the residual with a diffusion module, we can obtain the correction term to correct the base predictions. This innovative design enables BiST to achieve competitive performance while remaining lightweight. We evaluate BiST against 26 baselines across 13 datasets, including a large-scale dataset with ten thousand nodes and a longrange dataset spanning 20 years. An impressive experimental result demonstrates that BiST achieves a 8.13\% improvement in performance compared to state-of-the-art models while consuming only 1.86\% of the training time and 7.36\% of the memory usage.",10.14778/3725688.3725697,2025,,ACM,10.14778/3725688.3725697
HAG-MTF: Higher-Order Adaptive Generative Graph for Massive Traffic Forecasting in Industry 5.0,"With the evolution of urban smart transportation, the complexity of urban traffic networks escalates, emphasizing the importance of large-scale traffic data prediction in traffic management and urban planning. Traditional spatiotemporal graph models, such as Graph-WaveNet and MTGCN, face exponentially increasing computational complexity as the spatial dimensions expand. To address this challenge, we propose a novel Higher-order Adaptive Generative graph for Massive Traffic Forecasting (HAG-MTF) approach, which utilizes generative AI and high-order graph structures to model the intricate spatial dependencies in large-scale traffic data. The HAG-MTF incorporates a high-order dimensionality reduction module to optimize traffic node processing, utilizing prior graph relationships to generate a fusion graph that dynamically incorporates neighborhood information for efficient, localized graph convolution. The model further incorporates the high-order spatiotemporal relationship extraction module (H-net), enhancing the capacity and speed of traffic data processing while boosting prediction accuracy for complex spatial structures. Furthermore, HAG-MTF introduces a fusion loss function that hierarchically balances multiple objectives, ensuring both precision and computational efficiency. HAG-MTF adaptively handles large-scale real-world traffic data, meeting the needs of traffic controllers and urban planners for predicting massive datasets in practical settings. It supports efficient, flexible interactions via parameter tuning and model outputs, ultimately integrating human insights into traffic analysis and decision-making. This dynamic human-machine collaboration differs from non-Industry 5.0 approaches, which rely on purely automated systems without human input. Those lead to inflexible, brittle conclusions and recommendations, neglecting shifts in traffic patterns driven by human behavior. Extensive experiments on real-world traffic datasets demonstrate that HAG-MTF significantly improves processing efficiency for high-complexity spatial data while delivering precise, human-informed predictions through generative AI-driven operations.",10.1145/3772723,2025,,ACM,10.1145/3772723
Short-term Load Forecasting Method of Power Distribution Station Area Integrating Multiple Temporal Characteristics,"In order to solve the problem of short term power load forecasting and improve the accuracy of load forecasting in distribution station area, a short term power load forecasting model integrating multiple temporal series characteristics is proposed in this paper. Firstly, we solve the problems of missing and outliers in acquired load and weather data through data preprocessing. Then, we consider the historical load, weather, working day/holiday and other factors, then explore the long-short term, periodicity and particularity of the load and weather information. After that, we establish the short-term power load prediction feature model of the platform area. In addition, we use the deep residual network as the basic structure to eliminate the overfitting problem caused by the deep network. Experiments show that the proposed method has smaller prediction error compared with the existing methods.",10.1145/3635638.3635641,2024,,ACM,10.1145/3635638.3635641
CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events,"Large-scale human mobility exhibits spatial and temporal patterns that can assist policymakers in decision making. Although traditional prediction models attempt to capture these patterns, they are often affected by nonperiodic public events, such as disasters and occasional celebrations. Since regular human mobility patterns are affected by these events, estimating their causal effects is critical to accurate mobility predictions. News articles provide unique perspectives on these events, though processing them is a challenge. In this study, we propose a causality based prediction model, CausalMob, to analyze the causal effects of public events. We first utilize large language models (LLMs) to extract human intentions from news and transform them into features that act as causal treatments. Next, the model learns representations of spatio-temporal regional covariates from multiple data sources to serve as confounders for causal inference. Finally, we present a causal effect estimation framework to ensure that event features remain independent of confounders during prediction. Based on large-scale real-world data, the experimental results show that the proposed model excels in human mobility prediction, outperforming state-of-the-art models.",10.1145/3690624.3709231,2025,,ACM,10.1145/3690624.3709231
Oxygen Uptake Estimation during Cardiopulmonary Exercise Testing Using Temporal Fusion Networks,Accurate measurement of oxygen uptake ( (dot{mathrm{V,10.1145/3728370,2025,,ACM,10.1145/3728370
TempASD: Temporal Anomalous Subgraph Discovery in Large-Scale Dynamic Financial Networks,"In this paper, we investigate the discovery of temporal anomalous subgraphs in large-scale financial networks, aiming to identify abnormal transaction behaviors among users over time. This task is crucial for the real-time detection of transaction anomalies in financial networks, such as money laundering and trading fraud. However, it poses significant challenges due to the diverse distribution of transactions, the dynamic nature of temporal networks, and the absence of theoretical foundation. To tackle these challenges, we introduce a novel Temporal Anomalous Subgraph Discovery (TempASD) algorithm with theoretical analysis. First, we propose a temporal candidate detection module that quickly pinpoints abnormal candidates by detecting anomalies in both the temporal structure and transaction distribution. Then, we introduce a carefully crafted reinforcement-learning-based refiner to optimize these candidates toward the most abnormal directions. We conducted extensive evaluations against thirteen advanced competitors. TempASD achieves an average improvement of 7x in abnormal degree compared to the state-of-the-art and is efficient in large-scale dynamic financial networks.",10.1145/3711896.3737149,2025,,ACM,10.1145/3711896.3737149
Multi-Attribute Spatial-temporal Graph Convolutional Network for Taxi Demand Forecasting,"Accurate forecasting taxi demand help reduce waiting time for drivers and passengers as well as ease traffic congestion. However, most of the current research work has mostly ignored the impact of historical cab inflows and potential spatial dependencies between different regions on taxi demand. In view of this, this paper integrates several attributes affecting taxi demand and develops a multi-attribute spatial-temporal graphical convolutional network model (MASTGCN) with the expectation of accurately predicting the MASTGCN model is designed to accurately predict the demand for rental cars. Specifically, the MASTGCN model is designed with four components, which model the temporal dependence of taxi demand on the demand series at the near moment, the daily demand series, the historical taxi inflow series, and the daily demand series, respectively. The components are designed to model the temporal dependence of taxi demand on proximity demand series, daily demand series, historical cab inflow series, and the potential spatial dependence among different regions. To demonstrate the effectiveness of the MASTGCN model, we compare it with five benchmark models commonly used for traffic forecasting and three metrics, RMSE, MAE and MAPE, are used for evaluation. The experimental results show that the MASTGCN model, which incorporates multiple attributes, can more accurately the multiattribute MASTGCN model can predict taxi demand more accurately.",10.1145/3565291.3565301,2022,,ACM,10.1145/3565291.3565301
PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection,"With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications. In this setting, time series anomaly detection is practically important. It endeavors to identify deviant samples from the normal sample distribution in time series. Existing approaches generally assume that all the time series is available at a central location. However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices. To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a &lt;u&gt;P&lt;/u&gt;arameter-&lt;u&gt;e&lt;/u&gt;fficient &lt;u&gt;F&lt;/u&gt;ederated &lt;u&gt;A&lt;/u&gt;nomaly &lt;u&gt;D&lt;/u&gt;etection framework named PeFAD with the increasing privacy concerns. PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability. To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update. PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training. A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients. We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74\%.",10.1145/3637528.3671753,2024,,ACM,10.1145/3637528.3671753
TriD-MAE: A Generic Pre-trained Model for Multivariate Time Series with Missing Values,"Multivariate time series(MTS) is a universal data type related to various real-world applications. Data imputation methods are widely used in MTS applications to deal with the frequent data missing problem. However, these methods inevitably introduce biased imputation and training-redundancy problems in downstream training. To address these challenges, we propose TriD-MAE, a generic pre-trained model for MTS data with missing values. Firstly, we introduce TriD-TCN, an end-to-end module based on TCN that effectively extracts temporal features by integrating dynamic kernel mechanisms and a time-flipping trick. Building upon that, we designed an MAE-based pre-trained model as the precursor of specialized downstream models. Our model cooperates with a dynamic positional embedding mechanism to represent the missing information and generate transferable representation through our proposed encoder units. The overall mixed data feed-in strategy and weighted loss function are established to ensure adequate training of the whole model. Comparative experiment results in time series prediction and classification manifest that our TriD-MAE model outperforms the other state-of-the-art methods within six real-world datasets. Moreover, ablation and interpretability experiments are delivered to verify the validity of TriD-MAE's",10.1145/3583780.3615097,2023,,ACM,10.1145/3583780.3615097
GraphSparseNet: A Novel Method for Large Scale Traffic Flow Prediction,"Traffic flow forecasting is a critical spatio-temporal data mining task with wide-ranging applications in intelligent route planning and dynamic traffic management. Recent advancements in deep learning, particularly through Graph Neural Networks (GNNs), have significantly enhanced the accuracy of these forecasts by capturing complex spatio-temporal dynamics. However, the scalability of GNNs remains a challenge due to their exponential growth in model complexity with increasing nodes in the graph. Existing methods to address this issue, including sparsification, decomposition, and kernel-based approaches, either do not fully resolve the complexity issue or risk compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet), a novel framework designed to improve both the scalability and accuracy of GNN-based traffic forecasting models. GraphSparseNet is comprised of two core modules: the Feature Extractor and the Relational Compressor. These modules operate with linear time and space complexity, thereby reducing the overall computational complexity of the model to a linear scale. Our extensive experiments on multiple real-world datasets demonstrate that GraphSparseNet not only significantly reduces training time by 3.51x compared to state-of-the-art linear models but also maintains high predictive performance.",10.14778/3734839.3734862,2025,,ACM,10.14778/3734839.3734862
Leveraging ResNet CNN and XGBoost for Enhanced Bitcoin Price Forecasting,"This research proposes a novel approach for forecasting cryptocurrency prices, specifically Bitcoin which dominates the market. Accurately predicting cryptocurrency values is challenging due to their highly volatile nature. The proposed hybrid model uses ResNet Convolutional Neural Network to encode Bitcoin price time series data into discriminative representations. These representations capture long-range dependencies using XGBoost regression. Additionally, wavelet denoising is applied to filter noise from the price data. The combined ResNet-XGBoost-Wavelet model achieves satisfactory results for Bitcoin price forecasting and has practical applications for developing quantitative trading strategies. While incorporating sentiment analysis and additional influencing factors could further improve predictions, this work presents a competitive approach for minimizing investment risks and maximizing profits in the complex domain of cryptocurrency markets.",10.1145/3639631.3639648,2024,,ACM,10.1145/3639631.3639648
Graph Neural Networks in IoT: A Survey,"The Internet of Things (IoT) boom has revolutionized almost every corner of people’s daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.",10.1145/3565973,2023,,ACM,10.1145/3565973
3DGCN: 3-Dimensional Dynamic Graph Convolutional Network for Citywide Crowd Flow Prediction,"Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin–destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn and incorporate urban structures in crowd flow prediction, we design the GCN aggregator to be learned from both crowd flow prediction and region function inference at the same time. Extensive experiments with real-world datasets in two cities demonstrate that our model outperforms state-of-the-art baselines by 9.6\%∼19.5\% for the next-time-interval prediction.",10.1145/3451394,2021,,ACM,10.1145/3451394
SUSTeR: Sparse Unstructured Spatio Temporal Reconstruction on Traffic Prediction,"Mining spatio-temporal correlation patterns for traffic prediction is a well-studied field. However, most approaches are based on the assumption of the availability of and accessibility to a sufficiently dense data source, which is rather the rare case in reality. Traffic sensors in road networks are generally highly sparse in their distribution: fleet-based traffic sensing is sparse in space but also sparse in time. There are also other traffic application, besides road traffic, like moving objects in the marine space, where observations are sparsely and arbitrarily distributed in space. In this paper, we tackle the problem of traffic prediction on sparse and spatially irregular and non-deterministic traffic observations. We draw a border between imputations and this work as we consider high sparsity rates and no fixed sensor locations. We advance correlation mining methods with a Sparse Unstructured Spatio Temporal Reconstruction (SUSTeR) framework that reconstructs traffic states from sparse non-stationary observations. For the prediction the framework creates a hidden context traffic state which is enriched in a residual fashion with each observation. Such an assimilated hidden traffic state can be used by existing traffic prediction methods to predict future traffic states. We query these states with query locations from the spatial domain.",10.1145/3589132.3625631,2023,,ACM,10.1145/3589132.3625631
Liquidity takers behavior representation through a contrastive learning approach,"Thanks to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyze agents’ behaviors in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilize the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behavior types within each cluster.",10.1145/3604237.3626851,2023,,ACM,10.1145/3604237.3626851
Session-Based News Recommendation from Temporal User Commenting Dynamics,"With the increase in volume of daily online news items, it is more and more difficult for readers to identify news articles relevant to their interests. Thus, effective recommendation systems are critical for an effective user news consumption experience. Existing news recommendation methods usually rely on the news click history to model user interest. However, there are other signals about user behaviors, such as user commenting activity, which have not been used before. We propose a recommendation algorithm that predicts articles a user may be interested in, given her historical sequential commenting behavior on news articles. We show that following this sequential user behavior the news recommendation problem falls into in the class of session-based recommendation. The techniques in this class seek to model users' sequential and temporal behaviors. While we seek to follow the general directions in this space, we face unique challenges specific to news in modeling temporal dynamics, e.g., users' interests shift over time, users comment irregularly on articles, and articles are perishable items with limited lifespans. We propose a recency-regularized neural attentive framework for session-based news recommendation. The proposed method is able to capture the temporal dynamics of both users and news articles, while maintaining interpretability. We design a lag-aware attention and a recency regularization to model the time effect of news articles and comments. We conduct extensive empirical studies on 3 real-world news datasets to demonstrate the effectiveness of our method.",10.1109/asonam55673.2022.10068595,2023,,ACM,10.1109/asonam55673.2022.10068595
Deep Pipeline Embeddings for AutoML,"Automated Machine Learning (AutoML) is a promising direction for democratizing AI by automatically deploying Machine Learning systems with minimal human expertise. The core technical challenge behind AutoML is optimizing the pipelines of Machine Learning systems (e.g. the choice of preprocessing, augmentations, models, optimizers, etc.). Existing Pipeline Optimization techniques fail to explore deep interactions between pipeline stages/components. As a remedy, this paper proposes a novel neural architecture that captures the deep interaction between the components of a Machine Learning pipeline. We propose embedding pipelines into a latent representation through a novel per-component encoder mechanism. To search for optimal pipelines, such pipeline embeddings are used within deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters of the pipeline embedding network using existing evaluations of pipelines on diverse collections of related datasets (a.k.a. meta-datasets). Through extensive experiments on three large-scale meta-datasets, we demonstrate that pipeline embeddings yield state-of-the-art results in Pipeline Optimization.",10.1145/3580305.3599303,2023,,ACM,10.1145/3580305.3599303
Deep Transfer Learning Across Cities for Mobile Traffic Prediction,"Precise citywide mobile traffic prediction is of great significance for intelligent network planning and proactive service provisioning. Current traffic prediction approaches mainly focus on training a well-performed model for the cities with a large amount of mobile traffic data. However, for the cities with scarce data, the prediction performance will be greatly limited. To tackle this problem, in this paper we propose a novel cross-city deep transfer learning framework named CCTP for citywide mobile traffic prediction in cities with data scarcity. Specifically, we first present a novel spatial-temporal learning model and pre-train the model by abundant data of a source city to obtain prior knowledge of mobile traffic dynamics. We then devise an efficient generative adversarial network (GAN) based cross-domain adapter for distribution alignment between target data and source data. To deal with data scarcity issue in some clusters of target city, we further design an inter-cluster transfer learning strategy for performance enhancement. Extensive experiments conducted on real-world mobile traffic datasets demonstrate that our proposed CCTP framework can achieve superior performance in citywide mobile traffic prediction with data scarcity.",10.1109/tnet.2021.3136707,2021,,ACM,10.1109/tnet.2021.3136707
MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation,"Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.",10.1145/3583780.3614962,2023,,ACM,10.1145/3583780.3614962
Automated Spatio-Temporal Synchronous Modeling with Multiple Graphs for Traffic Prediction,"Traffic prediction plays an important role in many intelligent transportation systems. Many existing works design static neural network architecture to capture complex spatio-temporal correlations, which is hard to adapt to different datasets. Although recent neural architecture search approaches have addressed this problem, it still adopts a coarse-grained search with pre-defined and fixed components in the search space for spatio-temporal modeling. In this paper, we propose a novel neural architecture search framework, entitled AutoSTS, for automated spatio-temporal synchronous modeling in traffic prediction. To be specific, we design a graph neural network (GNN) based architecture search module to capture localized spatio-temporal correlations, where multiple graphs built from different perspectives are jointly utilized to find a better message passing way for mining such correlations. Further, we propose a convolutional neural network (CNN) based architecture search module to capture temporal dependencies with various ranges, where gated temporal convolutions with different kernel sizes and convolution types are designed in search space. Extensive experiments on six public datasets demonstrate that our model can achieve 4\%-10\% improvements compared with other methods.",10.1145/3511808.3557243,2022,,ACM,10.1145/3511808.3557243
ImputeFormer: Low Rankness-Induced Transformers for Generalizable Spatiotemporal Imputation,"Missing data is a pervasive issue in both scientific and engineering tasks, especially for the modeling of spatiotemporal data. Existing imputation solutions mainly include low-rank models and deep learning models. The former assumes general structural priors but has limited model capacity. The latter possesses salient expressivity, but lacks prior knowledge of the underlying spatiotemporal structures. Leveraging the strengths of both two paradigms, we demonstrate a low rankness-induced Transformer to achieve a balance between strong inductive bias and high expressivity. The exploitation of the inherent structures of spatiotemporal data enables our model to learn balanced signal-noise representations, making it generalizable for a variety of imputation tasks. We demonstrate its superiority in terms of accuracy, efficiency, and versatility in heterogeneous datasets, including traffic flow, solar energy, smart meters, and air quality. Promising empirical results provide strong conviction that incorporating time series primitives, such as low-rankness, can substantially facilitate the development of a generalizable model to approach a wide range of spatiotemporal imputation problems.",10.1145/3637528.3671751,2024,,ACM,10.1145/3637528.3671751
Event Prediction in the Big Data Era: A Systematic Survey,"Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.",10.1145/3450287,2021,,ACM,10.1145/3450287
DARKER: Efficient Transformer with Data-Driven Attention Mechanism for Time Series,"Transformer-based models have facilitated numerous applications with superior performance. A key challenge in transformers is the quadratic dependency of its training time complexity on the length of the input sequence. A recent popular solution is using random feature attention (RFA) to approximate the costly vanilla attention mechanism. However, RFA relies on only a single, fixed projection for approximation, which does not capture the input distribution and can lead to low efficiency and accuracy, especially on time series data. In this paper, we propose DARKER, an efficient transformer with a novel DAta-dRiven KERnel-based attention mechanism. To precisely present the technical details, this paper discusses them with a fundamental time series task, namely, time series classification (tsc). First, the main novelty of DARKER lies in approximating the softmax kernel by learning multiple machine learning models with trainable weights as multiple projections offline, moving beyond the limitation of a fixed projection. Second, we propose a projection index (called pIndex) to efficiently search the most suitable projection for the input for training transformer. As a result, the overall time complexity of DARKER is linear with the input length. Third, we propose an indexing technique for efficiently computing the inputs required for transformer training. Finally, we evaluate our method on 14 real-world and 2 synthetic time series datasets. The experiments show that DARKER is 3\texttimes{",10.14778/3681954.3681996,2024,,ACM,10.14778/3681954.3681996
Real Time Index and Search Across Large Quantities of GNN Experts for Low Latency Online Learning,"Online learning is a powerful technique that allows models to adjust to concept drift in dynamically changing graphs. This approach is crucial for large mobility-based companies like Grab, where batch-learning methods fail to keep up with the large amount of training data. Our work focuses on scaling graph neural network mixture of expert (MoE) models for real-time traffic speed prediction on road networks, while meeting high accuracy and low latency requirements. Conventional spatio-temporal and incremental MoE frameworks struggle with poor inference accuracy and linear time complexity when scaling experts, for the latter, leading to prohibitively high latency in model updates. To address this issue, we introduce the Indexed Router, a novel method that categorizes experts into a structured hierarchy called the indexed tree. This approach reduces the time to scale and search N number of experts from O(N) to O(log N), making it ideal for online learning under tight service level agreements. Our experiments show that these time savings do not compromise inference accuracy, and our Indexed Router outperforms state-of-the-art spatio-temporal and incremental MoE models in terms of traffic speed prediction accuracy on real-life GPS traces from Grab's database and publicly available records. In summary, the Indexed Router enables MoE models to scale across large numbers of experts with low latency, while accurately identifying the relevant experts for inference.",10.1145/3580305.3599893,2023,,ACM,10.1145/3580305.3599893
Uncertainty-Aware Probabilistic Travel Time Prediction for On-Demand Ride-Hailing at DiDi,"Travel Time Estimation (TTE) aims to accurately forecast the expected trip duration from an origin to a destination. As one of the world's largest ride-hailing platforms, DiDi answers billions of TTE queries per day. The quality of TTE directly decides the customer's experience and the effectiveness of passenger-to-driver matching. However, existing studies mainly regard TTE as a deterministic regression problem and focus on improving the prediction accuracy of a single label, which overlooks the travel time uncertainty induced by various dynamic contextual factors. To this end, in this paper, we propose a probabilistic framework, ProbTTE, for uncertainty-aware travel time prediction. Specifically, the framework first transforms the single-label regression task to a multi-class classification problem to estimate the implicit travel time distribution. Moreover, we propose an adaptive local label-smoothing scheme to capture the ordinal inter-class relationship among soft travel time labels. Furthermore, we construct a route-wise log-normal distribution regularizer to absorb prior knowledge from large-scale historical trip data. By explicitly considering the travel uncertainty, the proposed approach not only improves the TTE accuracy but also provides additional travel time information to benefit downstream tasks in ride-hailing. Extensive experiments on real-world datasets demonstrate the superiority of the proposed framework compared with state-of-the-art travel time prediction algorithms. In addition, ProbTTE has been deployed in production at DiDi in late 2022 to empower various order dispatching services, and improves passenger and driver experiences significantly.",10.1145/3580305.3599925,2023,,ACM,10.1145/3580305.3599925
MSDR: Multi-Step Dependency Relation Networks for Spatial Temporal Forecasting,"Spatial temporal forecasting plays an important role in improving the quality and performance of Intelligent Transportation Systems. This task is rather challenging due to the complicated and long-range spatial temporal dependencies in traffic network. Existing studies typically employ different deep neural networks to learn the spatial and temporal representations so as to capture the complex and dynamic dependencies. In this paper, we argue that it is insufficient to capture the long-range spatial dependencies from the implicit representations learned by temporal extracting modules. To address this problem, we propose Multi-Step Dependency Relation (MSDR), a brand new variant of recurrent neural network. Instead of only looking at the hidden state from only one latest time step, MSDR explicitly takes those of multiple historical time steps as the input of each time unit. We also develop two strategies to incur the spatial information into the dependency relation embedding between multiple historical time steps and the current one in MSDR. On the basis of it, we propose the Graph-based MSDR (GMSDR) framework to support general spatial temporal forecasting applications by seamlessly integrating graph-based neural networks with MSDR. We evaluate our proposed approach on several popular datasets. The results show that the proposed GMSDR framework outperforms state-of-the-art methods by an obvious margin.",10.1145/3534678.3539397,2022,,ACM,10.1145/3534678.3539397
TrajLearn: Trajectory Prediction Learning using Deep Generative Models,"Trajectory prediction aims to estimate an entity’s future path using its current position and historical movement data, benefiting fields like autonomous navigation, robotics, and human movement analytics. Deep learning approaches have become key in this area, utilizing large-scale trajectory datasets to model movement patterns, but face challenges in managing complex spatial dependencies and adapting to dynamic environments. To address these challenges, we introduce TrajLearn, a novel model for trajectory prediction that leverages generative modeling of higher-order mobility flows based on hexagonal spatial representation. TrajLearn predicts the next k steps by integrating a customized beam search for exploring multiple potential paths while maintaining spatial continuity. We conducted a rigorous evaluation of TrajLearn, benchmarking it against leading state-of-the-art approaches and meaningful baselines. The results indicate that TrajLearn achieves significant performance gains, with improvements of up to ~40\% across multiple real-world trajectory datasets. In addition, we evaluated different prediction horizons (i.e., various values of k), conducted resolution sensitivity analysis, and performed ablation studies to assess the impact of key model components. Furthermore, we developed a novel algorithm to generate mixed-resolution maps by hierarchically subdividing hexagonal regions into finer segments within a specified observation area. This approach supports selective detailing, applying finer resolution to areas of interest or high activity (e.g., urban centers) while using coarser resolution for less significant regions (e.g., rural or uninhabited areas), effectively reducing data storage requirements and computational overhead. We promote reproducibility and adaptability by offering complete code, data, and detailed documentation with flexible configuration options for various applications.",10.1145/3729226,2025,,ACM,10.1145/3729226
Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models,"Existing anomaly detection models for time series are primarily trained with normal-point-dominant data and would become ineffective when anomalous points intensively occur in certain episodes. To solve this problem, we propose a new approach, called DiffAD, from the perspective of time series imputation. Unlike previous prediction- and reconstruction-based methods that adopt either partial or complete data as observed values for estimation, DiffAD uses a density ratio-based strategy to select normal observations flexibly that can easily adapt to the anomaly concentration scenarios. To alleviate the model bias problem in the presence of anomaly concentration, we design a new denoising diffusion-based imputation method to enhance the imputation performance of missing values with conditional weight-incremental diffusion, which can preserve the information of observed values and substantially improves data generation quality for stable anomaly detection. Besides, we customize a multi-scale state space model to capture the long-term dependencies across episodes with different anomaly patterns. Extensive experimental results on real-world datasets show that DiffAD performs better than state-of-the-art benchmarks.",10.1145/3580305.3599391,2023,,ACM,10.1145/3580305.3599391
T-DPSOM: an interpretable clustering method for unsupervised learning of patient health states,"Generating interpretable visualizations of multivariate time series in the intensive care unit is of great practical importance. Clinicians seek to condense complex clinical observations into intuitively understandable critical illness patterns, like failures of different organ systems. They would greatly benefit from a low-dimensional representation in which the trajectories of the patients' pathology become apparent and relevant health features are highlighted. To this end, we propose to use the latent topological structure of Self-Organizing Maps (SOMs) to achieve an interpretable latent representation of ICU time series and combine it with recent advances in deep clustering. Specifically, we (a) present a novel way to fit SOMs with probabilistic cluster assignments (PSOM), (b) propose a new deep architecture for probabilistic clustering (DPSOM) using a VAE, and (c) extend our architecture to cluster and forecast clinical states in time series (T-DPSOM). We show that our model achieves superior clustering performance compared to state-of-the-art SOM-based clustering methods while maintaining the favorable visualization properties of SOMs. On the eICU data-set, we demonstrate that T-DPSOM provides interpretable visualizations of patient state trajectories and uncertainty estimation. We show that our method rediscovers well-known clinical patient characteristics, such as a dynamic variant of the Acute Physiology And Chronic Health Evaluation (APACHE) score. Moreover, we illustrate how it can disentangle individual organ dysfunctions on disjoint regions of the two-dimensional SOM map.",10.1145/3450439.3451872,2021,,ACM,10.1145/3450439.3451872
Improved Customer Lifetime Value Prediction With Sequence-To-Sequence Learning and Feature-Based Models,"The prediction of the Customer Lifetime Value (CLV) is an important asset for tool-supported marketing by customer relationship managers. Since standard methods based on purchase recency, frequency, and past profit and revenue statistics often have limited predictive power, advanced machine learning (ML) techniques were applied to this task in recent years. However, existing approaches are often not fully capable of modeling certain temporal patterns that can be commonly found in practice, such as periodic purchasing behavior of customers. To address these shortcomings, we propose a novel method for CLV prediction based on a combination of several ML techniques. At its core, our method consists of a tailored deep learning approach based on encoder–decoder sequence-to-sequence recurrent neural networks with augmented temporal convolutions. This model is then combined with gradient boosting machines (GBMs) and a set of novel features in a hybrid framework. Empirical evaluations based on real-world data from a larger e-commerce company and a public dataset from the domain of online retail show that already the sequence-based model leads to competitive performance results. Stacking it with the GBM model is synergistic and further improves accuracy, indicating that the two models capture different patterns in the data.",10.1145/3441444,2021,,ACM,10.1145/3441444
Forecasting Interaction Order on Temporal Graphs,"Link prediction is a fundamental task for graph analysis and the topic has been studied extensively for static or dynamic graphs. Essentially, the link prediction is formulated as a binary classification problem about two nodes. However, for temporal graphs, links (or interactions) among node sets appear in sequential orders. And the orders may lead to interesting applications. While a binary link prediction formulation fails to handle such an order-sensitive case. In this paper, we focus on such an interaction order prediction problem among a given node set on temporal graphs. For the technical aspect, we develop a graph neural network model named Temporal ATtention network (TAT), which utilizes the fine-grained time information on temporal graphs by encoding continuous real-valued timestamps as vectors. For each transformation layer of the model, we devise an attention mechanism to aggregate neighborhoods' information based on their representations and time encodings attached to their specific edges. We also propose a novel training scheme to address the permutation-sensitive property of the problem. Experiments on several real-world temporal graphs reveal that TAT outperforms some state-of-the-art graph neural networks by 55\% on average under the AUC metric.",10.1145/3447548.3467341,2021,,ACM,10.1145/3447548.3467341
CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining,"The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83\% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.",10.1145/3659597,2024,,ACM,10.1145/3659597
HiGRN: A Hierarchical Graph Recurrent Network for Global Sea Surface Temperature Prediction,"Sea surface temperature (SST) is one critical parameter of global climate change, and accurate SST prediction is important to various applications, e.g., weather forecasting, fishing directions, and disaster warnings. The global ocean system is unified and complex, and the SST patterns in different oceanic regions are highly diverse and correlated. However, existing data-driven SST prediction methods mainly consider the local patterns within a certain oceanic region, e.g., El Nino region and the Black sea. It is challenging but necessary to model the global SST correlations rather than that in a specific region to enhance the prediction accuracy of SST. In this work, we proposed a new method called Hierarchical Graph Recurrent Network&nbsp;(HiGRN) to address the issue. First, to learn the dynamic and diverse local SST patterns of specific locations, we design an adaptive node embedding with self-learned parameters to learn various SST patterns. Then we develop a hierarchical cluster generator to aggregate the locations with similar patterns into regional clusters and utilize a graph convolution network to learn the spatial correlations among these clusters. Finally, we introduce a multi-level attention mechanism to fuse the local patterns and regional correlations, and the output is fed into a recurrent network to achieve SST predictions. Extensive experiments on two real-world datasets show that our method largely outperforms the state-of-the-art SST prediction methods. The source code is available at .",10.1145/3597937,2023,,ACM,10.1145/3597937
"Algorithms in future capital markets: a survey on AI, ML and associated algorithms in capital markets","This paper reviews Artificial Intelligence (AI), Machine Learning (ML) and associated algorithms in future Capital Markets. New AI algorithms are constantly emerging, with each 'strain' mimicking a new form of human learning, reasoning, knowledge, and decisionmaking. The current main disrupting forms of learning include Deep Learning, Adversarial Learning, Transfer and Meta Learning. Albeit these modes of learning have been in the AI/ML field more than a decade, they now are more applicable due to the availability of data, computing power and infrastructure. These forms of learning have produced new models (e.g., Long Short-Term Memory, Generative Adversarial Networks) and leverage important applications (e.g., Natural Language Processing, Adversarial Examples, Deep Fakes, etc.). These new models and applications will drive changes in future Capital Markets, so it is important to understand their computational strengths and weaknesses. Since ML algorithms effectively self-program and evolve dynamically, financial institutions and regulators are becoming increasingly concerned with ensuring there remains a modicum of human control, focusing on Algorithmic Interpretability/Explainability, Robustness and Legality. For example, the concern is that, in the future, an ecology of trading algorithms across different institutions may 'conspire' and become unintentionally fraudulent (cf. LIBOR) or subject to subversion through compromised datasets (e.g. Microsoft Tay). New and unique forms of systemic risks can emerge, potentially coming from excessive algorithmic complexity. The contribution of this paper is to review AI, ML and associated algorithms, their computational strengths and weaknesses, and discuss their future impact on the Capital Markets.",10.1145/3383455.3422539,2021,,ACM,10.1145/3383455.3422539
Time-Series Event Prediction with Evolutionary State Graph,"The accurate and interpretable prediction of future events in time-series data often requires the capturing of representative patterns (or referred to as states) underpinning the observed data. To this end, most existing studies focus on the representation and recognition of states, but ignore the changing transitional relations among them. In this paper, we present evolutionary state graph, a dynamic graph structure designed to systematically represent the evolving relations (edges) among states (nodes) along time. We conduct analysis on the dynamic graphs constructed from the time-series data and show that changes on the graph structures (e.g., edges connecting certain state nodes) can inform the occurrences of events (i.e., time-series fluctuation). Inspired by this, we propose a novel graph neural network model, Evolutionary State Graph Network (EvoNet), to encode the evolutionary state graph for accurate and interpretable time-series event prediction. Specifically, EvoNet models both the node-level (state-to-state) and graph-level (segment-to-segment) propagation, and captures the node-graph (state-to-segment) interactions over time. Experimental results based on five real-world datasets show that our approach not only achieves clear improvements compared with 11 baselines, but also provides more insights towards explaining the results of event predictions.",10.1145/3437963.3441827,2021,,ACM,10.1145/3437963.3441827
Probabilistic framework for modeling event shocks to financial time series,"In financial market, certain types of stochastic events are intrinsically impactful to the prediction of financial times series, such as stock return, while few existing research attempts have been made to incorporate stochastic event modeling to time series modeling in a principled way. In this paper, we present a pioneering study that fills this gap. In particular, we introduce a generic probabilistic model that captures 1) the inter-dependencies among stochastic events, and 2) the impact of these events on time series. To this end, we extend multivariate Hawkes process (MHP) and proximal graphical event model (PGEM) and apply this framework to modeling two financial events, companies' quarterly revenue releases and updates of consensus prediction of quarterly revenue, and their impacts on the mean and correlation structures of future stock return. Our model not only improves prediction of financial time series, but also promotes AI trust for finance by revealing the causal relationship among the events. Extensive experimental results based on real financial market data validate the effectiveness of our models in learning event impact and improving investment decision by incorporating stochastic event impacts.",10.1145/3490354.3494407,2022,,ACM,10.1145/3490354.3494407
"(Vision Paper) A Vision for Spatio-Causal Situation Awareness, Forecasting, and Planning","Successfully tackling many urgent challenges in socio-economically critical domains, such as public health and sustainability, requires a deeper understanding of causal relationships and interactions among a diverse spectrum of spatio-temporally distributed entities. In these applications, the ability to leverage spatio-temporal data to obtain causally based situational awareness and to develop informed forecasts to provide resilience at different scales is critical. While the promise of a causally grounded approach to these challenges is apparent, the core data technologies needed to achieve these are in the early stages and lack a framework to help realize their potential. In this article, we argue that there is an urgent need for a novel paradigm of spatio-causal research built on computational advances in spatio-temporal data and model integration, causal learning and discovery, large scale data- and model-driven simulations, emulations, and forecasting, as well as spatio-temporal data-driven and model-centric operational recommendations, and effective causally driven visualization and explanation. We thus provide a vision, and a road map, for spatio-causal situation awareness, forecasting, and planning.",10.1145/3672556,2024,,ACM,10.1145/3672556
Identifying bad software changes via multimodal anomaly detection for online service systems,"In large-scale online service systems, software changes are inevitable and frequent. Due to importing new code or configurations, changes are likely to incur incidents and destroy user experience. Thus it is essential for engineers to identify bad software changes, so as to reduce the influence of incidents and improve system re- liability. To better understand bad software changes, we perform the first empirical study based on large-scale real-world data from a large commercial bank. Our quantitative analyses indicate that about 50.4\% of incidents are caused by bad changes, mainly be- cause of code defect, configuration error, resource contention, and software version. Besides, our qualitative analyses show that the current practice of detecting bad software changes performs not well to handle heterogeneous multi-source data involved in soft- ware changes. Based on the findings and motivation obtained from the empirical study, we propose a novel approach named SCWarn aiming to identify bad changes and produce interpretable alerts accurately and timely. The key idea of SCWarn is drawing support from multimodal learning to identify anomalies from heterogeneous multi-source data. An extensive study on two datasets with various bad software changes demonstrates our approach significantly outperforms all the compared approaches, achieving 0.95 F1-score on average and reducing MTTD (mean time to detect) by 20.4\%∼60.7\%. In particular, we shared some success stories and lessons learned from the practical usage.",10.1145/3468264.3468543,2021,,ACM,10.1145/3468264.3468543
"Social Network Analysis: A Survey on Measure, Structure, Language Information Analysis, Privacy, and Applications","The rapid growth in popularity of online social networks provides new opportunities in computer science, sociology, math, information studies, biology, business, and more. Social network analysis (SNA) is a paramount technique supporting understanding social relationships and networks. Accordingly, certain studies and reviews have been presented focusing on information dissemination, influence analysis, link prediction, and more. However, the ultimate aim is for social network background knowledge and analysis to solve real-world social network problems. SNA still has several research challenges in this context, including users’ privacy in online social networks. Inspired by these facts, we have presented a survey on social network analysis techniques, visualization, structure, privacy, and applications. This detailed study has started with the basics of network representation, structure, and measures. Our primary focus is on SNA applications with state-of-the-art techniques. We further provide a comparative analysis of recent developments on SNA problems in the sequel. The privacy preservation with SNA is also surveyed. In the end, research challenges and future directions are discussed to suggest to researchers a starting point for their research.",10.1145/3539732,2023,,ACM,10.1145/3539732
Modeling Temporal Patterns of Cyberbullying Detection with Hierarchical Attention Networks,"Cyberbullying is rapidly becoming one of the most serious online risks for adolescents. This has motivated work on machine learning methods to automate the process of cyberbullying detection, which have so far mostly viewed cyberbullying as one-off incidents that occur at a single point in time. Comparatively less is known about how cyberbullying behavior occurs and evolves over time. This oversight highlights a crucial open challenge for cyberbullying-related research, given that cyberbullying is typically defined as intentional acts of aggression via electronic communication that occur repeatedly and persistently. In this article, we center our discussion on the challenge of modeling temporal patterns of cyberbullying behavior. Specifically, we investigate how temporal information within a social media session, which has an inherently hierarchical structure (e.g., words form a comment and comments form a session), can be leveraged to facilitate cyberbullying detection. Recent findings from interdisciplinary research suggest that the temporal characteristics of bullying sessions differ from those of non-bullying sessions and that the temporal information from users’ comments can improve cyberbullying detection. The proposed framework consists of three distinctive features: (1) a hierarchical structure that reflects how a social media session is formed in a bottom-up manner; (2) attention mechanisms applied at the word- and comment-level to differentiate the contributions of words and comments to the representation of a social media session; and (3) the incorporation of temporal features in modeling cyberbullying behavior at the comment-level. Quantitative and qualitative evaluations are conducted on a real-world dataset collected from Instagram, the social networking site with the highest percentage of users reporting cyberbullying experiences. Results from empirical evaluations show the significance of the proposed methods, which are tailored to capture temporal patterns of cyberbullying detection.",10.1145/3441141,2021,,ACM,10.1145/3441141
Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud,"Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.",10.1145/3626246.3653378,2024,,ACM,10.1145/3626246.3653378
High-dimensional Multivariate Time Series Forecasting using Self-Organizing Maps and Fuzzy Time Series,"Machine learning models that follow the FTS (Fuzzy Time Series) approach stand out as data-driven non-parametric models of easy implementation and high accuracy, which can be applied to uni-variate and multivariate time series. However, this approach encounters difficulties when dealing with databases of many variables, given the explosion of rules that are generated for the construction of models. Usually filter and wrapper techniques (e.g. Boruta test) and data projection techniques (e.g. Principal Component Analysis) are used. The present work proposes a methodology for tackling this issue by projecting the original high-dimensional data into a low dimensional embedding space using self-organizing Kohonnen maps and later using the Weighted Multivariate FTS method (WMVFTS) for rule discovery and forecasting. The results obtained showed good values of RMSE and MAPE, illustrating the validity and potential of the method.",10.1109/fuzz45933.2021.9494496,2021,3,IEEE,10.1109/fuzz45933.2021.9494496
Toward Digital Twin: Leveraging Pre-training Approaches for Multivariate Time Series Forecasting,"Time series forecasting has been an active research area, particularly in the context of Digital Twin (DT) systems. Despite the excellent results yielded by pre-trained models in Natural Language Processing (NLP) and Computer Vision (CV), only a few studies have researched pre-training strategies for time series forecasting networks within DT systems. Recent studies demonstrate that transfer learning across multiple time series datasets does not always provide promising results, making self-supervised pre-training directly on the downstream dataset a temporarily considered optimal solution. To the best of our knowledge, the only general pre-training task in the time series field is the Masked Autoencoder. However, this approach may lead to redundant representations for downstream forecasting within DT systems. Therefore, we propose three pre-training tasks specially designed for time series forecasting within DT frameworks: Inverse Forecasting (IF), Coarser Forecasting (CF), and Anomaly Forecasting (AF). These tasks are respectively designed to capture bidirectional dependency, reduce noise, and augment data, all crucial aspects in enhancing the predictive capabilities of DT systems. By integrating the three tasks, we obtain a composite pre-training task which generally improves the forecasting results of time series models within DT systems across multiple datasets. This work contributes to the ongoing efforts to improve the accuracy and efficiency of DT systems, paving the way for more robust and reliable digital representations of physical systems.",10.1109/iceict57916.2023.10245025,2023,2,IEEE,10.1109/iceict57916.2023.10245025
LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting,"Modern Internet of Things (IoT) systems generate massive, heterogeneous multivariate time series data. Accurate Multivariate Time Series Forecasting (MTSF) of such data is critical for numerous applications. However, existing methods almost universally employ a shared embedding layer that processes all channels identically, creating a representational bottleneck that obscures valuable channel-specific information. To address this challenge, we introduce a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into a shared base component capturing common patterns and channel-specific auxiliary components modeling unique deviations. Within this decomposition, we empirically observe that the auxiliary components tend to exhibit low-rank and clustering characteristics, a structural pattern that is significantly less apparent when using purely independent embeddings. Consequently, we design LightSAE, a parameter-efficient embedding module that operationalizes these observed characteristics through low-rank factorization and a shared, gated component pool. Extensive experiments across 9 IoT-related datasets and 4 backbone architectures demonstrate LightSAE’s effectiveness, achieving MSE improvements of up to 22.8% with only 4.0% parameter increase. Code is available at https://github.com/EDM314/LightSAE.",10.1109/jiot.2025.3631505,2025,,IEEE,10.1109/jiot.2025.3631505
Dwtformer: Wavelet decomposition Transformer with 2D Variation for Long-Term Series Forecasting,"Benefiting from the boom in deep learning and natural language processing, RNNs, CNNs and Transformers have significantly improved the accuracy of multivariate long time series prediction, which focus on how to discover the long-term dependence of long time series and how to capture the overall trend of time series. But They ignore the complex intrinsic features of the series (the characteristics of intra-period and inter-period variations). Based on the observation of the multi-periodicity of time series, this study extends the analysis of time series to a higher space by decomposing a complex 1D time series into a set of 2D tensors based on multiple frequencies. Through this transformation, we connect the time series prediction to the computer vision so we can get more effective techniques which can be employed to extract complex temporal variations from the transformed 2D tensors. To address these issues, this paper proposes to combine the Transformer with a wavelet decomposition-based 2D feature learning module. The 2D feature learning module captures the complex period variations of the time series and the Transformer captures the long-term historical details. To more fully learn the periodic features, this paper proposes Dwtformer by referring to the auto-correlation mechanism in Autoformer. Experiments on four benchmark datasets show that compared to state-of-the-art methods, Dwtformer can reduce multivariate time series prediction errors by 14.9%.",10.1109/itnec56291.2023.10082078,2023,3,IEEE,10.1109/itnec56291.2023.10082078
A Multistep Multivariate Fuzzy-Based Time-Series Forecasting on Internet of Things Data,"Multistep ahead time series forecasting is essential in Internet of Things (IoT) applications in smart cities and smart homes to make accurate future predictions and precise decision making. Thus, this study introduces a novel multiple-input single-output (MISO) forecasting method called Multistep Embedding-based fuzzy time series (MS-EFTS), designed to predict high-dimensional nonstationary time series data. As a first-order approach, it employs a direct strategy that integrates an embedding transformation with a weighted multivariate FTS (WMVFTS) model. This combination allows for effective predictions over long-term horizons within low-dimensional, learned continuous representations. The effectiveness of the proposed MS-EFTS is assessed using three high-dimensional IoT time series in this investigation. The obtained results showcase the superior performance of the proposed method compared to some deep learning forecasting methods, including LSTM, BiLSTM, TCN, and CNN-LSTM, in terms of accuracy, parsimony, and efficiency.",10.1109/jiot.2025.3549715,2025,2,IEEE,10.1109/jiot.2025.3549715
STNet: Spatial-Temporal Transformers are Effective for Multivariate Time Series Forecasting,"The recent boom of Transformer-based models have enhanced state-of-the-art results of multivariate time series (MTS) forecasting. However, MTS forecasting remains a challenging problem, primarily because of the intricate temporal patterns and obscured spatial correlations. Existing models are not only computationally expensive in modeling long-term temporal dependencies, but more importantly, fail to adequately capture the interrelations among variables. To address these problems, we propose STNet, a Spatial-Temporal Transformer Network with self-supervised pre-training scheme for MTS forecasting. In STNet, the MTS are formalized as a data-driven graph structure, which is learned through the training process to extract the latent patterns within the spatial dependencies of the data. Then we encode the structural information of the graph into the spatial Transformer encoder to help STNet better model refined spatial dependencies. A patch-level Transformer encoder is implemented to efficiently enhance locality and comprehensively capture semantic information pertaining to temporal dependencies. Moreover, the pre-training model generates rich contextual information, which consistently leads to reliable outcomes in transfer performance for downstream tasks. Extensive experiments conducted on five real-world benchmark datasets show the proposed STNet improves the prediction accuracy by 5.0%-25.2% compared to previous state-of-the-arts.",10.1109/ijcnn64981.2025.11228192,2025,,IEEE,10.1109/ijcnn64981.2025.11228192
RecVAE-GBRT: Memory-Fused XGBoost for Time-Series Forecasting,"Time series forecasting is a crucial task for control and decision in various fields. Recent efforts focus on integrating complex deep learning techniques, such as RNN or Transformer, into sequential models. However, these solutions are often criticized due to their excessive complexity. Inspired by the effectiveness of Gradient Boosted Regression Trees (GBRT) methods (such as XGBoost) on tabular datasets, this study proposes a hybrid method for time series forecasting. In this method, we design a memory mechanism for GBRT, namely, Recursive Variational AutoEncoder (RecVAE), which can generate compressed representations of historical sequences by recursively summarizing a section of input time series and preceding internal outputs into current internal outputs. This compensates for the limitation of the GBRT in incorporating long historical sequences for time series forecasting. The resulting memory-fused forecasting model, namely, RecVAE-GBRT, is tested on 4 real-world time series datasets. The results indicate that it generates competitive results compared to Transformer-based time series forecasting methods, all happening at the same level of computation efficiency or better.",10.1109/ijcnn60899.2024.10650508,2024,2,IEEE,10.1109/ijcnn60899.2024.10650508
Time Series Forecasting with Multi-scale Decomposition and Fourier Neural Operators,"Time series forecasting has a wide range of applications in weather forecasting, energy price prediction, and many other fields. However, real-world time series data are often inherently non-stationary, which makes modeling time series data challenging. Existing research methods typically use seasonal-trend decomposition to disentangle time series data, and then leverage Transformer and other model structures to learn complex, evolving temporal variations.However, we observe that single seasonal-trend decomposition is often insufficient, and time series data exhibit different pattern regularities at different sampling scales. To address this, we propose a novel method that performs multi-scale seasonal-trend decomposition and aggregates features from fine to coarse scales to fully exploit semantic information. Furthermore, we draw inspiration from ensemble learning and employ Fourier neural operator-based backbone networks at different scales, with the predictions from multiple scales aggregated as the final output prediction. Extensive experiments demonstrate that our proposed model achieves superior prediction performance than state-of-the-art models on multiple public datasets.",10.1109/cisat62382.2024.10695364,2024,,IEEE,10.1109/cisat62382.2024.10695364
Robust Time Series Contrastive Representation Learning via Explicit Seasonal-Trend Disentanglement,"We address universal self-supervised representation learning for time series under label scarcity and distribution shifts. A key challenge is that prevalent encode-then-decompose pipelines only implicitly separate seasonal and trend signals, which mixes noise across components and degrades robustness, especially with sudden jumps or stochastic movements. In this work, we propose an explicit, decomposition-aware contrastive framework: original time series are split via a Fourier transform into seasonal (high-frequency) and trend (low-frequency) components. Seasonality is modeled by a frequency-enhanced attention encoder with amplitude-induced augmentations; trend is captured by a tree-structured causal convolution encoder with random perturbations to handle non-stationary drift. The two views are trained contrastively and then fused with lightweight fine-tuning, delivering state-of-the-art accuracy, improved robustness to jumps, and interpretable attributions.",10.1109/access.2025.3621317,2025,,IEEE,10.1109/access.2025.3621317
Domain Generalization for Time-Series Forecasting via Extended Domain-Invariant Representations,"Time-series forecasting is crucial for IoT applications, but generalizing across domains is challenging due to distinct data distributions and dynamics. Most domain generalization methods work well for image processing and classification, but they struggle with time-series forecasting. This is because they solely learn domain-invariant representations of input data, ignoring variations in the output space across domains. This oversight can lead to inaccurate forecasts when outputs in new domains exhibit different distributions or temporal patterns. In this work, we present a new approach to improve the time-series forecasting model generalization by extracting domain-invariant representations from both input and output data. Experiments demonstrate the effectiveness of our approach, achieving significant improvements in forecasting accuracy across multiple test domains. Compared to state-of-the-art methods, our approach delivers up to an 8% increase in accuracy.",10.1109/aiot63253.2024.00031,2024,1,IEEE,10.1109/aiot63253.2024.00031
IL-DiffTSF: Invertible Latent Diffusion for Probabilistic Time Series Forecasting,"Internet of Things (IoT) devices generate large volumes of time series data that are often volatile and complex, making probabilistic time series forecasting (TSF) essential for modeling the distribution of future outcomes. Recently, diffusion-based TSF methods have gained attention for their ability to learn complex distributions. However, they typically apply the diffusion process directly in the time domain, which may struggle to capture complex temporal dependencies, thus limiting the full potential of the diffusion process. Besides, they obtain probabilistic forecasts by sampling multiple plausible outcomes from the learned distribution, which is time-consuming and less effective. To solve these problems, we propose Invertible Latent Diffusion for probabilistic Time Series Forecasting (IL-DiffTSF), a novel approach based on a latent diffusion model. Specifically, we design an invertible latent projection between time series and latent space, where a conditional diffusion process is applied. This design ensures bidirectional consistency and minimal information loss, enabling more accurate TSF. Moreover, instead of sampling-based probabilistic forecasting, IL-DiffTSF represents uncertainties by directly learning a mapping from latent representations to prediction errors, achieving faster and more reliable uncertainty estimates. Experiments on univariate and multivariate benchmarks validate the efficiency and effectiveness of IL-DiffTSF. The code for this project is available at https://github.com/vanerkz/IL-DiffTSF.",10.1109/jiot.2025.3636872,2025,,IEEE,10.1109/jiot.2025.3636872
iBACon: imBalance-Aware Contrastive Learning for Time Series Forecasting,"Time series forecasting (TSF) has gained significant attention as a widely explored research area in diverse applications. Existing methods, which focus on improvements in the most common scenarios, focus little on performance in rare cases. Despite their scarce occurrences in the data, these rare samples are more challenging and easily overlooked by models, significantly contributing to the total loss. In this paper, we propose a novel approach (dubbed iBACon) that overcomes this limitation by employing imbalance-aware contrastive learning and trend-seasonal decomposition architecture, specifically designed to solve TSF. To this end, we first introduce the Input-Output Difference (IOD) metric as a pseudo-label and reveal the data imbalance phenomenon in TSF. This label continuity inherently provides a meaningful distance between targets, implying a similarity between nearby targets in both label and feature spaces. Based on this similarity, the proposed imbalance-aware contrastive loss aims to reshape feature embeddings to facilitate knowledge dissemination among challenging samples and learn specific predictive features. Finally, when combined with our trend-seasonal decomposition network, iBACon significantly improves TSF accuracy. Experiments show that iBACon enhances overall average accuracy and substantially improves the 1-3% most challenging samples.",10.1109/tkde.2025.3589693,2025,,IEEE,10.1109/tkde.2025.3589693
Data-driven Latent Graph Structure Learning for Diagnosis of Alzheimer’s Syndrome,"Complex systems often have a latent graph structure. Studying the underlying graph structure will help us to analyze the mechanisms of complex phenomena. However, it is a challenging problem to learn effective graph structures from the data and apply them to downstream tasks. In this paper, we propose an end-to-end graph learning approach for Alzheimer’s syndrome diagnosis based on functional magnetic resonance imaging (fMRI) data of brain regions, which is completely data-driven. The interactions between time-series of each brain region are represented as graph structures, and a multi-head attention mechanism is used to update the representations of the nodes. Then, the graph structures are obtained from the feature sampling of the edges. Finally, the learned graph structure is combined with the left-out time-series data features and the node prior to completing the classification task of the brain network. In comparison with the latest research methods, our approach achieves higher classification accuracy.",10.1109/icpr56361.2022.9956713,2022,,IEEE,10.1109/icpr56361.2022.9956713
SFLGNN: Power Load Forecasting Based on Spectral-Frequency Learning and Graph Neural Network,"With the continuous development of modern power systems, accurate power load forecasting has gradually become a key issue in energy management. Compared to deep learning models, existing statistical-based prediction models are not well suited to learn how to represent power load data and mine the rich information in the data. In addition, power load data needs to consider both intra-series temporal correlation and inter-series correlation. Recently, attempts have been made to capture both correlations simultaneously, but most of the studies capture only temporal correlations in the time domain and use predefined a priori as inter-sequence relationships. In this paper, SFLGNN (Spectral-Frequency Learning Based Graph Neural Network) is designed for power load forecasting. SFLGNN effectively solves the problem by capturing both variable correlation and inter-sequence correlation using graph neural networks, and extracts important features through CP decomposition with multi-attention mechanism. In addition, SFLGNN enhances representation learning through Spectral-Frequency Learning. We performed comparative experiments, ablation experiments, and hyper-parameter sensitivity experiments on our collected dataset. The experiments demonstrate the effectiveness of our proposed model in the power load forecasting task.",10.1109/iccs62594.2024.10795826,2024,,IEEE,10.1109/iccs62594.2024.10795826
Contrastive Representation Learning for Time Series via Compound Consistency and Hierarchical Contrasting,"In this paper, a novel contrastive representation learning framework for time series data is proposed. The framework is designed to learn general representations of time series at various semantic levels and is capable of transferring across different datasets. The framework incorporates two key components. Firstly, a hierarchical contrasting method is used to consider both the temporal and instance dimensions of the time series and captures information at different levels through maximum pooling at corresponding timestamps, enabling the model to learn fine-grained and multi-scale time-stamped representations for time series prediction tasks. Secondly, a compound consistency constraint is leveraged, which combines transformation consistency and temporal-frequency consistency, to effectively learn a universal representation of the time series, thereby ensuring its transferability across different datasets. Additionally, the framework considers both the temporal and frequency information of the time series, and uses an adaptive wavelet transform to obtain the frequency domain representation while maintaining temporal alignment, facilitating the contrast of temporal-frequency consistency. Finally, the proposed framework is evaluated through extensive experiments on time series prediction tasks and compared with existing models on four public datasets. The results show that the linear regressor trained with the representations learned by the proposed model outperforms existing time series prediction models in terms of prediction accuracy and transferability.",10.1109/ddcls58216.2023.10166246,2023,,IEEE,10.1109/ddcls58216.2023.10166246
SimEXT: Self-supervised Representation Learning for Extreme Values in Time Series,"Forecasting extreme values in time series is an important but challenging problem as the extreme values are rarely observed even when a large amount of historical data is available. The modeling of extreme values requires a specific focus on estimating the tail distribution of the time series, whose statistical properties may differ from the distribution of its non-extreme values. To overcome this challenge, we present a novel self-supervised learning framework, SimEXT, to learn a robust representation of the time series that preserves the fidelity of its tail distribution. The framework employs a combination of contrastive learning and a reconstruction-based autoencoder architecture to facilitate robust representation learning of the temporal patterns associated with the extreme events. SimEXT also incorporates a wavelet-based data augmentation technique with a distribution-based loss function to prioritize the learning of extreme value distribution. We provide probabilistic guarantees on the wavelet-based augmentation that enables the wavelet coefficients to be perturbed during data augmentation without significantly altering the extreme values of the time series. Experimental results on real-world datasets show that SimEXT can effectively learn a robust representation of the time series to boost the performance of downstream tasks for forecasting block maxima values.",10.1109/icdm58522.2023.00119,2023,,IEEE,10.1109/icdm58522.2023.00119
Representation Learning and Knowledge Distillation for Lightweight Domain Adaptation,"In industrial machine learning applications, insufficient data, lack of labeling, distribution shift between subsets, varying operational conditions, etc. result in poor generalizing performance by pre-trained neural network models across domains. In contrast to image detection tasks, time series dataset contain critical domain-specific characteristics that must be learned by the corresponding networks. Naively aligning the learned representations during the adaptation process increases the risk of losing these key information, thus resulting in poor performance. This paper proposes a lightweight domain adaptation method involving representation learning and knowledge distillation (RepLKD). A separate network is pre-trained to learn valuable information from the target data in its latent space with the help of a reconstructor. In the adaptation stage, we use maximum mean discrepancy to minimize the difference in distributions between the source and target latent space. Additionally, we implement knowledge distillation to encourage the target network to generate source-like latent embedding and penalize only when an upper-bound condition is not fulfilled to prevent over-regularization and loss of domain-specific features. Finally, we test our proposed method on 12 cross-domain scenarios with the C-MAPSS dataset and compare the efficacy of our method against existing literature methods.",10.1109/cai59869.2024.00214,2024,,IEEE,10.1109/cai59869.2024.00214
A Review for Pre-Trained Transformer-Based Time Series Forecasting Models,"Transformer-based models have proven their superiority against recurrent networks in time series forecasting. Enhancing transformer-based forecasting models via pretraining tasks is a novel approach in the literature. In this paper, we are reviewing the most recent papers about pretraining aspects of time series as well as pretraining tasks that are used in transformer-based architectures.",10.1109/itms59786.2023.10317721,2023,,IEEE,10.1109/itms59786.2023.10317721
Improving Time-Series Classification Accuracy Based on Temporal Feature Representation Learning Using CRU-LSTM Autoencoder,"Time-series data consists of a sequence of observations recorded in chronological order, where the data changes over time. This type of data exhibits various characteristics, such as temporal volatility, trends, and seasonality. Recently, a new layer structure called Correlation Recurrent Units (CRU) has been proposed to capture not only temporal variability but also trends and seasonality in time-series data. In this study, we propose an end-to-end model that utilizes a CRU autoencoder to learn temporal feature representations and address time-series classification problems simultaneously. To validate the performance of our proposed model, we conducted comparative experiments using 30 time-series classification datasets from six different types. The experimental results showed that the proposed model outperformed the baseline models in 20 out of the 30 time-series datasets. This indicates that the proposed approach effectively captures various temporal features in time-series data and improves the performance of time-series classification tasks.",10.1109/cogmi58952.2023.00033,2023,1,IEEE,10.1109/cogmi58952.2023.00033
A Deep Learning Framework for Non-stationary Time Series Prediction,"In non-stationary time series, there are data bursts, which brings challenges to accurately predict data. This paper proposes a deep learning framework for non-stationary time series prediction. In this framework, the first-order and second-order difference and decomposition of the original time series are first made respectively, so as to generate five new time series, which are as the input of the framework. Then, a prediction model is constructed sequentially by GRU (gated recurrent unit) and FCN (fully-connected network) networks to predict and fit data. Finally, a two-stage training mode is designed, which first predicts the trend and component, and then fits with the cycle to produce the prediction data. The experiments are tested on the public air quality dataset, and the results show that our approach can accurately predict the non-stationary time series, especially overcomes the lag, and achieves better performance than typical statistics methods and deep learning models.",10.1109/cvidliccea56201.2022.9824863,2022,11,IEEE,10.1109/cvidliccea56201.2022.9824863
MTAP-DK: Multivariate Time-Series Anomaly Prediction with Domain Knowledge,"Predicting anomalies of mobile equipment plays an important role in performing preventive maintenance, alleviating major economic losses and personal safety issues. Previous studies basically adopted data-driven models for anomaly prediction or detection of industrial equipment, ignoring the importance of domain knowledge. The domain knowledge can more accurately and theoretically capture the complex relationship among features. However, building the deep learning models incorporating domain knowledge is very difficult due to the following challenges. First, the domain knowledge is often different from the actual state of the equipment, so it is difficult to obtain knowledge information that conforms to the real situation. Second, domain knowledge is difficult to directly and effectively be applied to deep learning models due to its diverse representations. In this paper, we propose a Multivariate Time-Series Anomaly Prediction with Domain Knowledge (MTAP-DK) to address these issues. Specifically, we firstly propose a knowledge extraction module, which can extract the domain equations that conform to the actual situation with the domain knowledge and historical data. Secondly, we design a domain guidance module to guide and constrain the graph neural network from the knowledge level, to improve its capabilities to express the relationship among features. Thirdly, we predict future data based on the graph incorporating knowledge information. Finally, the prediction is reconstructed by the multi-scale convolution reconstruction method, and the abnormal information is inferred according to the reconstruction error.",10.1109/ijcnn55064.2022.9892923,2022,,IEEE,10.1109/ijcnn55064.2022.9892923
Characterizing Disease Spreading via Visibility Graph Embedding,"Gaining timely insights on real-world emergency events, such as infectious disease outbreaks, is critical for developing appropriate response strategies. In this work, we propose a data-driven approach to study the spreading dynamics of the global Covid-19 pandemic. Specifically, we aim to identify a set of most “similar” geographic regions as proxies for making predictions on a targeted location. Example predictions include the number of new cases, number of hospitalizations, and number of deaths. Such predictions can be made at different levels of regional granularities, including city, county, and state levels. Our approach starts by transforming regional time series into graph representations using the natural visibility graph (NVG) model in order to capture their intrinsic trends and properties. These graphs are then projected onto a common embedding space using graph-level network embedding techniques. Essentially, each time series is converted as a data point in a feature embedding space, where spatial proximity indicates similarity among time series. Given a targeted region, our approach can identify the most “relevant” geographic regions by finding its k-nearest neighbors in the embedding space. Subsequently, appropriate response strategies and policies (e.g., school shutdown, indoor dining restriction) can be adapted based on the success or failure experiences from relevant regions. Our approach will potentially provide valuable insights in mitigating the spreading of infectious disease.",10.1109/bigdata52589.2021.9671810,2021,,IEEE,10.1109/bigdata52589.2021.9671810
A Large-Scale Ensemble Learning Framework for Demand Forecasting,"Demand forecasting is a crucial component of supply chain management for revenue optimization and inventory planning. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful ensemble framework capable of accurately predicting future demand for a diverse range of items. Forchestra consists of two parts: 1) base predictors and 2) a neural conductor. For a given time series, each base predictor outputs its respective forecast based on historical observations. On top of the base predictors, the neural conductor adaptively assigns the importance weight for each predictor by looking at the representation vector provided by a representation module. Finally, Forchestra aggregates the predictions by the weights and constructs a final prediction. In contrast to previous ensemble approaches, the neural conductor and all base predictors of Forchestra are trained in an end-to-end manner; this allows each base predictor to modify its reaction to different inputs, while supporting other predictors and constructing a final prediction jointly. We empirically show that the model size is scalable to up to 0.8 billion parameters ($\approx$400-layer LSTM). The proposed method is evaluated on our proprietary E-Commerce (100K) and the public M5(30K) datasets, and it outperforms existing forecasting models with a significant margin. In addition, we observe that our framework generalizes well to unseen data points when evaluated in a zeroshot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional ensemble approaches. The code is available at https://github.com/young-j-parld22-ICDM-Forchestra.",10.1109/icdm54844.2022.00048,2022,2,IEEE,10.1109/icdm54844.2022.00048
CoGenT: A Unified Contrastive-Generative Framework for Time Series Classification,"Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at distinguishing between different examples, and generative approaches that learn the overall data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive-Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. Co-GenT addresses fundamental limitations of both approaches: it overcomes contrastive learning’s sensitivity to high intra-class similarity in temporal data while reducing generative methods’ dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2& and 14.27& F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the CoGenT preserves high accuracy while acquiring structural reliability. These findings establish a foundation for hybrid SSL in time series analysis. Code at https://github.com/DL4mHealth/cogent/.",10.1109/tai.2025.3637168,2025,,IEEE,10.1109/tai.2025.3637168
From Uniform Models To Generic Representations: Stock Return Prediction With Pre-training,"The emergence of deep learning has cast new light on the century-old problem of stock return prediction. For single stock return prediction, incorporating peripheral data such as cross sectional information has become the de facto standard for target horizons denoted in hours and above. However, such approach is not directly applicable to predicting short-term stock returns due to their strong stochastic nature. Little has been reported in public domain on how to utilize the rich exogenous data in short-term scenarios effectively. We propose a representation learning solution based on a pretrain-finetune framework. To help models learn high-quality feature extractors, we further propose to use triplet loss as a novel pre-train task. We present a new sample selection criterion and three versions of triplet selection in this context: “easy sample”, “multiple samples”, and “hard sample”. Experiment results using the proposed method demonstrate significant improvement over standard approaches. We also share some insight on how to apply triplet loss effectively in the context of short-term stock return prediction. Specifically, we demonstrate that using regression labels to select triplets is more effective than using embedding similarity. The proposed training framework is model-agnostic and shows great performance improvements in various settings.",10.1109/ijcnn55064.2022.9892697,2022,3,IEEE,10.1109/ijcnn55064.2022.9892697
IProbeTrans: A Long-Term Series Forecasting Method Based on Self-Supervised Learning,"Long-term time series forecasting (LTSF) is essential for domains like meteorology and finance, requiring accurate predictions over many time points. While Transformer-based models have shown promise in capturing long-term dependencies, they face challenges due to potential information loss and quadratic scaling of time complexity, impacting efficiency. Thus, this work proposes a forecasting method called iProbTrans, which uses inverted embedding and probsparse self-attention to capture temporal representations and correlations between variables. It outperforms transformer-based methods on multivariate datasets, reducing MSE and MAE by 9.6% and 6.6%, respectively, compared to the FEDformer baseline. A self-supervised learning approach is proposed, decomposing time series into patches and applying random masking to reduce computational costs. This model, trained on mean squared error loss for mask reconstruction, improves upon supervised learning by reducing MSE and MAE by 26.3% and 27.5%. It excels in capturing long-term dependencies, enhancing generalization, and offers a solution to the limitations of Transformer-based methods in LTSF.",10.1109/acait63902.2024.11021826,2024,,IEEE,10.1109/acait63902.2024.11021826
TimesFNP: Contrastive Learning for Financial Domain with Noise-Resilient Prediction,"Long-term time series forecasting is a long-standing research topic in financial scenarios. Recent studies have shown that Transformer models have great potential in time series forecasting. However, time series in financial scenarios contain complex noise disturbances. To address this issue, we propose a new framework called TimesFNP, which aims to improve the noise resistance of long-term time series forecasting in financial scenarios based on contrastive learning methods. Specifically, first, we introduce a noise-based data augmentation method to simulate the noise components in financial scenarios. Second, we fully consider the potential correlations between different companies in long-term time series forecasting tasks and represent the time series features at the company level. Remarkably, our framework demonstrates significant improvements over state-of-the-art algorithms in time series forecasting, achieving performance enhancements of at least $\mathbf{8. 5 7 \%}$ in MSE and $\mathbf{4. 4 2 \%}$ in MAE",10.1109/iccai66501.2025.00111,2025,,IEEE,10.1109/iccai66501.2025.00111
Ranking Neighborhood and Class Prototype Contrastive Learning for Time Series,"Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. Existing contrastive learning methods conduct augmentations and maximize their similarity. However, they ignore the similarity of adjacent timestamps and suffer from the problem of sampling bias. In this paper, we propose a self-supervised framework for learning generalizable representations of time series, called $\mathbf {R}$Ranking n$\mathbf {E}$E ighborhood and cla$\mathbf {S}$Ss prototyp$\mathbf {E}$E contr$\mathbf {A}$Astive $\mathbf {L}$Learning (RESEAL). It exploits information about similarity ranking to learn an embedding space, ensuring that positive samples are ranked according to their temporal order. Additionally, RESEAL introduces a class prototype contrastive learning module. It contrasts time series representations and their corresponding centroids as positives against truly negative pairs from different clusters, mitigating the sampling bias issue. Extensive experiments conducted on several multivariate and univariate time series tasks (i.e., classification, anomaly detection, and forecasting) demonstrate that our representation framework achieves significant improvement over existing baselines of self-supervised time series representation.",10.1109/tbdata.2024.3495509,2025,1,IEEE,10.1109/tbdata.2024.3495509
A Novel Approach of ESN Reservoir Structure Learning for Improved Predictive Performance,"This paper presents a novel method to enhance the predictive performance of the Echo State Network (ESN) model by adopting reservoir topology learning. ESNs are a type of Recurrent Neural Network (RNN) that have demonstrated considerable potential in various applications, but they can be challenging to train and optimize due to their random initialization. To improve the learning capabilities of ESNs and enhance their effectiveness in a broad range of predictive tasks, we utilize a structure learning algorithm. The proposed approach modifies the ESN reservoir's connectivity by applying techniques such as reversing, deleting, and adding new connections. We evaluate our proposal performance using both synthetic and real datasets, and our results indicate that it can substantially improve predictive accuracy compared to traditional ESNs.",10.1109/iscc58397.2023.10218132,2023,1,IEEE,10.1109/iscc58397.2023.10218132
Multivariate Time-Series Modeling and Forecasting With Parallelized Convolution and Decomposed Sparse-Transformer,"Many real-world scenarios require accurate predictions of time series, especially in the case of long sequence time-series forecasting (LSTF), such as predicting traffic flow and electricity consumption. However, existing time-series prediction models encounter certain limitations. First, they struggle with mapping the multidimensional information present in each time step to high dimensions, resulting in information coupling and increased prediction difficulty. Second, these models fail to effectively decompose the intertwined temporal patterns within the time series, which hinders their ability to learn more predictable features. To overcome these challenges, we propose a novel end-to-end LSTF model with parallelized convolution and decomposed sparse-Transformer (PCDformer). PCDformer achieves the decoupling of input sequences by parallelizing the convolutional layers, enabling the simultaneous processing of different variables within the input sequence. To decompose distinct temporal patterns, PCDformer incorporates a temporal decomposition module within the encoder–decoder structure, effectively separating the input sequence into predictable seasonal and trend components. Additionally, to capture the correlation between variables and mitigate the impact of irrelevant information, PCDformer utilizes a sparse self-attention mechanism. Extensive experimentation conducted on five diverse datasets demonstrates the superior performance of PCDformer in LSTF tasks compared to existing approaches, particularly outperforming encoder–decoder-based models.",10.1109/tai.2024.3410934,2024,,IEEE,10.1109/tai.2024.3410934
Grouped Graph Neural Networks for Anomaly Detection in Time Series,"Anomaly detection in time series data (e.g., sensor data) is becoming a fundamental research problem that has various applications. Due to the complex inter-sensor relationships, it is challenging to detect anomalous events such as system faults and attacks hidden the high-dimensional time series. Recent advancements in deep learning approaches such as Graph Neural Networks (GNN) have greatly improved anomaly detection performance in time series data. However, existing methods do not learn the dependence relationships between sensors and groups of sensors and may not efficiently detect anomalous events in time series. In this paper, we propose a novel approach GGNN (short for Grouped Graph Neural Networks) that combines a structure learning approach with graph neural networks. In particular, GGNN learns the graph structure containing groups of sensors, which are represented by virtual nodes. In addition, we use the learned graph structure and attention weights to explain the detected anomalies. The experiments on three real world datasets show our superiority in detection accuracy, anomaly diagnosis, and model interpretation compared with state-of-the-art methods.",10.1109/ijcnn60899.2024.10649927,2024,1,IEEE,10.1109/ijcnn60899.2024.10649927
Scaling Up Multivariate Time Series Pre-Training with Decoupled Spatial-Temporal Representations,"Data scale has been acknowledged as a crucial factor for enhancing the generalization and effectiveness of pre-training models. While existing methods of multivariate time series pre-training are primarily limited to a single specific dataset, scaling to a larger scenario that includes multiple diverse datasets (e.g., multi-region data) remains a substantial challenge. In this paper, we present a novel Decoupled Spatial-Temporal Representation Learning (DeSTR) framework to serve as the backbone network for investigating the data scaling capability of multivariate time series pre-training architectures. Specifically, DeSTR utilizes two separate encoders to capture both the temporal dynamics within each time series and the spatial correlations among multiple variables. The obtained representations of distinct modalities are then fed into a Spatial-Guided Temporal Transformer to equip the temporal features with spatial discriminative information. Moreover, we employ masked autoencoding as the foundational pre-training framework and introduce spacetime-agnostic augmentation to improve robustness and facilitate implicit spatiotemporal modeling. Finally, we successfully pre-train a unified time series representation learning framework on real-world datasets from three different cities. Extensive experiments are carried out on various downstream tasks to validate the performance of DeSTR, compared with three categories of state-of-the-art baselines: deep sequential models, spatial-temporal graph neural networks, and time series representation learning methods. The results clearly demonstrate the advantages of scaling multivariate time series pre-training to multiple datasets, highlighting the effectiveness of DeSTR as a general spatiotemporal learner.",10.1109/icde60146.2024.00057,2024,5,IEEE,10.1109/icde60146.2024.00057
Hybrid Deep Learning and XGBoost Models for Enhanced Energy Forecasting: A Comparative Analysis,"Energy forecasting is vital for the optimization of power distribution and, subsequently, the management of grids. This paper examines a range of time series forecasting approaches for energy data that include classical statistical methods (ARIMA), gradient boosting-XGBoost, deep learning architectures (CycleNet, xLSTMTime), and the novel hybrid combinations proposed. Using a comprehensive dataset from the U.S. Energy Information Administration (125,000 records over two years), we implement and compare such models over several performance metrics. Our novel contribution is a weighted ensemble methodology that optimal combines deep learning and gradient boosting predictions. The proposed hybrid model combines XGBoost and LSTM predictions and therefore achieves a $\mathrm{R}^{2}$ score of 0.9842 (0.9821-0.9863), 5.3% improvements in RMSE compared to the isolated modeling and 3.7% over current benchmarks. This work further proves while deep learning is clearly adept at grasping temporal dependencies, gradient boosting brings a good deal to the picture when used in an integrated modality due to their multifactorial advantages. The applicability and practicability of hybrid models by means of a detailed analysis of computational efficiencies and deployment considerations.",10.1109/temsconglobal64363.2025.11238333,2025,,IEEE,10.1109/temsconglobal64363.2025.11238333
A Neural Network Architecture for Spatiotemporal PM2.5 Forecasting,"PM2.5 concentrations have been increasing at an alarming rate, making it critical to precisely estimate their regional and temporal distributions. The task is complicated by the non-linear property of PM2.5 and the large number of geological and climatic elements that influence PM2.5 concentrations, as well as the difficulty inherent in modelling their varying spatiotemporal association. Conventional physical and statistical forecasting techniques fail at incorporating several variables and discovering intricate correlations, essential for reliable predictions. This paper proposes a graph neural network capable of modelling PM2.5 concentrations on real-world data by leveraging PM2.5 transport, domain knowledge and considering spatial correlation, by reworking PM2.5 historical data, meteorological and weather forecast data into graph data and employing graph isomorphism networks, similar to the Weisfeiler Lehman graph isomorphism test for powerful graph representation learning, an attention mechanism, and a dedicated recurrent neural network to model temporal distributions, to provide accurate forecasting.",10.1109/ic3sis54991.2022.9885669,2022,,IEEE,10.1109/ic3sis54991.2022.9885669
Research on Financial Time Series Risk Assessment Model Based on Computer Deep Learning,"Financial risk assessment plays a crucial role in the financial market, as it enables risk quantification and management, further risk identification and warning, and provides reference for investment decision support and systematic risk prevention. In the current trend of big data, it has become possible to collect a large amount of financial time series data, which contains a lot of useful features that need to be mined and analyzed. Therefore, based on the research of multivariate financial time series, this article proposes a financial time series risk identification method based on GCN-LSTM-CLUSTING. Specifically, we perform patch segmentation on multivariate time series to extract relationships between different patch nodes using GCN, followed by extracting long time series dependencies using LSTM, and utilizing end-to-end regression models to extract features from small time series. Finally, clustering methods are used to cluster the potential features of the time series and identify anomalous financial time series. The experimental results show that the method proposed in this paper has a good recognition rate and can effectively identify abnormal financial time series.",10.1109/icmiii62623.2024.00088,2024,,IEEE,10.1109/icmiii62623.2024.00088
GRL-ITransformer: An Intelligent Method for Multi-Wind-Turbine Wake Analysis Based on Graph Representation Learning With Improved Transformer,"The importance of examining the wake effect of wind farms for optimizing their layout and augmenting their power generation efficiency is immense. Considering that the establishment of extensive wind farms often leads to a significant number of turbines being positioned downstream of preceding ones, it significantly diminishes their power generation efficiency. In our study, we propose a graph representation learning model with improved Transformer (GRL-ITransformer) to better integrate feature information, so that the model can capture the dynamic time relationship of different variables and establish its spatial relationship, striving to enhance the precision in predicting wind turbine wake field. Different from the previous way involving handling reduced-order and separating prediction process, we combine the reduced-order technique with the proposed model to make the model more efficiently and intelligently determine the number of modes required for model prediction. After that, the data driven method is employed to update the parameters, and the superiority of GRL-ITransformer is highlighted by analyzing and comparing with the existing five classical intelligent algorithms (belongs to four categories). The comprehensive results show that GRL-ITransformer has excellent performance in wind turbine wake field prediction and reconstruction, and always possesses the lowest error for a series of error evaluation indexes among all models.",10.1109/access.2025.3549035,2025,,IEEE,10.1109/access.2025.3549035
Empowering PHM Applications with Time Series Foundation Models: A Unified Multi-Task Learning Approach,"Currently, small, task-specific models dominate the development of Prognostics and Health Management (PHM) applications. However, these isolated models often struggle to address the diverse and fragmented requirements present in real industrial environments. The emergence of time-series foundation models has attracted considerable attention, providing a more flexible and effective approach for PHM applications. This study explores how time-series foundation models can enhance PHM applications. Using a typical aero-engine degradation dataset as the research context, we propose a novel unified multi-task learning approach that leverages pre-trained time-series foundation models. Specifically, we utilize these foundation models as the basis for time-series representation learning to tackle various PHM tasks. To accommodate the diverse requirements of these tasks, we design specialized output heads tailored for multi-task learning objectives. The pre-trained foundation model is then fine-tuned with specific datasets to develop localized task-specific models. We validate our approach through case studies using the C-MAPSS datasets. The experimental results demonstrate the feasibility and effectiveness of foundation models for the development of PHM applications.",10.1109/case58245.2025.11163911,2025,,IEEE,10.1109/case58245.2025.11163911
Earthquake Magnitude Prediction using Spatia-temporal Features Learning Based on Hybrid CNN- BiLSTM Model,"Earthquakes are a very catastrophic natural event that occurs due to sudden changes in the earth's crust, leading to human, financial, and environmental losses in society. Therefore, employing an efficient and dependable method for earthquake prediction can significantly reduce casualties. In this regard, we proposed a deep neural network called the hybrid convolutional neural network and bi-directional long-short-term memory (HC-BiLSTM) to predict the mean magnitude of the future earthquake in a specific area of Japan. To achieve this goal, we suggest a strategy based on four key steps: the division of areas, the preprocessing, the spatial and temporal feature learning, and the prediction. In the division of areas step, The part of Japan is divided into 49 smaller areas to better predict the next earthquake's location. The preprocessing step uses the zero-order hold method in the time series of the mean magnitude of the earthquake. In the next step, the learning spatial and temporal characteristics between earthquake data include three layers of CNN and pooling and two layers of LSTM. Finally, the prediction step has two fully connected layers that combine information supplied by HC-BiLSTMs to predict the mean magnitude for the earthquake next month. As a result, using a comparative method, this study demonstrates the superiority of the proposed method over other common earthquake prediction methods.",10.1109/icspis54653.2021.9729358,2021,12,IEEE,10.1109/icspis54653.2021.9729358
NRL4AQF: Noise-Resistant Learning for Long-Sequence Air Quality Forecasting using Cross-Time Embedding,"Recently, deep learning (DL) has greatly advanced data analysis, including time-series forecasting. Recurrent neural networks (RNNs) are commonly used for DL-based forecasting, but they face limitations in capturing complex, long-range dependencies, especially with cross-dimensional input data. To address these challenges, transformer-based architectures have been introduced, offering improved performance for long-range predictions. However, they still struggle with modeling long input sequences and managing noise in temporal feature learning. To overcome these issues, we propose the NRL4AQF (Noise-Resistant Learning for Air Quality Forecasting) model, a novel denoising transformer-based approach for time-series forecasting. By combining cross-dimensional transformer-based embeddings with a radial basis function neural network (RBFNN), NRL4AQF effectively reduces noise and captures more accurate temporal patterns. Applied to long-sequence air quality forecasting, the model achieves superior results compared to traditional and state-of-the-art DL techniques, as demonstrated by experiments on a real-world dataset.",10.1109/atc63255.2024.10908270,2024,1,IEEE,10.1109/atc63255.2024.10908270
Is Single Enough? A Joint Spatiotemporal Feature Learning Framework for Multivariate Time Series Prediction,"A fuzzy cognitive map (FCM) is a simple but effective tool for modeling and predicting time series. This article focuses on the problem of multivariate time series prediction (TSP), which is essential and challenging in data mining. Although several FCM-based approaches have been designed to solve this problem, their feature extraction module designed for single mode falls short in capturing the nonlinear spatiotemporal dependencies among variates, thereby resulting in low prediction accuracy in forecasting multivariate time series, which shows that the single mode learning is not enough. Therefore, in this article, we propose a joint spatiotemporal feature learning framework for multivariate TSP, where a mix-resolution spatial module consisting of multiple sparse autoencoders (SAEs) is designed to extract the feature series with different spatial resolutions, and a mix-order spatiotemporal module concluding multiple high-order FCMs (HFCMs) is designed to model the spatiotemporal dynamics of these feature series. Finally, the outputs of the two modules are concatenated to predict future values. We refer to this framework as the spatiotemporal FCM (STFCM). Especially, an efficient learning algorithm is designed to update the integral weights of STFCM based on the batch gradient descent algorithm when it deems necessary. We validate the performance of the STFCM on four real-world datasets. Compared with the existing state-of-the-art (SOTA) methods, the experimental results not only show the advantages of the two designed modules in the STFCM but also show the excellent performance of the STFCM.",10.1109/tnnls.2022.3216107,2024,14,IEEE,10.1109/tnnls.2022.3216107
A Survey on Time-Series Pre-Trained Models,"Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difficult due to data annotation costs. Recently, pre-trained models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Specifically, we first briefly introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments involving 27 methods, 434 datasets, and 679 transfer learning scenarios are conducted to analyze the advantages and disadvantages of transfer learning strategies, Transformer-based models, and representative TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future work.",10.1109/tkde.2024.3475809,2024,40,IEEE,10.1109/tkde.2024.3475809
CATS: Contrastive learning for Anomaly detection in Time Series,"Anomaly detection (AD) plays a critical role in a wide variety of big data applications, including cybersecurity, monitoring, and network systems. It consists in finding patterns in time series data that indicate unexpected events such as faults or defects. Traditional AD approaches, predominantly based on reconstruction techniques, often yield suboptimal performance, particularly when anomalies are present in the training set. Conversely, contrastive learning (CL) has shown significant performance in image processing tasks and is increasingly applied in time series data classification and forecasting. However, traditional CL frameworks are not well-adapted for time series AD due to two key challenges. First, AD is typically performed only on normal instances, and thus CL does not benefit from knowledge about anomalous instances. Second, the temporal nature of time series data is often neglected when computing time series similarity, thereby hindering the effective learning of time series representation.To overcome these limitations, we propose CATS, a novel approach that leverages a temporal similarity measure to learn time series representations. Moreover, through negative data augmentation, CATS generates a more realistic distribution of anomalies, which enables anomaly-informed CL. Extensive experiments conducted on six real-world datasets demonstrate that CATS outperforms existing AD methods. Our results highlight the efficacy of CATS in enhancing time series AD performance in big data environment across various application domains.",10.1109/bigdata62323.2024.10825476,2024,1,IEEE,10.1109/bigdata62323.2024.10825476
Intraday Wind Power Forecasting by Ensemble of Overlapping Historical Numerical Weather Predictions,"The numerical weather prediction (NWP) is crucial to improve intraday wind power forecasting (WPF) accuracy. However, conventional WPF methods relied solely on a latest reported single NWP, overlooking hidden information from sequentially reported multiple historical NWPs that are partially overlapped over time. Additionally, it's challenging to tackle intraday WPF as it involves both ultra-short-term and short-term horizons with different characteristics. Therefore, a novel spatio-temporal representation learning network is proposed for intraday WPF by ensemble of overlapping historical NWPs. Initially, an integrated mask-reconstruction representation learning pretraining strategy is employed to extract hidden representations of historical wind power measurements and overlapping historical NWPs, providing contextual information for the subsequent intraday WPF task. Then, the output layer is trained and end-to-end fine-tuning of the entire network is conducted to adapt to the specific forecasting task. Moreover, a multi-task learning strategy based on hard parameter sharing is adopted to ensure balanced predictive accuracy across each of forecasted wind farms. Case study and detailed ablation tests based on 5 real-world wind farms demonstrate that the proposed method enhances the forecasting accuracy of most wind farms by leveraging spatio-temporal correlation, achieving the best average performance across all time horizons compared to the baseline models.",10.1109/tste.2024.3521384,2025,2,IEEE,10.1109/tste.2024.3521384
Self-Supervised Generative Pre-Trained Model with a Learnable Mask Network for Industrial Time Series Prediction,"Industrial time series prediction (ITSP) is an indispensable part of predictive control in modern industry. Recently, supervised deep learning-based methods have provided solutions with sufficient annotated data. However, there is massive unlabeled data with complex temporal features in modern industrial production, resulting in poor performance of these methods. To address this problem, a self-supervised generative pre-trained model with a learnable mask network (SSGPM-LMN) is proposed in this paper. First, the multivariate time series are made into patches channel-independently. Then, these patches are fed into a Transformer encoder with the learnable mask-reconstruction paradigm, drawing mask indices with high temporal features by calculating the cosine similarity in low-dimensional feature space to better learn general representations. Furthermore, a two-step fine-tuning strategy, including linear probing and full fine-tuning, is adopted for various downstream scenarios. Finally, extensive experimental results on case studies of ITSP and transfer learning indicate that our SSGPM-LMN achieves superior performance.",10.1109/smc54092.2024.10831502,2024,,IEEE,10.1109/smc54092.2024.10831502
Self-Supervised Time Series Classification Method Based on FRFT Cross-Channel Fusion,"Recently, self-supervised representation learning has been widely applied to various time series tasks (e.g., electric device classification). However, building models for large-scale time series classification remains challenging due to the high cost of labeling time series data, which requires specialized expertise. Additionally, many datasets consist solely of unlabeled data or contain only a small number of labeled samples. Existing solutions for traditional time series tasks are not directly applicable to modern complex temporal problems due to two unique characteristics: (i) long-term temporal dependencies and (ii) complex cross-channel interactions. To address these challenges, we propose TC-FrC, a self-supervised time series classification model that leverages seasonal-trend decomposition for data augmentation and incorporates contrastive losses based on both temporal features and the Fractional Fourier Transform (FRFT). Specifically, we: (i) design a sparse attention mechanism within the temporal contrastive module to enhance feature extraction and improve robustness in long-term time series data, (ii) introduce a seasonal-trend decomposition approach to mitigate inter-class feature confusion, and (iii) develop a cross-channel FRFT-based feature fusion module, which transforms contextual features from the time domain to the fractional domain. We extensively evaluate TC-FrC on seven publicly available datasets, including HAR, Sleep-EDF, and Epilepsy, among others. Experimental results demonstrate that our method outperforms state-of-the-art baselines across various evaluation metrics.",10.1109/ijcnn64981.2025.11229038,2025,,IEEE,10.1109/ijcnn64981.2025.11229038
Adaptive Graph Convolution Neural Differential Equation for Spatio-Temporal Time Series Prediction,"Multivariate time series prediction has aroused widely research interests during decades. However, the spatial heterogeneity and temporal evolution characteristics bring much challenges for high-dimensional time series prediction. In this paper, a novel adaptive graph convolution module is introduced to automatically learn the spatial correlation of multivariate time series and a Koopman-based neural differential equation is proposed to simulate the nonlinear system state evolution. In detail, the correlation between multivariate time series is revealed by the consine similarity of node embedding to infer the potential relationship between nodes and the spatio-temporal feature fusion module is utilized. The LSTM-based network is adopted as Koopman operator to reveal the latent states of spatio-temporal time series and the reversible assumption is imposed on the Koopman operator. Furthermore, the Euler-trapezoidal integration are utilized to simulate the temporal dynamics and multiple-step prediction is carried out in the latent space from the perspective of dynamical differential equation. The proposed model could explicitly discover the spatial correlation by adaptive graph convolution and reveal the temporal dynamics by neural differential equation, which make the modeling more interpretable. Simulation results show the effectiveness on spatio-temporal dynamic discovery and prediction performance.",10.1109/tkde.2024.3383895,2025,3,IEEE,10.1109/tkde.2024.3383895
Research on Commodities Constraint Optimization Based on Graph Neural Network Prediction,"Business intelligence makes good sale prediction crucial in any commercial activity as it has a significant impact on production and supply plan. However, practical commercial data presents explicit constraints, that how to get the optimal forecasts of commodity sales under the constraints is a vital problem many researchers face. The present research proposes a prediction model which combines graph convolution neural network and node bipartite graph. Firstly, the node bipartite graph algorithm is used to merge the constraint graph and the store graph, obtaining the “store-constraint bipartite graph”. Secondly, a graph convolutional neural network integrating GRU and AR is utilized to extract temporal features (X). Finally, a fully connected network is applied to predict the optimal solution (Y) after constraint optimization. The former can effectively learn complex features of stores, meanwhile, the later combines the constraint conditions with the store, which can effectively predict the sales of goods under the constraint conditions. In terms of model performance, we compared the proposed model with the classical method such as SVR, LSTM, ARIMA. RMSE, MSE, MAE and MAPE are used for evaluation indexes, and the results show that MAPE for one month’s sales of some product from both datasets is 7.75%.",10.1109/access.2023.3302923,2023,1,IEEE,10.1109/access.2023.3302923
SMCL: Towards Semi-Supervised Automatic Modulation Recognition via Semantic Mask Contrastive Learning,"Automatic modulation recognition (AMR) is essential for ensuring the physical-layer security for Internet of things (IoT) networks. Despite advancements in deep learning, most current AMR methods rely heavily on a large number of labeled samples to achieve high recognition accuracy. However, acquiring labeled samples can be costly and impractical in many real-world scenarios due to privacy concerns and economic constraints. In contrast, unlabeled data is often abundant and readily available. This paper presents a novel semi-supervised AMR framework that addresses the challenge of label scarcity by leveraging semantic mask contrastive learning (SMCL). Through a self-supervised modulation semantic mask contrastive prediction task within IQ sequence, our method learns subtle modulation features directly from unlabeled radio signals. It is important to note that SMCL requires neither data augmentation nor representation domain transformation. Sufficient experiments on public datasets have demonstrated our method outperforms existing semi-supervised and supervised methods when using the same number of labeled samples. SMCL effectively enables the representation learning of unlabeled radio signals, overcoming the limitations posed by the lack of sufficient labeled data and providing a solid technical foundation for the development of signal-based IoT large language models (IoT-LLMs).",10.1109/jiot.2025.3630897,2025,,IEEE,10.1109/jiot.2025.3630897
A Multilevel Deep Fusion Framework for FeO Content Prediction in Sintering Process,"Iron ore sintering is a critical procedure in steel production, and the content of ferrous oxide (FeO) in the finished sinter directly reflects sintering quality. This key indicator is commonly obtained by data-driven soft sensor modeling technology. However, existing methods struggle to fully utilize the multisource and heterogeneous characteristics of the sintering dataset, and this may limit the improvement of FeO prediction accuracy. To address this issue, this paper proposes a multilevel deep fusion framework (MDFF) for detecting FeO content in the sintering process. This novel framework integrates a multilevel fusion of multisource heterogeneous data, i.e., data-level, feature-level, and decision-level. First, shallow features are extracted from images based on expert experience for data-level fusion. Then, multiscale encoding network and shared representation learning network are used for feature extraction and fusion. Finally, the prediction results of shared representations and modality-specific features are combined at the decision level to realize real-time sensing of FeO content. The proposed MDFF fully exploits the intrinsic correlations between multisource information at multiple levels, and experimental results on real sintering datasets further prove its accuracy and stability.",10.1109/cac63892.2024.10864891,2024,,IEEE,10.1109/cac63892.2024.10864891
Energy usage prediction with ensemble graph convolutional recurrent neural networks: case study of Greek islands,"This study investigates the use of graph convolutional and recurrent neural networks to forecast energy consumption on five Greek islands. The model is trained on historical energy usage data, using graph convolutional networks (GCNs) with graphs constructed from power production and their geographical location which their results are averaged. The evaluation metrics mean absolute error (MAE), mean squared error (MSE), and mean absolute percentage error (MAPE) were utilised to measure the accuracy of the proposed prediction algorithms. The results show that all the suggested EGCRNN models with LSTM, Bi-LSTM, and GRU demonstrated excellent performance, strong model fit, and enhanced predictions of energy consumption. In particular, models which utilise long-short term memory (LSTM) and gated recurrence units (GRU) followed with better prediction in one model each, Thira and Rhodes, respectively.",10.1049/icp.2024.4680,2024,,IEEE,10.1049/icp.2024.4680
Multi-attention based Feature Embedding for Irregular Asynchronous Time Series Modelling,"Forecasting time series values based on historic covariates has been an active area of research in statistics and machine learning. With the availability of computation resources and big data infrastructure supporting massive volume, velocity and variety, the algorithms have evolved from classic statistical learning to neural-network driven loss minimisation techniques. While state of the art attention and self-attention-transformers have shown promise of improved performance with sufficient training data, most of them fail to generalise to different problems of time-series modelling (such as classification and extremum forecasting) with asynchronously sampled covariates. This paper introduces the concept of a generalised time series embedding and transfer learning for time series (analogous to token-to-vector or image-to-vector embeddings in language and vision models respectively) that allow joint training with a unified interface. The major benefit of this work is a unified embedding model employing multi-attention for feature representation which enables benchmark performance against state of the art models from recent literature.",10.1109/iecon51785.2023.10312633,2023,,IEEE,10.1109/iecon51785.2023.10312633
Kolmogorov—Arnold Networks: Overview of Architectures and Use Cases,"Kolmogorov-Arnold Networks (KANs) are an emerging class of neural network architectures grounded in the Kolmogorov-Arnold representation theorem, offering a sym-bolic and interpretable approach to modeling complex, high-dimensional functions. By replacing traditional activation functions with learnable univariate splines, KANs deliver enhanced expressiveness, parameter efficiency, and transparency. This survey provides a comprehensive overview of KAN developments, including foundational designs and specialized variants tailored to time series, graphs, scientific computing, image analysis, and biomedicine. We highlight the strengths of KANs in bridging the gap between symbolic reasoning and data-driven learning, while also discussing challenges such as computational overhead and spline optimization complexity. Through detailed architec-tural taxonomy and real-world application examples, this paper positions KANs as a compelling framework for interpretable, high-performance machine learning.",10.1109/iccsc66714.2025.11135248,2025,,IEEE,10.1109/iccsc66714.2025.11135248
AI-based Gas Turbine Multi-Component Health Prognosis via Recurrent Expansion of Gas Path Parameters,"Investigating Gas Turbine (GT) degradation based on Gas Path Parameters (GPPs) is essential for its maintenance and operation. Monitoring GPPs is crucial for early detection of degradation, enabling timely maintenance interventions and preventing potential failures. Integrating physics-based thermodynamic models with representation learning significantly improves predictive maintenance studies and provides a solution to challenges posed by expensive and impractical accelerated aging experiments. However, this integration also presents challenges in managing both data complexity and data drift. In this context, this article aims to address these gaps by extending and improving previous research through (i) exclusive use of GPPs; (ii) the implementation of advanced data preprocessing techniques; and (iii) the use of innovative representation learning strategies. Specifically, it introduces ProgMachina, a tool for data quality analysis in prognosis studies that addresses issues related to data complexity in GPPs. Furthermore, to diversify the feature space and improve the adaptability of representation learning to degradation patterns, this paper proposes using Multiverse Recurrent Expansion with Multiple Repeats (MV-REMR) approach, which is based on a series of Recurrent Neural Networks (RNNs). For evaluation, this study incorporates cross-validation and multiple metrics while comparing against multiple RNNs and state-of-the-art works, demonstrating stable and promising performance, making it a suitable choice for GT prognosis tasks.",10.1109/iccad60883.2024.10554011,2024,2,IEEE,10.1109/iccad60883.2024.10554011
Multivariate Time-Series Anomaly Detection Based on Dynamic Graph Neural Networks and Self-Distillation in Industrial Internet of Things,"Time-series anomaly detection is critical to securing the Industrial Internet of Things (IIoT). Although numerous deep learning-based methods have been proposed, these methods fail to consider the interdependencies between different dimensions of the data and often neglect the dynamic changes in these dependencies. Moreover, these methods utilize only the global features from the last layer of the network for anomaly detection. However, local features can capture subtle variations in the data, which are crucial for accurately detecting anomalies. To alleviate these problems, this article proposes a novel framework for detecting time-series anomalies, including four parts, namely, the graph structure learning module, the dynamic graph module, the anomaly scoring module, and the self-distillation. The graph structure learning module generates different graph structures based on the inputs, which will be used in the dynamic graph module. The dynamic graph module employs dynamic graph neural networks to capture the complex relationships within time series from both temporal and spatial dimensions. The anomaly scoring module obtains anomaly scores from predictions and observed values, and the model makes anomaly judgments based on these scores. Additionally, self-distillation enhances model performance by utilizing mutual learning between the teacher and student models, thereby integrating local and global information for better anomaly detection. We carry out a series of experiments on IIoT datasets, which verify the performance of the framework. The experimental results of the proposed method outperform other methods, demonstrating the advantage of our framework.",10.1109/jiot.2024.3520362,2025,2,IEEE,10.1109/jiot.2024.3520362
Medium-Term Jointly Load Forecasting via an Enhanced KAN-Based MTL Framework,"Electricity load forecasting involves predicting future power demand based on historical data and related factors. Accurate forecasting is crucial for energy distribution and system management. This study introduces a novel multi-task learning (MTL) framework that integrates Kolmogorov-Arnold Networks (KAN) with a multi-head self-attention (MHSA) with a both hard and soft parameter sharing strategy to effectively merge different types of inputs for joint load forecasting. The KAN layer is tasked with cross-feature learning and output fitting while the MHSA mechanism captures the temporal information from multiple perspectives, aiming to facilitate comprehensive nonlinear feature learning. Experimental results show that the proposed method can attains better forecasting accuracy, with an average mean absolute percentage error of 3.842% for 10-day medium-term forecasts.",10.1109/appeec61255.2024.10922466,2024,,IEEE,10.1109/appeec61255.2024.10922466
The New Abnormal: Network Anomalies in the AI Era,"Anomaly detection aims at finding unexpected patterns in data. It has been used in several problems in computer networks, from the detection of port scans and distributed denial‐of‐service (DDoS) attacks to the monitoring of time series collected from Internet monitoring systems. Data‐driven approaches and machine learning have seen widespread application on anomaly detection too, and this trend has been accelerated by the recent developments on Artificial Intelligence (AI) research. This chapter summarizes ongoing recent progresses on anomaly detection research. In particular, we evaluate how developments on AI algorithms bring new possibilities for anomaly detection. We cover new representation learning techniques such as Generative Artificial Networks and Autoencoders, as well as techniques that can be used to improve models learned with machine learning algorithms, such as reinforcement learning. We survey both research works and tools implementing AI algorithms for anomaly detection. We found that the novel algorithms, while successful in other fields, have hardly been applied to networking problems. We conclude the chapter with a case study that illustrates a possible research direction.",10.1002/9781119675525.ch11,2021,,IEEE,10.1002/9781119675525.ch11
Vector Representation and Machine Learning for Short-Term Photovoltaic Power Prediction,"Short-term photovoltaic (PV) energy production forecasting is critical for managing grid-connected systems and energy trading. Machine learning models are widely used for accurate prediction, and this study proposes using Time2Vec as an embedding for a transformer-based neural network architecture. Experiments on two PV power plants in India showed significant improvements comparing our proposed architecture to MLP, LSTM, and the persis-tence model, which is a standard baseline prediction in this type of forecasting, with over 20 % improvements in some horizons. These findings demonstrate the effectiveness of the proposed approach for short-term PV forecasting using machine learning models.",10.1109/smc53992.2023.10394456,2023,3,IEEE,10.1109/smc53992.2023.10394456
Anomaly detection for steam turbine based on dual-attention autoencoder,"Anomaly detection plays an essential role in routine operation and maintenance of steam turbine. Due to vague parameter correlation, various working condition, and nonstationary industry process, there still remain challenges in building representation models to detect abnormal working condition accurately and sensitively. To alleviate this problem, this paper proposes an autoencoder(AE) approach with dual-attention mechanism, including parameter attention and temporal attention, to learn data distribution under the normal working condition. In dual-attention mechanism, parameter attention mechanism exerts varying weight to parameters referring to their current significance, and temporal attention mechanism improves information integration by utilizing the hidden state of gated recurrent unit(GRU) cells. Based on the output of AE, box-cox transformation and three-sigma rule of thumb determine the dynamic threshold. The proposed approach is evaluated through experiments on steam turbine from a real case. The experiment result demonstrates it outperforms the state-of-the-art baselines for advanced alarm time and better stability.",10.1049/icp.2022.3129,2022,,IEEE,10.1049/icp.2022.3129
Learning Low-Dimensional Representation for O-RAN Testing via Transformer-ESN,"Open Radio Access Network (O-RAN) architectures enhance flexibility for 6G and NextG networks. However, it also brings significant challenges in O-RAN testing with evaluating abundant, high-dimensional key performance indicators (KPIs). In this paper, we introduce a novel two-stage framework to learn temporally-aware low-dimensional representations of O-RAN testing KPIs. To be specific, stage one employs an information-theoretic H-score to train a hybrid self-attentive transformer and echo state network (ESN) reservoir, called Transformer-ESN, capturing temporal dynamics and producing task-aligned 8-dimensional embeddings. Stage two evaluates these embeddings by training a lightweight multilayer perceptron (MLP) predictor exclusively on them for key target KPIs such as reference signal received quality (RSRQ) and spectral efficiency. Using real-world O-RAN testbed data (video streaming with interference), our approach demonstrates a significant advantage specifically when training samples are very limited. In this scenario, the low-dimensional representations learned from the Transformer-ESN yield mean square error (MSE) reductions of up to 41.9% for RSRQ and 29.9% for spectral efficiency compared to predictions from the original high-dimensional data. The framework exhibits high efficiency for O-RAN testing, significantly reducing testing complexities for O-RAN systems.",10.1109/mass66014.2025.00030,2025,1,IEEE,10.1109/mass66014.2025.00030
Attack Detection and Location Using State Forecasting in Multivariate Time Series of ICS,"ICS (industrial control systems) security researches have paid a great effort on anomaly detection base on the analyzes of communication protocols, network dataflow, sensor time series. However, few research have been done to recognize cyber attacks as well as the localization, which make active security control impossible. Actually, to recognize cyber attacks is crucial for ICS security control. In this paper, we proposed a novel multivariate time series attack detection and location framework based on adaptive state space formulation and forecasting. To dynamically describe systems' state transition characteristics, a graph structure learning scheme was designed based on Attention mechanism. Furthermore, to achieve state forecasting of systems, an improved Kalman filter with Transformer mechanism was proposed. Experiments on datasets from real industrial scenario demonstrated the effectiveness, and proved that the proposed method achieved higher location accuracy than the state-of-the-art methods.",10.1109/tnse.2025.3555764,2025,,IEEE,10.1109/tnse.2025.3555764
WirMAE: Learning Well-Logging Interval Representations via Masked Autoencoders for Gas Hydrate Reservoir Characterization,"Reservoir characterization (identification and parameter estimation) is critical for gas hydrate exploration and development. While machine learning (ML) techniques excel at capturing complex relationships in well-logging reservoir characterization, existing research mainly focuses on end-to-end supervised learning approaches relying on costly labeled data and lacking multitask learning capabilities. In this article, we introduce a self-supervised learning (SSL) framework to learn general representations of large-scale unlabeled Well-Logging Interval Representations via Masked Autoencoders (WirMAE). By incorporating channel-based attention mechanisms and a masked reconstruction pretraining strategy for variable tokens, WirMAE effectively extracts intrinsic multivariate correlations within logging data, enabling the generation of various missing log curves. The model is validated on data from globally distributed hydrate with diverse accumulation patterns. Compared to supervised deep learning methods and classical ML models, fine-turned WirMAE achieves superior reservoir identification accuracy (average  $F1$ -score: 0.864) using only 1% labeled data in complex geological settings. Combined with domain expertise, WirMAE yields precise estimation of key reservoir parameters such as hydrate saturation and permeability, outperforming conventional petrophysical methods. Additionally, embedding visualizations and attention analyses reveal the inner workings of the model and its consistency with expert-driven geological interpretations. Our findings highlight the potential of SSL for advancing more accurate and transparent intelligent reservoir characterization using well-log data, indicating that the application of WirMAE could be extended to broader hydrocarbon reservoirs in the future.",10.1109/tgrs.2025.3577988,2025,,IEEE,10.1109/tgrs.2025.3577988
A causal graph-based framework for satellite health monitoring,"In satellite operations, one of the essential tasks is to monitor the health status of the systems, which involves forecasting telemetry data that reflects the state of health. The application of data-driven approaches in system monitoring has led to significant improvements in health monitoring and anomaly detection. However, existing methods fail to fully leverage the complex inter-sensor relationships present in satellites. They do not explicitly exploit the structure of these relationships to predict the expected behavior of telemetry time series either. To address these limitations, this paper introduces a novel health monitoring framework for artificial satellites that combines causal graphs and deep learning. In the causality learning phase, we propose a method that integrates mRMR (Maximum Relevance Minimum Redundancy) and PCMCI (Peter-Clark Momentary Conditional Independence) to construct an efficient and accurate causal discovery approach for learning causal graphs for high-dimensional telemetry data. Subsequently, we design a graph attention-based neural network that incorporates these causal graphs into a deep network for prediction. Experimental evaluation on two datasets from satellite attitude control systems and power systems demonstrates the superior performance of our proposed method in accurately predicting health status compared to baseline approaches. Furthermore, the experiments highlight the interpretability-enhancing role of causal graphs, which is beneficial for health monitoring and anomaly detection.",10.1109/icphm57936.2023.10194125,2023,,IEEE,10.1109/icphm57936.2023.10194125
Deep Collaborative Intelligence-Driven Traffic Forecasting in Green Internet of Vehicles,"Accompanied with the development of green wireless communication, the green Internet of Vehicles (GIoV) has been a latent solution for future transportation. Among them, intelligent traffic forecasting for key nodes in GIoV is a significant research topic. Much research had been devoted to this issue, and graph learning-based approaches seemed to be a promising solution. However, existing research works concentrated more on graph-structured features in GIoV yet neglected global reliability. To deal with such issue, this work combines both deep embedding and graph embedding together and proposes a deep collaborative intelligence-driven traffic forecasting model in GIoV. By establishing more reliable feature spaces for traffic flow prediction, forecasting efficiency is expected to be promoted. Specifically, deep embedding is utilized to generate more abstract representation for basic features of road networks, and graph embedding is employed to update feature representation for different timestamps. Their collaboration contributes to considerable reliability. In addition, experiments are also conducted on a real-world dataset, and the results indicate that forecasting deviation receives about 15%-25% reduction.",10.1109/tgcn.2022.3193849,2023,62,IEEE,10.1109/tgcn.2022.3193849
Anomaly Detection for Small Hydropower Based on Deep Spatio-Temporal Modeling,"Anomaly detection in small hydropower plays a crucial role in small hydropower data-driven condition monitoring systems, contributing to improved equipment durability and reduced operational and maintenance expenses. Benefiting from advancements in the industrial internet, various sensors in small hydropower stations generate co-evolving time-series data with distinct characteristics at any given moment, which are recorded in the small hydropower condition monitoring system. The joint modeling of variable associations and temporal dependencies in small hydropower multivariate time-series data presents significant challenges for anomaly detection tasks. This study characterizes the complex relationships within small hydropower data as a combination of temporal dependencies and inter-feature correlations. To address these, it introduces a novel anomaly detection framework for multivariate time series, integrating adaptive graph structure learning, graph attention mechanisms, and temporal feature pyramid networks to effectively capture spatiotemporal dependencies. The proposed method aims to dynamically capture the most significant relationships, enabling timely detection of potential anomalies for more reliable small hydropower station monitoring. Experimental results on real-world sensor datasets from small hydropower stations show that the proposed method outperforms traditional approaches in anomaly detection, with superior capability in modeling the spatiotemporal dependencies inherent in multivariate time-series data.",10.1109/icmtim65484.2025.11040954,2025,,IEEE,10.1109/icmtim65484.2025.11040954
TransGlow: Attention-augmented Transduction model based on Graph Neural Networks for Water Flow Forecasting,"The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control. However, the task is difficult due to the dynamic nature and limited data of water systems. Highly interconnected water systems can significantly affect hydrometric forecasting. Consequently, it is crucial to develop models that represent the relationships between other system components. In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction. Existing methods are unable to model the influence of adjacent regions between pairs of variables. In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism. The attention layer allows the decoder to access different parts of the input sequence selectively. Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data. Spatiotemporal forecasting relies on historical data. In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions. Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes. Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin.",10.1109/icmla58977.2023.00092,2023,3,IEEE,10.1109/icmla58977.2023.00092
Time Series Prediction Problems Under Covariate Drift,"In the real world, time series data are ubiquitous, and the prediction task of time series data is very important. Most real-world time series data do not satisfy the assumption of independent and identical distribution (i.i.d.) due to environmental changes, that is, the distribution of the training datasets is different from the distribution of the test datasets, $P(X_{i})= P(X_{j})$, but the conditional distribution is usually considered to be unchanged, $P(y\vert x_{i})= P(y\vert x_{j})$. In this case, it is defined as covariate drift. However, most of the existing prediction algorithms are based on the assumption of i.i.d., so these algorithms have great limitations in the prediction of time series data under covariant drift. Therefore, the AEIF-MLP model is proposed, a time series data prediction model based on MLP and causal structures. The model mainly consists of two modules. Based on the principle of maximum entropy, we propose an adaptive environment segmentation module to separate different environments in the training datasets. Based on the causal structure, we propose an invariant feature learning module to learn common invariant features in different environments to train the model to deal with test datasets of unknown distribution. In summary, this method solves the problem of time series prediction under covariate drift. The validity of the model is verified by drift data sets in different environments for the first time, and the validity of the model is further verified on two real data sets.",10.1109/ddcls61622.2024.10606927,2024,,IEEE,10.1109/ddcls61622.2024.10606927
Online Topology Identification of Higher-Order Cell Structures,"Topology identification in cellular complexes is a central challenge in Topological Signal Processing, yet existing methods face major limitations: they fail to generalize to graph learning and inadequately capture the connectivity patterns of cellular complexes. Moreover, most approaches are limited to offline learning with batch data, restricting their applicability in dynamic or non-stationary data environments. We propose a unified framework that explicitly distinguishes between simple and general cycles, enabling seamless generalization across graphs, simplicial complexes, and cellular complexes. Our framework also bridges offline and online learning through a state-space formulation. Based on this, we introduce an online topology identification algorithm and demonstrate its effectiveness through preliminary experiments on synthetic datasets.",10.1109/mlsp62443.2025.11204205,2025,,IEEE,10.1109/mlsp62443.2025.11204205
Forecasting Application Counts in Talent Acquisition Platforms: Harnessing Multimodal Signals using LMs,"As recruitment and talent acquisition have become more and more competitive, recruitment firms have become more sophisticated in using machine learning (ML) methodologies for optimizing their day to day activities. But, most of published ML based methodologies in this area have been limited to the tasks like candidate matching, job to skill matching, job classification and normalization. In this work, we discuss a novel task in the recruitment domain, namely, application count forecasting, motivation of which comes from designing of effective outreach activities to attract qualified applicants. We show that existing auto-regressive based time series forecasting methods perform poorly for this task. Henceforth, we propose a multimodal LM-based model which fuses job-posting metadata of various modalities through a simple encoder. Experiments from large real-life datasets from CareerBuilder LLC show the effectiveness of the proposed method over existing state-of-the-art methods.",10.1109/bigdata62323.2024.10825459,2024,,IEEE,10.1109/bigdata62323.2024.10825459
Graph-Time Convolutional Neural Networks: Architecture and Theoretical Analysis,"Devising and analysing learning models for spatiotemporal network data is of importance for tasks including forecasting, anomaly detection, and multi-agent coordination, among others. Graph Convolutional Neural Networks (GCNNs) are an established approach to learn from time-invariant network data. The graph convolution operation offers a principled approach to aggregate information and offers mathematical analysis by exploring tools from graph signal processing. This analysis provides insights into the equivariance properties of GCNNs; spectral behaviour of the learned filters; and the stability to graph perturbations, which arise from support perturbations or uncertainties. However, extending the convolutional learning and respective analysis to the spatiotemporal domain is challenging because spatiotemporal data have more intrinsic dependencies. Hence, a higher flexibility to capture jointly the spatial and temporal dependencies is required to learn meaningful higher-order representations. Here, we leverage product graphs to represent the spatiotemporal dependencies in the data and introduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled architecture. We also introduce a parametric product graph to learn the spatiotemporal coupling. The convolution principle further allows a similar mathematical tractability as for GCNNs. In particular, the stability result shows GTCNNs are stable to spatial perturbations. owever, there is an implicit trade-off between discriminability and robustness; i.e., the more complex the model, the less stable. Extensive numerical results on benchmark datasets corroborate our findings and show the GTCNN compares favorably with state-of-the-art solutions. We anticipate the GTCNN to be a starting point for more sophisticated models that achieve good performance but are also fundamentally grounded.",10.1109/tpami.2023.3311912,2023,16,IEEE,10.1109/tpami.2023.3311912
Attention-Based Deep Learning Model for Prediction of Major Adverse Cardiovascular Events in Peritoneal Dialysis Patients,"Major adverse cardiovascular events (MACE) encompass pivotal cardiovascular outcomes such as myocardial infarction, unstable angina, and cardiovascular-related mortality. Patients undergoing peritoneal dialysis (PD) exhibit specific cardiovascular risk factors during the treatment, which can escalate the likelihood of cardiovascular events. Hence, the prediction and key factor analysis of MACE have assumed paramount significance for peritoneal dialysis patients. Current pathological methodologies for prognosis prediction are not only costly but also cumbersome in effectively processing electronic health records (EHRs) data with high dimensionality, heterogeneity, and time series. Therefore in this study, we propose the CVEformer, an attention-based neural network designed to predict MACE and analyze risk factors. CVEformer leverages the self-attention mechanism to capture temporal correlations among time series variables, allowing for weighted integration of variables and estimation of the probability of MACE. CVEformer first captures the correlations among heterogeneous variables through attention scores. Then, it analyzes the correlations within the time series data to identify key risk variables and predict the probability of MACE. When trained and evaluated on data from a large cohort of peritoneal dialysis patients across multiple centers, CVEformer outperforms existing models in terms of predictive performance.",10.1109/jbhi.2023.3338729,2024,5,IEEE,10.1109/jbhi.2023.3338729
Cloudformer: Contrastive Learning Based Cloud Workload Prediction,"During the last 3 years, researchers have endeavored to extend the efficacy of contrastive learning (CL) towards addressing the challenges inherent in cloud workload prediction, which has demonstrated considerable success in the domains of Computer Vision (CV) and Natural Language Processing(NLP). However, due to the distinctive temporal characteristics of serialized workload information, relying solely on empirical guidance from other domains may prove insufficient for cloud workload prediction. Therefore, we systematically investigated three key components of CL, including: 1) designing backbone encoder for feature extraction, 2) designing methods for extracting negative samples for contrast, and 3) designing the CL loss. We found that inappropriate construction of negative samples may introduce excessive pseudo-negative samples, which neither preserve temporal characteristics nor provide sufficient discriminative features. Additionally, focusing solely on the discrimination between positive and negative samples in the CL loss may not be adequate for enabling the model to learn the temporal patterns of serialized workload information. To address these problems, we propose a novel self-supervised model named Cloudformer. Specifically, we first constructed a CL network based on the Transformer architecture using a pre-train-finetune framework. Following this, we proposed a method to filter pseudo-negative samples based on differential cosine similarity, aimed at assisting the model in more effectively distinguishing between positive and negative samples. Additionally, we introduced the BatchNCE loss, combining MSE loss with InfoNCE loss as a joint optimization objective for CL, effectively enhancing the predictive capability of the model. The experimental results indicate that Cloudformer is capable of learning high-quality patterns in serialized workload sequences and achieves more advanced performance in short sequence prediction tasks.",10.1109/icet61945.2024.10672804,2024,1,IEEE,10.1109/icet61945.2024.10672804
Causality-Aware Multi-Graph Convolutional Networks With Critical Node Dynamics for Electric Vehicle Charging Station Load Forecasting,"Accurately forecasting the load of electric vehicle charging stations (EVCSs) is crucial for optimizing grid operations and facilitating EV integration, yet existing methods struggle to capture the intricate spatio-temporal dependencies and the impact of influential EVCSs within charging networks. To address this, we propose a novel framework, Causality-Aware Dynamic Multi-Graph Convolutional Network (CADGN), a multi-graph convolutional network that integrates causal inference and critical node modeling. It consists of two core modules: the Causality-Aware Graph Learning Module (CAGLM) uncovers and represents causal relationships between EVCSs, while the Critical Relationship Graph Learning Module (CRGLM) dynamically models the evolving connections among critical EVCS nodes. Temporal patterns extracted from these modules are then fused to generate accurate load predictions. Extensive experiments using real-world datasets of hourly charging data from multiple cities demonstrate CADGN’s superiority over state-of-the-art EVCS load forecasting models, particularly for short-term and mid-term horizons. Notably, our model achieves an average 4.7% reduction in Mean Absolute Error (MAE) compared to Graph WaveNet across all datasets and prediction horizons, highlighting the practical benefits of considering both causal and critical relationships for enhanced grid operations and EV integration. These results emphasize the importance of incorporating causality and the identification of critical relationships in the EVCS load forecast to achieve higher accuracy.",10.1109/tsg.2025.3570955,2025,1,IEEE,10.1109/tsg.2025.3570955
Knowledge Base-Guided Modeling of ICS Device Behavior for Status Prediction,"Predicting device status in Industrial Control Systems (ICS) is important for ensuring operational efficiency and preventing costly failures. Traditional univariate forecasting models grapple with the complexities inherent in multivariate time series data characterized by high interdependencies among devices. This study pioneers a novel methodology, which can fuse of linear model principles with graph embedding techniques (GCNs), for device behavior modeling. Specifically, we innovatively establish a device behavior knowledge base and exploits graph embedding algorithms to decipher both the spatial-temporal intricacies and underlying correlations embedded within extensive sensor data collections. The behavior knowledge base employs statistical methodologies like Pearson correlation to derive an adjacency matrix, which can facilitate the model’s realization of the static structure and dynamic interaction of device features. Moreover, to enhance predictive precision, we synthesize the strengths of linear model interpretations with the nuanced insights derived from graph-based feature learning. GCNs, serving as the backbone for learning sophisticated inter-device relations within this knowledge base, significantly influence the efficacy of device status prediction. Linear models are strategically utilized to distill time-dependent features from individual device sequences, overcoming scalability limitations associated with Recurrent Neural Networks (RNNs) when handling extended observation periods. Extensive experiments on real word dataset are conducted to validate our model’s performance. Experimental results illustrate that the proposed method achieves high performance on status prediction of ICS device.",10.1109/dsc63484.2024.00081,2024,,IEEE,10.1109/dsc63484.2024.00081
A Dynamic Evolving Fuzzy System for Streaming Data Prediction,"This article proposes a dynamic evolving fuzzy system (DEFS) for streaming data prediction. DEFS utilizes the enhanced data potential and prediction errors of individual local models as the main criteria for fuzzy rule generation. A vital feature of the proposed system is its novel rule merging scheme that can self-adjust its tolerance toward the degree of similarity between two similar fuzzy rules according to the size of the rule base. To better handle the shifts and drifts in the data patterns, a novel rule quality measure based on both the utility values and the prediction accuracy of individual fuzzy rules is further introduced to help DEFS identify these less activated fuzzy rules with poorer descriptive capabilities and, thereby, maintaining a healthier fuzzy rule base by removing these stale rules. Very importantly, the thresholds used by DEFS are self-adaptive toward the input data. The adaptive thresholds can help DEFS to precisely capture the underlying structure and dynamically changing patterns of streaming data, enabling the system to perform accurate approximation reasoning. Numerical examples based on several popular benchmark problems show the superior performance of DEFS over the state-of-the-art evolving fuzzy systems. The prediction performance of the proposed method is at least 2.88% better than the best-performing comparative EFSs on each individual regression benchmark problem considered in this study, and the average performance improvement across all the numerical experiments is approximately 30%.",10.1109/tfuzz.2024.3395643,2024,22,IEEE,10.1109/tfuzz.2024.3395643
Remaining Useful Life Prediction for Bearings Based on Generative Pretrained Transformer,"Accurate prediction of bearing remaining useful life (RUL) is crucial for ensuring the safe operation of critical equipment. To address the limitations of existing methods, including insufficient generalization capability caused by reliance on single datasets and increased deployment costs due to the requirement for customized prediction heads for different operating conditions, a novel solution is proposed in this paper. Specifically,mixed dataset pre-training dataset is constructed to expand the training scale, enabling the model to learn more generalizable degradation trend representations. Meanwhile, a multi-scale transformer architecture integrated with autoregressive decoding is adopted, where hierarchical temporal feature extraction and iterative residual learning are synergistically optimized to achieve progressive refinement of prediction results. Experimental results demonstrate that the proposed method significantly outperforms baseline models in both prediction accuracy and robustness, with the RMSE metric being reduced by $8.6 \%$ (reaching 0.0317) compared to the suboptimal PatchTST model, while the MAE metric is decreased by $\mathbf{4 9. 9 \%}$ (optimized to $\mathbf{0. 0 2 4 6}$) relative to conventional Transformer architectures.",10.1109/icbdse65491.2025.11220134,2025,,IEEE,10.1109/icbdse65491.2025.11220134
Towards Spatio-Temporal Aware Real Location Restoration for Signaling Data,"This study introduces the novel problem of Real Location Restoration, aimed at reconstructing accurate user trajectories from the coarse-grained mobile signaling data. To tackle this problem, we propose the Spatio-Temporal Aware framework for Signaling Data (STASD), a pioneering approach that encodes the complex spatiotemporal relationships of cellular trajectories. Leveraging a unique global transition graph, STASD captures high-order spatial relationships to effectively mitigate the Ping Pong Effect, a common issue in signaling data analysis. Our extensive experiments showcase the framework’s capability to accurately restore real-world trajectories, significantly advancing the field of mobile data analysis by providing a novel method to interpret and utilize signaling data for detailed location insights.",10.1109/yac63405.2024.10598525,2024,,IEEE,10.1109/yac63405.2024.10598525
Advanced Learning Techniques for Short-Term Atmospheric Predictions: An Overview,"Atmospheric Prediction is a complex task influenced by various factors such as temperature, pressure, air movement, moisture, and the earth’s rotation. Achieving accurate forecasts with high geographical resolution poses significant challenges, requiring substantial computational resources. This study focuses on nowcasting meteorological radar images. Deep learning has emerged as a promising approach for unsupervised representation learning, with next-frame prediction being a particularly intriguing research area in computer vision. This approach involves predicting future images based on prior image information, with applications ranging from robot decision-making to autonomous driving. This review presents the latest advancements in next-frame prediction networks specifically tailored for atmosphere data nowcasting. These networks can be categorized into two main approaches: Machine Learners and deep learners. The study comprehensively analyzes and compare various strategies based on their advantages and limitations, highlighting the benefits and drawbacks of each method. Additionally, potential research directions that hold promise for future investigations in this field are discussed. By identifying the most significant challenges and opportunities, the study aims to inspire further advancements in deep learning methods for atmosphere data nowcasting. Overall, this study provides a comprehensive overview of the current state-of-the-art deep learning techniques for nowcasting atmosphere data, shedding light on their potential applications and suggesting avenues for future research.",10.1109/icacrs58579.2023.10405022,2023,,IEEE,10.1109/icacrs58579.2023.10405022
CGF: A Category Guidance Based PM$_{2.5}$ Sequence Forecasting Training Framework,"PM$_{2.5}$2.5 concentration forecasting is important yet challenging. First, complicated local fluctuations in PM$_{2.5}$2.5 concentrations disturb modeling global trends. Second, forecasting errors are often accumulated through an autoregressive process. To contend with the two challenges, we propose a Category Guidance based PM${_{2.5}}$2.5 sequence Forecasting training framework (CGF) to enhance the performance of existing PM${_{2.5}}$2.5 concentration forecasting models. CGF contains a Category based Representation Learning (CRL) module and a Category based Self-paced Learning (CSL) module, both of which utilize PM${_{2.5}}$2.5 category information that is easily obtained and publicly available. First, CRL employs category information to guide forecasting models to produce more robust hidden representations that are insensitive to local fluctuations, thus alleviating the negative impact of local fluctuations. Second, CSL adaptively selects real PM${_{2.5}}$2.5 concentration values versus autoregressive PM${_{2.5}}$2.5 forecast values when training forecasting models, helping alleviate error accumulations. The CGF framework is applied to existing PM${_{2.5}}$2.5 forecasting models, and the experimental results on two real-world datasets demonstrate that CGF is able to consistently improve the accuracy of existing forecasting models. Furthermore, to validate the generality of CGF, we conduct extensional experiments in two other time-series prediction tasks, including exchange rate forecasting and electricity forecasting. The experimental results also verify the effectiveness of CGF.",10.1109/tkde.2023.3253703,2023,6,IEEE,10.1109/tkde.2023.3253703
AI Algorithms in Networks,"This chapter presents the application of diverse machine learning (ML) techniques in various key areas of networking across different network technologies. It considers a heterogeneous network with base stations, small base stations, and users distributed according to independent Poisson point processes. The chapter presents different aspects of using ML algorithms for self‐organizing cellular networks. It discusses the data sources and strong drivers for the adoption of the data analytics, and the role of ML and artificial intelligence in making the system intelligent with regard to being self‐aware, self‐adaptive, proactive, and prescriptive. The chapter also discusses a topology‐aware, dynamic, and autonomous system for managing resources in network function virtualization based on the concept of graph neural networks. The chapter also considers network slicing in a more complex setup. Network representation learning aims to learn latent, low‐dimensional representations of network vertices, while preserving network topology structure, vertex content, and other side information.",10.1002/9781119790327.ch7,2022,,IEEE,10.1002/9781119790327.ch7
Super Resolution Graph With Conditional Normalizing Flows for Temporal Link Prediction,"Temporal link prediction on dynamic graphs has attracted considerable attention. Most methods focus on the graph at each timestamp and extract features for prediction. As graphs are directly compressed into feature matrices, the important latent information at each timestamp has not been well revealed. Eventually, the acquisition of dynamic evolution-related patterns is rendered inadequately. In this paper, inspired by the process of Super-Resolution (SR), a novel deep generative model SRG (Super Resolution Graph) is proposed. We innovatively introduce the concepts of the Low-Resolution (LR) graph, which is a single adjacent matrix at a timestamp, and the High-Resolution (HR) graph, which includes the link status of surrounding snapshots. Specifically, two major aspects are considered regarding the construction of the HR graph. For edges, we endeavor to obtain an extensive information transmission description that affects the current link status. For nodes, similar to the SR process, the neighbor relationship among nodes is maintained. In this form, we could predict the link status from a new perspective: Under the supervision of the graph moving average strategy, the conditional normalizing flow effectively realizes the transformation between LR and HR graphs. Extensive experiments on six real-world datasets from different applications demonstrate the effectiveness of our proposal.",10.1109/tkde.2023.3295367,2024,3,IEEE,10.1109/tkde.2023.3295367
Design and Development of Deep Learning Framework for Recognition of Calisthenics Movement,"Calisthenics movement recognition has also received considerable interest in recent years given its applications to fitness monitoring, coaching, and rehabilitation. Classic systems to recognize exercises like push-ups, pull-ups, and squats typically employ isolated computer vision methods or shallow deep networks such as CNNs. Those current systems have significant disadvantages in representing fine-grained spatiotemporal patterns, leading to poor recognition performance and challenges to cope with variations in movement execution and style. These limitations reduce model generalization and lead to inconsistent recognition with approximate accuracy rates, precision and other performance metrics. To overcome these limitations, in this paper, research introduces a propoed deep learning architecture that combined model, a strong spatiotemporal feature learning. The CNN layers capture dense spatial representations of every video frame, whereas the GRU layer models temporal patterns throughout movement sequences. Comprehensive experiments on a large-scale as well as exercises filtered from the Kinetics-400 action recognition dataset self-collected and publicly available calisthenics dataset, as well as exercises filtered from the Kinetics-400 action recognition dataset, demonstrate that our proposed CNN+GRU architecture substantially enhances recognition performance. Our model recorded an accuracy of 95.8%, precision of 95.5%, recall of 94.9%, and F1-score of 95.2%, outperforming state-of-the-art methods by about 7-9% across all measures. This significant enhancement proves the efficacy of utilizing both convolutional and recurrent architectures for modeling spatiotemporal differences among exercises. In addition, the introduced framework is computationally lightweight and can be implemented for real-time feedback in training and fitness settings.",10.1109/icicke65317.2025.11136632,2025,,IEEE,10.1109/icicke65317.2025.11136632
MetaSTC: A Backbone Agnostic Spatio-Temporal Framework for Traffic Forecasting,"Traffic flow prediction is a critical issue in transportation engineering and presents distinct challenges when handling large-scale datasets in the real world. Existing complex spatio-temporal forecasting paradigms use the same parameters to fit traffic sequences with varying spatio-temporal features, and tend to train an average performance model over different time series. This approach greatly reduces their accuracy when applied to larger road networks. Moreover, the significant differences in traffic data distribution from one city to another can also pose great challenges. The same model may be excellent for one city and mediocre when applied to another. To this end, we propose a Meta Backbone Agnostic Spatio-Temporal Clustering Framework for Traffic Forecasting on Large-Scale Road Networks named MetaSTC. We tackle the disparities of spatio-temporal features of traffic flow through a spatio-temporal clustering-based strategy. We design meta-learner for large-scale road network that dynamically extracts the shared information across roads in the same sub-task. In this way, the model can represent task-specific details with a simpler model and make quick and accurate predictions. Our paradigm is backbone-agnostic and can be combined with different traffic prediction models, solving the problem caused by the difference in data distribution. Extensive experimental results conducted on real-world traffic dataset demonstrate the high accuracy and computational efficiency of our model over SOTA approaches.",10.1109/icdm59182.2024.00112,2024,1,IEEE,10.1109/icdm59182.2024.00112
A Brief Review of Unsupervised Learning Algorithms for Zero-Day Attacks in Intrusion Detection Systems,"This research paper presents a brief review of ten popular unsupervised algorithms widely utilized in pattern recognition publications. The algorithms are assessed based on their popularity, strengths, limitations, and resource require-ments. Considering these factors, we propose two most-preferred algorithms suitable for adoption in IDS (Intrusion Detection Systems) to address the problems associated with Zero Day exploits or attacks. Our review of the surveyed algorithms facilitated the recommendation of specific algorithms that can enhance IDS capabilities in detecting and mitigating Zero-Day attacks and anomalous intrusion attempts. These algorithms leverage unsupervised learning techniques to overcome the limitations of traditional signature-based approaches. By incorporating these algorithms, IDS can better handle sophisticated and evolving attacks that often evade detection. In conclusion, this research provides valuable insights into the strengths, limitations, and resource requirements of popular unsupervised algorithms used in pattern recognition. It highlights the potential of adopting these algorithms in IDS systems to bolster their ability to detect and respond to Zero-Day attacks. By recommending the integration of these algorithms, we contribute to the development of intelligent IDS solutions that can adapt to dynamic threat landscapes.",10.1109/icmi60790.2024.10585925,2024,1,IEEE,10.1109/icmi60790.2024.10585925
STGNNM: Spatial-Temporal Graph Neural Network with Mamba for Cellular Traffic Prediction,"Accurate long-term prediction of cellular traffic is a critical task in the rapidly developing field of intelligent communications. However, due to the high mobility of users and the complex scheduling mechanism within the network, cellular traffic data presents significant spatial-temporal dependencies, which pose a considerable challenge to long-term cellular traffic prediction. Although Transformer-based models perform well in dealing with long-term dependencies, their quadratic computational complexity leads to low efficiency and high overhead. Moreover, existing studies are often insufficient in dealing with the spatial-temporal correlation of cellular network traffic, limiting the further improvement of prediction accuracy. To overcome these challenges, we propose a novel deep learning model, Spatial-Temporal Graph Neural Network with Mamba (STGNNM). First, we introduce a bidirectional Mamba module to capture the dynamic characteristics of the time series. Second, we apply a double-view graph learning module. The Graph Convolutional Network (GCN) captures the characteristics of neighboring base stations, while the Graph Attention Network (GAT) records the relationships between distant base stations. Finally, the bidirectional Mamba module processes spatial-temporal features comprehensively. We conduct extensive experimental evaluations on a real-world cellular traffic dataset. The results show that STGNNM outperforms the current state-of-the-art methods in all evaluation metrics, demonstrating its superior performance and effectiveness in cellular network traffic prediction.",10.1109/wcsp62071.2024.10827036,2024,,IEEE,10.1109/wcsp62071.2024.10827036
Graph Neural Network-Based Internet Traffic Prediction in 6G Networks with Genetic Algorithm Hyperparameter Optimization,"Accurate internet traffic prediction is a key challenge in managing next-generation networks such as 6G. This paper presents a novel approach based on Graph Neural Networks (GNNs) for predicting internet traffic in 6G networks. The proposed model integrates Graph Attention Networks (GAT) and Transformer architectures to learn spatial and temporal dependencies in traffic data. A K-Nearest Neighbors (KNN)-based graph construction method is utilized to represent spatial relationships between network cells. The model’s performance is enhanced by leveraging a Genetic Algorithm (GA) for hyperparameter optimization. Experimental results demonstrate the effectiveness of the proposed model in achieving superior prediction accuracy, as evidenced by improvements in RMSE, and MAE compared to baseline models. This work offers a scalable solution for traffic prediction in 6G networks.",10.1109/compsac65507.2025.00100,2025,,IEEE,10.1109/compsac65507.2025.00100
A Novel Spatial-Temporal Deep Neural Network for Electricity Price Forecasting,"Electricity price forecasting is a difficult task because it depends on various factors such as weather, fuel, load, and bidding strategies. These characteristics bring a lot of volatility to electricity prices. In addition, there exist coupling relationships between different price zones in Europe. CNN-based or LSTM-based methods cannot capture the relationship by their structures or there is a need to extract these couplings explicitly manually. In this work, an end-to-end graph neural network is proposed for the first time to learn the coupling between different price zones automatically. The proposed model mainly consists of two parts: a graph learning module and a temporal learning module, which both are designed to learn spatial information of different price zones and temporal information of historical data, respectively. The performance of the proposed model is evaluated on one-year public data collected from the Nord Pool. The results indicate that our model provides a better solution for electricity price forecasting.",10.1109/icapai58366.2023.10193970,2023,,IEEE,10.1109/icapai58366.2023.10193970
"ROI-demand Traffic Prediction: A Pre-train, Query and Fine-tune Framework","Traffic prediction has drawn increasing attention due to its essential role in smart city applications. To achieve precise predictions, a large number of approaches have been proposed to model spatial dependencies and temporal dynamics. Despite their superior performance, most existing studies focus datasets that are usually in large geographic scales, e.g., citywide, while ignoring the results on specific regions. However, in many scenarios, for example, route planning on time-dependent road networks, only small regions are of interest. We name the task of answering forecasting requests from any query region of interest (ROI) as ROI-demand traffic prediction (RTP). In this paper, we make a primary observation that existing methods fail to jointly achieve effectiveness and efficiency for RTP. To address this issue, a novel model-agnostic framework based on pre-Training, Querying and fine-Tuning, named TQT, is proposed, which first customizes input data given an ROI, and then makes fast adaptation from pre-trained traffic prediction backbone models by fine-tuning. We evaluate TQT on two real-world traffic datasets, performing both flow and speed prediction tasks. Extensive experiment results demonstrate the effectiveness and efficiency of the proposed method.",10.1109/icde55515.2023.00107,2023,9,IEEE,10.1109/icde55515.2023.00107
Contrastive Learning for Multivariate Time Series Classification: an Early Fusion Approach,"In recent years, the use of contrastive learning methods for time series classification has shown promising results. State-of-the-art approaches leverage self-supervised contrastive learning representations that encode the underlying series’ features. On top of the latent representation, classification is addressed as a downstream task. While the effectiveness of contrastive models in univariate series classification is established, their portability towards a multivariate scenario is still debated. In this work, we explore the use of contrastive time series representations on multivariate data. We compare the performance of state-of-the-art contrastive models on 30 benchmark datasets and explore the use of an early fusion network to combine the input dimensions. The preliminary results show that incorporating a preliminary stage of information fusion is beneficial to improve the performance of state-of-the-art contrastive time series classifiers.",10.1109/aict59525.2023.10313147,2023,,IEEE,10.1109/aict59525.2023.10313147
Evaluating Time Series Predictability via Transition Graph Analysis,"This study is focused on exploring time series intrinsic predictability using transition graph analysis. The goal is to find out whether a special graph that reproduces system transition along its trajectory in the state space is useful for distinguishing time series of “good” and “bad” predictability. We perform a state space clustering to construct a weighted and directed transition graph and then to calculate different graph characteristics. We train several predictive models (in particular, the well-known auto-regression, singular spectrum analyses, artificial neural network and specific dynamic models of local approximation and maximal similarity) for time series and apply k-means algorithm to divide the set of the series into two parts using the properties of the corresponding transition graph. As a result we have artificial and real-world datasets divided into two clusters in one of which the mean forecasting error is much less than in the other. The F<inf>1</inf>-score value (≈ 0.87) for this clustering shows that our approach performs better than those in some related works. We also train several classification models on a set of artificial series so that they are able to distinguish real-world time series of “good” and “bad” predictability. The results of this work can be used for data engineering in time series forecasting tasks and for predictive model design and evaluation. The datasets, the framework implementation and the results related to our study are publicly available on GitHub.",10.1109/icdmw53433.2021.00135,2021,5,IEEE,10.1109/icdmw53433.2021.00135
"Guest Editorial: Deep Neural Networks for Graphs: Theory, Models, Algorithms, and Applications","Deep neural networks for graphs (DNNGs) represent an emerging field that studies how the deep learning method can be generalized to graph-structured data. Since graphs are a powerful and flexible tool to represent complex information in the form of patterns and their relationships, ranging from molecules to protein-to-protein interaction networks, to social or transportation networks, or up to knowledge graphs, potentially modeling systems at very different scales, these methods have been exploited for many application domains.",10.1109/tnnls.2024.3371592,2024,146,IEEE,10.1109/tnnls.2024.3371592
Deep Learning or Trees? A Trade-off Analysis for Multivariate Time Series Forecasting,,10.1007/978-3-032-02725-2_48,2026,0,Scopus,10.1007/978-3-032-02725-2_48
Multivariate Time Series forecasting based on temporal decomposition and graph neural network,,10.1016/j.engappai.2025.112074,2025,2,Scopus,10.1016/j.engappai.2025.112074
Sensitivity-propagated dual-frequency graph neural network for multivariate time series forecasting,,10.1016/j.neucom.2025.131644,2025,0,Scopus,10.1016/j.neucom.2025.131644
HUTFormer: Hierarchical U-Net transformer for long-term traffic forecasting,,10.1016/j.commtr.2025.100218,2025,0,Scopus,10.1016/j.commtr.2025.100218
Efficient spatial-temporal feature aggregation for multivariate time series forecasting with STCA,,10.1016/j.dsp.2025.105460,2025,0,Scopus,10.1016/j.dsp.2025.105460
Kolmogorov-Arnold networks for time series forecasting: a comprehensive review,,10.1007/s10586-025-05574-9,2025,0,Scopus,10.1007/s10586-025-05574-9
Enhancing Multivariate Time Series Forecasting: A Novel Approach with Mallows Model Averaging and Graph Neural Networks,,10.1007/s11424-024-4044-9,2025,1,Scopus,10.1007/s11424-024-4044-9
Frequency-domain analysis for cooling load prediction: A Multi-Scale FourierGNN Crossformer approach,,10.1016/j.ijrefrig.2025.04.018,2025,2,Scopus,10.1016/j.ijrefrig.2025.04.018
Application of Rainbow Vertex Antimagic Coloring in Multi-Step Time Series Forecasting for Efficient Railway Passenger Load Management,,10.19139/soic-2310-5070-2214,2025,0,Scopus,10.19139/soic-2310-5070-2214
DFGCN: Decoupled dual-flow dynamic graph convolutional network for multivariate time series forecasting,,10.1016/j.knosys.2025.113720,2025,2,Scopus,10.1016/j.knosys.2025.113720
Graph Deep Learning for Time Series Forecasting,,10.1145/3742784,2025,1,Scopus,10.1145/3742784
DeepHGNN: Study of graph neural network based forecasting methods for hierarchically related multivariate time series,,10.1016/j.eswa.2025.127658,2025,2,Scopus,10.1016/j.eswa.2025.127658
TMF-GNN: Temporal matrix factorization-based graph neural network for multivariate time series forecasting with missing values,,10.1016/j.eswa.2025.127001,2025,6,Scopus,10.1016/j.eswa.2025.127001
DAMixer: A dual-stage attention-based mixer model for multivariate time series forecasting,,10.1016/j.eswa.2025.127030,2025,0,Scopus,10.1016/j.eswa.2025.127030
Graph Neural Networks for multivariate time-series forecasting via learning hierarchical spatiotemporal dependencies,,10.1016/j.engappai.2025.110304,2025,2,Scopus,10.1016/j.engappai.2025.110304
TVC Former: A transformer-based long-term multivariate time series forecasting method using time-variable coupling correlation graph,,10.1016/j.knosys.2025.113147,2025,3,Scopus,10.1016/j.knosys.2025.113147
GC-MT: A Novel Vessel Trajectory Sequence Prediction Method for Marine Regions,,10.3390/info16040311,2025,2,Scopus,10.3390/info16040311
High–low frequency dynamic interactive fusion network for multivariate time series forecasting,,10.1016/j.knosys.2024.112951,2025,4,Scopus,10.1016/j.knosys.2024.112951
Improved Pearson Correlation Coefficient-Based Graph Neural Network for Dynamic Soft Sensor of Polypropylene Industries,,10.1021/acs.iecr.4c02832,2025,4,Scopus,10.1021/acs.iecr.4c02832
Spatio-Temporal Graph Fusion Network-Based Multivariate Time Series Forecasting of Environmental Factors in Utility Tunnels,,10.1007/978-981-96-1024-2_24,2025,0,Scopus,10.1007/978-981-96-1024-2_24
Design of an Iterative Method for Time Series Forecasting Using Temporal Attention and Hybrid Deep Learning Architectures,,10.1109/access.2025.3538577,2025,1,Scopus,10.1109/access.2025.3538577
Probabilistic forecasting of renewable energy and electricity demand using Graph-based Denoising Diffusion Probabilistic Model,,10.1016/j.egyai.2024.100459,2025,10,Scopus,10.1016/j.egyai.2024.100459
Nearest Neighbor Multivariate Time Series Forecasting,,10.1109/tnnls.2024.3490603,2025,0,Scopus,10.1109/tnnls.2024.3490603
DyGraphformer: Transformer combining dynamic spatio-temporal graph network for multivariate time series forecasting,,10.1016/j.neunet.2024.106776,2025,10,Scopus,10.1016/j.neunet.2024.106776
Adaptive Spatio-Temporal Relation Based Transformer for Traffic Flow Prediction,,10.1109/tvt.2024.3390997,2025,9,Scopus,10.1109/tvt.2024.3390997
Exploiting Spatial-Temporal Joint Information from the Frequency Domain for Multivariate Time Series Forecasting,,10.1109/ijcnn64981.2025.11228734,2025,0,Scopus,10.1109/ijcnn64981.2025.11228734
A Dynamic Stiefel Graph Neural Network for Efficient Spatio-Temporal Time Series Forecasting,,10.24963/ijcai.2025/796,2025,1,Scopus,10.24963/ijcai.2025/796
State Feedback Enhanced Graph Differential Equations for Multivariate Time Series Forecasting,,10.24963/ijcai.2025/820,2025,0,Scopus,10.24963/ijcai.2025/820
Dynamic Spatio-Temporal Attention-Based Graph Neural Network Using Ordinary Differential Equation and Multi-Scale Semantics for Traffic Prediction,,10.1109/tits.2025.3612204,2025,0,Scopus,10.1109/tits.2025.3612204
Variable Spatiotemporal Framework for Multivariate Time Series Prediction,,10.1109/icdew67478.2025.00022,2025,0,Scopus,10.1109/icdew67478.2025.00022
MGTDGraph: Multi-granularity Graph Attention Networks for Multivariate Long-Term Time Series Forecasting,,10.1007/978-981-95-0009-3_4,2025,0,Scopus,10.1007/978-981-95-0009-3_4
BiG-Mamba: Bidirectional Graph and Mamba Modeling for Multivariate Time Series Forecasting,,10.1007/978-981-96-9946-9_26,2025,0,Scopus,10.1007/978-981-96-9946-9_26
A Patch-Based Multiscale Graph-Enhanced Transformer for Multivariate Time Series Forecasting,,10.1007/978-981-96-6948-6_32,2025,0,Scopus,10.1007/978-981-96-6948-6_32
PANDA: Patch-Aware Graph Network with Dual Alignment for Time Series Forecasting,,10.1109/icassp49660.2025.10889936,2025,1,Scopus,10.1109/icassp49660.2025.10889936
Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks,,10.1109/icassp49660.2025.10889685,2025,0,Scopus,10.1109/icassp49660.2025.10889685
Tribe Graph Enhanced Bidirectional Mamba for Multivariate Time Series Forecasting,,10.1109/icassp49660.2025.10889482,2025,0,Scopus,10.1109/icassp49660.2025.10889482
Graph Neural Network-Enhanced Multivariate Time Series Forecasting with Series-Core Fusion,,10.1109/icaace65325.2025.11019045,2025,0,Scopus,10.1109/icaace65325.2025.11019045
Research on Time Series Forecasting Models Based on Hybrid Attention Mechanism and Graph Neural Networks,,10.31449/inf.v49i21.7580,2025,0,Scopus,10.31449/inf.v49i21.7580
Leveraging Long-Term Multivariate History Representation for Time Series Forecasting,,10.1109/tai.2025.3570676,2025,0,Scopus,10.1109/tai.2025.3570676
GinAR+: A Robust End-to-End Framework for Multivariate Time Series Forecasting With Missing Values,,10.1109/tkde.2025.3569649,2025,12,Scopus,10.1109/tkde.2025.3569649
Leveraging Heterophily in Spatial-Temporal Graphs for Multivariate Time-Series Forecasting,,10.1109/icassp49660.2025.10888419,2025,0,Scopus,10.1109/icassp49660.2025.10888419
Scene-GCN: a time-series prediction method in complex monitoring environments through spatial–temporal knowledge graph (ST-KG),,10.1080/13658816.2025.2479183,2025,0,Scopus,10.1080/13658816.2025.2479183
Multivariate sequence prediction for graph convolutional networks based on ESMD and transfer entropy,,10.1007/s11042-024-18787-8,2024,3,Scopus,10.1007/s11042-024-18787-8
Functional Relation Field: A Model-Agnostic Framework for Multivariate Time Series Forecasting,,10.1016/j.artint.2024.104158,2024,2,Scopus,10.1016/j.artint.2024.104158
Multiview Spatial-Temporal Meta-Learning for Multivariate Time Series Forecasting,,10.3390/s24144473,2024,2,Scopus,10.3390/s24144473
Self-learning dynamic graph neural network with self-attention based on historical data and future data for multi-task multivariate residential air conditioning forecasting,,10.1016/j.apenergy.2024.123156,2024,13,Scopus,10.1016/j.apenergy.2024.123156
Electricity demand forecasting at distribution and household levels using explainable causal graph neural network,,10.1016/j.egyai.2024.100368,2024,23,Scopus,10.1016/j.egyai.2024.100368
Multivariate Time Series Forecasting: A Review,,10.1145/3663976.3664241,2024,10,Scopus,10.1145/3663976.3664241
MDG: A Multi-Task Dynamic Graph Generation Framework for Multivariate Time Series Forecasting,,10.1109/tetci.2024.3352407,2024,9,Scopus,10.1109/tetci.2024.3352407
Adversarial Danger Identification on Temporally Dynamic Graphs,,10.1109/tnnls.2023.3252175,2024,12,Scopus,10.1109/tnnls.2023.3252175
A lightweight multi-layer perceptron for efficient multivariate time series forecasting,,10.1016/j.knosys.2024.111463,2024,29,Scopus,10.1016/j.knosys.2024.111463
Adapt to small-scale and long-term time series forecasting with enhanced multidimensional correlation,,10.1016/j.eswa.2023.122203,2024,2,Scopus,10.1016/j.eswa.2023.122203
Learning evolving relations for multivariate time series forecasting,,10.1007/s10489-023-05220-0,2024,7,Scopus,10.1007/s10489-023-05220-0
An attentive Copula-based spatio-temporal graph model for multivariate time-series forecasting,,10.1016/j.asoc.2024.111324,2024,29,Scopus,10.1016/j.asoc.2024.111324
STAE-TA: Spatio-Temporal Frequency Adaptive Embedding with Multi-Scal Trend Attention,,10.1109/cbase64041.2024.10824493,2024,0,Scopus,10.1109/cbase64041.2024.10824493
Multivariate Time Series Forecasting of Integrated Energy Systems Based on Fast Fourier Transform Fully Connected Space-Time Graph,,10.1007/978-981-97-9674-8_22,2024,0,Scopus,10.1007/978-981-97-9674-8_22
Navigating Data Scarcity in Multivariate Time Series Forecasting: A Hybrid Model Perspective,,10.1109/tensymp61132.2024.10752270,2024,2,Scopus,10.1109/tensymp61132.2024.10752270
Time-Decay Dynamic Graph Neural Network for Multivariate Time Series Forecasting,,10.1109/ijcnn60899.2024.10651177,2024,1,Scopus,10.1109/ijcnn60899.2024.10651177
GAGNN: Generative Adversarial Network and Graph Neural Network for Prognostic and Health Management,,10.1109/jiot.2024.3435917,2024,3,Scopus,10.1109/jiot.2024.3435917
SAGDFN: A Scalable Adaptive Graph Diffusion Forecasting Network for Multivariate Time Series Forecasting,,10.1109/icde60146.2024.00101,2024,14,Scopus,10.1109/icde60146.2024.00101
Evolving Super Graph Neural Networks for Large-Scale Time-Series Forecasting,,10.1007/978-981-97-2266-2_16,2024,2,Scopus,10.1007/978-981-97-2266-2_16
Multi-Granularity Spatio-Temporal Correlation Networks for Stock Trend Prediction,,10.1109/access.2024.3393774,2024,4,Scopus,10.1109/access.2024.3393774
Explainable Spatio-Temporal Graph Neural Networks for multi-site photovoltaic energy production,,10.1016/j.apenergy.2023.122151,2024,44,Scopus,10.1016/j.apenergy.2023.122151
Dynamic spatiotemporal interactive graph neural network for multivariate time series forecasting,,10.1016/j.knosys.2023.110995,2023,26,Scopus,10.1016/j.knosys.2023.110995
Recurrent neural networks integrate multiple graph operators for spatial time series prediction,,10.1007/s10489-023-04632-2,2023,11,Scopus,10.1007/s10489-023-04632-2
Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting,,10.1145/3583780.3615253,2023,8,Scopus,10.1145/3583780.3615253
Multivariate Time Series Forecasting With Dynamic Graph Neural ODEs,,10.1109/tkde.2022.3221989,2023,108,Scopus,10.1109/tkde.2022.3221989
Graph neural networks for multivariate time series regression with application to seismic data,,10.1007/s41060-022-00349-6,2023,46,Scopus,10.1007/s41060-022-00349-6
Spatio-temporal wind speed forecasting using graph networks and novel Transformer architectures,,10.1016/j.apenergy.2022.120565,2023,149,Scopus,10.1016/j.apenergy.2022.120565
Graph Convolution Recurrent Denoising Diffusion Model for Multivariate Probabilistic Temporal Forecasting,,10.1007/978-3-031-46661-8_44,2023,5,Scopus,10.1007/978-3-031-46661-8_44
Causal-Based Spatio-Temporal Graph Neural Networks for Industrial Internet of Things Multivariate Time Series Forecasting,,10.1007/978-3-031-44070-0_6,2023,1,Scopus,10.1007/978-3-031-44070-0_6
Temporal Chain Network With Intuitive Attention Mechanism for Long-Term Series Forecasting,,10.1109/tim.2023.3322508,2023,16,Scopus,10.1109/tim.2023.3322508
Multivariate Long-Term Traffic Forecasting with Graph Convolutional Network and Historical Attention Mechanism,,10.1007/978-3-031-40292-0_10,2023,1,Scopus,10.1007/978-3-031-40292-0_10
Spatiotemporal Causal Discovery Graph Convolutional Networks for Multivariate Time Series Forecasting of Industrial Process,,10.1109/itnec56291.2023.10082527,2023,3,Scopus,10.1109/itnec56291.2023.10082527
Interpretable temporal-spatial graph attention network for multi-site PV power forecasting,,10.1016/j.apenergy.2022.120127,2022,58,Scopus,10.1016/j.apenergy.2022.120127
Knowledge Graph Guided Simultaneous Forecasting and Network Learning for Multivariate Financial Time Series,,10.1145/3533271.3561702,2022,4,Scopus,10.1145/3533271.3561702
Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting,,10.1145/3511808.3557702,2022,321,Scopus,10.1145/3511808.3557702
Multi-scale temporal features extraction based graph convolutional network with attention for multivariate time series prediction,,10.1016/j.eswa.2022.117011,2022,53,Scopus,10.1016/j.eswa.2022.117011
Research on prediction algorithm of ship equipment heath condition,,10.1016/j.oceaneng.2022.110750,2022,13,Scopus,10.1016/j.oceaneng.2022.110750
Migration Data-based Graph Neural Network for Disease Forecasting,,10.1109/bigdia56350.2022.9874050,2022,1,Scopus,10.1109/bigdia56350.2022.9874050
AGCNT: Adaptive Graph Convolutional Network for Transformer-based Long Sequence Time-Series Forecasting,,10.1145/3459637.3482054,2021,4,Scopus,10.1145/3459637.3482054
Dc-stgcn: Dual-channel based graph convolutional networks for network traffic forecasting,,10.3390/electronics10091014,2021,31,Scopus,10.3390/electronics10091014
Inductive Graph Neural Networks for Spatiotemporal Kriging,,10.1609/aaai.v35i5.16575,2021,136,Scopus,10.1609/aaai.v35i5.16575
Multi Scale Graph Wavenet for Wind Speed Forecasting,,10.1109/bigdata52589.2021.9671624,2021,27,Scopus,10.1109/bigdata52589.2021.9671624
Spatio-Temporal Multi-graph Networks for Demand Forecasting in Online Marketplaces,,10.1007/978-3-030-86514-6_12,2021,9,Scopus,10.1007/978-3-030-86514-6_12
CrossLinear: Plug-and-Play Cross-Correlation Embedding for Time Series Forecasting with Exogenous Variables,"Time series forecasting with exogenous variables is a critical emerging paradigm that presents unique challenges in modeling dependencies between variables. Traditional models often struggle to differentiate between endogenous and exogenous variables, leading to inefficiencies and overfitting. In this paper, we introduce CrossLinear, a novel Linear-based forecasting model that addresses these challenges by incorporating a plug-and-play cross-correlation embedding module. This lightweight module captures the dependencies between variables with minimal computational cost and seamlessly integrates into existing neural networks. Specifically, it captures time-invariant and direct variable dependencies while disregarding time-varying or indirect dependencies, thereby mitigating the risk of overfitting in dependency modeling and contributing to consistent performance improvements. Furthermore, CrossLinear employs patch-wise processing and a global linear head to effectively capture both short-term and long-term temporal dependencies, further improving its forecasting precision. Extensive experiments on 12 real-world datasets demonstrate that CrossLinear achieves superior performance in both short-term and long-term forecasting tasks. The ablation study underscores the effectiveness of the cross-correlation embedding module. Additionally, the generalizability of this module makes it a valuable plug-in for various forecasting tasks across different domains. Codes are available at https://github.com/mumiao2000/CrossLinear.",10.1145/3711896.3736899,2025,,ACM,10.1145/3711896.3736899
Telecommunications Product Revenue Time-Series Forecasting Using Target Variable Preprocessing Methods,"Accurate revenue forecasting is critical for decision-making support of telecommunications companies (telcos). This study explored the use of machine learning for time-series revenue forecasting of a telco product. While existing research explores machine learning for time-series forecasting primarily for stocks price prediction and different use cases in other industries, this study focused on telco revenue and the impact of target variable preprocessing on forecasting accuracy. Two datasets with different business rules for the same attribute were used, with two preprocessing techniques for converting monthly revenue data to daily applied to each dataset: even distribution and a weighted distribution based on daily subscriber count. Recurrent neural networks (RNNs), specifically long short-term memory (LSTM) and gated recurrent unit (GRU), were employed for revenue prediction. Various factors were used to produce additional model variations, specifically seed selection, dataset, preprocessing technique, and input window size. Mean Absolute Percentage Error (MAPE) was the key metric for comparison of model performance. The results showed that weighted preprocessing produced the most accurate model with an MAPE of 3.08\% despite its reliance on a specific variable combination. This study concludes that target variable preprocessing impacts model outputs, with weighted distribution offering the highest accuracy for telco product revenue forecasting using RNNs.",10.1145/3690771.3690784,2025,,ACM,10.1145/3690771.3690784
CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting,"Probabilistic time-series forecasting enables reliable decision making across many domains. Most forecasting problems have diverse sources of data containing multiple modalities and structures. Leveraging information from these data sources for accurate and well-calibrated forecasts is an important but challenging problem. Most previous works on multi-view time-series forecasting aggregate features from each data view by simple summation or concatenation and do not explicitly model uncertainty for each data view. We propose a general probabilistic multi-view forecasting framework CAMul, which can learn representations and uncertainty from diverse data sources. It integrates the information and uncertainty from each data view in a dynamic context-specific manner, assigning more importance to useful views to model a well-calibrated forecast distribution. We use CAMul for multiple domains with varied sources and modalities and show that CAMul outperforms other state-of-art probabilistic forecasting models by over 25\% in accuracy and calibration.",10.1145/3485447.3512037,2022,,ACM,10.1145/3485447.3512037
A Spatial-Temporal Aggregated Graph Neural Network for Docked Bike-sharing Demand Forecasting,"Predicting the number of rented and returned bikes at each station is crucial for operators to proactively manage shared bike relocation. Although existing research has proposed spatial-temporal prediction models that significantly advance traffic prediction, these models often neglect the unique characteristics of shared bike systems (BSS). Spatially, the entire bike-sharing system (BSS) experiences peak activity during morning and evening rush hours, whereas, during other periods, activity is localized to local stations, with some recording no rides, highlighting the need to distinguish between global and local spatial information across different times. Temporally, the historical riding records for each station exhibit non-stationary patterns, necessitating the analysis of both global trends and local fluctuations. Existing Graph Neural Network (GNN) approaches to predicting shared bike demand primarily capture static spatial-temporal data and fail to account for the dynamic nature of bike flows. Moreover, these studies focus on global spatial-temporal information without considering local nuances, making it challenging to capture spatiotemporal dynamics in fluctuating BSS. To address these challenges, we introduce the Spatial-Temporal Aggregated Graph Neural Network (STAGNN). Our model first constructs a dynamic adjacent matrix to describe the evolving connections between stations, followed by local and global information layers to capture spatial-temporal information from large-scale shared bike networks accurately. Our methodology has been validated through experiments on four real-world datasets, comparing it against benchmark models to demonstrate superior prediction accuracy. Additionally, we conduct extended experiments on four datasets during the morning and evening rush hours, and the results also affirm the efficacy of the STAGNN in enhancing prediction performance.",10.1145/3690388,2024,,ACM,10.1145/3690388
AutoCTS+: Joint Neural Architecture and Hyperparameter Search for Correlated Time Series Forecasting,"Sensors in cyber-physical systems often capture interconnected processes and thus emit correlated time series (CTS), the forecasting of which enables important applications. The key to successful CTS forecasting is to uncover the temporal dynamics of time series and the spatial correlations among time series. Deep learning-based solutions exhibit impressive performance at discerning these aspects. In particular, automated CTS forecasting, where the design of an optimal deep learning architecture is automated, enables forecasting accuracy that surpasses what has been achieved by manual approaches. However, automated CTS solutions remain in their infancy and are only able to find optimal architectures for predefined hyperparameters and scale poorly to large-scale CTS. To overcome these limitations, we propose AutoCTS+, a joint, scalable framework, to automatically devise effective CTS forecasting models. Specifically, we encode each candidate architecture and accompanying hyperparameters into a joint graph representation. We introduce an efficient Architecture-Hyperparameter Comparator (AHC) to rank all architecture-hyperparameter pairs, and we then further evaluate the top-ranked pairs to select an architecture-hyperparameter pair as the final model. Extensive experiments on six benchmark datasets demonstrate that AutoCTS+ not only eliminates manual efforts but also is capable of better performance than manually designed and existing automatically designed CTS models. In addition, it shows excellent scalability to large CTS.",10.1145/3588951,2023,,ACM,10.1145/3588951
Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks,"Modeling multivariate time series has long been a subject that has attracted researchers from a diverse range of fields including economics, finance, and traffic. A basic assumption behind multivariate time series forecasting is that its variables depend on one another but, upon looking closely, it is fair to say that existing methods fail to fully exploit latent spatial dependencies between pairs of variables. In recent years, meanwhile, graph neural networks (GNNs) have shown high capability in handling relational dependencies. GNNs require well-defined graph structures for information propagation which means they cannot be applied directly for multivariate time series where the dependencies are not known in advance. In this paper, we propose a general graph neural network framework designed specifically for multivariate time series data. Our approach automatically extracts the uni-directed relations among variables through a graph learning module, into which external knowledge like variable attributes can be easily integrated. A novel mix-hop propagation layer and a dilated inception layer are further proposed to capture the spatial and temporal dependencies within the time series. The graph learning, graph convolution, and temporal convolution modules are jointly learned in an end-to-end framework. Experimental results show that our proposed model outperforms the state-of-the-art baseline methods on 3 of 4 benchmark datasets and achieves on-par performance with other approaches on two traffic datasets which provide extra structural information.",10.1145/3394486.3403118,2020,,ACM,10.1145/3394486.3403118
Data-Driven Time Series Forecasting for Social Studies Using Spatio-Temporal Graph Neural Networks,"Time series forecasting with additional spatial information has attracted a tremendous amount of attention in recent research, due to its importance in various real-world applications on social studies, such as conflict prediction and pandemic forecasting. Conventional machine learning methods either consider temporal dependencies only, or treat spatial and temporal relations as two separate autoregressive models, namely, space-time autoregressive models. Such methods suffer when it comes to long-term forecasting or predictions for large-scale areas, due to the high nonlinearity and complexity of spatio-temporal data. In this paper, we propose to address these challenges using spatio-temporal graph neural networks. Empirical results on Violence Early Warning System (ViEWS) dataset and U.S. Covid-19 dataset indicate that our method significantly improved performance over the baseline approaches.",10.1145/3462203.3475929,2021,,ACM,10.1145/3462203.3475929
ST-CopulaGNN : A Multi-View Spatio-Temporal Graph Neural Network for Traffic Forecasting,"Modern cities heavily rely on complex transportation, making accurate traffic speed prediction crucial for traffic management authorities. Classical methods, including statistical techniques and traditional machine learning techniques, fail to capture complex relationships, while deep learning approaches may have weaknesses such as error accumulation, difficulty in handling long sequences, and overlooking spatial correlations. Graph neural networks (GNNs) have shown promise in extracting spatial features from non-Euclidean graph structures, but they usually initialize the adjacency matrix based on distance and may fail to detect hidden statistical correlations. The choice of correlation measure can have a significant impact on the resulting adjacency matrix and the effectiveness of graph-based models. This paper proposes a novel approach for accurately forecasting traffic patterns by utilizing a multi-view spatio-temporal graph neural network that captures data from both realistic and statistical domains. Unlike traditional correlation measures such as Pearson correlation, copula models are utilized to extract hidden statistical correlations and construct multivariate distribution functions to obtain the correlation relationship among traffic nodes. A two-step approach is adopted, which involves selecting and testing different types of bivariate copulas to identify the ones that best fit the traffic data, and utilizing these copulas to create multi-weight adjacency matrices. The second step involves utilizing a graph convolutional network to extract spatial information and capturing temporal trends using dilated causal convolutions. The proposed ST-CopulaGNN model outperforms other models in spatio-temporal traffic forecasting that solely rely on distance-based adjacency matrices, such as DCRNN and Graph WaveNet. It also achieves the lowest MAE for 30 and 60 minutes ahead and the lowest MAPE for 15 minutes ahead on the PEMS-BAY dataset. The model incorporates copulas, and the study explores copula function selection and the impact of using paired time-series with a time lag. The findings suggest that using copula-based adjacency matrix configurations, particularly those including Clayton and Gumbel copulas, can enhance traffic forecasting accuracy.",10.1145/3603719.3603740,2023,,ACM,10.1145/3603719.3603740
Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation,"Spatiotemporal time series are usually collected via monitoring sensors placed at different locations, which usually contain missing values due to various failures, such as mechanical damages and Internet outages. Imputing the missing values is crucial for analyzing time series. When recovering a specific data point, most existing methods consider all the information relevant to that point regardless of the cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths and establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could cause overfitting. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective and show how to block the confounders via the frontdoor adjustment. Based on the results of frontdoor adjustment, we introduce a novel &lt;u&gt;C&lt;/u&gt;ausality-&lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;Sp&lt;/u&gt;atiot&lt;u&gt;e&lt;/u&gt;mpo&lt;u&gt;r&lt;/u&gt;al Graph Neural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and a Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of confounders and SCA could discover the sparse causal relationships among embeddings. Theoretical analysis reveals that SCA discovers causal relationships based on the values of gradients. We evaluate Casper on three real-world datasets, and the experimental results show that Casper could outperform the baselines and could effectively discover the causal relationships.",10.1145/3627673.3679642,2024,,ACM,10.1145/3627673.3679642
CMMD: Cross-Metric Multi-Dimensional Root Cause Analysis,"In large-scale online services, crucial metrics, a.k.a., key performance indicators (KPIs), are monitored periodically to check the running statuses. Generally, KPIs are aggregated along multiple dimensions and derived by complex calculations among fundamental metrics from the raw data. Once abnormal KPI values are observed, root cause analysis (RCA) can be applied to identify the reasons for anomalies, so that we can troubleshoot quickly. Recently, several automatic RCA techniques were proposed to localize the related dimensions (or a combination of dimensions) to explain the anomalies. However, their analyses are limited to the data on the abnormal metric and ignore the data of other metrics which are also related to the anomalies, leading to imprecise or even incorrect root causes. To this end, we propose a cross-metric multi-dimensional root cause analysis method, named CMMD, which consists of two key components: 1) relationship modeling, which utilizes graph neural network (GNN) to model the unknown complex calculation among metrics and aggregation function among dimensions from historical data; 2) root cause localization, which adopts the genetic algorithm to efficiently and effectively dive into the raw data and localize the abnormal dimension(s) once the KPI anomalies are detected. Experiments on synthetic datasets, real-world datasets and online production environments demonstrate the superiority of our proposed CMMD method compared with baselines. Currently, CMMD is running as an online service in Microsoft Azure.",10.1145/3534678.3539109,2022,,ACM,10.1145/3534678.3539109
CrashFormer: A Multimodal Architecture to Predict the Risk of Crash,"Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose Crash-Former, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8\% in F1-score on average when using ",10.1145/3615900.3628769,2023,,ACM,10.1145/3615900.3628769
Decoder-only Pre-training Enhancement for Spatio-temporal Traffic Forecasting,"Although spatio-temporal graph neural networks (STGNNs) become widely used methods in traffic forecasting, they still encounter an issue named short-sightedness. Specifically, due to high model complexity and GPU memory usage, STGNNs are restricted to processing only very short input time series. This limited context often causes STGNNs to focus on local variations and overlook long-term patterns, leading to misinterpretation of time series trends. To tackle this issue, recent studies propose to perform mask reconstruction pre-training on traffic series to enhance STGNNs. However, we argue that mask reconstruction is a suboptimal pre-training paradigm for traffic forecasting, because there exists a great gap between pre-training and downstream forecasting, caused by their inconsistent training targets. To eliminate this gap, we propose a new pre-training paradigm named next patch prediction and prove its advantages from both empirical and theoretical perspectives. Based on this paradigm, we introduce a new framework called Decoder-only Pre-training Enhancement (DoP) to unleash the potential of traffic pre-training model. Specifically, DoP uses Transformer decoders as infrastructure, and leverages next patch prediction as target to conduct pre-training. In addition, we propose a new dual-view temporal embedding to fully capture temporal information and spatial spectral enhancement to model spatial information. After pre-training, DoP enhances existing STGNNs seamlessly with periodic enhancement mechanism. On four real-world traffic benchmarks, we demonstrate its start-of-the-art performance.",10.1145/3746252.3761432,2025,,ACM,10.1145/3746252.3761432
Divide and Conquer: Adaptive Graph Neural Networks Leveraging Sequence Factorization for IP Network,"Accurate IP network traffic prediction is vital for the efficient management of metropolitan area networks, allowing operators to foresee potential issues and maintain optimal service quality. Existing methods struggle with the complex spatio-temporal characteristics of traffic sequences and their dependence on precise network topology. To overcome these challenges, we propose an innovative prediction framework leveraging discrete wavelet transform (DWT) and a dual-channel adaptive spatial-temporal graph convolutional network (ASTGCN) with feature fusion : WASTGCN. We start with a divide-and-conquer approach, using a multilevel DWT to decompose multimodal traffic into simpler factor sequences. We then introduce an ASTGCN that learns spatial dependencies directly from the data, minimizing the need for predefined structures and reducing preprocessing. The ASTGCN features a dual-channel setup: one branch captures short-term events using temporal attention, while the other models long-term trends with temporal convolution, effectively analyzing temporal dynamics. A multi-head cross attention fusion module then integrates these features. Our experimental results show that this method surpasses traditional approaches in predictive accuracy and stability, without depending on physical topology, highlighting its potential for improved network planning and management.",10.1145/3708657.3708664,2025,,ACM,10.1145/3708657.3708664
Cola-GNN: Cross-location Attention based Graph Neural Networks for Long-term ILI Prediction,"Forecasting influenza-like illness (ILI) is of prime importance to epidemiologists and health-care providers. Early prediction of epidemic outbreaks plays a pivotal role in disease intervention and control. Most existing work has either limited long-term prediction performance or fails to capture spatio-temporal dependencies in data. In this paper, we design a cross-location attention based graph neural network (Cola-GNN) for learning time series embeddings in long-term ILI predictions. We propose a graph message passing framework to combine graph structures (e.g., geolocations) and time-series features (e.g., temporal sequences) in a dynamic propagation process. We compare the proposed method with state-of-the-art statistical approaches and deep learning models. We conducted a set of extensive experiments on real-world epidemic-related datasets from the United States and Japan. The proposed method demonstrated strong predictive performance and leads to interpretable results for long-term epidemic predictions.",10.1145/3340531.3411975,2020,,ACM,10.1145/3340531.3411975
HierST: A Unified Hierarchical Spatial-temporal Framework for COVID-19 Trend Forecasting,"The outbreak of the COVID-19 pandemic has largely influenced the world and our normal daily lives. To combat this pandemic efficiently, governments usually need to coordinate essential resources across multiple regions and adjust intervention polices at the right time, which all call for accurate and robust forecasting of future epidemic trends. However, designing such a forecasting system is non-trivial, since we need to handle all kinds of locations at different administrative levels, which include pretty different epidemic-evolving patterns. Moreover, there are dynamic and volatile correlations of pandemic conditions among these locations, which further enlarge the difficulty in forecasting. With these challenges in mind, we develop a novel spatial-temporal forecasting framework. First, to accommodate all kinds of locations at different administrative levels, we propose a unified hierarchical view, which mimics the aggregation procedure of pandemic statistics. Then, this view motivates us to facilitate joint learning across administrative levels and inspires us to design the cross-level consistency loss as an extra regularization to stabilize model training. Besides, to capture those dynamic and volatile spatial correlations, we design a customized spatial module with adaptive edge gates, which can both reinforce effective messages and disable irrelevant ones. We put this framework into production to help the battle against COVID-19 in the United States. A comprehensive online evaluation across three months demonstrates that our projections are the most competitive ones among all results produced by dozens of international group and even surpass the official ensemble in many cases. We also visualize our unique edge gates to understand the evolvement of spatial correlations and present intuitive case studies. Besides, we open source our implementation at https://github.com/dolphin-zs/HierST to facilitate future research towards better epidemic modeling.",10.1145/3459637.3481927,2021,,ACM,10.1145/3459637.3481927
Learning Reliable User Representations from Volatile and Sparse Data to Accurately Predict Customer Lifetime Value,"In industry, customer lifetime value (LTV) prediction is a challenging task, since user consumption data is usually volatile, noisy, or sparse. To address these issues, this paper presents a novel Temporal-Structural User Representation (named TSUR) network to predict LTV. We utilize historical revenue time series and user attributes to learn both temporal and structural user representations, respectively. Specifically, the temporal representation is learned with a temporal trend encoder based on a novel multi-channel Discrete Wavelet Transform~(DWT) module, while the structural representation is derived with Graph Attention Network (GAT) on an attribute similarity graph. Furthermore, a novel cluster-alignment regularization method is employed to align and enhance these two kinds of representations. In essence, such a fusion way can be considered as the association of temporal and structural representations in the low-pass representation space, which is also useful to prevent the data noise from being transferred across different views. To our knowledge, it is the first time that temporal and structural user representations are jointly learned for LTV prediction. Extensive offline experiments on two large-scale real-world datasets and online A/B tests have shown the superiority of our approach over a number of competitive baselines.",10.1145/3447548.3467079,2021,,ACM,10.1145/3447548.3467079
Forecasting at Full Spectrum: Holistic Multi-Granular Traffic Modeling under High-Throughput Inference Regimes,"Notably, current intelligent transportation systems rely heavily on accurate traffic forecasting and swift inference provision to make timely decisions. While Graph Convolutional Networks (GCNs) have shown benefits in modeling complex traffic dependencies, the existing GCN-based approaches cannot fully extract and fuse multi-granular spatiotemporal features across various spatial and temporal scales sufficiently in a complete manner, proven to yield less accurate results. As extracting multi-granular features across scales has been a promising strategy across domains such as computer vision, natural language processing, and time-series forecasting, pioneering studies have attempted to leverage a similar mechanism for spatiotemporal traffic data mining. However, additional feature extraction branches introduced in prior studies critically increased model complexity and extended inference time, making it challenging to provide fast forecasts. In this paper, we propose MultiGran-STGCNFog, an efficient fog distributed inference system with a novel traffic forecasting model that employs multi-granular spatiotemporal feature fusion on generated dynamic traffic graphs to fully capture interdependent traffic dynamics. The proposed scheduling algorithm GA-DPHDS, optimizing layer execution order and layer-device scheduling scheme simultaneously, contributes to considerable inference throughput improvement by coordinating heterogeneous fog devices in a pipelined manner. Extensive experiments on real-world datasets demonstrate the superiority of the proposed method over selected GCN baselines.",10.1145/3746252.3761330,2025,,ACM,10.1145/3746252.3761330
Graph Neural Rough Differential Equations for Traffic Forecasting,"Traffic forecasting is one of the most popular spatio-temporal tasks in the field of machine learning. A prevalent approach in the field is to combine graph convolutional networks and recurrent neural networks for the spatio-temporal processing. There has been fierce competition and many novel methods have been proposed. In this article, we present the method of spatio-temporal graph neural rough differential equation (STG-NRDE). Neural rough differential equations (NRDEs) are a breakthrough concept for processing time-series data. Their main concept is to use the log-signature transform to convert a time-series sample into a relatively shorter series of feature vectors. We extend the concept and design two NRDEs: one for the temporal processing and the other for the spatial processing. After that, we combine them into a single framework. We conduct experiments with 6 benchmark datasets and 27 baselines. STG-NRDE shows the best accuracy in all cases, outperforming all those 27 baselines by non-trivial margins.",10.1145/3604808,2023,,ACM,10.1145/3604808
Securities Price Movement Prediction Based on Graph Neural Networks,"Securities play a crucial role in the modern economy. However, securities price movement prediction, a type of time-series forecasting problem, remains challenging. This paper suggests that the underutilization of temporal structural information in the data hinders the improvement of accuracy in securities price movement prediction. Therefore, this paper proposes a securities price movement prediction method based on graph computing. By abstracting trading days and the temporal relationships between them as nodes and edges, the method transforms historical trading data into graph data. Subsequently, graph neural networks (GNN) are used to process the graph data and make predictions about stock price movements. Experiments show that the proposed method effectively improves the performance of price movement prediction. Thus, the proposed method is a simple, effective way to utilize time-series data and holds substantial value in securities price movement prediction.",10.1145/3650215.3650345,2024,,ACM,10.1145/3650215.3650345
LINet: A Location and Intention-Aware Neural Network for Hotel Group Recommendation,"Motivated by the collaboration with Fliggy1, a leading Online Travel Platform (OTP), we investigate an important but less explored research topic about optimizing the quality of hotel supply, namely selecting potential profitable hotels in advance to build up adequate room inventory. We formulate a WWW problem, i.e., within a specific time period (When) and potential travel area (Where), which hotels should be recommended to a certain group of users with similar travel intentions (Why). We identify three critical challenges in solving the WWW problem: user groups generation, travel data sparsity and utilization of hotel recommendation information (e.g., period, location and intention). To this end, we propose LINet, a Location and Intention-aware neural Network for hotel group recommendation. Specifically, LINet first identifies user travel intentions for user groups generalization, and then characterizes the group preferences by jointly considering historical user-hotel interaction and spatio-temporal features of hotels. For data sparsity, we develop a graph neural network, which employs long-term data, and further design an auxiliary loss function of location that efficiently exploits data within the same and across different locations. Both offline and online experiments demonstrate the effectiveness of LINet when compared with state-of-the-art methods. LINet has been successfully deployed on Fliggy to retrieve high quality hotels for business development, serving hundreds of hotel operation scenarios and thousands of hotel operators.",10.1145/3543507.3583202,2023,,ACM,10.1145/3543507.3583202
DHFM: Diversity-Enhanced Hypergraph Factorization Machines for Feature Interaction Modeling,"Feature interaction modeling, which exploits interactive information between features, has been widely explored in various applications. Recently, many graph neural network (GNN)-based models are proposed to model feature interactions by predicting the existence of edges between pairwise nodes that represent features. However, these models can only directly model 2-order feature interactions. Although stacking multiple GNN layers can implicitly capture the arbitrary high-order feature interactions, it may lead to the over-smoothing problem. To this end, we propose Diversity-Enhanced Hypergraph Factorization Machines (DHFMs) that incorporate hypergraphs into feature interaction modeling, which can model the diverse feature interactions of different orders explicitly. Specifically, the order-wise hyperedge predictors are proposed to discover beneficial feature interactions and explicitly model the feature interactions of different orders. In addition, diversity measures are introduced in hyperedge predictors and in the results of feature interactions to make discovered feature interactions as diverse as possible and avoid generating correlated errors. Extensive experiments on four real-world datasets demonstrate the superiority of the proposed model. In addition, the case study is conducted to further justify the effectiveness of the proposed model.",10.1145/3721982,2025,,ACM,10.1145/3721982
"Radflow: A Recurrent, Aggregated, and Decomposable Model for Networks of Time Series","We propose a new model for networks of time series that influence each other. Graph structures among time series are found in diverse domains, such as web traffic influenced by hyperlinks, product sales influenced by recommendation, or urban transport volume influenced by road networks and weather. There has been recent progress in graph modeling and in time series forecasting, respectively, but an expressive and scalable approach for a network of series does not yet exist. We introduce Radflow, a novel model that embodies three key ideas: a recurrent neural network to obtain node embeddings that depend on time, the aggregation of the flow of influence from neighboring nodes with multi-head attention, and the multi-layer decomposition of time series. Radflow naturally takes into account dynamic networks where nodes and edges change over time, and it can be used for prediction and data imputation tasks. On real-world datasets ranging from a few hundred to a few hundred thousand nodes, we observe that Radflow variants are the best performing model across a wide range of settings. The recurrent component in Radflow also outperforms N-BEATS, the state-of-the-art time series model. We show that Radflow can learn different trends and seasonal patterns, that it is robust to missing nodes and edges, and that correlated temporal patterns among network neighbors reflect influence strength. We curate WikiTraffic, the largest dynamic network of time series with 366K nodes and 22M time-dependent links spanning five years. This dataset provides an open benchmark for developing models in this area, with applications that include optimizing resources for the web. More broadly, Radflow has the potential to improve forecasts in correlated time series networks such as the stock market, and impute missing measurements in geographically dispersed networks of natural phenomena.",10.1145/3442381.3449945,2021,,ACM,10.1145/3442381.3449945
Online Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics,"Online purchase forecasting is of great importance in e-commerce platforms, which is the basis of how to present personalized interesting product lists to individual customers. However, predicting online purchases is not trivial as it is influenced by many factors including: (i) the complex temporal pattern with hierarchical inter-correlations; (ii) arbitrary category dependencies. To address these factors, we develop a Graph Multi-Scale Pyramid Networks (GMP) framework to fully exploit users' latent behavioral patterns with both multi-scale temporal dynamics and arbitrary inter-dependencies among product categories. In GMP, we first design a multi-scale pyramid modulation network architecture which seamlessly preserves the underlying hierarchical temporal factors--governing users' purchase behaviors. Then, we employ convolution recurrent neural network to encode the categorical temporal pattern at each scale. After that, we develop a resolution-wise recalibration gating mechanism to automatically re-weight the importance of each scale-view representations. Finally, a context-graph neural network module is proposed to adaptively uncover complex dependencies among category-specific purchases. Extensive experiments on real-world e-commerce datasets demonstrate the superior performance of our method over state-of-the-art baselines across various settings.",10.1145/3292500.3330790,2019,,ACM,10.1145/3292500.3330790
BiLSTM-KAN: A Time Series-based Traffic Flow Forecasting Model,"Currently, the task of traffic flow prediction poses a significant challenge. Most existing works utilize spatial features for overall forecasting, without giving much consideration to the issue of extracting data features from individual time series data. In the absence of knowledge about road topology, extracting effective time series features for a single node becomes particularly important. The BiLSTM-KAN model proposed in this paper is an innovative sequence-to-sequence (Seq2Seq) forecasting model designed to significantly enhance the accuracy and efficiency of time series data processing. This model deeply integrates the advanced feature extraction capabilities of Bidirectional Long Short-Term Memory Networks (BiLSTM) with Kolmogorov-Arnold Networks (KAN), forming a unique and powerful data processing mechanism. With the application of the BiLSTM-KAN model, it will be possible to more accurately capture the complex dynamic changes and underlying patterns in time series data, thereby providing more reliable and precise forecasting results for traffic flow prediction and other related field sequence data processing tasks.",10.1145/3704323.3704369,2025,,ACM,10.1145/3704323.3704369
Spatio-Temporal Wavelet Enhanced Attention Mamba for Stock Price Forecasting,"Stock price forecasting remains a critical challenge due to market non-stationarity and the influence of multiple factors. Existing studies apply frequency domain analysis methods to mitigate the impacts of non-stationarity by decoupling high- and low-frequency variation patterns. However, these approaches primarily focus on single series decomposition while neglecting cross frequency interactions among different stocks. Moreover, as a key indicator of overall market trends, current methods inadequately utilize market index information. In this paper, we propose STEAM, a Spatio-Temporal Wavelet Enhanced Attention Mamba model. We introduce Discrete Wavelet Transform (DWT) to disentangle multi-frequency temporal features and propose Wavelet Enhanced Attention (WEA) to capture cross frequency spatial dependencies, effectively leveraging both local and global inter-stock relationships. To extract the synergistic spatio-temporal dependencies in stock data, AMamba module is designed that integrates WEA into the Mamba-2 architecture. Additionally, to further enhance the model's perception of macro-market conditions, we incorporate market index as a prefix, guiding predictions with holistic market information in both spatial and temporal dependencies learning. Extensive experiments across multiple national stock markets demonstrate that STEAM achieves state-of-the-art forecasting performance.",10.1145/3746252.3761399,2025,,ACM,10.1145/3746252.3761399
AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting,"Spatio-temporal forecasting is a critical component of various smart city applications, such as transportation optimization, energy management, and socio-economic analysis. Recently, several automated spatio-temporal forecasting methods have been proposed to automatically search the optimal neural network architecture for capturing complex spatio-temporal dependencies. However, the existing automated approaches suffer from expensive neural architecture search overhead, which hinders their practical use and the further exploration of diverse spatio-temporal operators in a finer granularity. In this paper, we propose AutoSTF, a decoupled automatic neural architecture search framework for cost-effective automated spatio-temporal forecasting. From the efficiency perspective, we first decouple the mixed search space into temporal space and spatial space and respectively devise representation compression and parameter-sharing schemes to mitigate the parameter explosion. The decoupled spatio-temporal search not only expedites the model optimization process but also leaves new room for more effective spatio-temporal dependency modeling. From the effectiveness perspective, we propose a multi-patch transfer module to jointly capture multi-granularity temporal dependencies and extend the spatial search space to enable finer-grained layer-wise spatial dependency search. Extensive experiments on eight datasets demonstrate the superiority of AutoSTF in terms of both accuracy and efficiency. Specifically, our proposed method achieves up to 13.48x speed-up compared to state-of-the-art automatic spatio-temporal forecasting methods while maintaining the best forecasting accuracy. The source code and data are available at https://github.com/usail-hkust/AutoSTF.",10.1145/3690624.3709323,2025,,ACM,10.1145/3690624.3709323
DecisionFlow for SMEs: A Lightweight Visual Framework for Multi-Task Joint Prediction and Anomaly Detection,"The digital transformation of industry has placed immense pressure on small and medium-sized enterprises (SMEs), which often lack the resources and technical infrastructure to adopt complex AI pipelines and data visualization systems. This creates a pressing challenge: how can SMEs leverage real-time business intelligence without heavy computational or financial burdens. We propose the DecisionFlow framework to generate interactive KPI dashboards on the fly using Vega-Lite declarative syntax through a low-latency visualization engine. To run at the edge, we distilled the long sequence of self-attention into linear Performer blocks, using cross-prediction step weight sharing and 8-bit quantization, so that the model only contained 4.3 M parameters and could be deployed on a common CPU or browser WebAssembly environment. Secondly, the model couples continuous probability prediction with rare event detection with a joint uncertainty loss function, as well as a cross-layer visual feedback closed-loop in which the user interacts with real-time update of the attention mask, so as to support online incremental learning. On Online Retail II (UCI), a dataset for SMEs, DecisionFlow reduced inference latency by 68\%, demand forecasting MAE by 17\%, and anomaly detection F1 to 0.91.",10.1145/3770177.3770325,2025,,ACM,10.1145/3770177.3770325
Pre-trained Time Series Foundation Models for Traffic Flow Prediction Using Open Government Data: The case of Attica traffic OGD,"Rapid urbanization and increase in vehicular traffic in metropolitan areas necessitate advanced predictive models to enhance traffic management systems. Open Government Data (OGD) portals provide accessible, high-quality traffic datasets, offering a valuable resource for developing and evaluating such models. This paper investigates the effectiveness of pre-trained Time Series Foundation Models, specifically Lag-Llama, in forecasting urban traffic flow using open government traffic data from the Greek OGD portal. We assess Lag-Llama’s performance in both zero-shot and fine-tuned settings and compare it with traditional deep learning models, including Long Short-Term Memory (LSTM) networks and Graph Neural Networks (GNNs). Our experimental results demonstrate that Lag-Llama, especially when fine-tuned on traffic OGD, outperforms conventional models in prediction accuracy. These findings highlight the potential of combining foundation models with traffic open government data to advance intelligent transportation systems and contribute to the development of more robust and reliable traffic forecasting models, as well as provide innovative and efficient public services for citizens and businesses.",10.1145/3716554.3716619,2025,,ACM,10.1145/3716554.3716619
Architectural Bias vs. Feature Engineering: Deconstructing the Limits of Tabular Foundation Models in Traffic Forecasting,"Although spatio-temporal graph neural networks (STGNNs) demonstrate efficacy in the domain of traffic prediction, they are characterised by elevated data requirements and computational costs. Concurrently, pre-trained foundation models, such as the Prior-data Fitted Network (TabPFN), have demonstrated noteworthy performance in general tabular tasks with high efficiency. This juxtaposition gives rise to a critical question: can a general-purpose foundation model, augmented with domain-specific feature engineering, match the performance of specialized architectures in a complex domain such as traffic forecasting? In order to investigate this, an evaluation framework was introduced, known as TabPFN-ST-AR. This is an adaptation of TabPFN that has been designed for traffic prediction using a comprehensive spatio-temporal feature set. A rigorous comparison against a wide range of baselines is conducted on the benchmark METR-LA dataset. The baselines include state-of-the-art STGNNs (Graph WaveNet, DCRNN, STGCN, ASTGCN), traditional machine learning models (XGBoost, CatBoost), and classic deep learning models (LSTM). The findings demonstrate that while top-tier STGNNs such as GraphWaveNet maintain a clear performance advantage, our TabPFN-ST-AR framework is highly competitive, outperforming not only traditional baselines but also some established STGNN models. This outcome serves to emphasise the efficacy of feature engineering, while concurrently providing a quantifiable measurement of the residual performance disparity when compared to contemporary specialist models. It is concluded that, while feature engineering is beneficial, it cannot fully substitute for the architectural inductive biases inherent to models designed for spatio-temporal graph structures. This finding indicates a potential direction for future research, namely the exploration of hybrid modelling and the adaptation of foundation models to specific domains.",10.1145/3768740.3768798,2025,,ACM,10.1145/3768740.3768798
Multivariate Time-Series Data Anomaly Detection via Dimension Independence and Reconstruction,"Time-series data anomaly detection has received widespread attention from academia and industry, with crucial applications in service monitor, IoT surveillance, and network security. Existing anomaly detection methods for multivariate time-series data (MTS) typically (1) focus solely on low-accuracy anomalies, neglecting explicit errors, which limits the applicability; (2) treat data dimensionality as a fixed parameter during training and inference, which limits the scalability of trained model to data with varying dimensions. To address these problems, we propose a Transformer framework for MTS anomaly detection based on dimension independence and reconstruction. The framework comprises three components: (1) time-series data preprocessing, (2) MTS reconstruction model, and (3) anomaly detection. Preprocessing step resolves explicit errors and prepares data. MTS reconstruction model built on dimension independence and Transformer encoder, reconstructs each MTS dimension independently. Anomaly detection step identifies low-accuracy anomaly and outputs the final anomaly detection results. Comparative experiments demonstrate that the proposed framework outperforms all baseline methods on two real-world datasets and achieves second place on the remaining two datasets. Furthermore, preprocessing and scalability experiments yield highly satisfactory results, validating the completeness and scalability of the framework.",10.1145/3725472.3725475,2025,,ACM,10.1145/3725472.3725475
Enhancing Logical Reasoning in Large Language Models via Multi-Stage Ensemble Architecture with Adaptive Attention and Decision Voting,"Increasing difficulty of logical reasoning tasks suggests the deficiency of conventional large language models (LLMs) in solving multi-step reasoning problems. This paper presents a novel multi-stage ensemble method to enhance LLMsQS reasoning capability. The design includes cascading networks, in which dynamic candidates are selected as the inputs and an adaptive self-attention mechanism and voting are applied for decision- making, which together enhance the model's accuracy and robustness. Based on the confidence levels, candidate selection is carried out and the candidates are then refined utilizing multi-head adaptive attention. Then, decision voting fuses reasoning results of several different models, which improves the stability and diversity of the model. Proposed different from state-of-the-art methods, the multi-stage ensemble approach significantly enhances the logic reasoning ability of the model, especially in more complex multi-step problems according to the experimental results. An ablation study validates that the adaptive attention mechanism and ensemble decision method contribute positively to enhancing the model performance. Not only does this out-perform classical models in accuracy, but it also strikes a great balance in reasoning efficiency and model interpretability, thus establishing a new paradigm for AI-based logical reasoning tasks.",10.1145/3724154.3724348,2025,,ACM,10.1145/3724154.3724348
DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting  with Denoising Diffusion Models,"Spatio-temporal graph neural networks (STGNN) have emerged as the dominant model for spatio-temporal graph (STG) forecasting. Despite their success, they fail to model intrinsic uncertainties within STG data, which cripples their practicality in downstream tasks for decision-making. To this end, this paper focuses on probabilistic STG forecasting, which is challenging due to the difficulty in modeling uncertainties and complex ST dependencies. In this study, we present the first attempt to generalize the popular de-noising diffusion probabilistic models to STGs, leading to a novel non-autoregressive framework called DiffSTG, along with the first denoising network UGnet for STG in the framework. Our approach combines the spatio-temporal learning capabilities of STGNNs with the uncertainty measurements of diffusion models. Extensive experiments validate that DiffSTG reduces the Continuous Ranked Probability Score (CRPS) by 4\%-14\%, and Root Mean Squared Error (RMSE) by 2\%-7\% over existing methods on three real-world datasets.",10.1145/3589132.3625614,2023,,ACM,10.1145/3589132.3625614
Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting,"Traffic forecasting is crucial for intelligent transportation systems (ITS), aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank (MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, the traffic data of the data-scarce target city could query the traffic pattern bank, facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn, assumes a pivotal role as a robust guide in subsequent processes involving graph reconstruction and forecasting. Empirical assessments conducted on real-world traffic datasets affirm the superior performance of MTPB, surpassing existing methods across various categories and exhibiting numerous attributes conducive to the advancement of cross-city few-shot forecasting methodologies. The code is available in .",10.1145/3727622,2025,,ACM,10.1145/3727622
Context-driven Deep Learning Forecasting for Wastewater Treatment Plants,"Wastewater‑treatment utilities face various operational challenges that could benefit from embodied AI and other advanced cyber‑physical technologies. These challenges include optimizing pump schedules, managing energy and chemical consumption during extreme weather events, and interpreting sensor data for water‑quality treatment. Addressing these issues requires accurate short‑term, multi‑step forecasting tools to provide reliable real‑time decision support, particularly during heavy‑rainfall events that can overwhelm operations. Leading water‑system operators and vendors in the United States report that tools capable of forecasting 4–6 hours ahead can significantly enhance resource management, including energy, chemicals, and manpower. However, accurate short‑term forecasting is particularly difficult because of the non‑linearities and seasonal variations inherent in plant data, which limit effective decision‑making. To address these challenges, we propose cP2O, a context‑driven forecasting solution, a novel hybrid deep‑learning architecture integrating dynamic context extraction with hierarchical, dilated long‑short‑term‑memory (LSTM) cells. The proposed model utilizes internal water‑system data, such as flow rates and tunnel levels, along with exogenous variables including weather, river flow, and demographic information to derive relevant context. It captures both short‑term fluctuations and long‑term dependencies in water‑level data, while an internal attention mechanism dynamically weighs the importance of exogenous information. We validate the model on two full‑scale utilities: tunnel‑water‑level forecasting at DC Water’s Blue Plains facility and nitrate‑level prediction at AlexRenew. Relative to strong baselines, cP2O reduces mean absolute percentage error by 22 \% and 19 \%, respectively, and its 90 \% prediction bands cover 90.5 \% ± 3.2 \% of observations (5.9 \% below, 3.6 \% above). By dynamically incorporating contextual information, especially under critical conditions, the model delivers reliable real‑time forecasts that enhance resource allocation and strengthen the overall resilience of wastewater‑treatment operations.",10.1145/3744350,2025,,ACM,10.1145/3744350
Spatio-Temporal Transformer Network with Physical Knowledge Distillation for Weather Forecasting,"Weather forecasting has become a popular research topic recently, which mainly benefits from the development of spatio-temporal neural networks to effectively extract useful patterns from weather data. Generally, the weather changes in the meteorological system are governed by physical principles. However, it is challenging for spatio-temporal methods to capture the physical knowledge of meteorological dynamics. To address this problem, we propose in this paper a spatio-temporal Transformer network with physical knowledge distillation (PKD-STTN) for weather forecasting. First, the teacher network is implemented by a differential equation network that models weather changes by the potential energy in the atmosphere to reveal the physical mechanism of atmospheric movements. Second, the student network uses a spatio-temporal Transformer that concurrently utilizes three attention modules to comprehensively capture the semantic spatial correlation, geographical spatial correlation, and temporal correlation from weather data. Finally, the physical knowledge of the teacher network is transferred to the student network by inserting a distillation position encoding into the Transformer. Notice that the output of the teacher network is distilled to the position encoding rather than the output of the student network, which can largely utilize physical knowledge without influencing the feature extraction process of Transformers. Experiments on benchmark datasets show that the proposed method can effectively utilize physical principles of weather changes and has obvious performance advantages compared with several strong baselines.",10.1145/3627673.3679841,2024,,ACM,10.1145/3627673.3679841
Enhancing Transformer Models for Long-Term Time Series Classification with Multi-Channel Frequency-Domain Filters,"Time-series classification plays a critical role in numerous domains such as healthcare, activity recognition, and industrial monitoring. Traditional Transformer models, while effective in modeling long-range dependencies, tend to focus disproportionately on high-energy frequency components, potentially overlooking valuable low-frequency information. To address this issue, we propose a frequency-domain filter Transformer model that incorporates a multi-channel frequency decomposition module prior to the Transformer encoder. This module applies parallel frequency-specific filters to segment the input sequence into distinct bands, enabling the model to extract features from both high- and low-frequency components. Each frequency stream is processed by a dedicated Transformer branch, and the results are aggregated to form a comprehensive representation. Extensive experiments on benchmark datasets such as KU-HAR demonstrate that our model significantly outperforms baseline methods, including CNN, CNN-LSTM, and Transformer architectures, achieving superior accuracy and robustness. The proposed approach effectively mitigates the attention bias toward single-band information and enhances the interpretability and performance of Transformer-based time-series classifiers.",10.1145/3760658.3760677,2025,,ACM,10.1145/3760658.3760677
Automobile sales forecasting based on Special Zero-inflated Data,"Car sales projections are important for manufacturers in terms of production adjustments and strategic planning. Traditionally, such predictions tend to focus only on brand performance across a wide range of markets. The LSTM model showed good prediction results. Due to the increasing importance of Market Segmentation, the demand for some car sales forecasts (PAS) has increased, and PAS data contains a large number of zero values and has significant cyclicality. This creates problems with traditional statistical methods and becomes difficult to capture the nuances of the data. To solve this problem, a method is proposed that combines short-and long-term memory (LSTM) networks and zero-expansion Poisson models. The latter is suitable for processing data with superfluous zero values and complex patterns. The mixed-loss zero-expansion LSTM system (Zim-LSTM) has also been implemented to improve robust and long-term forecasting capabilities for future pa. Zim-LSTM has advantages in modeling common zero values and stores historical information to facilitate the short-sighted task of predicting time series. Using a method of verifying sales data of real cars and comparing them with existing reference models, the results show that the accuracy and reliability of Zim-LSTM have improved, making it a promising solution for predicting PAS..",10.1145/3745533.3745595,2025,,ACM,10.1145/3745533.3745595
Photovoltaic Power Output Prediction Based on Simple Weather Data and Graph Convolutional Networks,"Graph neural networks, as a class of models capable of handling graph-structured data, have been widely applied and researched in various fields in recent years. In the power industry, photovoltaic power output prediction is an important topic, and the relative positions of photovoltaic power stations, as a form of unstructured information, provide an opportunity for the application of graph neural networks. In this context, we utilize multiple layers of graph convolutional layers to construct the network, stack the graph convolutional layer with the normalization layer and connect two fully connected layers at the end. Regarding the dataset, existing algorithms may face challenges such as difficulty in acquisition and lack of sufficient data support. To address this, we use simple weather data as input variables, simultaneously construct regression models for meteorological indicators, and employ the variance inflation factor to remove highly similar nodes, aiming to reduce the complexity of the graph. The specific operation is to set the threshold, establish a regression model between each meteorological indicator of each node and the meteorological indicators of other nodes, and calculate the variance inflation factor. Filter the removable nodes according to the variance inflation factor, randomly remove a node and refit the regression. model, by iterating until the remaining nodes are not highly relevant. Experimental validation shows that our method outperforms existing approaches in terms of accuracy.",10.1145/3662739.3672175,2024,,ACM,10.1145/3662739.3672175
Physics-Informed vs. Deep Learning: Indoor Temperature Prediction with Different Data Availability,"Reducing energy consumption in the building sector is crucial for global sustainability. Achieving energy efficiency requires advanced technologies and robust building models that address uncertainties and environmental variations. White-box models, based on physical principles, provide interpretability but require significant expertise and resources. In contrast, black-box models rely on historical data, lacking interpretability and being dataset-dependent. To bridge this gap, Scientific Machine Learning integrates physical insights into machine learning frameworks, ensuring interpretability while maintaining the accuracy and computational efficiency of models like neural networks. This work incorporates physical knowledge through Ordinary Differential Equations into the neural network framework, developing a physics-informed model to predict indoor air temperature based on external conditions, system thermal powers, and building internal gains. Datasets from four cities with diverse climatic conditions were used, and the model was trained on varying amounts of data, from two weeks to two years. This approach offers a novel exploration of model performance under different data availability and multiple scenarios. A comparative analysis with a Long Short-Term Memory neural network shows that, especially with limited training data, the Physics-Informed Neural Network outperforms the conventional model, with a Mean Absolute Error up to 0.69°C lower. This advantage is due to the incorporation of physics-based constraints, reducing reliance on large datasets. Additionally, the Physics-Informed Neural Network demonstrates stable accuracy across seasonal and uncontrolled dynamics conditions, highlighting its potential for temperature prediction and building control applications.",10.1145/3679240.3734642,2025,,ACM,10.1145/3679240.3734642
The Impact of Artificial Neural Network Architecture on Network Attack Detection,"Artificial Neural Networks (ANNs) have emerged as a powerful tool for network attack detection due to their ability to learn complex patterns and behaviors. The architecture of an ANN plays a critical role in determining its performance and effectiveness in detecting network attacks. This article explores the impact of ANN architecture on network attack detection, highlighting different types of architectures used in the field of cybersecurity. It discusses the advantages and disadvantages of these architectures, along with the challenges associated with their usage. By understanding the significance of ANN architecture, security professionals can make informed decisions to enhance network defense mechanisms and protect against evolving cyber threats.",10.1145/3644713.3644792,2024,,ACM,10.1145/3644713.3644792
Exploring The Efficient Market Hypothesis for Accurate Stock Movement Prediction via Feature-Axis Transformer,"Stock movement forecasting is a significant challenge in financial machine-learning application fields due to its profound impact on financial markets. While the Efficient Market Hypothesis (EMH) [10] postulates that predicting stock movement is nearly impossible, recent studies using deep learning methodologies exhibit promising results. The EMH is based on the assumption that stock prices immediately incorporate all available information, such as financial statements, earnings announcements, and macroeconomic news. Input features used by the prior studies commonly include Open, High, Low, Close, and Adjusted Close (OHLCA), which potentially contain salient information for forecasting movements. However, most have yet to extract the information implicit in each price separately and utilize it to make predictions. This paper proposes FATE: Feature-Axis Transformer based on EMH designed to leverage each OHLCA component to facilitate stock movement prediction. FATE consists of three modules: 1) capturing each feature's temporal correlation between various stocks; 2) generating global market context data; and 3) constructing a contextual vector through correlating to other prices around the closing price. Experimental results show that FATE demonstrates better predictive results than state-of-the-art baselines on six real-world datasets. FATE also yields profitable portfolio trading gains compared to the baselines. Furthermore, it offers interpretable visualized results during its stock movement forecasting operations.",10.1145/3605098.3635928,2024,,ACM,10.1145/3605098.3635928
Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: Benchmarking energy load forecasting models without and with continual learning,"In traditional deep learning algorithms, one of the key assumptions is that the data distribution remains constant during both training and deployment. However, this assumption becomes problematic when faced with Out-of-Distribution periods, such as the COVID-19 lockdowns, where the data distribution significantly deviates from what the model has seen during training. This paper employs a two-fold strategy: utilizing continual learning techniques to update models with new data and harnessing human mobility data collected from privacy-preserving pedestrian counters located outside buildings. In contrast to online learning, which suffers from ’catastrophic forgetting’ as newly acquired knowledge often erases prior information, continual learning offers a holistic approach by preserving past insights while integrating new data. This research applies FSNet, a powerful continual learning algorithm, to real-world data from 13 building complexes in Melbourne, Australia, a city which had the second longest total lockdown duration globally during the pandemic. Results underscore the crucial role of continual learning in accurate energy forecasting, particularly during Out-of-Distribution periods. Secondary data such as mobility and temperature provided ancillary support to the primary forecasting model. More importantly, while traditional methods struggled to adapt during lockdowns, models featuring at least online learning demonstrated resilience, with lockdown periods posing fewer challenges once armed with adaptive learning techniques. This study contributes valuable methodologies and insights to the ongoing effort to improve energy load forecasting during future Out-of-Distribution periods.",10.1145/3600100.3623726,2023,,ACM,10.1145/3600100.3623726
A Clustering-based Multi-Task Learning Method using Graph Attention Network for Short-term Traffic Forecasting,"In modern intelligent transportation systems, accurate short-term traffic forecasting is pivotal for managers and travelers. While recent spatio-temporal traffic forecasting models excel in short-term predictions, data from different traffic node inherently possesses diverse characteristics, yet existing models tend to neglect the disparities between these nodes and treat neighboring nodes with different data in a uniform manner, overlooking their unique attributes, which can result in imprecise prediction results. To address these concerns, this paper introduces, the Clustering-based Multi-Task Learning Method using Graph Attention Network (CMTGAT). This model adopts a multi-task learning framework, enhanced with time-series clustering for nuanced pattern recognition and improved prediction accuracy in diverse traffic scenarios. Experimental results demonstrate that the CMTGAT model outperforms existing methods, almost doubling in forecasting precision. The integration of the time series clustering and the graph attention mechanism helps to reduce the MAPE approximately by 6\%.",10.1145/3669754.3669825,2024,,ACM,10.1145/3669754.3669825
DynaGraph: dynamic graph neural networks at scale,"In this paper, we present DynaGraph, a system that supports dynamic Graph Neural Networks (GNNs) efficiently. Based on the observation that existing proposals for dynamic GNN architectures combine techniques for structural and temporal information encoding independently, DynaGraph proposes novel techniques that enable cross optimizations across these tasks. It uses cached message passing and timestep fusion to significantly reduce the overhead associated with dynamic GNN processing. It further proposes a simple distributed data-parallel dynamic graph processing strategy that enables scalable dynamic GNN computation. Our evaluation of DynaGraph on a variety of dynamic GNN architectures and use cases shows a speedup of up to 2.7X compared to existing state-of-the-art frameworks.",10.1145/3534540.3534691,2022,,ACM,10.1145/3534540.3534691
Research and Application of Edge Cloud Load Prediction Based on DR-STGNN?,"Cloud servers generate a large amount of monitoring data in real-time, which is often composed of multiple time series monitoring indicators. Accurately predicting cloud load data is significant for capacity forecasting and reasonable resource allocation of cloud platforms. Multidimensional cloud load data has the characteristics of an extended period, low information density, and complex calling relationships between indicators. However, most current time series prediction algorithms perform poorly in cloud load prediction, the specific manifestation lies in the inadequate handling of cloud workload data with long-term dependencies, as well as situations involving multidimensional metrics with complex invocation relationships. This paper proposes the DR-STGNN algorithm for cloud load prediction scenarios. We designed temporal module and spatial module separately to address the challenges of long-term dependency relationships between historical and future data and complex calling relationships between indicators. A bidirectional residual structure was used to connect the modules to avoid the influence of gradient disappearance. We verified the model using the GWA-T-12 rnd trace dataset provided by Bitbrains and compared it with models such as informer, MTGNN, stemGNN, reformer, and TPA-LSTM. MAE and RMSE were used as evaluation indicators, and the results showed that DR-STGNN performed outstandingly in cloud load prediction.",10.1145/3627915.3628025,2023,,ACM,10.1145/3627915.3628025
Irregularity-Informed Time Series Analysis: Adaptive Modelling of Spatial and Temporal Dynamics,"Irregular Time Series Data (IRTS) has shown increasing prevalence in real-world applications. We observed that IRTS can be divided into two specialized types: Natural Irregular Time Series (NIRTS) and Accidental Irregular Time Series (AIRTS). Various existing methods either ignore the impacts of irregular patterns or statically learn the irregular dynamics of NIRTS and AIRTS data and suffer from limited data availability due to the sparsity of IRTS. We proposed a novel transformer-based framework for general irregular time series data that treats IRTS from four views: Locality, Time, Spatio and Irregularity to motivate the data usage to the highest potential. Moreover, we design a sophisticated irregularity-gate mechanism to adaptively select task-relevant information from irregularity, which improves the generalization ability to various IRTS data. We implement extensive experiments to demonstrate the resistance of our work to three highly missing ratio datasets (88.4\%, 94.9\%, 60\% missing value) and investigate the significance of the irregularity information for both NIRTS and AIRTS by additional ablation study. We release our implementation in https://github.com/IcurasLW/MTSFormer-Irregular_Time_Series.git.",10.1145/3627673.3679716,2024,,ACM,10.1145/3627673.3679716
FEST: A Multi-way Framework with Enhanced Spatial-Temporal Modeling for Traffic Forecasting,"Accurately forecasting traffic flow using time-series data from multimedia sensors remains a significant challenge, despite its importance for advancing intelligent transportation systems. Recent advancements in attention-based models have shown promise in capturing spatial-temporal dependencies in traffic flow data. Yet, these models exhibit three principal limitations: (1) they employ either factorized or coupled spatial-temporal attention mechanisms, potentially failing to fully harness the potential of these distinct approaches; (2) the attention allocation for spatial nodes is predominantly data-centric, which may overlook existing knowledge about the nodes' importance within the transportation network; (3) while traditional attention-based methods effectively capture long-term dependencies, they often struggle with adapting to the disparate lengths of temporal contexts. To overcome these limitations, we introduce a multi-way framework dubbed FEST that innovatively integrates both factorized and coupled spatial-temporal attention mechanisms. We then enhance FEST by incorporating PageRank-derived node importance scores to guide focus on nodes. Moreover, a novel multi-scale temporal learning approach is proposed to improve model capability with both long- and short-term temporal dynamics. Extensive experiments on real-world datasets under long- and short-term prediction scenarios confirm the effectiveness of our method.",10.1145/3652583.3658111,2024,,ACM,10.1145/3652583.3658111
Dynamic Routing Method for Integrated Satellite–Terrestrial Multi-Domain Networks Based on Transfer Learning,"With the development of communication technology and the diversification of users' needs, the space-earth integrated multi-domain network has become the core of modern communication system. However, rapidly changing topologies, frequent satellite switching, and heterogeneous traffic conditions can challenge classical deep reinforcement learning (DRL) algorithms, affecting real-time accuracy and robust convergence. Given that these networks continue to evolve, rapid adaptation is critical to maintaining data throughput and a seamless user experience. To solve these problems, this paper introduces STGT (Space-Ground Generative Transport), a novel dynamic routing framework that combines generative adversarial network (GAN) with near-end Policy Optimization (PPO) algorithm.STGT uses transfer learning to leverage the knowledge of previously trained models, reducing the training overhead under changing topological conditions. It can achieve stable convergence in the case of constant link fluctuation. Numerous experiments have shown that STGT outperforms leading DRL-based approaches, including PPO, DQN, SAP, and ospf, in terms of convergence speed, robustness, and flexibility. Notably, under the same constellation observed at different times, the STGT trained 5.7 times faster than the baseline PPO. As a result, STGT strikes a critical balance between adaptive speed and decision accuracy, resulting in stable, high-performance routing across a range of real-time conditions. These findings demonstrate that combining GAN and PPO through transfer learning effectively addresses dynamic routing challenges in satellite-ground integrated multi-domain networks, providing an efficient and scalable solution for real-world deployment.",10.1145/3732945.3732978,2025,,ACM,10.1145/3732945.3732978
Deep Learning techniques for stock market forecasting: Recent trends and challenges,"Stock market forecasting has been a very intensive area of research in recent years due to the highly uncertain and volatile nature of stock data which makes this task challenging. By accurately predicting a particular stock's price investors can gain maximum profit out of their investment. With the great success of Deep Learning methods in various domains, it has attracted the research community to apply these models for financial domain also. These DL methods have been proven to achieve better accuracy and predictions compared to econometric and traditional ML methods. This work reviews recent papers according to various Deep Learning models which included: Artificial Neural Networks, Convolution Neural Networks, Sequence to Sequence models, Generative Adversarial Networks, Graph Neural Networks and Transformers applied for stock market forecasting. Furthermore this work also reviews datasets, features, evaluation parameters and results of various methods. From the analysis done on various DL models we found that Graph Neural Networks and Transformer models have potential to interpret dynamic and non-linear patterns of financial time series data with greater accuracy. In addition to this, correlation among various stock indices and investors sentiment along with historical data has great influence on the prediction accuracy. We also identified the benchmark datasets for stock market forecasting based on market capitalization value of an economy. The aim of this paper is to provide insight into most recent work done in the finance domain and identify future directions for more accurate predictions.",10.1145/3584871.3584872,2023,,ACM,10.1145/3584871.3584872
Hierarchically Structured Transformer Networks for Fine-Grained Spatial Event Forecasting,"Spatial event forecasting is challenging and crucial for urban sensing scenarios, which is beneficial for a wide spectrum of spatial-temporal mining applications, ranging from traffic management, public safety, to environment policy making. In spite of significant progress has been made to solve spatial-temporal prediction problem, most existing deep learning based methods based on a coarse-grained spatial setting and the success of such methods largely relies on data sufficiency. In many real-world applications, predicting events with a fine-grained spatial resolution do play a critical role to provide high discernibility of spatial-temporal data distributions. However, in such cases, applying existing methods will result in weak performance since they may not well capture the quality spatial-temporal representations when training triple instances are highly imbalanced across locations and time. To tackle this challenge, we develop a hierarchically structured Spatial-Temporal ransformer network (STtrans) which leverages a main embedding space to capture the inter-dependencies across time and space for alleviating the data imbalance issue. In our STtrans framework, the first-stage transformer module discriminates different types of region and time-wise relations. To make the latent spatial-temporal representations be reflective of the relational structure between categories, we further develop a cross-category fusion transformer network to endow STtrans with the capability to preserve the semantic signals in a fully dynamic manner. Finally, an adversarial training strategy is introduced to yield a robust spatial-temporal learning under data imbalance. Extensive experiments on real-world imbalanced spatial-temporal datasets from NYC and Chicago demonstrate the superiority of our method over various state-of-the-art baselines.",10.1145/3366423.3380296,2020,,ACM,10.1145/3366423.3380296
An Onboard UAV Multi-task System for Trajectory Prediction and State Estimation Employing Transformer- and Reservoir-based Networks,"With the increasing technological advancements and deployment of unmanned aerial vehicles (UAVs) in different applications (e.g., delivery services, surveillance, critical infrastructure monitoring, military operations, and search-and-rescue operations), a robust, lightweight, and accurate system for UAV state identification and trajectory prediction is becoming a mandate. This work introduces an onboard real-time multi-task learning framework that combines Transformer neural networks and reservoir computing (RC) architectures to enhance outdoor UAV operations. The proposed system employs the Transformer-based architecture to capture the temporal dependencies in sequential data for long-term horizons, while RC-based networks are utilized to ensure robust and real-time performance. Specifically, custom multi-task models are implemented and fine-tuned to collect multi-modal sensor measurements, aiming to enhance the two-fold objective of simultaneous UAV state identification and trajectory prediction through shared feature learning. A dataset comprised of measurements collected from real-world UAV operations (in 3D space) under various conditions is employed to train and evaluate the proposed system. Furthermore, a prototype onboard UAV system is implemented and tested in real-world field experiments. Extensive evaluations of the experimental results demonstrate that the onboard framework achieves accuracy close to the ground truth in both state identification and trajectory prediction, consequently showcasing its potential for practical applications.",10.1145/3725893,2025,,ACM,10.1145/3725893
CLOCK: Online Temporal Hierarchical Framework for Multi-scale Multi-granularity Forecasting of User Impression,"User impression forecasting underpins various commercial activities, from long-term strategic decisions to short-term automated operations. As a representative that involves both kinds, the highly profitable Guaranteed Delivery (GD) advertising focuses mainly on promoting brand effect by allowing advertisers to order target impressions weeksin advance and get allocatedonline at the scheduled time. Such a business mode naturally incurs three issues making existing solutions inferior: 1) Timescale-granularity dilemma of coherently supporting the sales of day-level impressions of the distant future and the corresponding fine-grained allocation in real-time. 2) High dimensionality due to the Cartesian product of user attribute combinations. 3) Stability-plasticity dilemma of instant adaptation to emerging patterns of temporal dependency withoutcatastrophic forgetting of repeated ones facing the non-stationary traffic.To overcome the obstacles, we propose an online temporal hierarchical framework that functions analogously to a CLOCK and hence its name. Long-timescale, coarse-grained temporal data (e.g., the daily impression of one quarter) and short-timescale but fine-grained ones are handled separately by dedicated models, just like the hour/minute/second hands. Each tier in the hierarchy is triggered for forecasting and updating by need at different frequencies, thus saving the maintenance overhead. Furthermore, we devise a reconciliation mechanism to coordinate tiers by aggregating the separately learned local variance and global trends tier by tier. CLOCK solves the dimensionality dilemma by subsuming the autoencoder design to achieve an end-to-end, nonlinear factorization of streaming data into a low-dimension latent space, where a neural predictor produces predictions for the decoder to project them back to the high dimension. Lastly, we regulate the CLOCK's continual refinement by combining the complementary Experience Replay (ER) and Knowledge Distillation (KD) techniques to consolidate and recall previously learned temporal patterns. We conduct extensive evaluations on three public datasets and the real-life user impression log from the Tencent advertising system, and the results demonstrate CLOCK's efficacy.",10.1145/3583780.3614810,2023,,ACM,10.1145/3583780.3614810
A comparison of spatio-temporal prediction methods: a parking availability case study,"In this paper, we present a comparative analysis of Statistical, Machine Learning and Deep Learning spatio-temporal models for parking occupancy prediction1. We evaluate such models on three public datasets, which are enriched by a set of hand-crafted features to take into account the temporal and spatial components when they are not natively handled by a model. Two approaches for this regression task are investigated: a univariate one and a multivariate one. In the former, we build a separate model for each parking lot. In the latter, a single model is used to predict the availability of all parking lots so as to learn the interactions and the co-movements among all time-series. All models exhibit similar performance. However, we highlight the higher effectiveness of gradient boosted methods when encompassing both temporal and spatial awareness in the feature space and of deep-learning models that take into account the spatial structure of the data.",10.1145/3477314.3507035,2022,,ACM,10.1145/3477314.3507035
TraStrainer: Adaptive Sampling for Distributed Traces with System Runtime State,"Distributed tracing has been widely adopted in many microservice systems and plays an important role in monitoring and analyzing the system. However, trace data often come in large volumes, incurring substantial computational and storage costs. To reduce the quantity of traces, trace sampling has become a prominent topic of discussion, and several methods have been proposed in prior work. To attain higher-quality sampling outcomes, biased sampling has gained more attention compared to random sampling. Previous biased sampling methods primarily considered the importance of traces based on diversity, aiming to sample more edge-case traces and fewer common-case traces. However, we contend that relying solely on trace diversity for sampling is insufficient, system runtime state is another crucial factor that needs to be considered, especially in cases of system failures. In this study, we introduce TraStrainer, an online sampler that takes into account both system runtime state and trace diversity. TraStrainer employs an interpretable and automated encoding method to represent traces as vectors. Simultaneously, it adaptively determines sampling preferences by analyzing system runtime metrics. When sampling, it combines the results of system-bias and diversity-bias through a dynamic voting mechanism. Experimental results demonstrate that TraStrainer can achieve higher quality sampling results and significantly improve the performance of downstream root cause analysis (RCA) tasks. It has led to an average increase of 32.63\% in Top-1 RCA accuracy compared to four baselines in two datasets.",10.1145/3643748,2024,,ACM,10.1145/3643748
Large Language Model-Aware In-Context Learning for Code Generation,,10.1145/3715908,2025,,ACM,10.1145/3715908
Embracing Uncertainty for Equity in Resource Allocation in ML Training,"To reduce the Deep Learning (DL) model training time and hence resource consumption, it is critical to avoid stragglers. However, the dynamics and uncertainty features of resource availability pose a challenge to avoiding stragglers caused. To handle this challenge, we propose a Straggler-Avoiding job Scheduling approach (SAS), which smartly ensures that the tasks of a job receive resources with similar dynamics and uncertainty so that the tasks can complete at approximately the same time. Specifically, SAS uses an ML method to predict available resource amounts with probability in future times, groups nodes with similar available resource amounts and probabilities, and then assigns each job to one node group with the objective of minimizing job completion time (JCT). To reduce the decision making time, we also propose a reinforcement learning (RL) based scheduling approach (SAS-RL) that assigns each job to a node group. In addition, we propose a distributed parameter server (PS) load reassignment method to handle PS stragglers. Our trace-driven real experiments show that SAS reduce up to 45\% JCT and 63\% stragglers compared with existing job schedulers, and our PS load reassignment reduces up to 48\% JCT compared with the previous PS load distribution scheme.",10.1145/3605573.3605583,2023,,ACM,10.1145/3605573.3605583
Multi-Head Spatio-Temporal Attention Mechanism for Urban Anomaly Event Prediction,"Timely forecasting the urban anomaly events in advance is of great importance to the city management and planning. However, anomaly event prediction is highly challenging due to the sparseness of data, geographic heterogeneity (e.g., complex spatial correlation, skewed spatial distribution of anomaly events and crowd flows), and the dynamic temporal dependencies.In this study, we propose M-STAP, a novel Multi-head Spatio-Temporal Attention Prediction approach to address the problem of multi-region urban anomaly event prediction. Specifically, M-STAP considers the problem from three main aspects: (1) extracting the spatial characteristics of the anomaly events in different regions, and the spatial correlations between anomaly events and crowd flows; (2) modeling the impacts of crowd flow dynamic of the most relevant regions in each time step on the anomaly events; and (3) employing attention mechanism to analyze the varying impacts of the historical anomaly events on the predicted data. We have conducted extensive experimental studies on the crowd flows and anomaly events data of New York City, Melbourne and Chicago. Our proposed model shows higher accuracy (41.91\% improvement on average) in predicting multi-region anomaly events compared with the state-of-the-arts.",10.1145/3478099,2021,,ACM,10.1145/3478099
Parallel Connected LSTM for Matrix Sequence Prediction with Elusive Correlations,"This article is about a challenging problem called matrix sequence prediction, which is motivated from the application of taxi order prediction. Remarkably, the problem differs greatly from previous sequence prediction tasks in the sense that the time-wise correlations are quite elusive; namely, distant entries could be strongly correlated and nearby entries are unnecessarily related. Such distinct specifics make prevalent convolution-recurrence-based methods inadequate to apply. To remedy this trouble, we propose a novel architecture called Parallel Connected LSTM (PcLSTM), which integrates two new mechanisms, Multi-channel Linearized Connection (McLC) and Adaptive Parallel Unit (APU), into the framework of LSTM. Benefiting from the strengths of McLC and APU, our PcLSTM is able to handle well both the elusive correlations within each timestamp and the temporal dependencies across different timestamps, achieving state-of-the-art performance in a set of experiments demonstrated on synthetic and real-world datasets.",10.1145/3469437,2021,,ACM,10.1145/3469437
Predicting COVID-19 Spread from Large-Scale Mobility Data,"To manage the COVID-19 epidemic effectively, decision-makers in public health need accurate forecasts of case numbers. A potential near real-time predictor of future case numbers is human mobility; however, research on the predictive power of mobility is lacking. To fill this gap, we introduce a novel model for epidemic forecasting based on mobility data, called mobility marked Hawkes model. The proposed model consists of three components: (1) A Hawkes process captures the transmission dynamics of infectious diseases. (2) A mark modulates the rate of infections, thus accounting for how the reproduction number R varies across space and time. The mark is modeled using a regularized Poisson regression based on mobility covariates. (3) A correction procedure incorporates new cases seeded by people traveling between regions. Our model was evaluated on the COVID-19 epidemic in Switzerland. Specifically, we used mobility data from February through April 2020, amounting to approximately 1.5 billion trips. Trip counts were derived from large-scale telecommunication data, i.e., cell phone pings from the Swisscom network, the largest telecommunication provider in Switzerland. We compared our model against various state-of-the-art baselines in terms of out-of-sample root mean squared error. We found that our model outperformed the baselines by 15.52\%. The improvement was consistently achieved across different forecast horizons between 5 and 21 days. In addition, we assessed the predictive power of conventional point of interest data, confirming that telecommunication data is superior. To the best of our knowledge, our work is the first to predict the spread of COVID-19 from telecommunication data. Altogether, our work contributes to previous research by developing a scalable early warning system for decision-makers in public health tasked with controlling the spread of infectious diseases.",10.1145/3447548.3467157,2021,,ACM,10.1145/3447548.3467157
Block Popularity Prediction for Multimedia Storage Systems Using Spatial-Temporal-Sequential Neural Networks,"Predicting block popularity is of crucial importance for data placement in multi-tiered multimedia storage systems. Traditional methods, such as least recently used and exponential smoothing, are commonly employed to predict future block access frequencies and fail to achieve good performance for complex and changing access patterns. Recently, deep neural networks have brought great success to pattern recognition and prediction, which motivates us to introduce deep learning to solve the problem of block popularity prediction. In this paper, we first analyze and verify the temporal and spatial correlations among the multimedia I/O traces. Then, we design a multi-dimension feature to capture such correlations, which serves as the input of the designed deep neural network. A spatial-temporal-sequential neural network (STSNN) and its variants that capture the locality information, time dependency information, and block sequential information are proposed to predict the block popularity. We systematically evaluate our STSNN models against six baseline models from three different categories, i.e., heuristic methods, regression methods and neural network-based methods. Experiment results show that our proposed STSNN models are very promising for predicting block access frequencies under some of Huawei and Microsoft datasets and particularly achieve 2-6 times better performance compared with the baselines in terms of the I/O hit ratio, I/O recall rate and I/O prediction ratio under the Microsoft 64 MB-block dataset.",10.1145/3474085.3475495,2021,,ACM,10.1145/3474085.3475495
CPInformer for Efficient and Robust Compound-Protein Interaction Prediction,"Recently, deep learning has become the mainstream methodology for Compound-Protein Interaction (CPI) prediction. However, the existing compound-protein feature extraction methods have some issues that limit their performance. First, graph networks are widely used for structural compound feature extraction, but the chemical properties of a compound depend on functional groups rather than graphic structure. Besides, the existing methods lack capabilities in extracting rich and discriminative protein features. Last, the compound-protein features are usually simply combined for CPI prediction, without considering information redundancy and effective feature mining. To address the above issues, we propose a novel CPInformer method. Specifically, we extract heterogeneous compound features, including structural graph features and functional class fingerprints, to reduce prediction errors caused by similar structural compounds. Then, we combine local and global features using dense connections to obtain multi-scale protein features. Last, we apply ProbSparse self-attention to protein features, under the guidance of compound features, to eliminate information redundancy, and to improve the accuracy of CPInformer. More importantly, the proposed method identifies the activated local regions that link a CPI, providing a good visualisation for the CPI state. The results obtained on five benchmarks demonstrate the merits and superiority of CPInformer over the state-of-the-art approaches.",10.1109/tcbb.2022.3144008,2022,,ACM,10.1109/tcbb.2022.3144008
A Recurrent Spatio-Temporal Graph Neural Network Based on Latent Time Graph for Multi-Channel Time Series Forecasting,"With the advancement of technology, the field of multi-channel time series forecasting has emerged as a focal point of research. In this context, spatio-temporal graph neural networks have attracted significant interest due to their outstanding performance. An established approach involves integrating graph convolutional networks into recurrent neural networks. However, this approach faces difficulties in capturing dynamic spatial correlations and discerning the correlation of multi-channel time series signals. Another major problem is that the discrete time interval of recurrent neural networks limits the accuracy of spatio-temporal prediction. To address these challenges, we propose a continuous spatio-temporal framework, termed Recurrent Spatio-Temporal Graph Neural Network based on Latent Time Graph (RST-LTG). RST-LTG incorporates adaptive graph convolution networks with a time embedding generator to construct a latent time graph, which subtly captures evolving spatial characteristics by aggregating spatial information across multiple time steps. Additionally, to improve the accuracy of continuous time modeling, we introduce a gate enhanced neural ordinary differential equation that effectively integrates information across multiple scales. Empirical results on four publicly available datasets demonstrate that the RST-LTG model outperforms 19 competing methods in terms of accuracy.",10.1109/lsp.2024.3479917,2024,7,IEEE,10.1109/lsp.2024.3479917
Global-local Spatiotemporal Graph Neural Network for Power Load Forecasting,"Accurate power load forecasting is crucial for efficient grid management, benefiting production and living. However, traditional methods based on recurrent neural network fail to capture spatial details and complex inter-enterprise relationships, leading to prediction accuracy limitations. To solve this problem, this paper uses graph neural network (GNN) to capture the complex enterprises relationships, and recurrent neural network (RNN) to capture the spatiotemporal power load dependencies. Moreover, the unique characteristics of enterprise power consumption mode make local feature also an important factor in multivariable power load forecasting. Finally, a Global-local Spatiotemporal Graph Neural Network (GL-STGNN) model is proposed to improve the accuracy of power load forecasting. The model uses GRU and GCN to capture spatiotemporal dependence, discrete Fourier transform (DFT)to extract frequency domain features, and node Embedding to fuse features in encoders and decoders, thus comprehensively considering local features and global information. Experiments show improved accuracy and practical forecasting effectiveness over traditional approaches.",10.1109/iccepe62686.2024.10931504,2024,,IEEE,10.1109/iccepe62686.2024.10931504
$\mathrm{S}^{2}$-GNN: Time Series Forecasting with a Multi-Scale Adaptive Graph Neural Network Integrating Spatial and Spectral Graph Convolutions,"Existing multivariate time series forecasting (MTSF) methods have begun to explore architectures built entirely upon Graph Neural Networks (GNNs). Directly connecting variables across different timestamps with a fully connected adjacency matrix introduces unnecessary noise and ignores the inherent temporal ordering between nodes. Besides this, the limited depth of Spatial graph convolutional layers restricts the ability of the model to capture long-term dependencies. We propose $\text{S}^{\text{2}}$-$\text{GNN}$, a multi-scale adaptive graph neural network method, which fusion spatial and spectral graph convolutions. An adaptive mechanism is used to capture the unidirectional relationship between nodes at different timestamps, which enables the construction of a graph structure that preserves the temporal order. Multi-order neighbor information and original node features are fused at each layer of spatial graph convolution to improve the local feature extraction capability of the spatial graph convolution. $\text{S}^{\text{2}}$-GNN introduces spectral graph convolution and applies singular value decomposition (SVD) in the frequency domain to decompose the adjacency matrix and implement spectral graph convolution, which enables the extraction of key structural information and provides a compact representation of global spatio-temporal dependencies. We conduct extensive experiments on 7 public datasets for time series forecasting. The experimental results show that the $\text{S}^{\text{2}}$-GNN outperforms typical baseline models in time series forecasting tasks.",10.1109/ispa67752.2025.00084,2025,,IEEE,10.1109/ispa67752.2025.00084
Multi-site Forecasting of Energy Time Series with Spatio-Temporal Graph Neural Networks,"Climate change has prompted the energy sector to shift its focus to renewable energy sources, which are environmentally friendly but less in terms of cost, complexity, and plants' management. It becomes critical to have a reliable method for estimating the output power of these systems, which are dispersed across the country and vary in kind and technology, and whose output power is mostly determined by meteorological factors. In this paper, we exploit the capability of modeling dynamic graph-like data of a specific type of graph neural network, spatio-temporal graph neural network, which can process spatial information about plants' distribution in a particular region as well as temporal data on individual plant power production. Plants in the same region can share information and make more accurate forecasts in this way. The suggested model was evaluated on two types of datasets: one with data gathered from real photovoltaic systems and the other with synthesized power time series reconstructed from data acquired by satellite detection. Our studies discovered how these systems can estimate the production outputs of photovoltaic stations simultaneously and with higher accuracy with respect to previous state-of-the-art models, performing effectively even in the absence of meteorological data.",10.1109/ijcnn55064.2022.9892160,2022,4,IEEE,10.1109/ijcnn55064.2022.9892160
Limited Data Forecasting of Financial Time-Series Using Graph-Based Class Dynamics,"This paper addresses the issue of limited data in financial time series forecasting, a challenge regularly faced in the context of newly listed companies. While deep learning models excel at learning relevant representations for forecasting, their efficacy is hindered by the need for substantial data. To over-come this limitation, we propose a forecasting model that takes advantage of transfer learning using graph neural networks. Our model is constructed based on the assumption that a company's stock price is affected not only by the pertinent economic factors specific to the company but also by the shared class-specific factors within its business sector. The model comprises three neural network modules: $i$) a module that captures the individual dynamics of a company, ii) a graph neural network (GNN) that captures class-specific dynamics in which the graph is learned from the data, and iii) a module that integrates both the individual and the class-specific dynamics. We propose a novel transfer learning approach to train the GNN, enhancing its efficiency in forecasting time series with limited historical data. Experimental results on real financial time series demonstrate improved forecasting accuracy when incorporating information from class-specific time series.",10.23919/eusipco63174.2024.10714981,2024,,IEEE,10.23919/eusipco63174.2024.10714981
Spatio-Temporal Graph Neural Networks for Aggregate Load Forecasting,"Accurate forecasting of electricity demand is a core component of the modern electricity infrastructure. Several approaches exist that tackle this problem by exploiting modern deep learning tools. However, most previous works focus on predicting the total load as a univariate time series forecasting task, ignoring all fine-grained information captured by the smart meters distributed across the power grid. We introduce a methodology to account for this information in the graph neural network framework. In particular, we consider spatio-temporal graphs where each node is associated with the aggregate load of a cluster of smart meters, and a global graph-level attribute indicates the total load on the grid. We propose two novel spatio-temporal graph neural network models to process this representation and take advantage of both the finer-grained information and the relationships existing between the different clusters of meters. We compare these models on a widely used, openly available, benchmark against a competitive baseline which only accounts for the total load profile. Within these settings, we show that the proposed methodology improves forecasting accuracy.",10.1109/ijcnn55064.2022.9892780,2022,4,IEEE,10.1109/ijcnn55064.2022.9892780
Spatial Temporal Graph Transformers for Probabilistic Load Forecasting,"Ensuring a balance between electricity supply and demand is crucial for effective energy generation and scheduling. To this end, accurate probabilistic energy prediction is essential. In this paper, we introduce a novel transformer-based framework, Spatial Temporal Graph Transformers (STGT), designed to estimate probability distributions for future time series data. By combining Graph Neural Networks (GNNs) with Transformers, STGT is able to extract both temporal and spatial features, ultimately resulting in more reliable and accurate probability predictions. The architecture of STGT consists of a transformer decoder to capture historical load data and a graph neural network to model the spatial relationships present across different user loads. Additionally, quantile regression is utilized to model load probability distributions. Through extensive experiments conducted on real-world load time series datasets, we demonstrate that STGT outperforms alternative approaches in both point prediction and probabilistic prediction accuracy.",10.1109/csis-iac60628.2023.10364082,2023,1,IEEE,10.1109/csis-iac60628.2023.10364082
Causal-TSF: A Causal Intervention Approach to Mitigate Confounding Bias in Time Series Forecasting,"Time series forecasting, aiming to learn models from historical data and predict future values in time series, is a fundamental research topic in machine learning. However, few efforts have been devoted to addressing the confounding effects in time series data, e.g., the historical data are affected by some hidden surrounding factors (i.e., confounders), leading to biased forecasting models for future data. This paper presents a causal intervention approach to eliminate the bias that is raised by some hidden confounders. By using a causal graph, we illustrate why hidden confounders can bring bias in time series forecasting and how to tackle it. We implement causal intervention by a deep architecture that consists of two modules, a Confounders Estimation module to estimate the hidden confounders and a Debiasing module to eliminate the confounding bias in the forecasting model via sampling on confounders. We conduct comprehensive evaluations on various time series datasets. The experiment results indicate that the proposed method can reduce the negative confounding effects in time series data, and it achieves superior gains over state-of-the-art baselines for time series forecasting.",10.1109/tkde.2025.3536107,2025,,IEEE,10.1109/tkde.2025.3536107
Multi-Level Knowledge Inheritance Graph Neural Network for Tobacco Pest Time-Series Forecasting,"The quality of tobacco raw materials is the decisive factor affecting the quality of cigarette products. The monitoring and forecasting of tobacco pest distribution in the factory is crucial in preventing the invasion of tobacco pests into the raw materials, thereby mitigating potential economic losses. However, traditional time series forecasting methods fail to deal with the multi-level spatial characteristics within the tobacco pest distribution data, therefore leading to poor forecasting performance. In this work, a multi-level knowledge inheritance graph network (MKIGN) is proposed to handle this problem. First, by creating virtual variables, a workshop-level dataset and a district-level dataset were generated from the original point-level dataset. Then, a multi-level graph network structure with an integrated knowledge inheritance strategy is designed, which will be applied to the two newly constructed datasets to capture the multi-level spatial characteristics of the tobacco pest distribution data. The effectiveness and superiority of the proposed method are illustrated on a real tobacco pest distribution dataset.",10.1109/iai63275.2024.10730675,2024,,IEEE,10.1109/iai63275.2024.10730675
Active Elastic Scaling Strategy Based on Spatio-Temporal Graph Neural Network,"The microservice architecture has accelerated the development of containerized deployment in cloud computing, with elastic scaling emerging as a key technology to address dynamic workloads. Traditional reactive strategies struggle to adapt to complex load fluctuations due to cold start latency and rigid resource allocation. Although proactive strategies have gained attention, their prediction accuracy remains challenging, especially as they often overlook the invocation relationships among microservices. To address this, this paper proposes a load prediction method based on a spatio-temporal graph neural network, which integrates Graph Attention Networks (GAT) to model spatial dependencies between microservices and Gated Recurrent Units (GRU) to capture temporal dynamics. Experimental results demonstrate that the proposed method outperforms traditional models in prediction accuracy.",10.1109/iccea65460.2025.11103345,2025,,IEEE,10.1109/iccea65460.2025.11103345
Research on Traffic Flow Forecasting Method Based on Graph Neural Network,"Traffic flow data are typical spatial-temporal data. Most of the traditional traffic flow prediction methods only consider the temporal correlation of data, but ignore the spatial correlation, so that the accuracy of prediction reduce. We summarizes the traffic flow prediction model based on graph neural network (GNN), starting from the basic definition of graph convolution, covering frequency domain and spatial domain graph convolution, and introducing the chebyshev network, graph convolution neural network (GCN) and graph attention network (GAT). We consider the spatial correlation of traffic flow, building three forecasting model based on Graph Neural Network, compared and analyzed the prediction results, which proves the effectiveness of the application of graph neural network in traffic flow prediction.",10.1109/seai55746.2022.9832353,2022,7,IEEE,10.1109/seai55746.2022.9832353
Time Series Forecasting with GCN-LSTM Based Unified Model for Product Demand Prediction,"This paper introduces LSTMGraph, a unified time-series model designed for demand prediction across multiple products. This method integrates Long Short-Term Memory (LSTM) networks to capture temporal dynamics, such as price fluctuations, and Graph Convolutional Networks (GCN) to model global dependencies between products. We represent demand data as a network where each product is a node, constructing three distinct graphs with different types of edges: (i) a weekly sales similarity graph, (ii) a customer-based relationship graph, and (iii) an invoice-based similarity graph. These graphs are merged to enhance predictive accuracy by incorporating diverse temporal and relational patterns. Extensive experiments show that LSTMGraph significantly outperforms existing baseline models. Additionally, an ablation study is conducted to quantify the impact of each graph type on overall performance.",10.1109/bigdata62323.2024.10825969,2024,,IEEE,10.1109/bigdata62323.2024.10825969
DNGNN: Efficient Deep Noisy Graph Neural Network for Spatio-Temporal Series Forecasting,"Spatio-temporal series forecasting plays a vital role in the domain of multivariate time series prediction. By leveraging accurate and comprehensive spatio-temporal sequence prediction models, it becomes possible to extract higher-order spatio-temporal interactions between real-world connections, thereby contributing to smart city construction. Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as a highly effective approach for addressing spatio-temporal series prediction challenges. Nevertheless, most existing methods predominantly rely on traditional graph convolutional networks (GCNs) and their variants for spatial feature extraction. Due to inherent limitations such as over-smoothing, these models often constrain spatial feature encoding to shallow architectures, typically limited to 2-3 layers. Additionally, the presence of noisy data in real-world scenarios significantly impacts the prediction accuracy of existing STGNN models. In this paper, building upon the classic STGNN framework, we propose a graph neural network framework based on deep residual connections and noise injection mechanism to address the aforementioned issues. Specifically, inspired by the principles of initial residual connection and identity mapping, we proposed a deep spatio-temporal graph neural network framework of 12 layers to capture the high-dimensional interactions, while using noise injection mechanism to mitigate the adverse effects of noisy data. Sufficient experimental results on typical time-series datasets demonstrate the effectiveness of our proposed framework.",10.1109/asens64990.2025.11011208,2025,,IEEE,10.1109/asens64990.2025.11011208
Multi-Scenario Cellular KPI Prediction Based on Spatiotemporal Graph Neural Network,"With the increasing demand for high-quality telecommunication services, cellular KPI prediction becomes crucial for telecommunication network monitoring and management. In this work, we propose a novel framework for cellular KPI prediction, which considers its distribution discrepancy under different network operation scenarios. In particular, three specific predictors for normal, target alarm, and neighbor alarm scenarios are proposed based on spatiotemporal graph neural networks and unified through transfer learning. Temporal convolution and attention mechanism are embedded to model the impact of anomalies on KPIs and its propagation across neighboring cells according to the cellular network topology. An experiment on a real cellular KPI dataset shows the effectiveness of the proposed method compared to the state-of-the-arts. Note to Practitioners—Cellular network KPI prediction under scenarios of network alarms is crucial to evaluate the impact of alarms on network services and guides cellular network maintenance policies. This problem is similar to a general multivariate time series prediction problem with data multimodality. However, the first challenge in our case is that, under different scenarios, i.e., normal, target alarm, and neighbor alarm, the effective information and spatiotemporal dependencies among KPIs are different. The second challenge is the imbalanced or sparse sample size for specific scenarios, deteriorating the model performance. This paper proposes a cellular KPI prediction framework consisting of three scenario-specific predictors with similar but different modules to process different scenario-specific data. To address the dataset imbalance across scenarios, we adopt a transfer learning strategy to unify the training and prediction of three predictors. The experiment results on a real cellular KPI dataset demonstrate that the proposed framework is more feasible and effective than the state-of-the-art models for multivariate time series prediction. Future research can consider developing maintenance policies such that the cost caused by abnormal KPIs can be minimized.",10.1109/tase.2024.3416952,2025,3,IEEE,10.1109/tase.2024.3416952
Gaia: Graph Neural Network with Temporal Shift aware Attention for Gross Merchandise Value Forecast in E-commerce,"E-commerce has gone a long way in empowering merchants through the internet. In order to store the goods efficiently and arrange the marketing resource properly, it is important for them to make the accurate gross merchandise value (GMV) prediction. However, it's nontrivial to make accurate prediction with the deficiency of digitized data. In this article, we present a solution to better forecast GMV inside Alipay app. Thanks to graph neural networks (G NN) which has great ability to correlate different entities to enrich information, we propose Gaia, a graph neural network (GNN) model with temporal shift aware attention. Gaia leverages the relevant e-seller’ sales information and learn neighbor correlation based on temporal dependencies. By testing on Alipay's real dataset and comparing with other baselines, Gaia has shown the best performance. And Gaia is deployed in the simulated online environment, which also achieves great improvement compared with baselines.",10.1109/icde53745.2022.00313,2022,5,IEEE,10.1109/icde53745.2022.00313
HiGraph: Learning Hierarchical Graph for Multivariate Time Series Anomaly Detection in Microservice Systems,"Microservices enable flexible, scalable, and efficient application development in cloud environments. A service instance is a chain of microservices running in virtual pods. The service invocation trace and the pod performance metrics are recorded and analyzed to detect anomalies and ensure system stability. Spatiotemporal graph neural network models are popular for time-series representation as they can capture intra- and inter-correlation of time series. However, we find that the performance of anomaly detection depends on the dynamic correlation between containers in microservice system greatly, but has not been considered in existing work. To capture the correlation both on pod level and metric level, we propose a hierachcical graph neural network model, HiGraph, cascading of MetricLayer and PodLayer modules. MetricLayer is used to compute the correlation between metrics through mutual information. PodLayer is used to learn the dynamical correlation of the pods from trace data. It is important to note that trace data continuously records calls, while metric data has a sampling interval, making temporal alignment difficult. To address this, we innovatively use the edge weights of the graph to align them. We count the call frequency between different pods in the trace data over a specific period to update the weights of the spatial correlation graph. Extensive experiments on real data demonstrate that HiGraph improves RMSE by 4.9%, MAE by 4.8%, F1-score by 4.2% and recall by 9.2% compared to the best baseline.",10.1109/wccct65447.2025.11028023,2025,,IEEE,10.1109/wccct65447.2025.11028023
QSTGNN: Quaternion Spatio-Temporal Graph Neural Networks,"Spatio-temporal time series forecasting has attracted great attentions in various fields, including climate, power, and traffic forecasting. Recently, Spatio-temporal Graph Neural Networks (STGNNs) have shown promising performances in modeling spatial dependencies based on graph neural networks (GNNs) and temporal dependencies based on temporal learning modules. However, most STGNNs do not effectively integrate explicit and implicit relationships between nodes, nor do they adequately capture long and short-term time dependencies. To address these challenges, this paper presents a Quaternion Spatio-temporal Graph Neural Network (QSTGNN). Specifically, the quaternion spatio-temporal graph is constructed firstly, such that the information of both short and long-term time steps are preserved in quaternion feature tensor, and information of multiple explicit graphs and implicit graph are integrated in quaternion graph adjacency matrix. Then, two modules are designed: a 1D quaternion convolution module and a quaternion graph convolution module. In the 1D quaternion convolution module, complex temporal correlations among short and long-term time steps can be well exploited by 1D quaternion convolution operator based on the quaternion Hamilton product. In the quaternion graph convolution module, quaternion graph convolution is designed to characterize nonlinear dependencies among multiple spatial graphs, including explicit and implicit graphs. Extensive experiments are conducted on six datasets, and the results show that QSTGNN achieves state-of-the-art performances over the existing ten methods. Explainable analysis presents that multiple spatial correlations can accurately illustrate the traffic flow and road functional information in real traffic roads.",10.1109/tkde.2025.3571983,2025,,IEEE,10.1109/tkde.2025.3571983
SAGoG: Similarity-Aware Graph of Graphs Neural Networks for Multivariate Time Series Classification,"Multivariate Time Series Classification (MTSC) has important research significance and practical value. Deep learning models have achieved considerable success in addressing MTSC problems. However, a key challenge faced by existing classification models is how to effectively consider the correlations between time series instances and across channels simultaneously, as well as how to capture the dynamic of these inter-channel correlations over time. Current methods often fall short in these aspects: on one hand, they fail to fully account for the combined effects of inter-instance and inter-channel correlations; on the other hand, they largely overlook the dynamic nature of how inter-channel correlations change over time. To address these issues, we propose a novel graph neural network model, called Similarity-Aware Graph of Graphs neural networks (SAGoG), for multivariate time series classification. This model can comprehensively consider the dependencies between channel-level and instance-level time series, it dynamically learns dependency features through graph structure evolution and graph pooling layers. We conduct experiments on the UEA dataset to validate the SAGoG model, and the results demonstrate its outstanding performance in multivariate time series classification tasks.",10.1109/tkde.2025.3572216,2025,,IEEE,10.1109/tkde.2025.3572216
Towards Expressive Spectral-Temporal Graph Neural Networks for Time Series Forecasting,"Time series forecasting has remained a focal point due to its vital applications in sectors such as energy management and transportation planning. Spectral-temporal graph neural network is a promising abstraction underlying most time series forecasting models that are based on graph neural networks (GNNs). However, more is needed to know about the underpinnings of this branch of methods. In this paper, we establish a theoretical framework that unravels the expressive power of spectral-temporal GNNs. Our results show that linear spectral-temporal GNNs are universal under mild assumptions, and their expressive power is bounded by our extended first-order Weisfeiler–Leman algorithm on discrete-time dynamic graphs. To make our findings useful in practice on valid instantiations, we discuss related constraints in detail and outline a theoretical blueprint for designing spatial and temporal modules in spectral domains. Building on these insights and to demonstrate how powerful spectral-temporal GNNs are based on our framework, we propose a simple instantiation named Temporal Graph Gegenbauer Convolution (TGGC), which significantly outperforms most existing models with only linear components and shows better model efficiency.",10.1109/tpami.2025.3545671,2025,4,IEEE,10.1109/tpami.2025.3545671
Hybrid Temporal-Spatial Energy Prediction in Wireless Sensor Networks using Transformer and Graph Neural Network Models,"Wireless Sensor Networks (WSNs) are widely used in a variety of applications, but energy efficiency is still a major concern. Accurate energy prediction can dramatically improve network lifetime and performance. This study investigates energy prediction in WSNs with transformer-based models and graph neural networks (GNNs). Our tests show that our hybrid model improves network lifespan by 15%, with a Mean Squared Error (MSE) of 0.034 and an R-squared score of 0.92. It does this better than baseline models like LSTM and standalone GNNs. The suggested method takes into account both time and space dependencies, which leads to better resource allocation and a longer network lifespan.",10.1109/iccmc65190.2025.11140970,2025,,IEEE,10.1109/iccmc65190.2025.11140970
Causalformer: Causal Discovery-based Transformer for Multivariate Time Series Forecasting,"The forecasting of time series is finding increasingly widespread applications in real-world scenarios, such as medical data and electricity consumption. Recent work primarily employs the Transformer and its variant to capture broad temporal dependencies from time series. However, most approaches often overly focus on the impact of temporal relation, while neglecting the interactions among multivariate elements, and lacking the application of causal relationships. Int the paper, we introduce a Transformer variant based on causal discovery to discover and utilize causal relationships, termed the Causalformer. Our Causalformer not only captures temporal features but also learns a Granger causality graph from multivariate time series, resulting in a sparse adjacency matrix that represents the causal relationships between variables. This allows us to leverage causal relationships to estimate the degree of influence among multivariate elements, thereby further enhancing forecast accuracy. Building upon this, we configure the decoder part as multi-headed output to utilize the causal matrix for understanding how each variable is influenced by others. To accelerate the model’s learning speed, we also design the decoder as generative, allowing it to output an extended time series sequence in a single shot rather than step-by-step, significantly improving inference efficiency. We conduct experiments on three datasets. In most cases, the forecast results were significantly better than other baselines, and the accuracy of causal discovery was not significantly different from that of SOTA.",10.1109/cisp-bmei60920.2023.10373365,2023,3,IEEE,10.1109/cisp-bmei60920.2023.10373365
Unified Spatio-Temporal Graph Neural Networks: Data-Driven Modeling for Social Science,"Time series forecasting with additional spatial de-pendencies has attracted a tremendous amount of research interest in social sciences, due to its importance in modern real-world applications. The Graph Neural Networks (GNN) is one of the most exciting deep learning techniques among these spatio-temporal modeling approaches. Most existing spatio-temporal GNN frameworks are based on a two-step modeling process. In such scenario, spatial and temporal dependencies are modeled in separate steps, which lead to problems such as complex architecture design, hard to scale, etc. Targeting the shortcomings of existing studies, we take both spatial and temporal dependencies from another perspective, and consider them as two heterogeneous types of edges in the graph. We propose a unified spatio-temporal GNN framework that captures both dependencies in a single step. More specifically, for each node in the graph, a unified neural network component is designed to simultaneously extract information from its sur-rounding neighbors (spatial) and its past records (temporal), which enables much easier dependency aggregation with faster execution. Experiment results demonstrate the superiority of the proposed framework over state-of-the-art (SOTA) baselines on various applications, including modeling smart cities and data-driven political science research.",10.1109/ijcnn55064.2022.9892911,2022,,IEEE,10.1109/ijcnn55064.2022.9892911
Multivariate Time Series Forecasting with Transfer Entropy Graph,"Multivariate Time Series (MTS) forecasting is an essential problem in many fields. Accurate forecasting results can effectively help in making decisions. To date, many MTS forecasting methods have been proposed and widely applied. However, these methods assume that the predicted value of a single variable is affected by all other variables, ignoring the causal relationship among variables. To address the above issue, we propose a novel end-to-end deep learning model, termed graph neural network with neural Granger causality, namely CauGNN, in this paper. To characterize the causal information among variables, we introduce the neural Granger causality graph in our model. Each variable is regarded as a graph node, and each edge represents the casual relationship between variables. In addition, convolutional neural network filters with different perception scales are used for time series feature extraction, to generate the feature of each node. Finally, the graph neural network is adopted to tackle the forecasting problem of the graph structure generated by the MTS. Three benchmark datasets from the real world are used to evaluate the proposed CauGNN, and comprehensive experiments show that the proposed method achieves state-of-the-art results in the MTS forecasting task.",10.26599/tst.2021.9010081,2023,38,IEEE,10.26599/tst.2021.9010081
Effective Time Series Prediction Model using Transformer based Graph Neural Network,"In last few areas, time series prediction has become a crucial task in fields such as traffic management, finance and energy demand prediction, which aims at predicting the future values based on the past observations. However, the existing transformer-based model combined with Convolutional Neural Network (CNN) and attention mechanism failed to capture dynamic intervariable relationships and faced high computational costs. Hence, to overcome this limitation, a hybrid graph-based transformer namely, Transformer Graph Neural Network (TransGNN) is proposed for accurate and reliable time series predictions. Initially, the real-world traffic data is collected from the traffic dataset. After that, the collected data is preprocessed using data cleaning technique to handle missing values, outliers are removed by Inter Quartile Range (IQR) and normalization is performed using z score normalization. Furthermore, these normalized data is represented as graph, where nodes represent sensors and edges represents the spatiotemporal relationships. Then, these graph representations are fed to the TransGNN, where CNN captures the local and global patterns and GNN captures the spatial relationships. Lastly, these features are fused to perform accurate and reliable time series predictions.",10.1109/icdsis65355.2025.11070842,2025,,IEEE,10.1109/icdsis65355.2025.11070842
GNN4W: Graph Neural Network for Dual Active Bridge Converter Waveform Modeling with Operational Generalization,"Temporal modeling of dual active bridge (DAB) converters can not only obtain more comprehensive waveform information but also capture the transient response and dynamic characteristics of the system more accurately. However, existing data-driven temporal modeling methods are subject to many limitations in practical applications due to their high dependence on large-scale training data and insufficient out-of-domain generalization capability. To address these challenges, this paper proposes a GNN4W temporal modeling method. Different from the traditional long and short-term memory (LSTM) networks, the proposed method introduces graph neural networks to extract spatial topological features of DAB converters. Through feature fusion, these features are combined with key temporal characteristics to construct a comprehensive feature representation. Comprehensive algorithm experiment results show that with 10% of training data, the mean squared error and mean absolute error of the proposed GNN4W method are reduced by 77.80% and 50.52% compared to LSTM and exhibit good out-of-domain generalization ability. In addition, 1 kW hardware experiments further validate the feasibility of the approach.",10.1109/ecce58356.2025.11260305,2025,,IEEE,10.1109/ecce58356.2025.11260305
Cross Domain Transfer Learning Techniques for Residential Energy Forecasting,"Residential energy prediction has been accomplished by various techniques. For the improvement of residential energy forecasting in terms of accuracy and efficiency, a Graph Neural Network (GNN) model with transfer learning capacity and Temporal Fusion Transformer (TFT) model have been adopted and compared in this study. Group 1 utilizes the designed GNN model, and Group 2 utilizes the TFT model. Both models use a sample size of 20 datasets and analyze various time periods and trends in energy usage. The predictive accuracy, training time, computational complexity, and flexibility of both models are compared. With a 2.7% increase in prediction accuracy, 35% decrease in training time, 20% decrease in computational cost, and improved generalization across many residential energy datasets, the TFT model is superior to the GNN model. The results indicate that the suggested TFT model provides a more efficient and scalable residential energy forecasting method compared to the GNN model with better computing efficiency and flexibility.",10.1109/icc-robins64345.2025.11086132,2025,,IEEE,10.1109/icc-robins64345.2025.11086132
Graph Neural Networks for Model Recommendation using Time Series Data,"Time series prediction aims to predict future values to help stakeholders make proper strategic decisions. This problem is relevant in all industries and areas, ranging from financial data to demand to forecast. However, it remains challenging for practitioners to select the appropriate model to use for forecasting tasks. With this in mind, we present a model architecture based on Graph Neural Networks to provide model recommendations for time series forecasting. We validate our approach on three relevant datasets and compare it against more than sixteen techniques. Our study shows that the proposed method performs better than target baselines and state of the art, including meta-learning. The results show the relevancy and suitability of GNN as methods for model recommendations in time series forecasting.",10.1109/icmla51294.2020.00236,2020,3,IEEE,10.1109/icmla51294.2020.00236
Enhancing Financial Forecasting with a Hybrid LSTM-Graph Neural Network Model,"Forecasting stock prices is inherently challenging due to the dynamic and intricate nature of financial data. This research introduces an innovative model that integrates Long Short-Term Memory (LSTM) networks with Graph Neural Networks (GNN), addressing limitations of standalone approaches. Unlike conventional methods that separately analyze temporal patterns or interrelationships among stocks, this hybrid model processes both dimensions concurrently. This dual capability significantly enhances prediction precision and establishes a fundamental stock market information to validate its effectiveness. By combining the strengths of LSTM in capturing temporal dependencies and GNN in modeling relationships between stocks, the hybrid model achieves notable improvements over traditional machine learning and individual models. Experimental results demonstrate superior performance, evidenced by reduced Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) values, as well as higher R2 scores, underscoring its accuracy and reliability. This model offers promising applications in domains such as financial forecasting, algorithmic trading, and portfolio optimization. By addressing both the temporal and relational complexities of stock data, the proposed approach sets a new benchmark for predictive analytics in the financial sector. Its ability to provide more accurate forecasts not only supports better decision-making but also opens avenues for further advancements in predictive modeling and financial technology.",10.1109/giet65294.2025.11234865,2025,,IEEE,10.1109/giet65294.2025.11234865
Handover Forecasting in Cellular Networks: A Spatio-temporal Graph Neural Network Approach,"The proliferation of connected devices, as well as the continuous integration of data demanding applications, have brought significant challenges to mobile network operators. Indeed, mobile networks need to accommodate the resulting exponential growth of traffic, while still ensuring a decent Quality of Service (QoS) and Quality of Experience (QoE) to their users. To do so, adequate management solutions are needed. So far, a variety of problems have been tackled, including resource allocation and network planning. Yet, handovers (HO) management has not received much attention, despite its importance for users QoS and QoE. In this work, we study the problem of mobile devices HO forecasting, over time, among base stations. To solve the problem, we introduce a Handover Graph Convolutional Long Short-Term Memory (HGC-LSTM) neural network forecasting approach. Our approach allows capturing spatio-temporal correlations among neighboring pairs of base stations in the forecasting process. The evaluation on a real-world dataset shows that the proposed HGC-LSTM approach outperforms other methods in the state-of-art in terms of accuracy and execution time.",10.1109/nof58724.2023.10302814,2023,4,IEEE,10.1109/nof58724.2023.10302814
FGNet: Feature Engineering-Guided Attentive Graph Neural Network for SOH Estimation of Lithium Battery,"The precise estimation of the state-of-health (SOH) in lithium-ion battery (LIB) holds significant importance for ensuring the safe operation of electric vehicles (EVs). While existing methods predominantly center around conventional recurrent neural networks (RNNs), these approaches inherently encounter challenges in effectively extracting features and modeling ultra-long-term time-series data. In this article, we introduce a novel time-series prediction framework that integrates feature engineering with an attentive graph neural network (GNN) to enhance the accuracy and efficiency of SOH estimation for lithium batteries. Specifically, we begin by extracting health factors (HFs) from the original charge and discharge data of the battery. Subsequently, we identify 3-D features exhibiting strong correlations, which serve as the primary inputs for the network. Our proposed network, termed the feature engineering-guided attentive graph neural network (FGNet), is designed to comprehensively capture and model the intricate relationships between HFs and SOH output. This is achieved by embedding both the feature extraction module and the attention module within the GNN architecture. Extensive experiments are conducted using the Center for Advanced Life Cycle Engineering (CALCE) aging dataset and National Aeronautics and Space Administration (NASA) battery dataset. The results substantiate the superiority of our method over existing state-of-the-art methods, with a mean absolute error (MAE) consistently averaging below 2%.",10.1109/tte.2024.3492135,2025,6,IEEE,10.1109/tte.2024.3492135
Spatiotemporal Learning With Decoupled Causal Attention for Multivariate Time Series,"In multivariate time series prediction tasks, the inter- and intra-variable relations have significant influence on prediction outcomes. In many engineering and industrial scenarios, the multivariate time series also contain a large number of subjective influencing factors, such as settings and behaviors of users. Existing learning methods neglect the interactions of these subjective factors among variables. This leads to the learning of incorrect inter-variable influences, consequently yielding inaccurate prediction results. To address this challenge, we propose a Decoupled Casal Attention Network (DECA) for multivariate time series prediction from a spatiotemporal learning perspective. multivariate time series prediction. The causality decoupling module, based on the captured causal relations among variables, disentangles the subjective factors from the objective factors. Then the objective learning module utilizes an objective causal attention to capture objective cross-variable dependencies; while the subjective learning module utilizes a subjective causal graph attention to capture subjective influences. Finally, the prediction module fuses the multi-scale features of subjective and objective factors to produce predictions. The performance is evaluated using three benchmark datasets. Results indicate that, compared to state-of-the-art methods, DECA exhibits superior accuracy in multivariate time series prediction and can be effectively used for recommendations.",10.1109/tbdata.2024.3499312,2025,1,IEEE,10.1109/tbdata.2024.3499312
Temporal-Spatial Graph Neural Network for Wind Power Forecasting Considering the Blockage Effects,"Wind power forecasting (WPF) plays a critical role in ensuring the security, stability, and economics of the power grid. However, the variable nature of wind energy poses significant challenges to WPF accuracy, especially when considering the complex mutual influence between wind turbines in wind farms. To address this issue, a novel neural network for WPF has been proposed in this study. The proposed model utilizes a gated dilated inception network and graph neural network to learn temporal and spatial features concurrently. Additionally, a novel mechanism has been developed to calculate the mutual influence between wind turbines and improve forecasting accuracy by incorporating the blockage effect on each turbine. The proposed model has been validated on a real-world dataset for wind power forecasting with a prediction horizon of 48 hours. The experimental results demonstrate that the proposed model outperforms state-of-the-art methods in terms of forecasting accuracy. The study highlights the importance of considering the spatial and temporal features of wind farms to improve WPF accuracy and demonstrates the efficacy of the proposed model in addressing this challenge.",10.1109/icapai58366.2023.10193907,2023,,IEEE,10.1109/icapai58366.2023.10193907
Spatio-Temporal Based Architecture Topology Search for Multivariate Time Series Prediction,"Multivariate time series (MTS) prediction has been widely applied in a diverse range of fields including electricity, economics, finance, and traffic. Many studies have successfully constructed spatial and temporal convolution modules called spatio-temporal block (ST-block) for multivariate time series prediction. However, existing methods need to manually design the architecture topology based on ST-blocks, which is time-consuming and requires extensive expert experience. In this paper, we propose a Spatio-Temporal based Architecture Topology Search (STATS) method for multivariate time series prediction, which can automatically design the ST-block for multivariate time series prediction. In the STATS, we construct static and dynamic graphs topologically to integrate both static and dynamic information to obtain more expressive ST-graphs for the prediction task. Then, STATS explores the architecture topology with the differentiable search algorithm based on ST-blocks automatically. Extensive experiments on four commonly used multivariate time series prediction benchmark datasets demonstrate that our proposed method STATS can outperform the state-of-the-art baseline models.",10.1109/bigdata55660.2022.10020729,2022,2,IEEE,10.1109/bigdata55660.2022.10020729
Temporal Graph Transformer for Digital Twins of Waste Incineration Power Plant,"Digital twins play an important role in operating waste incineration power plants (WIPP). Existent works usually establish univariate forecasting models ignoring connection between variables, which leads to the inaccuracy of predicting critical metrics. This paper proposed a Graph Neural Network--based model considering dynamic correlations within the system. We first construct temporal dependence between sensors, then utilize Transformer as inference pipeline. With real data collected from a WIPP in China, we conducted numerical experiments whose results illustrate the outstanding performance of our model.",10.1109/mlise62164.2024.10674369,2024,,IEEE,10.1109/mlise62164.2024.10674369
A Dual-Prediction Framework for High-Energy Proton Flux Driven by Graph Neural Networks,"Predicting high-energy proton flux is essential for radiation-effect protection of satellite devices. We introduce a dual-prediction framework based on Graph Neural Networks (GNN) to model proton flux from both non-time-series and time-series perspectives. In the non-time-series approach, the model directly predicts proton flux at specific times using static inputs, allowing rapid assessment of each feature’s impact on prediction accuracy. In the time-series approach, the model utilizes historical data to capture the temporal dynamics of proton flux. The GNN effectively captures complex spatial correlations among input features, particularly under varying solar activity and magnetic-field conditions. Experimental results demonstrate that the GNN performs well in both approaches, with the time-series method achieving higher accuracy for long-term predictions. In both frameworks, the GNN serves as the core modeling tool, structuring spatial locations and geomagnetic variables into a graph to capture dependencies between different physical variables, particularly the complex interactions between solar wind and the geomagnetic field. This graph structure effectively enhances the model’s spatial dependency modeling capacity, aiding in accurately understanding and predicting the distribution patterns of high-energy proton flux.",10.1109/access.2025.3624417,2025,,IEEE,10.1109/access.2025.3624417
Prediction and analysis of ship traffic flow based on a space-time graph traffic computing framework,"Port traffic flow modeling based on big data is an important research direction in the shipping field, having the task of traffic forecasting for ports worldwide. Graph neural networks have a strong ability to capture the spatial topology characteristics and may be combined with recurrent neural networks or dilated convolution methods in time series prediction, producing a large number of spatiotemporal graph convolution models. Such models have been widely and successfully applied in traffic forecasting. Differing from urban traffic flow data, the statistical time span of port vessel flow and throughput data is large, its spatial span is wide, and the data experience significant fluctuations. Consequently, certain spatiotemporal graph convolution traffic prediction models are unsuitable for shipping scenarios. To address this shortcoming, we have created a unique port flow dataset based on automatic identification system (AIS) and port geographic data. Using theoretical analysis and experimental comparison, we have determined the most appropriate model for shipping predictions based on existing spatiotemporal graph models and have proposed model optimization recommendations for the maritime domain. Our experiment based on an open source traffic forecasting framework to compare the results of multiple existing spatiotemporal graph models under fair conditions with the central ports of Rotterdam, Shanghai, Boston, and Singapore. The results show that Graph WaveNet exhibits better performance in shipping scenarios.",10.1109/euc57774.2022.00014,2022,1,IEEE,10.1109/euc57774.2022.00014
Public Bicycle Flow Forecasting using Spatial and Temporal Graph Neural Network,"Public bicycle systems (PBSs) that connect end users’ houses to public mass transportation are typically viewed as the ""last-mile"" of public transportation. Because of the limited capacity of stations in a PBS, the PBS operator must dispatch bicycles between stations to ensure that there are always bicycles/spaces available for bicycle borrowing/returning. However, because the variances in flows among stations are large, bicycle dispatch is difficult without a precise flow forecasting approach. In this paper, we propose an innovative approach to forecast bicycle flow on the basis of a graph neural network (GNN). Instead of processing the temporal information using RNN, or 1D-CNN, our approach integrates both spatial and temporal information into graphs, and analyzes them using graph convolution. Our approach works well on NYCitibike open dataset in terms of prediction accuracy. From the experiment, our approach shows it capability in accurate forecasting of peak flows and self-adjustment while perceiving abnormal flows caused by sporadic situations.",10.1109/compsac57700.2023.00071,2023,,IEEE,10.1109/compsac57700.2023.00071
Learning Latent ODEs With Graph RNN for Multi-Channel Time Series Forecasting,"Forecasting tasks involving multi-channel time series data pervade numerous practical applications and have attracted significant attention. Spatio-temporal graph neural network models for multi-channel time series forecasting have recently gained traction, owing to their ability in capturing both spatial and temporal features. A common practice is the integration of graph convolutional networks with recurrent neural networks. However, the discrete intervals of recurrent neural networks pose limitations on the temporal resolution of time series forecasting, impeding the model's ability to capture subtle changes in the data. To address this challenge, we introduce a continuous spatio-temporal framework, termed Graph Ordinary Differential Equation Recurrent Network (GODERN). GODERN incorporates continuous recurrent neural networks with a learnable and directed graph convolution layer to model the spatio-temporal dynamics in latent space. Furthermore, given the actual time representation in GODERN, we propose a novel augmented method of neural ordinary differential equation with fast-slow dynamics, thus allowing the encapsulation of multi-scale information. Through our experiments, we demonstrate that GODERN achieves superior accuracy on four real-life datasets, outperforming 13 baseline models.",10.1109/lsp.2023.3320439,2023,6,IEEE,10.1109/lsp.2023.3320439
Graph-Enabled Reinforcement Learning for Time Series Forecasting With Adaptive Intelligence,"Reinforcement learning (RL) is renowned for its proficiency in modeling sequential tasks and adaptively learning latent data patterns. Deep learning models have been extensively explored and adopted in regression and classification tasks. However, deep learning has limitations, such as the assumption of equally spaced and ordered data, and the inability to incorporate graph structure in time-series prediction. Graph Neural Network (GNN) can overcome these challenges by capturing the temporal dependencies in time-series data effectively. In this study, we propose a novel approach for predicting time-series data using GNN, augmented with Reinforcement Learning(GraphRL) for monitoring. GNNs explicitly integrate the graph structure of the data into the model, enabling them to naturally capture temporal dependencies. This approach facilitates more accurate predictions in complex temporal structures, as encountered in healthcare, traffic, and weather forecasting domains. We further enhance our GraphRL model's performance through fine-tuning with a Bayesian optimization technique. The proposed framework surpasses baseline models in time-series forecasting and monitoring. This study's contributions include introducing a novel GraphRL framework for time-series prediction and demonstrating GNNs' efficacy compared to traditional deep learning models, such as Recurrent Neural Networks (RNN) and Long Short-Term Memory Networks(LSTM). Overall, this study underscores the potential of GraphRL in yielding accurate and efficient predictions within dynamic RL environments.",10.1109/tetci.2024.3398024,2024,10,IEEE,10.1109/tetci.2024.3398024
Anomaly Detection in IoT Networks using Graph Neural Networks,"The importance of anomaly detection in IoT device networks has gained much significance in enhancing security, enabling reliable monitoring and reducing potential threats. A deep learning model for detecting different types of cyberattacks on various devices using the autoencoder model and distinguishing normal patterns of traffic from malicious ones by using the RT-IoT2022 dataset is proposed. The proposed scheme uses GNN to perceive the environment for the identification and classification of real-time cyberattacks. It makes IoT devices more secure, stable and achieves high accuracy.The proposed GNN-based algorithm demonstrated an impressive 99% accuracy in the identification of anomalies in IoT networks, providing strong security and threat avoidance.",10.1109/iciss63372.2025.11076391,2025,,IEEE,10.1109/iciss63372.2025.11076391
MSPredictor: A Multi-Scale Dynamic Graph Neural Network for Multivariate Time Series Prediction,"In the field of multivariate time series prediction, capturing the dynamic relationships and complex cyclical patterns between sequences is key to improving prediction accuracy. To address this challenge, our paper introduces MSPredictor, a multi-scale dynamic graph neural network model, which uses Fast Fourier Transform for multi-scale decoupling in the frequency domain and employs Kolmogorov-Arnold Networks for multi-scale fusion, effectively extracting significant cyclical patterns. By decomposing the original series across different scales, MSPredictor accurately models complex cyclical patterns. To enhance the model's transparency and interpretability, we introduced the ClarityLens explanatory strategy, which employs visualization techniques to make the prediction process more transparent. Specifically, it displays the adjacency matrices learned at different scales, intuitively showing the dynamic correlations between series. We also visualized the proportion of different periods in the prediction results and the specific forecasting performance at each time scale. Extensive testing on multiple real-world datasets has demonstrated that the MSPredictor significantly outperforms existing benchmarks, validating its practicality and high transparency.",10.1109/tetci.2025.3548719,2025,,IEEE,10.1109/tetci.2025.3548719
Stock price prediction method based on TCN-BiGRU model,"Deep learning technology is now applied in many fields. In the financial field, deep learning as an emerging technology is also widely used, such as high-frequency trading, investment portfolio, stock price prediction and risk management. Among them, the most valuable and popular for investors is stock price prediction. In this paper, we adopt a combination model of time convolution network and bidirectional gated recurrent unit for stock prediction. We choose the stock price of Amazon as the target price, use the NASDAQ Composite Index, the US Dollar Index and so on as features, and compare with the baseline model.",10.1109/iciibms60103.2023.10347745,2023,1,IEEE,10.1109/iciibms60103.2023.10347745
Spatial-Temporal Aware Inductive Graph Neural Network for C-ITS Data Recovery,"With the prevalence of Intelligent Transportation Systems (ITS), massive sensors are deployed on roadside, vehicles, and infrastructures. One key challenge is imputing several different types of missing entries in spatial-temporal traffic data to meet the high-quality demand of data science applied in Cooperative-ITS (C-ITS) since accurate data recovery is critical to many downstream tasks in ITSs, such as traffic monitoring and decision making. For such, it is proposed in this article solutions to three kinds of data recovery tasks in a unified model via spatial-temporal aware Graph Neural Networks (GNNs), named Spatial-Temporal Aware Data Recovery Network (STAR), enabling a real-time and inductive inference. A residual gated temporal convolution network is designed to permit the proposed model to learn the temporal pattern from long sequences with masks and an adaptive memory-based attention model for utilizing implicit spatial correlation. To further exploit the generalization power of GNNs, a sampling-based method is adopted to train the proposed model to be robust and inductive for online servicing. Extensive numerical experiments on two real-world spatial-temporal traffic datasets are performed, and results show that the proposed STAR model consistently outperforms other baselines at 1.5-2.5 times on all kinds of imputation tasks. Moreover, STAR can support recovery data for 2 to 5 hours, with its performance barely unchanged, and has comparable performance in transfer learning and time-series forecast. Experimental results demonstrate that STAR provides adequate performance and rich features for multiple data recovery tasks under the C-ITS scenario.",10.1109/tits.2022.3156266,2023,112,IEEE,10.1109/tits.2022.3156266
PIDGeuN: Graph Neural Network-Enabled Transient Dynamics Prediction of Networked Microgrids Through Full-Field Measurement,"A Physics-Informed Dynamic Graph Neural Network (PIDGeuN) is presented to accurately, efficiently and robustly predict the nonlinear transient dynamics of microgrids in the presence of disturbances. The graph-based architecture of PIDGeuN provides a natural representation of the microgrid topology. Using only the state information that is practically measurable, PIDGeuN employs a time delay embedding formulation to fully reproduce the system dynamics, avoiding the dependency of conventional methods on internal dynamic states, e.g., of controllers. Based on a judiciously designed message passing mechanism, the PIDGeuN incorporates two physics-informed techniques to improve its predictive performance, including a physics-data-fusion approach to determining the inter-dependencies between buses, and a loss term to enforce the known physical law of the power system, i.e., the Kirchhoff’s law, to ensure the feasibility of the model prediction. Extensive tests show that PIDGeuN can provide accurate and robust prediction of transient dynamics for nonlinear microgrids over a long-term time period. Therefore, the PIDGeuN offers a potent tool for the modeling of large scale networked microgrids (NMs), with potential applications to predictive or preventive control in real time applications for the stable and resilient operations of NMs.",10.1109/access.2024.3384457,2024,1,IEEE,10.1109/access.2024.3384457
TCGPN: Temporal-Correlation Graph Pre-trained Network for Stock Forecasting,"The integration of temporal features and correlations across time series has emerged as an effective strategy in time series prediction. Spatial-Temporal Graph Neural Networks (STGNNs) have demonstrated strong performance on many temporal-correlation forecasting problems. However, their effectiveness and robustness are less satisfactory when applied to tasks that lack periodicity, such as stock market prediction, and they are constrained by memory limitations, rendering them unsuitable for problems with a large number of nodes. To address these challenges, we propose the Temporal-Correlation Graph Pre-trained Network (TCGPN), which utilizes a temporal-correlation fusion encoder for mixed representation and incorporates pre-training methods with carefully designed temporal and correlation tasks. The structure is independent of node number and order, enabling improved outcomes through various data augmentation techniques, and reduces memory consumption during training via multiple sampling strategies. Experiments conducted on real stock market datasets, CSI300, CSI500, NASDAQ and NYSE, demonstrate that fine-tuning a simple MLP in downstream tasks achieves state-of-the-art results, validating TCGPN’s ability to capture robust temporal correlation patterns.",10.1109/ijcnn64981.2025.11228809,2025,,IEEE,10.1109/ijcnn64981.2025.11228809
Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations,"The rapid expansion of electric vehicles (EVs) has rendered the load forecasting of electric vehicle charging stations (EVCS) increasingly critical. The primary challenge in achieving precise load forecasting for EVCS lies in accounting for the nonlinear of charging behaviors, the spatial interactions among different stations, and the intricate temporal variations in usage patterns. To address these challenges, we propose a Multiscale Spatio-Temporal Enhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM incorporates a multiscale graph neural network to discern hierarchical nonlinear temporal dependencies across various time scales. Besides, it also integrates a recurrent learning component and a residual fusion mechanism, enhancing its capability to accurately capture spatial and temporal variations in charging patterns. The effectiveness of the proposed MSTEM has been validated through comparative analysis with six baseline models using three evaluation metrics. The case studies utilize real-world datasets for both fast and slow charging loads at EVCS in Perth, UK. The experimental results demonstrate the superiority of MSTEM in short-term continuous load forecasting for EVCS.",10.1109/aeees61147.2024.10544962,2024,1,IEEE,10.1109/aeees61147.2024.10544962
"Landslide Deformation Uncertainty Quantification Using Conformalized Graph Neural Networks: A Case Study in Sichuan Province, China","Landslide deformation prediction plays a crucial role in geohazard risk management, yet existing methods often struggle to quantify prediction uncertainties effectively. This paper presents GNN-CF, a novel framework that integrates Graph Neural Networks (GNN) with Conformal Prediction for reliable interval forecasting of landslide deformation. The proposed approach addresses two significant challenges: ensuring valid marginal coverage despite dependencies between calibration (training) and test data, and reducing prediction interval inefficiency while maintaining coverage guarantees. The framework incorporates a topology-aware correction model and employs graph-based regularization terms to enhance prediction accuracy. The methodology is validated using field monitoring data from the Wutong Village landslide in Sichuan Province, China, where six GNSS monitoring points track surface deformation patterns. Experimental results demonstrate that GNN-CF consistently outperforms state-of-the-art (SOTA) methods, including GRU-LUBE, DNLSSM, and SA-DeepAR, achieving superior Prediction Interval Coverage Probability (PICP) while maintaining smaller Prediction Interval Normalized Average Width (PINAW). The framework’s effectiveness in balancing coverage and computational complexity makes it a feasible solution for landslide monitoring applications requiring reliable uncertainty quantification.",10.1109/access.2025.3568273,2025,1,IEEE,10.1109/access.2025.3568273
Context Integrated Relational Spatio-Temporal Resource Forecasting,"Traditional resource (demand or supply) forecasting models mainly focus on modeling temporal dependency. However, spatio-temporal data include complex non-linear relational and spatial dependencies. In addition, dynamic contextual information also impacts resources. Methods that consider context assume that the impact of context on resources is fixed, which is not realistic. For example, in a bicycle-sharing system, bike supply in stations is affected by the weather, and that effect changes over time. We propose a novel graph-based context integrated relational model, Context Integrated Graph Neural Network (CIGNN), which models temporal, relational, spatial, and dynamic contextual dependencies for multi-step ahead resource forecasting. We define a resource graph, where nodes represent locations with associated resource time-series, and context graphs (one for each type of context), where nodes represent locations with associated contextual time-series. Assuming that various contexts have dynamic impact on resources, our proposed CIGNN model employs a novel fusion mechanism that jointly learns from multiple contextual time-series. To the best of our knowledge, CIGNN is the first approach that integrates dynamic contextual information using graph neural networks for resource forecasting. Empirical results on two real-world datasets demonstrate that CIGNN consistently outperforms state-of-the-art approaches.",10.1109/bigdata52589.2021.9671705,2021,1,IEEE,10.1109/bigdata52589.2021.9671705
Long-term Spatio-Temporal Forecasting using Spectral Graph Neural Networks,"Multivariate Time Series (MTS) forecasting is vital in various practical applications. Current research in this area is categorized into Spatial-Temporal Forecasting (STF) and Long-term Time Series Forecasting (LTSF). While these tasks share similarities, the methods and benchmarks used differ significantly. Spatio-Temporal Graph Neural Networks (STGNNs) excel at modeling interrelationships in STF tasks but face difficulties with long sequence inputs due to inefficient training. In contrast, LTSF models handle long sequences well but struggle with capturing complex variable interrelationships. This paper proposes the Spectral Spatio-Temporal Graph Neural Network (S2GNN) to address these challenges, proposing a framework capable of handling long-term spatiotemporal forecasting. S2GNN leverages a decoupled GNN along with an MLP architecture to ensure efficiency. Specifically, it employs spectral GNNs for global feature extraction on an adaptive graph structure; the visualization of the filters resembles a band-rejection shape, indicating the presence of both homophilic and heterophilic relationships between nodes. Additionally, we introduce scale-adaptive node embeddings and cross-correlation embeddings for better differentiation between similar temporal patterns. Extensive experiments on eight public datasets, including STF and LTSF, demonstrate that S2GNN consistently outperforms state-of-the-art models across diverse prediction tasks. Code is available at https://github.com/superarthurlx/S2GNN.",10.1109/ijcnn64981.2025.11229200,2025,,IEEE,10.1109/ijcnn64981.2025.11229200
App Popularity Prediction by Incorporating Time-Varying Hierarchical Interactions,"App popularity prediction is a significant task in mobile service development, which predicts an app's future popularity based on its current behaviors. It provides benefits from app development to targeted investment. Popularity is affected by two factors, i.e., internal ones like reviews and external ones like interaction among apps. However, most related studies only explore internal factors but neglect external ones. In fact, external factor plays an important role in popularity prediction modelling since it is the promoting and/or inhibiting influence resulted by app interaction. The app interaction has two major characteristics, i.e., interactivity and dynamicity, which brings challenges to app popularity prediction due to two reasons: 1) interactivity—it is hard to evaluate the existence and influence intensity of interactions; 2) dynamicity—the nature of interaction influence, e.g., promoting or inhibiting, and its intensity on popularity change with time. In this paper, we propose DeePOP, a popularity prediction model that innovatively leverages time-varying hierarchical interactions. First, we propose Hierarchical Interaction Graph, which is first studied in this work, to organically characterize the relationship and influence among apps. Second, DeePOP integrates internal factors and time-varying hierarchical interactions as inputs to build the prediction model. It develops multi-level modules based on Recurrent Neural Network with attention mechanism and generates multi-step time series predictions by fusing the outputs of modules. Experiments on a real-world dataset show that DeePOP outperforms state-of-the-art methods in prediction accuracy, effectively reducing the Root Mean Square Error (RMSE) to 0.088.",10.1109/tmc.2020.3029718,2022,11,IEEE,10.1109/tmc.2020.3029718
Pre-trained Multivariate Time Series Graph Neural Networks for Wind Power Forecasting,"Wind power is an important part of the future energy transition, and improving the accuracy of wind power forecasting tasks can significantly enhance the security, stability and economics of the grid. Despite continuous advances in wind power forecasting methods, they still have limitations such as insufficient forecast accuracy, excessive model complexity and unstable predictions. In this research, we propose a wind power forecasting model that integrates the masked autoencoders (MAE) pre-training method with the Spatio-Temporal Graph Neural Networks (STGNN). First, we constructed a pre-training model called Wind Power Forecasting with Masked Autoencoders (WPFMAE), which is designed to extract long-term wind power output patterns using an autoencoder structure with a high masking rate. This information provides contextual information for the downstream Multi-Temporal Graph Neural Network (MTGNN), which learns the temporal dependencies of wind power output while capturing its spatio-temporal correlation. The effectiveness of the proposed method is validated using data from real wind farms. The results indicate that the developed model can effectively learn long-term variation patterns in wind power data and provides superior accuracy compared to other models tested. In addition, the model maintains a concise and competent structure, which provides clear advantages.",10.1109/spies60658.2023.10474659,2023,1,IEEE,10.1109/spies60658.2023.10474659
Sociologically-Informed Graph Neural Network for Opinion Prediction,"Social media platforms has long served as open arenas where individuals discuss and change their opinions on various events, subsequently influencing the progression of these events. Public opinion, recognized as an important social signal, is instrumental in understanding the developmental patterns of social events and in guiding more informed responses. In light of this, we propose a sociologically-informed opinion prediction model, which integrates rich social interaction data with time series forecasting techniques using a graph neural network framework. This model, enriched by a sociological theoretical model, reflects the real-world dynamics of opinion evolution. Experimental results derived from three synthetic datasets and two real-world datasets indicate that incorporating user interaction data, along with more effective utilization of historical information, has led to a large improvement in the accuracy of opinion predictions. The source code and sample data for our study are available at https://github.com/RiikkaYang/SIGNN.",10.1109/icassp49660.2025.10889413,2025,1,IEEE,10.1109/icassp49660.2025.10889413
Machine Learning Approaches for Region-level Prescription Demand Forecasting,"Region-level prescription demand is closely intertwined with the incidence of diseases within a given area. However, conventional forecasting methods primarily rely on historical data, and ignore the spatial correlation in prescription data. In this study, we employ graph structures to capture the interactions among drug demand in different regions. By leveraging two popular graph neural network-based models, our objective is to harness the power of spatial-temporal correlation to enhance the accuracy of predictions. To assess the effectiveness of the graph neural network-based model, we conduct extensive experiments on a comprehensive real world dataset. The results demonstrate that the performance of the graph neural network consistently surpasses that of statistical learning-based methods and traditional deep learning-based methods.",10.1109/swc57546.2023.10449058,2023,,IEEE,10.1109/swc57546.2023.10449058
STGNN-TCN: Hybrid Model for Spatiotemporal Air Quality Prediction based on Spatio-Temporal Graph Neural Networks and Temporal Convolutional Networks,The development of correct air quality forecasting remains essential for the task of environmental monitoring as well as public health management practices. Traditional deep learning techniques find it difficult to analyse complex patterns of spatial along with temporal relationships in air quality datasets. The authors present a new hybrid deep learning structure which combines Spatio-Temporal Graph Neural Networks (ST-GNN) with Temporal Convolutional Networks (TCN) to address this issue. ST-GNN extracts valuable spatial features by building complex spatial relationship models which TCN uses to detect long-range temporal patterns in order to produce reliable time-series forecasts. A hyperparameter search using Bayesian Optimization helps to optimize model performance by speeding up convergence while reducing potential overfitting issues. The proposed framework shows superior performance through air quality data evaluation which demonstrates both enhanced predictive accuracy and improved computational efficiency when compared to traditional deep learning approaches. The putative evidence demonstrates that hybrid framework achieves strong scalability with reliability which makes it suitable as a tool for real-time air quality prediction systems. The research establishes a contemporary data-directed system for environmental monitoring which supports better decision outcomes in public health as well as pollution control activities.,10.1109/icaiss61471.2025.11042243,2025,4,IEEE,10.1109/icaiss61471.2025.11042243
A Network Nodes Fault Prediction Method Based on Dynamic Spatial-Temporal Graph Model,"With the development of network, manual fault detection methods have become increasingly insufficient. Recently, many deep learning based methods have been proposed for network state prediction. Recurrent neural networks have been introduced to capture the temporal features for prediction tasks, while graph neural networks based approaches leverage adjacency matrices and degree matrices to effectively capture spatial relationships between nodes, thereby improving prediction performance. However, these methods struggle to address the challenges posed by the highly dynamic modern networks. To address this issue, we propose a novel method for network node fault prediction based on dynamic graphs and long-term temporal dependency capture. Specifically, we employ self-attention mechanisms to dynamically compute the relationships between nodes and integrate self-attention with convolutional operations to capture long-term temporal dependencies, thereby enhancing prediction performance. Finally, we conduct experiments across different time steps, and the results demonstrate the effectiveness of our proposed method.",10.1109/igarss55030.2025.11243452,2025,,IEEE,10.1109/igarss55030.2025.11243452
SGDP: A Stream-Graph Neural Network Based Data Prefetcher,"Data prefetching is important for storage system optimization and access performance improvement. Traditional prefetchers work well for mining access patterns of sequential logical block address (LBA) but cannot handle complex non-sequential patterns that commonly exist in real-world applications. The state-of-the-art (SOTA) learning-based prefetchers cover more LBA accesses. However, they do not adequately consider the spatial interdependencies between LBA deltas, which leads to limited performance and robustness. This paper proposes a novel Stream-Graph neural network-based Data Prefetcher (SGDP). Specifically, SGDP models LBA delta streams using a weighted directed graph structure to represent interactive relations among LBA deltas and further extracts hybrid features by graph neural networks for data prefetching. We conduct extensive experiments on eight real-world datasets. Empirical results verify that SGDP outperforms the SOTA methods in terms of the hit ratio by 6.21%, the effective prefetching ratio by 7.00%, and speeds up inference time by 3.13× on average. Besides, we generalize SGDP to different variants by different stream constructions, further expanding its application scenarios and demonstrating its robustness. SGDP offers a novel data prefetching solution and has been verified in commercial hybrid storage systems in the experimental phase. Our codes and appendix are available at https://github.com/yyysjz1997/SGDP/.",10.1109/ijcnn54540.2023.10191927,2023,3,IEEE,10.1109/ijcnn54540.2023.10191927
Spatio-Temporal ESN-based Model for Predicting Water Level in Yangtze River,"Water level prediction plays a vital role in navigation, particularly for ports and harbors, which attracts more attention in the academic domain. The conventional machine learning algorithms, such as support vector regression and artificial neural network, are commonly employed for predicting water level. However, these algorithms have the high computational cost, which directly impacts on their performance and implementation. Recent, a typical randomization-based algorithm called echo state network obtains the good performance with high efficiency in aspect of water level prediction. To enhance forecasting performance and overcome its own limitations, this study proposes three approaches for enriching features in the conventional echo state network. Firstly, we propose the random bar features selection approach to select useful features. Secondly, a novel structure of ESN is designed to capture much richer temporal features. Next, a spatial feature extraction method is proposed based on a latent correlation and graph neural network to capture the spatial features. Based on these methods, this study proposes a Spatio-temporal ESN-based model (ST-ESN). The experimental results and statistical analysis represent that our proposed model has superior forecasting ability in water level prediction rather than other compared models. It not only overcomes the limitation of single features consideration, but it also provides the data support from the high accuracy water level prediction data, which is benefited in managing water-land transportation, flood protection, and ship route management.",10.1109/icitee59582.2023.10317663,2023,1,IEEE,10.1109/icitee59582.2023.10317663
Transmission Line Operation Status Prediction Method Based on Spatiotemporal Graph Convolutional Network,"In order to deal with the problems of strong nonlinearity, complex spatial correlation and significant temporal fluctuation in the prediction of transmission line operation status, a prediction model based on spatiotemporal graph convolutional network (ST-GCN) was proposed. This method models the topological relationship between transmission nodes through a graph structure, introduces a gated temporal convolution mechanism to extract timing features, and achieves a deep fusion of spatial structure and temporal dynamics. Experimental verification is carried out on the SoCal 28-Bus transmission system dataset. The results show that the proposed model is superior to the existing methods in terms of prediction accuracy, convergence efficiency and robustness. Especially in the multi-step prediction of voltage, current and power variables, the mean square error (MSE) is as low as 0.0024, and the coefficient of determination (R2) exceeds 0.97, showing good practicality and promotion value. The research results provide reliable algorithm support for intelligent operation and status warning of power grid.",10.1109/icsece65727.2025.11256953,2025,,IEEE,10.1109/icsece65727.2025.11256953
Enhanced Sensor Environment Graph Based Deep Learning Approach for Air Quality Anomaly Detection,"Air pollution is among the major threats to human well-being, highlighting the critical need for air quality monitoring, especially in urban areas. Whereas the development of low-cost pollution sensors has facilitated a widespread monitoring, a reliable anomaly detection system is required to properly characterize data for the end-users. In this paper, we propose an enhanced deep learning approach based on the A3T-GCN (Attention Temporal Graph Convolutional Network) model that accurately forecasts particulate matter PM2.5concentrations using real past measurements from a deployed sensor network. Our proposed Enhanced-A3T-GCN embeds all the available spatial and temporal correlations within the sensor network, along with additional information regarding the sensor environment in a graph. It is shown to achieve significant performance improvement with respect to other deep learning forecasting methods, emphasizing the importance of exploiting the sensor environment-based information. Further, the achieved accurate forecasting makes it possible to detect anomalies injected at both single and multiple sensor levels.",10.23919/eusipco63174.2024.10715088,2024,,IEEE,10.23919/eusipco63174.2024.10715088
Toward Nonuniformly Distributed Weather Forecasting: Adaptive Filtered Hypergraph Convolution Network,"Weather forecasting, compared to other multivariate time-series prediction tasks, exhibits notably nonuniform distribution of observation sites. The prevailing approaches primarily leverage graph convolutional neural networks (GCNs) to extract spatial features. However, some studies suggest that the poor performance on uneven graphs is primarily due to the fact that traditional graph neural networks (GNNs) are essentially low-pass filters, discarding information beyond low-frequency information on the graph. From another perspective, since the essence of graph convolution is the smoothing of node features, for uneven graphs, there are noticeable differences in the smoothing rates of node features, leading to the coexistence of overfitting and underfitting phenomena. This issue is further exacerbated in higher order graph structures, such as hypergraphs, due to the irregular and complex nature of hyperedges. To address this issue, we propose a filtered hypergraph neural network. Building on the calculation of hypergraph node smoothing rates, we balance the low-pass and high-pass filter convolutions’ feature extraction through a dual-stream architecture. On uneven graphs, it can be observed that neglecting high-frequency information and concentrating solely on low-frequency information impede the learning of node representations, thereby significantly affecting the performance of downstream prediction tasks. We conducted multidimensional time-series prediction experiments using meteorological data, and the results demonstrate that our model performs with high accuracy in node regression tasks across multiple channels.",10.1109/tgrs.2025.3640219,2025,,IEEE,10.1109/tgrs.2025.3640219
Research on Self-diagnosis Method of Nickel top-Blowing Furnace Sensor Based on Causal Graph Neural Network,"As the scale of nickel top-blowing furnace melting systems expands and the complexity of the equipment increases, the maintenance workload for sensors has gradually increased. Manual maintenance approaches consume significant resources and are not suitable for the development of smart sensors. To address this issue, an unsupervised sensor self-diagnosis method is proposed in this paper. Firstly, the Pearson correlation coefficient is introduced to construct a graph network of sensors of the same type, and node embedding is used to form super nodes of sensors. Secondly, transfer entropy is utilized to assess the causal relationships between these super nodes, based on which a super node graph network is constructed. Finally, a Multi-Head Self-Attention Gated Graph Convolutional Network (MCB-GCN) is introduced. This network captures spatial and temporal dependencies of nodes and, with the help of an enhanced fusion module, achieves time-series prediction for sensors. Subsequently, sensor self-diagnosis is achieved through a standardized residual consistency check algorithm. Simulation experiments on the measurement system of a nickel top-blowing furnace demonstrate the effectiveness of the proposed method, in addressing the problem of autonomous sensor diagnostics.",10.1109/rcae62637.2024.10834163,2024,,IEEE,10.1109/rcae62637.2024.10834163
Global and Local Interattribute Relationships-Based Graph Convolutional Network for Flight Trajectory Prediction,"The rapid development of the aviation industry urgently requires efficient airspace traffic management, in which flight trajectory prediction is a core component. Existing trajectory prediction methods mainly capture the relationships between trajectory points. However, there are complex and implicit relationships between the attributes of trajectory points. Furthermore, there is room for improvement when applying previous multivariate time series prediction methods on flight track forecasting, since both local and global attribute features and interattribute relationships have an important impact on the flight track features. In this article, we propose a global and local interattribute relationships-based graph convolutional network (GLAR-GCN) to solve the flight trajectory prediction problem. First, we fuse the local embedded attribute feature and global attribute pattern to obtain the accumulated local embedded features at each point. Meanwhile, we synthesize the local and global attribute correlations to obtain the augmented attribute correlations at each point. Second, we construct an attribute graph at each point, where the nodes are the accumulated local embedded features and the edges are the augmented attribute correlations. Third, we extract the integrated attribute features from each attribute graph with a graph convolutional network. Finally, we perform trajectory prediction with the integrated attribute features as the input of a long short-term memory (LSTM) network. We evaluate the proposed model GLAR-GCN on real short-haul, medium-haul, and long-haul flight datasets for single-step and multistep prediction. Experimental results demonstrate that GLAR-GCN effectively improves the prediction performance on all datasets compared with the classical and the state-of-the-art methods.",10.1109/taes.2024.3357668,2024,17,IEEE,10.1109/taes.2024.3357668
Back to the Future: GNN-Based No2 Forecasting Via Future Covariates,"Due to the latest environmental concerns in keeping at bay contaminants emissions in urban areas, air pollution forecasting has been rising the forefront of all researchers around the world. When predicting pollutant concentrations, it is common to include the effects of environmental factors that influence these concentrations within an extended period, like traffic, meteorological conditions and geographical information. Most of the existing approaches exploit this information as past covariates, i.e., past exogenous variables that affected the pollutant but were not affected by it. In this paper, we present a novel forecasting methodology to predict NO2 concentration via both past and future covariates. Future covariates are represented by weather forecasts and future calendar events, which are already known at prediction time. In particular, we deal with air quality observations in a city-wide network of ground monitoring stations, modeling the data structure and estimating the predictions with a Spatiotemporal Graph Neural Network (STGNN). We propose a conditioning block that embeds past and future covariates into the current observations. After extracting meaningful spatiotemporal representations, these are fused together and projected into the forecasting horizon to generate the final prediction. To the best of our knowledge, it is the first time that future covariates are included in time series predictions in a structured way. Remarkably, we find that conditioning on future weather information has a greater impact than considering past traffic conditions. We release our code implementation at https://github.com/polimi-ispl/MAGCRN.",10.1109/igarss53475.2024.10642608,2024,,IEEE,10.1109/igarss53475.2024.10642608
Enhance COVID-19 Mortality Prediction with Human Mobility Trend and Medical Information,"In this work, we study national and state-level COVID-19 pandemic data in the United States with the help of human mobility trend data and auxiliary medical information. We analyze and compare various state-of-the-art time-series prediction techniques. We assess a spatio-temporal graph neural network model which forecasts the pandemic course by utilizing a hybrid deep learning architecture and human mobility data. Nodes in the graph represent the state-level deaths due to COVID-19 at any particular time point, edges represent the human mobility trend and temporal edges correspond to node attributes across time. We also study statistical modeling and machine learning techniques for mortality prediction in the United States. We evaluate these techniques on both state and national level COVID-19 data in the United States and claim that the SARIMAX and GCN-LSTM model generated forecast values using exogenous hospital information variables can enrich the underlying model to improve the prediction accuracy at both levels. Our best machine learning models perform 50% and 60% better than the baseline on an average on the national level and state-level data, respectively, while the statistical models perform 63% and 42% better.",10.1109/hpcc-dss-smartcity-dependsys53884.2021.00190,2021,,IEEE,10.1109/hpcc-dss-smartcity-dependsys53884.2021.00190
Accurate Anomaly Detection Leveraging Knowledge-enhanced GAT,"Anomaly detection is a long-standing research topic to support the prompt remedy of potential risks for dependency-aware tasks, where Graph Neural Networks (GNNs) models have been adopted to differentiate anomalies from normal patterns. Generally, GNN models utilize time series data to construct graph structures for capturing task dependencies between Internet of Things (IoT) devices, such that deviations from predicted behaviours are assumed as anomalies. Current forecasting-based anomaly detection methods can hardly detect anomalies, which are uncovered by historical sensory data, but are explicitly specified by domain knowledge. To solve this issue, this paper proposes a Knowledge-enhanced graph attention-based Anomaly Detection (KeAD) method. Specifically, a knowledge-enhanced graph structure is constructed by incorporating domain-specific knowledge to represent spatio-temporal dependencies between IoT devices. Thereafter, a knowledge-enhanced graph attention-based forecasting network is developed to predict future behaviours of IoT devices. Anomalies are detected by analyzing deviations from these predicted behaviours, taking domain-specific knowledge into account. Extensive experiments are conducted based on publicly-available datasets, and evaluation results demonstrate that our KeAD outperform the state-of-the-art techniques in terms of the accuracy of anomaly detection.",10.1109/icws62655.2024.00077,2024,3,IEEE,10.1109/icws62655.2024.00077
A Review of Graph Neural Networks and Their Applications in Power Systems,"Deep neural networks have revolutionized many machine learning tasks in power systems, ranging from pattern recognition to signal processing. The data in these tasks are typically represented in Euclidean domains. Nevertheless, there is an increasing number of applications in power systems, where data are collected from non-Euclidean domains and represented as graph-structured data with high-dimensional features and interdependency among nodes. The complexity of graph-structured data has brought significant challenges to the existing deep neural networks defined in Euclidean domains. Recently, many publications generalizing deep neural networks for graph-structured data in power systems have emerged. In this paper, a comprehensive overview of graph neural networks (GNNs) in power systems is proposed. Specifically, several classical paradigms of GNN structures, e. g., graph convolutional networks, are summarized. Key applications in power systems such as fault scenario application, time-series prediction, power flow calculation, and data generation are reviewed in detail. Further-more, main issues and some research trends about the applications of GNNs in power systems are discussed.",10.35833/mpce.2021.000058,2022,130,IEEE,10.35833/mpce.2021.000058
Graph-Guided Neural Network for Tourism Demand Forecasting,"An accurate tourism demand forecasting model is crucial for tourism decision-makers. In recent years, several deep learning-based models have been developed to predict tourist arrivals via search intensity indices. However, few methods consider the lag effect in the long-term time range and the interaction between different search intensity indices factors. To alleviate the above limitations, we propose a graph-guided tourism demand forecasting network, which can model the lag effect of historical variables on future variables. Specifically, each variable is individually encoded via a convolutional neural network in the time dimension. Then, lag effects are modeled dynamically in a bipartite graph, and mined via graph aggregation. Finally, a fully-connected network is designed for regression prediction. Experimental results on two public datasets demonstrate the superiority of the proposed method in both one-step and multi-step prediction compared with existing methods.",10.1109/access.2023.3336702,2023,6,IEEE,10.1109/access.2023.3336702
Workload Prediction for Volatile Nodes in Multi-Access Edge Networks,"Advancement of edge and far-edge computing, driven by the increasing demand for real-time, data-intensive applications, has heightened the need for reliable and efficient resource management in volatile environments. This paper introduces GTMixer, a deep learning architecture tailored for predicting resource usage in volatile edge computing scenarios. GTMixer utilizes a Dynamic Temporal Graph (DTG) to capture the evolving interdependencies in workload exchanges across edge and far-edge nodes. By processing snapshots of this graph, GTMixer identifies patterns in resource utilization, even in the absence of historical CPU data. Our contributions include: (1) the creation of a DTG that reflects migration patterns and resource utilization among nodes; (2) the development of the GTMixer model, which integrates feature mixing with graph neural networks for improved predictive accuracy; and (3) empirically evaluating GTMixer against state-of-the-art models using a modified version of the Alibaba 2021 traces dataset that accounts for volatility. Our results demonstrate that GTMixer not only effectively anticipates resource requirements in unpredictable Multi-access Edge Computing (MEC) scenarios but also significantly outperforms current state-of-the-art models in terms of efficiency, showcasing its potential to enhance the reliability and performance of edge computing systems crucial for nextgeneration network technologies and applications.",10.1109/icc52391.2025.11162043,2025,,IEEE,10.1109/icc52391.2025.11162043
Graph Portfolio: High-Frequency Factor Predictors via Heterogeneous Continual GNNs,"This study aims to address the challenges of financial price prediction in high-frequency trading (HFT) by introducing a novel continual learning framework based on factor predictors via graph neural networks. The model integrates multi-factor pricing theory with real-time market dynamics, effectively bypassing the limitations of conventional time series forecasting methods, which often lack financial theory guidance and ignore market correlations. We propose three heterogeneous tasks, including price gap regression, changepoint detection, and price moving average regression to trace the short-, intermediate-, and long-term trend factors present in the data. We also account for the cross-sectional correlations inherent in the financial market, where prices of different assets show strong dynamic correlations. To accurately capture these dynamic relationships, we resort to spatio-temporal graph neural network (STGNN) to enhance the predictive power of the model. Our model allows a continual learning strategy to simultaneously consider these tasks (factors). To tackle the catastrophic forgetting in continual learning while considering the heterogeneity of tasks, we propose to calculate parameter importance with mutual information between original observations and the extracted features. Empirical studies on the Chinese futures data and U.S. equity data demonstrate the superior performance of the proposed model compared to other state-of-the-art approaches.",10.1109/tkde.2025.3566111,2025,2,IEEE,10.1109/tkde.2025.3566111
Energy Data Forecasting Based on the STRLM Time Series Prediction Model,"We propose an improved model, the Seasonal-Trend Relational Large Language Model (STRLM), for time-series prediction, which enhances prediction accuracy in energy-related applications and achieves robust performance under data-scarce conditions. The key methodological contributions include: (1) employing Exponential Moving Average (EMA) to decompose preprocessed time-series data into trend and seasonal components, facilitating the learning of complex temporal patterns; (2) introducing a dual-scale Graph Neural Network (GNN) to ensure structural and logical alignment between sequential and relational data for effective LLM adaptation; and (3) optimizing LLM performance through few-shot prompt-based context alignment to improve adaptability to limited training data. Extensive evaluations across multiple datasets demonstrate that STRLM consistently outperforms state-of-the-art baselines, particularly in few-shot and zero-shot scenarios, achieving superior performance in both MSE and MAE metrics across prediction horizons (96 to 720 steps) with a consistent improvement margin of $\mathbf{4 \% - 1 3 \%}$ over competing models.",10.1109/icetis66286.2025.11144172,2025,,IEEE,10.1109/icetis66286.2025.11144172
Evaluation of Traffic Flow Prediction Models in a Real-World Urban Intelligent Transportation System Pilot,"Accurate traffic flow prediction is a critical component of modern Intelligent Transportation Systems (ITS), supporting real-time decision-making and congestion mitigation in smart cities. This paper presents a comparative analysis of two different approaches to traffic flow prediction problem: a temporal Transformer-based model (iReformer) and a spatio-temporal Graph Convolutional Network combined with Long Short-Term Memory (GCN-LSTM). The evaluation is conducted using a real-world urban traffic dataset from Istanbul, Turkey. The models are assessed under several different prediction settings, varying in historical input window length and forecasting horizon. Results show that GCN-LSTM performs best in short-term prediction scenarios, while iReformer achieves better performance with longer input sequences. According to the authors best knowledge, this is the first comparative analysis of novel temporal and spatio-temporal approaches on real-world urban data.",10.1109/elmar66948.2025.11194003,2025,,IEEE,10.1109/elmar66948.2025.11194003
Enhanced Prediction of Water Pipeline Failures Using a Novel MTGNN-Based Classification Model for Smart City Infrastructure,"Accurate prediction of waterpipe failures is critical for urban infrastructure resilience and operational efficiency, especially as smart city initiatives increasingly rely on data-driven approaches to manage infrastructure assets. Traditional machine learning models for predicting pipeline failures have limitations, often failing to capture the spatial dependencies intrinsic to interconnected water networks and falling short on short-term prediction accuracy. This study introduces a novel Multi-Task Graph Neural Network (MTGNN)-based classification method specifically designed to address these limitations by leveraging spatial and temporal dependencies. Using the Kitchener waterpipe failure dataset, the MTGNN-driven approach achieves precision rates of 0.69, 0.98, and 0.95 for six-month, one-year, and two-year prediction horizons, respectively. This improved accuracy highlights the model's potential to enhance proactive maintenance strategies and infrastructure sustainability in digital city environments. This work is the first to employ MTGNN for waterpipe failure prediction, offering a methodological advancement in short-term prediction and introducing a binary classification model that improves prediction precision across multiple time horizons.",10.1109/sustech63138.2025.11025674,2025,,IEEE,10.1109/sustech63138.2025.11025674
Exploring Bus Stop Mobility Pattern: A Multi-Pattern Deep Learning Prediction Framework,"The spatio-temporal prediction task in the transportation network is the core of the solutions for various traffic problems. On one hand, the mobility pattern in traffic can be reflected in the travel behavior of the crowd. In most traffic prediction tasks, the importance of the mobility pattern is often overlooked. On the other hand, traffic prediction also has a variety of predicting scenarios, including short-term and long-term prediction, and relevant research cannot solve the problems under the two scenarios at the same time. In view of the problem of existing work, we propose a multi-pattern traffic prediction framework, MPGNNFormer. First, we construct a new bus stop distance network to model the relationships between stops. Then, we use a graph neural network-based deep clustering method to extract the bus stop mobility pattern. Finally, we design a transformer-based spatio-temporal prediction model (STGNNFormer) to predict bus stop flow by taking full advantage of time dependency and space dependency. After that, we conduct a series of experiments to evaluate and test them on the real bus dataset, including analyzing mobility patterns and comparing prediction results. The experimental results prove that MPGNNFormer can improve the calculation efficiency in the prediction scene while ensuring prediction accuracy in the stop-flow prediction of the transportation network.",10.1109/tits.2023.3345872,2024,25,IEEE,10.1109/tits.2023.3345872
Gegenbauer Graph Neural Networks for Time-Varying Signal Reconstruction,"Reconstructing time-varying graph signals (or graph time-series imputation) is a critical problem in machine learning and signal processing with broad applications, ranging from missing data imputation in sensor networks to time-series forecasting. Accurately capturing the spatio-temporal information inherent in these signals is crucial for effectively addressing these tasks. However, existing approaches relying on smoothness assumptions of temporal differences and simple convex optimization techniques that have inherent limitations. To address these challenges, we propose a novel approach that incorporates a learning module to enhance the accuracy of the downstream task. To this end, we introduce the Gegenbauer-based graph convolutional (GegenConv) operator, which is a generalization of the conventional Chebyshev graph convolution by leveraging the theory of Gegenbauer polynomials. By deviating from traditional convex problems, we expand the complexity of the model and offer a more accurate solution for recovering time-varying graph signals. Building upon GegenConv, we design the Gegenbauer-based time graph neural network (GegenGNN) architecture, which adopts an encoder–decoder structure. Likewise, our approach also uses a dedicated loss function that incorporates a mean squared error (MSE) component alongside Sobolev smoothness regularization. This combination enables GegenGNN to capture both the fidelity to ground truth and the underlying smoothness properties of the signals, enhancing the reconstruction performance. We conduct extensive experiments on real datasets to evaluate the effectiveness of our proposed approach. The experimental results demonstrate that GegenGNN outperforms state-of-the-art methods, showcasing its superior capability in recovering time-varying graph signals.",10.1109/tnnls.2024.3381069,2024,13,IEEE,10.1109/tnnls.2024.3381069
Network Traffic Forecasting via Fuzzy Spatial-Temporal Fusion Graph Neural Networks,"Spatial-temporal network traffic prediction remains a formidable challenge due to the intricate spatial relationships and dynamic temporal patterns characteristic of individual nodes. Traditional regression methods fall short in handling such graph-structured data effectively. In recent developments, Graph Neural Networks (GNNs) have shown promise in modeling these complex spatial-temporal interactions. Despite their potential, existing GNN-based approaches exhibit notable limitations: (1) they typically rely on fixed spatial adjacency matrices, which overlook fuzzy latent temporal dependencies; and (2) they often process spatial and temporal information independently, resulting in a loss of joint fuzzy dependencies or restricting the model to either global or local patterns alone. To overcome these issues, we introduce the Fuzzy Spatial-Temporal Fusion Graph Neural Network (FSTFGNN) based on Fuzzy Rough Sets. Our approach constructs a dynamic, data-driven fuzzy spatial-temporal fusion matrix to capture underlying low-level spatial-temporal joint relationships. Additionally, a fuzzy global-local unified GNN layer is incorporated to simultaneously learn global-local spatialtemporal dependencies. Experimental results on two real-world datasets validate the efficacy of the proposed FSTFGNN framework.",10.1109/iscmi63661.2024.10851677,2024,2,IEEE,10.1109/iscmi63661.2024.10851677
Mobile Traffic Prediction in Consumer Applications: A Multimodal Deep Learning Approach,"Mobile traffic prediction is an important yet challenging problem in consumer applications because of the dynamic nature of user behavior, varying application quality of service (QoS) requirements, network congestion, and proliferation of diverse mobile devices. The mobile traffic prediction problem with multiple services, e.g., SMS, call, and Internet, is defined as the mapping from historical traffic data to future traffic prediction. Both grid and graph-based mobile traffic prediction formulations have been extensively considered in the literature. However, an effective multimodal deep learning approach with both grid and graph modals has not yet been fully considered. This study proposes a multimodal convolutional neural network (CNN)-graph neural network (GNN) hybrid framework for single-step mobile traffic prediction, in which the information extracted from SMS, call and Internet services are fused to make a precise prediction for future traffic consumption of consumers in the next hour. The CNN module is built using ConvLSTM, the GNN module is built using adaptive graph convolutional network (AGCN), and a fusion layer is designed to combine the outputs from the CNN and GNN modules. Numerical experiments based on a real-world dataset demonstrate the effectiveness of the proposed framework, which achieves a prediction error lower than ten baselines.",10.1109/tce.2024.3361037,2024,63,IEEE,10.1109/tce.2024.3361037
Large Language Models for Wireless Cellular Traffic Prediction: A Multi-timespan Approach,"Wireless cellular traffic prediction is essential for efficient network management and monitoring, yet it is a challenging task due to the spatial and temporal characteristics of traffic. Recently, machine learning based traffic prediction algorithms have been proposed in the literature. However, these algorithms lack good generalization ability as they cannot adapt to frequent changes in traffic distribution typically encountered in wireless networks. In this paper, we propose a traffic prediction algorithm using large language models (LLMs). We first analyze the temporal characteristics of traffic and identify those timespans in the historical traffic information which are important for traffic prediction. We use a clustering algorithm to identify cells with similar traffic patterns. To predict the traffic in a cell, we incorporate the multi-timespan historical traffic information of the cell as well as those cells with similar traffic patterns into natural language sentences and provide them as input to the LLM. Using our proposed framework, we fine-tune three popular LLMs (BART, BigBird, and PEGASUS) on the traffic prediction task. Experimental results show that our proposed LLM framework outperforms a state-of-the-art graph neural network (GNN) baseline and achieves up to 12.32% improvement in terms of the mean absolute error (MAE). Moreover, the proposed LLM framework has excellent generalization ability under the zero-shot setting, reducing the MAE by up to 46.84% compared to the baseline. The ablation studies reveal that providing information from multiple timespans to the model reduces the MAE by up to 15.05% compared to only providing information from the most recent timespan.",10.1109/globecom52923.2024.10901784,2024,2,IEEE,10.1109/globecom52923.2024.10901784
Graph Attention LSTM Network: A New Model for Traffic Flow Forecasting,"For the road networks containing multiple intersections and links, the traffic flow forecasting is essentially a time series forecasting problem on graphs. The task is challenging due to (1) complex spatiotemporal dependence among traffic flows of the whole road network and (2) sharp non-linearity and dynamic nature under different conditions. In this paper, by extending the LSTM to have graph attention structure in both the input-to-state and state-to-state transitions, we propose the Graph Attention LSTM Network (GAT-LSTM) and use it to build an end-to-end trainable encoder-forecaster model to solve the multi-link traffic flow forecasting problem. Experiment results show that our GAT-LSTM network could capture spatiotemporal correlations better and has achieved improvement of 15% - 16% over state-of-the-art baseline.",10.1109/icisce.2018.00058,2018,45,IEEE,10.1109/icisce.2018.00058
Sustainable AI for Zero Touch Network & Service Management with Graph Neural Networks,"In the pursuit of sustainable and efficient 6G network management, leveraging advanced AI methodologies becomes imperative. Our work introduces a comprehensive framework for resource usage prediction, focusing on data-compute 6G networks. This novel approach relies on state-of-the-art AI/ML techniques to achieve accurate resource usage and energy consumption predictions in 6G networks. By predicting various metrics obtained from Prometheus and Kepler, such as memory usage and energy consumption, we dynamically scale services across nodes using the Edge Platform of Intracom Telecom, aiming to reduce the energy footprint while preventing performance degradation and maintaining high Quality of Service (QoS). A core component of our approach are the Graph Neural Network (GNN) models, which are based on a Spatio-Temporal Graph Neural Network (STGNN), a very capable deep learning technique in predicting future values by modeling both spatial and temporal dependencies among network nodes. This enables a proactive and accurate forecasting mechanism that outperforms traditional Attention Temporal Graph Convolutional Network (A3T-GCN), but also cutting-edge Large Language Models (LLMs) in time series forecasting tasks. Our framework additionally incorporates automated AI models Life Cycle Management (LCM) using zero-touch MLOps techniques through tools like Kubeflow and Katib, ensuring efficient deployment, monitoring, and maintenance of AI models. Our extensive evaluation demonstrates the superiority of our approach in terms of prediction accuracy and operational efficiency compared to A3T-GCN and LLM based methods. The results indicate significant improvements in resource utilization and energy efficiency, positioning our framework as a sustainable and effective solution for zero-touch network and service management in 6G networks.",10.1109/camad62243.2024.10942655,2024,,IEEE,10.1109/camad62243.2024.10942655
