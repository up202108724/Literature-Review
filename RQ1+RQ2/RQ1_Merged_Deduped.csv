title,abstract,doi,year,citations,source
Graph-patchformer: Patch interaction transformer with adaptive graph learning for multivariate time series forecasting,,10.1016/j.neunet.2025.108140,2026,0,Scopus
Dual Attention Transformer with Multi-scale Perception for Multivariate Time Series Forecasting,,10.1007/978-981-95-3052-6_24,2026,0,Scopus
Enhancing Salesforce Sales Forecasting with Contrastive Learning-Based Time Series Representation,,10.1007/978-3-032-03558-5_29,2026,0,Scopus
M3E: Mixture of Multi-scale Multi-modal Experts for Time Series Forecasting,,10.1007/978-981-95-3398-5_6,2026,0,Scopus
DiM: Improving multivariate time series forecasting with DI embedding and multi-head graph learning mechanism,,10.1016/j.neucom.2025.131777,2026,0,Scopus
Attention-based spatial-temporal interactive couple neural networks for multivariate time series forecasting,,10.1016/j.ins.2025.122647,2026,0,Scopus
Multi-resolution leak detection based on shared expert MoE forecasting for natural gas pipelines,,10.1016/j.ipm.2025.104353,2026,0,Scopus
An Efficient Denoising Transformer-Based Architecture for Long-Ranged Time-Series Air Quality Prediction,,10.1002/cpe.70450,2025,0,Scopus
Adaptive hybrid spatial hypergraph convolution module with data embedding optimization for stock ranking prediction,,10.1016/j.physa.2025.131046,2025,0,Scopus
MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting,,10.1145/3746252.3761173,2025,0,Scopus
Structural Entropy-based Multivariate Time Series Forecasting,,10.1145/3746252.3761007,2025,0,Scopus
TD-IVDM: A multi-scale concept drift detection method for time series forecasting tasks,,10.1016/j.neucom.2025.131120,2025,0,Scopus
Financial Time Series Prediction With Multi-Granularity Graph Augmented Learning,,10.1109/tkde.2025.3607005,2025,1,Scopus
PRformer: Pyramidal recurrent transformer for multivariate time series forecasting,,10.1016/j.neunet.2025.107769,2025,0,Scopus
From a multi-period perspective: A periodic dynamics forecasting network for multivariate time series forecasting,,10.1016/j.patcog.2025.111760,2025,1,Scopus
LLM-Empowered Kolmogorov-Arnold Frequency Learning for Time Series Forecasting in Power Systems,,10.3390/math13193149,2025,0,Scopus
Learnable decomposition meets the neuro-fuzzy learning for robust rich spatial–temporal feature representation learning and better stock price forecasting,,10.1007/s00500-025-10898-0,2025,0,Scopus
DS-SGCHN: dynamic-static synergetic graph convolutional hierarchical network for traffic forecasting,,10.1088/1361-6501/ae014b,2025,0,Scopus
A Survey on Kolmogorov-Arnold Network,,10.1145/3743128,2025,25,Scopus
A novel deep graph learning-based multivariate clustering method for time series forecasting of complex chemical systems,,10.1016/j.compchemeng.2025.109214,2025,0,Scopus
Imputation via Domain Adaptation: Rethinking Variable Subset Forecasting from Knowledge Transfer,,10.1145/3711896.3737007,2025,0,Scopus
Merlin: Multi-View Representation Learning for Robust Multivariate Time Series Forecasting with Unfixed Missing Rates,,10.1145/3711896.3737046,2025,1,Scopus
Stochastic Diffusion: A Diffusion Based Model for Stochastic Time Series Forecasting,,10.1145/3711896.3737137,2025,2,Scopus
FAT: Frequency-Aware Pretraining for Enhanced Time-Series Representation Learning,,10.1145/3711896.3736952,2025,1,Scopus
TSGformer: A Unified Temporal–Spatial Graph Transformer with Adaptive Cross-Scale Modeling for Multivariate Time Series,,10.3390/systems13080688,2025,0,Scopus
VCformer: Variable-Centric Multi-Scale Transformer for Multivariate Time Series Forecasting,,10.3390/s25165202,2025,0,Scopus
SSSLN:Multivariate Time Series Forecasting via Collaborative Dynamic Graph Learning,,10.1016/j.neunet.2025.107485,2025,0,Scopus
A temporal graph-based contrastive approach for financial time series forecasting,,10.1016/j.engappai.2025.110834,2025,1,Scopus
Heteroscedastic ensemble deep random vector functional link neural network with multiple output layers for High Frequency Volatility Forecasting and Risk Assessment,,10.1016/j.neucom.2025.130078,2025,1,Scopus
A dynamic graph-based multiscale spatio-temporal feature enhancement network applied to ENSO prediction,,10.1007/s10489-025-06691-z,2025,0,Scopus
Popularity-aware dynamic graph neural collaborative filtering with local-global convergence,,10.1016/j.asoc.2025.113289,2025,0,Scopus
AGGA-MVFLN: Multivariate Time Series Forecasting via Adaptive Generalized Graph Accompanied with Multi-View Learning in Frequency Domain,,10.1145/3731715.3733272,2025,0,Scopus
Self-Optimizing Teacher and Auto-Matching Student Framework for Change-Point Representation Learning in Time Series Forecasting,,10.1145/3718091,2025,0,Scopus
Gaze Prediction as a Function of Eye Movement Type and Individual Differences,,10.1145/3715669.3723116,2025,0,Scopus
Intra and inter-series pattern representations fusion network for multiple time series forecasting,,10.1016/j.asoc.2025.113024,2025,0,Scopus
Evolving graph structure learning for multivariate time series forecasting,,10.1016/j.knosys.2025.113190,2025,1,Scopus
Beyond spatial neighbors: Utilizing multivariate transfer entropy for interpretable graph-based spatio–temporal forecasting,,10.1016/j.engappai.2025.110161,2025,1,Scopus
Ada-STGMAT: An adaptive spatio-temporal graph multi-attention network for intelligent time series forecasting in smart cities,,10.1016/j.eswa.2025.126428,2025,9,Scopus
LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters,,10.1145/3719207,2025,25,Scopus
TITD: enhancing optimized temporal position encoding with time intervals and temporal decay in irregular time series forecasting,,10.1007/s10489-025-06293-9,2025,2,Scopus
Adaptive Non-Stationary Fuzzy Time Series Forecasting with Bayesian Networks,,10.3390/s25051628,2025,1,Scopus
Knowledge-enhanced data-driven modeling of wastewater treatment processes for energy consumption prediction,,10.1016/j.compchemeng.2024.108982,2025,2,Scopus
Heterogeneous Graph Transformer Auto-Encoder for multivariate time series forecasting,,10.1016/j.compeleceng.2024.109927,2025,0,Scopus
Forecasting of exchange rate time series based on event-aware transformer mode,,10.1007/s00500-025-10558-3,2025,1,Scopus
Fuzzy-Probabilistic Time Series Forecasting Combining Bayesian Network and Fuzzy Time Series Model,,10.3390/sym17020275,2025,1,Scopus
Parallel multi-scale dynamic graph neural network for multivariate time series forecasting,,10.1016/j.patcog.2024.111037,2025,10,Scopus
A Memory Guided Transformer for Time Series Forecasting,,10.14778/3705829.3705842,2025,3,Scopus
TSI: A Multi-view Representation Learning Approach for Time Series Forecasting,,10.1007/978-981-96-0348-0_21,2025,0,Scopus
Time-lagged relation graph neural network for multivariate time series forecasting,,10.1016/j.engappai.2024.109530,2025,3,Scopus
Mitigating Channel Redundancy for Multivariate Time Series Forecasting,,10.1109/ijcnn64981.2025.11228045,2025,0,Scopus
TravelNet: A Recursive Decomposition-Based Time Series Forecasting Framework for Bus Travel Time Estimation,,10.1109/ijcnn64981.2025.11228543,2025,0,Scopus
A Hybrid BERT-ELM Framework for Robust Time Series Forecasting of Solar Energy Generation in EU Renewable Power Plants,,10.37394/232016.2025.20.25,2025,0,Scopus
AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting,,,2025,0,Scopus
Multi-Dimensional Series Forecasting for Multi-Node Microservices: Leveraging Specialized Embedding in LLMs,,10.1109/hpcc67675.2025.00030,2025,0,Scopus
FusionBC: Contrastive Graph and Information Bottleneck Fusion Learning for Time Series Forecasting,,10.1109/hpcc67675.2025.00040,2025,0,Scopus
FreEformer: Frequency Enhanced Transformer for Multivariate Time Series Forecasting,,10.24963/ijcai.2025/401,2025,0,Scopus
Transformer-PLM Enhanced Multimodal Time Series Forecasting via Decoupled Dual-Temporal Graph Adaptation,,10.1109/lsp.2025.3630087,2025,0,Scopus
DGraFormer: Dynamic Graph Learning Guided Multi-Scale Transformer for Multivariate Time Series Forecasting,,10.24963/ijcai.2025/391,2025,0,Scopus
Dynamic graph structure correction with nonadjacent correlations for multivariate time series forecasting,,10.1016/j.eswa.2025.129768,2025,0,Scopus
Time series forecasting of network traffic with latent domain generalization: Addressing out-of-distribution challenges,,10.1007/s10844-025-01001-y,2025,0,Scopus
Decomposing masked time series model: a self-supervised time-series forecasting framework,,10.1117/12.3068730,2025,0,Scopus
UFGTime: Mining Intertwined Dependencies in Multivariate Time Series via an Efficient Pure Graph Approach,,10.14778/3746405.3746436,2025,0,Scopus
STCA-LLM: Spatial–Temporal Cross-Attention Large Language Model for Wind Speed Forecasting,,10.1109/jiot.2025.3599836,2025,1,Scopus
MORL: A Multi-Objective Representation Learning Modeling for Time Series Forecasting,,10.1109/icsp65755.2025.11086755,2025,0,Scopus
Semi4TSF: End-to-End Semi-Supervised Contrastive Representation Learning for Time Series Forecasting,,10.1109/tii.2025.3588582,2025,1,Scopus
Shareformer: A Patch Transformer Model with Shared Attention for Multivariate Time Series Forecasting,,10.1007/978-981-96-9875-2_27,2025,0,Scopus
CRGNet: Learning Causal Relationships for Multivariate Time Series Forecasting,,10.1007/978-981-96-9818-9_15,2025,0,Scopus
A Novel Discrete Time Series Representation With De Bruijn Graphs for Enhanced Forecasting Using TimesNet,,10.1109/access.2025.3588507,2025,0,Scopus
A Graph SIR Network Based on Dynamic Graph Structures and Residual Learning for Epidemic Prediction,,10.1109/tce.2025.3587036,2025,0,Scopus
A Survey on Neural Ordinary Differential Equations,,10.1007/978-981-96-8183-9_27,2025,1,Scopus
Fourier-driven Lightweight Token Mixing Model for Efficient Time Series Forecasting,,10.1109/tai.2025.3584693,2025,1,Scopus
EGENN: An Efficient Graph-Enhanced Neural Network for Multivariate Time Series Forecasting,,10.1109/icassp49660.2025.10890196,2025,0,Scopus
GT-LSTM: Integrating High-Resolution Particulate Matter Data for Urban Air Quality Forecasting,,10.1007/978-3-031-95728-4_5,2025,0,Scopus
Two-in-One Models for Event Prediction and Time Series Forecasting. Comparison of Four Deep Learning Approaches to Simulate a Digital Patient Under Anesthesia,,10.1007/978-3-031-91398-3_28,2025,0,Scopus
A Multi-scenario Attention-based Generative Model for Personalized Blood Pressure Time Series Forecasting,,10.1109/icassp49660.2025.10889293,2025,1,Scopus
A Data-Level Augmentation Framework for Time Series Forecasting With Ambiguously Related Source Data,,10.1109/tkde.2025.3555530,2025,1,Scopus
Adaptive Graph Structure Learning Neural Rough Differential Equations for Multivariate Time Series Forecasting,,10.1109/tbdata.2025.3552334,2025,2,Scopus
Scale-Aware Neural Architecture Search for Multivariate Time Series Forecasting,,10.1145/3701038,2024,4,Scopus
VTNet: A multi-domain information fusion model for long-term multi-variate time series forecasting with application in irrigation water level,,10.1016/j.asoc.2024.112251,2024,5,Scopus
Contrastive learning enhanced by graph neural networks for Universal Multivariate Time Series Representation,,10.1016/j.is.2024.102429,2024,2,Scopus
Navigating Weight Prediction with Diet Diary,,10.1145/3664647.3680977,2024,3,Scopus
Dynamic Spatial-Temporal Embedding via Neural Conditional Random Field for Multivariate Time Series Forecasting,,10.1145/3675165,2024,0,Scopus
Breaking the Weak Semantics Bottleneck of Transformers in Time Series Forecasting,,10.3233/faia240645,2024,0,Scopus
Mining latent patterns with multi-scale decomposition for electricity demand and price forecasting using modified deep graph convolutional neural networks,,10.1016/j.segan.2024.101436,2024,10,Scopus
Recurrent ensemble random vector functional link neural network for financial time series forecasting,,10.1016/j.asoc.2024.111759,2024,35,Scopus
Root cause localization for wind turbines using physics guided multivariate graphical modeling and fault propagation analysis,,10.1016/j.knosys.2024.111838,2024,13,Scopus
DPHM-Net:de-redundant multi-period hybrid modeling network for long-term series forecasting,,10.1007/s11280-024-01281-4,2024,2,Scopus
Distillation enhanced time series forecasting network with momentum contrastive learning,,10.1016/j.ins.2024.120712,2024,6,Scopus
Toward Using Representation Learning for Cloud Resource Usage Forecasting,,10.1145/3660605.3660942,2024,0,Scopus
A hybrid forecasting system using convolutional-based extreme learning with extended elephant herd optimization for time-series prediction,,10.1007/s00500-023-09499-6,2024,4,Scopus
Dynamic multi-fusion spatio-temporal graph neural network for multivariate time series forecasting,,10.1016/j.eswa.2023.122729,2024,16,Scopus
Time-aware personalized graph convolutional network for multivariate time series forecasting,,10.1016/j.eswa.2023.122471,2024,11,Scopus
A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction,,10.1609/aaai.v38i18.29956,2024,4,Scopus
Learning from Polar Representation: An Extreme-Adaptive Model for Long-Term Time Series Forecasting,,10.1609/aaai.v38i1.27768,2024,11,Scopus
Attentive neural controlled differential equations for time-series classification and forecasting,,10.1007/s10115-023-01977-5,2024,12,Scopus
Bayesian network based probabilistic weighted high-order fuzzy time series forecasting,,10.1016/j.eswa.2023.121430,2024,19,Scopus
AMGCN: adaptive multigraph convolutional networks for traffic speed forecasting,,10.1007/s10489-024-05301-8,2024,3,Scopus
Deep joint modelling of mixed asynchronous streams - Proof of concept for data-driven simulation of a digital patient under anaesthesia,,10.1016/j.procs.2024.09.438,2024,1,Scopus
Multivariate Segment Expandable Encoder-Decoder Model for Time Series Forecasting,,10.1109/access.2024.3513256,2024,1,Scopus
A Novel Discrete Time Series Representation with De Bruijn Graphs for Enhanced Forecasting Using TimesNet (Extended Abstract),,10.1109/dsaa61799.2024.10722826,2024,2,Scopus
Long-Term Interpretable Air Quality Trend Forecasting via Directed Interval Fuzzy Cognitive Maps,,10.1109/tfuzz.2024.3482282,2024,4,Scopus
Long Sequence Multivariate Time-Series Forecasting for Industrial Processes Using SASGNN,,10.1109/tii.2024.3424214,2024,5,Scopus
FedDGCL: Federated Graph Neural Network with Dual Graph Contrast Learning for Multivariable Time Series Forecasting,,10.1007/978-981-97-5552-3_27,2024,0,Scopus
MLFGCN: short-term residential load forecasting via graph attention temporal convolution network,,10.3389/fnbot.2024.1461403,2024,5,Scopus
STGNA: Spatial-Temporal Graph Convolutional Networks with Node Level Attention for Shortwave Communications Parameters Forecasting,,10.1007/978-3-031-72344-5_14,2024,0,Scopus
ESSformer: Transformers with ESS Attention for Long-Term Series Forecasting,,10.1007/978-3-031-72347-6_15,2024,0,Scopus
Time Series Forecasting Based on Structured Decomposition and Variational Autoencoder,,10.1109/ijcnn60899.2024.10650587,2024,0,Scopus
CNN-Based Time Series Decomposition Model for Video Prediction,,10.1109/access.2024.3458460,2024,1,Scopus
Dynamic Personalized Graph Neural Ordinary Differential Equation Network for Multivariate Time Series Prediction of Chemical Processes,,10.1109/ddcls61622.2024.10606557,2024,0,Scopus
Generative Representation Learning in Recurrent Neural Networks for Causal Timeseries Forecasting,,10.1109/tai.2024.3446465,2024,2,Scopus
Learning Time-Aware Graph Structures for Spatially Correlated Time Series Forecasting,,10.1109/icde60146.2024.00338,2024,17,Scopus
TimeDRL: Disentangled Representation Learning for Multivariate Time-Series,,10.1109/icde60146.2024.00054,2024,18,Scopus
Predictive modeling of Alzheimer's disease progression: Integrating temporal clinical factors and outcomes in time series forecasting,,10.1016/j.ibmed.2024.100159,2024,4,Scopus
A Regional Short-term Load Forecasting Method Based on Adaptive Graph Construction and Kernel Size Selection,,10.1109/icps60943.2024.10563907,2024,1,Scopus
GTformer: Graph-Based Temporal-Order-Aware Transformer for Long-Term Series Forecasting,,10.1109/jiot.2024.3419768,2024,11,Scopus
Time Series Representation Learning: A Survey on Deep Learning Techniques for Time Series Forecasting,,10.1007/978-3-031-60606-9_25,2024,1,Scopus
Kernel Representation Learning with Dynamic Regime Discovery for Time Series Forecasting,,10.1007/978-981-97-2266-2_20,2024,7,Scopus
"Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects",,10.1109/tpami.2024.3387317,2024,142,Scopus
TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting,,10.1007/978-3-031-53468-3_8,2024,13,Scopus
Wind Power Forecasting Based on a Spatial-Temporal Graph Convolution Network with Limited Engineering Knowledge,,10.1109/tim.2024.3374321,2024,16,Scopus
Dynamic Hypergraph Structure Learning for Multivariate Time Series Forecasting,,10.1109/tbdata.2024.3362188,2024,25,Scopus
TimeTuner: Diagnosing Time Representations for Time-Series Forecasting with Counterfactual Explanations,,10.1109/tvcg.2023.3327389,2024,6,Scopus
Time-Series Forecasting Through Contrastive Learning with a Two-Dimensional Self-attention Mechanism,,10.1007/978-981-99-8082-6_12,2024,2,Scopus
Multi-scale Multi-step Dependency Graph Neural Network for Multivariate Time-Series Forecasting,,10.1007/978-981-99-8132-8_8,2024,2,Scopus
Dynamic personalized graph neural network with linear complexity for multivariate time series forecasting,,10.1016/j.engappai.2023.107291,2024,9,Scopus
Simple Contrastive Representation Learning for Time Series Forecasting,,10.1109/icassp48485.2024.10446875,2024,6,Scopus
Multi-scale adaptive attention-based time-variant neural networks for multi-step time series forecasting,,10.1007/s10489-023-05057-7,2023,7,Scopus
TDG4MSF: A temporal decomposition enhanced graph neural network for multivariate time series forecasting,,10.1007/s10489-023-04987-6,2023,6,Scopus
Long-term multivariate time series forecasting in data centers based on multi-factor separation evolutionary spatial–temporal graph neural networks,,10.1016/j.knosys.2023.110997,2023,7,Scopus
Learning and integration of adaptive hybrid graph structures for multivariate time series forecasting,,10.1016/j.ins.2023.119560,2023,11,Scopus
Spatiotemporal graph neural network for multivariate multi-step ahead time-series forecasting of sea temperature,,10.1016/j.engappai.2023.106854,2023,25,Scopus
Learning Visibility Attention Graph Representation for Time Series Forecasting,,10.1145/3583780.3615289,2023,2,Scopus
FEAT: A general framework for feature-aware multivariate time-series representation learning,,10.1016/j.knosys.2023.110790,2023,14,Scopus
Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series Forecasting,,10.1109/tkde.2023.3268199,2023,155,Scopus
MrCAN: Multi-relations aware convolutional attention network for multivariate time series forecasting,,10.1016/j.ins.2023.119277,2023,17,Scopus
TTS-Norm: Forecasting Tensor Time Series via Multi-Way Normalization,,10.1145/3605894,2023,20,Scopus
TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting,,10.1145/3580305.3599533,2023,236,Scopus
Look Ahead: Improving the Accuracy of Time-Series Forecasting by Previewing Future Time Features,,10.1145/3539618.3592013,2023,1,Scopus
Num2vec: Pre-Training Numeric Representations for Time Series Forecasting in the Sensing System,,10.1145/3599728,2023,2,Scopus
Spatio-Temporal Meta-Graph Learning for Traffic Forecasting,,10.1609/aaai.v37i7.25976,2023,259,Scopus
TC-GATN: Temporal Causal Graph Attention Networks With Nonlinear Paradigm for Multivariate Time-Series Forecasting in Industrial Processes,,10.1109/tii.2022.3211330,2023,29,Scopus
Multivariate long sequence time-series forecasting using dynamic graph learning,,10.1007/s12652-023-04579-9,2023,17,Scopus
Dynamic graph structure learning for multivariate time series forecasting,,10.1016/j.patcog.2023.109423,2023,91,Scopus
Dynamic spatio-temporal graph network with adaptive propagation mechanism for multivariate time series forecasting,,10.1016/j.eswa.2022.119374,2023,52,Scopus
Core: Transferable Long-Range Time Series Forecasting Enhanced by Covariates-Guided Representation,,10.1109/icassp49357.2023.10096231,2023,1,Scopus
VSNT: Adaptive Network Traffic Forecasting via VMD and Deep Learning with SCI-Block and Attention Mechanism,,10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00046,2023,4,Scopus
GNN and Encoder Integrated Model for Distributed Solar and Wind Power Forecasting,,10.1109/csecs60003.2023.10428146,2023,1,Scopus
Knowledge Enhanced Deep Learning: Application to Pandemic Prediction,,10.1109/cic58953.2023.00016,2023,1,Scopus
The PSR-Transformer Nexus: A Deep Dive into Stock Time Series Forecasting,,10.14569/ijacsa.2023.0141292,2023,3,Scopus
Contrastive Learning Enhanced by Transformer Block for Time Series Forecasting,,10.1117/12.3012295,2023,0,Scopus
SEED: An Effective Model for Highly-Skewed Streamflow Time Series Data Forecasting,,10.1109/bigdata59044.2023.10386959,2023,5,Scopus
H2-Nets: Hyper-hodge Convolutional Neural Networks for Time-Series Forecasting,,10.1007/978-3-031-43424-2_17,2023,2,Scopus
Higher-Order Spatio-Temporal Neural Networks for Covid-19 Forecasting,,10.1109/icassp49357.2023.10095012,2023,2,Scopus
Hierarchical Joint Graph Learning and Multivariate Time Series Forecasting,,10.1109/access.2023.3325041,2023,6,Scopus
MAGNet: Muti-scale Attention and Evolutionary Graph Structure for Long Sequence Time-Series Forecasting,,10.1007/978-3-031-44223-0_18,2023,2,Scopus
SimpleTS: An Efficient and Universal Model Selection Framework for Time Series Forecasting,,10.14778/3611540.3611561,2023,24,Scopus
Learning Gaussian Mixture Representations for Tensor Time Series Forecasting,,10.24963/ijcai.2023/231,2023,6,Scopus
Graph Construction Method for GNN-Based Multivariate Time-Series Forecasting,,10.32604/cmc.2023.036830,2023,5,Scopus
Correlated Time Series Self-Supervised Representation Learning via Spatiotemporal Bootstrapping,,10.1109/case56687.2023.10260640,2023,7,Scopus
Late Meta-learning Fusion Using Representation Learning for Time Series Forecasting,,10.23919/fusion52260.2023.10224217,2023,2,Scopus
Deep Representation Learning for Cluster-Level Time Series Forecasting †,,10.3390/engproc2022018022,2022,4,Scopus
Memory Augmented Graph Learning Networks for Multivariate Time Series Forecasting,,10.1145/3511808.3557638,2022,6,Scopus
Multi-channel fusion graph neural network for multivariate time series forecasting,,10.1016/j.jocs.2022.101862,2022,8,Scopus
Pay Attention to Evolution: Time Series Forecasting with Deep Graph-Evolution Learning,,10.1109/tpami.2021.3076155,2022,50,Scopus
Multivariate Time Series Deep Spatiotemporal Forecasting with Graph Neural Network,,10.3390/app12115731,2022,30,Scopus
Adaptive Dual-View WaveNet for urban spatial–temporal event prediction,,10.1016/j.ins.2021.12.085,2022,48,Scopus
W-Transformers: A Wavelet-based Transformer Framework for Univariate Time Series Forecasting,,10.1109/icmla55696.2022.00111,2022,34,Scopus
Regularized Graph Structure Learning with Semantic Knowledge for Multi-variates Time-Series Forecasting,,10.24963/ijcai.2022/328,2022,39,Scopus
MTHetGNN: A heterogeneous graph embedding framework for multivariate time series forecasting,,10.1016/j.patrec.2021.12.008,2022,49,Scopus
Learning knowledge-enriched company embeddings for investment management,,10.1145/3490354.3494390,2021,8,Scopus
Dependency Learning Graph Neural Network for Multivariate Forecasting,,10.1007/978-3-030-92307-5_14,2021,1,Scopus
Time-series forecasting of mortality rates using deep learning,,10.1080/03461238.2020.1867232,2021,73,Scopus
Weighted Knowledge Graph Embedding,"Knowledge graph embedding (KGE) aims to project both entities and relations in a knowledge graph (KG) into low-dimensional vectors. Indeed, existing KGs suffer from the data imbalance issue, i.e., entities and relations conform to a long-tail distribution, only a small portion of entities and relations occur frequently, while the vast majority of entities and relations only have a few training samples. Existing KGE methods assign equal weights to each entity and relation during the training process. Under this setting, long-tail entities and relations are not fully trained during training, leading to unreliable representations. In this paper, we propose WeightE, which attends differentially to different entities and relations. Specifically, WeightE is able to endow lower weights to frequent entities and relations, and higher weights to infrequent ones. In such manner, WeightE is capable of increasing the weights of long-tail entities and relations, and learning better representations for them. In particular, WeightE tailors bilevel optimization for the KGE task, where the inner level aims to learn reliable entity and relation embeddings, and the outer level attempts to assign appropriate weights for each entity and relation. Moreover, it is worth noting that our technique of applying weights to different entities and relations is general and flexible, which can be applied to a number of existing KGE models. Finally, we extensively validate the superiority of WeightE against various state-of-the-art baselines.",10.1145/3539618.3591784,2023,,ACM
Probabilistic Hypergraph Recurrent Neural Networks for Time-series Forecasting,"Leveraging graph structures for time-series forecasting has garnered significant attention due to their effective relationship modeling between nodes and their associated time-series. However, in scenarios entities communicate in a broadcasting manner, graph models fall short of pairwise modeling. Hypergraph models address this by capturing beyond-pairwise interactions among node time-series. Nevertheless, most hypergraph models overlook the dynamics between nodes and their incident hyperedges, assuming constant node-hyperedge connections. In this paper, we introduce a novel model, Probabilistic Hypergraph Recurrent Neural Networks (PHRNN), which leverages node-hyperedge dynamics for accurate time-series forecasting. PHRNN associates each time-series with a node and models node interactions on a hypergraph, capturing beyond-pairwise interactions. Moreover, PHRNN learns a probabilistic hypergraph in which node-hyperedge relations are modeled as probabilistic distributions instead of fixed values, capturing dynamic node-hyperedge relations. PHRNN further integrates a prior knowledge KNN hypergraph as regularization when learning the probabilistic hypergraph structure. To the best of our knowledge, PHRNN is the first time-series forecasting model that incorporates hypergraph modeling and probabilistic relationship modeling. Forecasting results from extensive experiments show that PHRNN outperforms state-of-the-art graph and hypergraph baselines on real-world datasets.",10.1145/3690624.3709202,2025,,ACM
STLAformer: Segment-based Temporal Lag Attention effective for time series forecasting,"In recent years, Transformer architectures have attracted considerable attention in multivariate time series forecasting due to their powerful sequence modeling capabilities. However, existing methods primarily focus on temporal dependencies while often overlooking complex lagged relationships among variables, where the current state of a variable is mainly influenced by the historical state of other variables at certain previous time steps, indicating strong lagged correlations among them. To address this limitation, we propose STLAformer, a novel model based on a Segment-based Temporal Lag Attention (STLA) mechanism. By partitioning multivariate time series into local segments and introducing a delay-aware attention module, STLAformer effectively captures cross-variable lagged dependencies. Additionally, we design a Temporal Preservation Segmentation Embedding (TPSE) module to independently encode each segment, preserving local dynamic features, and incorporate learnable temporal encoding to enhance the model's representation of temporal structures. Experimental results demonstrate that our approach achieves significant improvements in modeling capability and forecasting accuracy over existing Transformer variants on multiple real-world multivariate time series forecasting tasks, especially exhibiting stronger generalization ability when handling complex lag dependencies.",10.1145/3759928.3759960,2025,,ACM
Domain Generalization in Time Series Forecasting,"Domain generalization aims to design models that can effectively generalize to unseen target domains by learning from observed source domains. Domain generalization poses a significant challenge for time series data, due to varying data distributions and temporal dependencies. Existing approaches to domain generalization are not designed for time series data, which often results in suboptimal or unstable performance when confronted with diverse temporal patterns and complex data characteristics. We propose a novel approach to tackle the problem of domain generalization in time series forecasting. We focus on a scenario where time series domains share certain common attributes and exhibit no abrupt distribution shifts. Our method revolves around the incorporation of a key regularization term into an existing time series forecasting model: domain discrepancy regularization. In this way, we aim to enforce consistent performance across different domains that exhibit distinct patterns. We calibrate the regularization term by investigating the performance within individual domains and propose the domain discrepancy regularization with domain difficulty awareness. We demonstrate the effectiveness of our method on multiple datasets, including synthetic and real-world time series datasets from diverse domains such as retail, transportation, and finance. Our method is compared against traditional methods, deep learning models, and domain generalization approaches to provide comprehensive insights into its performance. In these experiments, our method showcases superior performance, surpassing both the base model and competing domain generalization models across all datasets. Furthermore, our method is highly general and can be applied to various time series models.",10.1145/3643035,2024,,ACM
FinCast: A Foundation Model for Financial Time-Series Forecasting,"Financial time-series forecasting is critical for maintaining economic stability, guiding informed policymaking, and promoting sustainable investment practices. However, it remains challenging due to various underlying pattern shifts. These shifts arise primarily from three sources: temporal non-stationarity (distribution changes over time), multi-domain diversity (distinct patterns across financial domains such as stocks, commodities, and futures), and varying temporal resolutions (patterns differing across per-second, hourly, daily, or weekly indicators). While recent deep learning methods attempt to address these complexities, they frequently suffer from overfitting and typically require extensive domain-specific fine-tuning. To overcome these limitations, we introduce FinCast, the first foundation model specifically designed for financial time-series forecasting, trained on large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot performance, effectively capturing diverse patterns without domain-specific fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate that FinCast surpasses existing state-of-the-art methods, highlighting its strong generalization capabilities.",10.1145/3746252.3761261,2025,,ACM
EAPformer: Entropy-Aware Patch Transformer for Multivariate Long-Term Time Series Forecasting,"Multivariate long-term time series forecasting is pivotal across numerous domains, yet precise predictions require a differentiated assessment of historical time segments due to their varying influence on future trends. Patch-based Transformer frameworks show promise for capturing local temporal patterns. However, they face limitations with static patching, which disrupts temporal continuity, fails to adapt to shifts between periodic and volatile patterns, and overlooks dynamic interactions between time segments and variables. To address these limitations, we propose Entropy-Aware Patch Transformer (EAPformer) which dynamically segments time series for differentiated assessments of historical patterns. Specifically, we overcome static patching limitations by leveraging temporal entropy to dynamically adjust patch boundaries through a two-stage policy, achieving interpretable and context-sensitive segmentation. Subsequently, we adapt EAPformer to periodic and volatile dynamics by employing entropy-aware segmentation that captures distinct temporal patterns across diverse segments. Finally, we further capture dynamic interactions across time segments and variables by introducing a multi-dimensional dependency learning architecture. Additionally, a gated fusion mechanism integrates local and global patterns, enhancing robustness. Extensive experiments on eight public benchmarks demonstrate that EAPformer outperforms state-of-the-art models, achieving superior accuracy across all metrics.",10.1145/3746252.3761055,2025,,ACM
AdaPatch: Adaptive Patch-Level Modeling for Non-Stationary Time Series Forecasting,"Time series forecasting has witnessed significant advancements through deep learning techniques. However, most existing methods struggle in non-stationary environments, where data distributions evolve over time due to concept drift. To address the challenge of non-stationarity in time series, various stabilization techniques have been proposed to mitigate temporal variations. Nonetheless, these methods operate at the instance level, assuming a homogeneous distribution across all time steps within an instance and relying on fixed statistical normalization. This limits their ability to effectively capture fine-grained distributional shifts.In this paper, we introduce AdaPatch, a novel forecasting model specifically designed to tackle non-stationary multivariate time series. AdaPatch addresses intra-instance distributional shifts by adopting an adaptive scheme for patch-level encoding and normalization, which makes the model capture fine-grained temporal variations more effectively. To further enhance the quality of representations, AdaPatch incorporates a patch reconstruction branch and jointly optimizes a reconstruction loss alongside the forecasting objective. This auxiliary path serves as an implicit regularization mechanism, guiding the encoder to retain meaningful local temporal structures. Furthermore, to enable AdaPatch to better model complex local dynamics, we propose a patch-based predictive decoding strategy that leverages the decoder from the reconstruction branch to replace conventional point-wise forecasting with a more structured patch-level prediction mechanism. Extensive experiments conducted on six real-world multivariate time series datasets demonstrate that AdaPatch achieves superior performance compared to several state-of-the-art baselines, highlighting its effectiveness and strong generalization capability. Our code and data are publicly available at https://github.com/iuaku/AdaPatch.",10.1145/3746252.3761360,2025,,ACM
TS-Fastformer: Fast Transformer for Time-series Forecasting,"Many real-world applications require precise and fast time-series forecasting. Recent trends in time-series forecasting models are shifting from LSTM-based models to Transformer-based models. However, the Transformer-based model has a limited ability to represent sequential relationships in time-series data. In addition, the transformer-based model suffers from slow training and inference speed due to the bottleneck incurred by a deep encoder and step-by-step decoder inference. To address these problems, we propose a time-series forecasting optimized Transformer model, called TS-Fastformer. TS-Fastformer introduces three new optimizations: First, we propose a Sub Window Tokenizer for compressing input in a simple manner. The Sub Window Tokenizer reduces the length of input sequences to mitigate the complexity of self-attention and enables both single and multi-sequence learning. Second, we propose Time-series Pre-trained Encoder to extract effective representations through pre-training. This optimization enables TS-Fastformer to capture both seasonal and trend representations as well as to mitigate bottlenecks of conventional transformer models. Third, we propose the Past Attention Decoder to forecast target by incorporating past long short-term dependency patterns. Furthermore, Past Attention Decoder achieves high performance improvement by removing a trend distribution that changes over a long period. We evaluate the efficiency of our model with extensive experiments using seven real-world datasets and compare our model to six representative time-series forecasting approaches. The results show that the proposed TS-Fastformer reduces MSE by 10.1\% compared to state-of-the-art model and demonstrates 21.6\% faster training time compared to the existing fastest transformer, respectively.",10.1145/3630637,2024,,ACM
Generative Pretrained Hierarchical Transformer for Time Series Forecasting,"Recent efforts have been dedicated to enhancing time series forecasting accuracy by introducing advanced network architectures and self-supervised pretraining strategies. Nevertheless, existing approaches still exhibit two critical drawbacks. Firstly, these methods often rely on a single dataset for training, limiting the model's generalizability due to the restricted scale of the training data. Secondly, the one-step generation schema is widely followed, which necessitates a customized forecasting head and overlooks the temporal dependencies in the output series, and also leads to increased training costs under different horizon length settings.  To address these issues, we propose a novel generative pretrained hierarchical transformer architecture for forecasting, named GPHT. There are two aspects of key designs in GPHT. On the one hand, we advocate for constructing a mixed dataset under the channel-independent assumption for pretraining our model, comprising various datasets from diverse data scenarios. This approach significantly expands the scale of training data, allowing our model to uncover commonalities in time series data and facilitating improved transfer to specific datasets. On the other hand, GPHT employs an auto-regressive forecasting approach, effectively modeling temporal dependencies in the output series. Importantly, no customized forecasting head is required, enablinga single model to forecast at arbitrary horizon settings. We conduct sufficient experiments on eight datasets with mainstream self-supervised pretraining models and supervised models. The results demonstrated that GPHT surpasses the baseline models across various fine-tuning and zero/few-shot learning settings in the traditional long-term forecasting task, providing support for verifying the feasibility of pretraining time series large models. We make our codes publicly availablefootnotehttps://github.com/icantnamemyself/GPHT.",10.1145/3637528.3671855,2024,,ACM
TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations,"Time series forecasting is critical across various domains, such as weather, finance and real estate forecasting, as accurate forecasts support informed decision-making and risk mitigation. While recent deep learning models have improved predictive capabilities, they often overlook time-lagged cross-correlations between related sequences, which are crucial for capturing complex temporal relationships. To address this, we propose the Time-Lagged Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances forecasting accuracy by effectively integrating time-lagged cross-correlated sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW) algorithm to capture lagged correlations and a contrastive learning-based encoder to efficiently approximate SSDTW distances. Experimental results on weather, finance and real estate time series datasets demonstrate the effectiveness of our framework. On the weather dataset, SSDTW reduces mean squared error (MSE) by 16.01\% compared with single-sequence methods, while the contrastive learning encoder (CLE) further decreases MSE by 17.88\%. On the stock dataset, SSDTW achieves a 9.95\% MSE reduction, and CLE reduces it by 6.13\%. For the real estate dataset, SSDTW and CLE reduce MSE by 21.29\% and 8.62\%, respectively. Additionally, the contrastive learning approach decreases SSDTW computational time by approximately 99\%, ensuring scalability and real-time applicability across multiple time series forecasting tasks.",10.1145/3746252.3761410,2025,,ACM
TSFM-Bench: A Comprehensive and Unified Benchmark of Foundation Models for Time Series Forecasting,"Time Series Forecasting (TSF) is key functionality in numerous fields, such as financial investment, weather services, and energy management. Although increasingly capable TSF methods occur, many of them require domain-specific data collection and model training and do not generalize well when applied in other domains. Time Series Foundation Models (TSFMs) that are pre-trained on massive heterogeneous time series data aim to overcome these limitations. The prospects for generalizability have spurred the development of a new generation of TSFMs. This study proposes a benchmark, TSFM-Bench, to facilitate comprehensive and unified evaluation of TSFMs. TSFM-Bench covers a wide range of TSFMs, including those based on large language models and those pre-trained on time series data. TSFM-Bench supports multiple forecasting scenarios, including zero-shot, few-shot, and full-shot, enabling assessment across the full range of adaptation strategies. TSFM-Bench also provides a standardized experimental protocols for critical evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, facilitating consistency and fairness. We report on an extensive evaluation of TSFMs across a diverse range of datasets spanning multiple domains and exhibiting varied statistical characteristics. Specifically, we identify pros and cons and inherent limitations of existing TSFMs, and we propose potential directions for new model designs.",10.1145/3711896.3737442,2025,,ACM
Scalable Transformer for High Dimensional Multivariate Time Series Forecasting,"Deep models for Multivariate Time Series (MTS) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional MTS data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address these issues, we propose STHD, the Scalable Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has three components: a) Relation Matrix Sparsity that limits the noise introduced and alleviates the memory issue; b) ReIndex applied as a training strategy to enable a more flexible batch size setting and increase the diversity of training data; and c) Transformer that handles 2-D inputs and captures channel dependencies. These components jointly enable STHD to manage the high-dimensional MTS while maintaining computational feasibility. Furthermore, experimental results show STHD's considerable improvement on three high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source code and dataset are publicly available https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.",10.1145/3627673.3679757,2024,,ACM
TF-GAN: Topology-Aware Generative Adversarial Network for Financial Time Series Forecasting,"Financial time series prediction has long been a topic of interest, and with the rise of machine learning, numerous models have been proposed to improve forecasting accuracy. However, existing approaches largely overlook the topological structure inherent in financial data. In this paper, we propose Topology-aware Financial Generative Adversarial Networks (TF-GAN), a topology-aware adversarial forecasting framework that incorporates topological data analysis (TDA) into the training process. Building upon the ForGAN and Fin-GAN frameworks, TF-GAN introduces a novel topology-aware loss function based on persistent homology that encourages generated sequences to preserve the structural patterns of real financial data. To the best of our knowledge, we are among the first to design and implement a differentiable topological loss function with full gradient support in PyTorch, enabling end-to-end training. Experiments on 5-minute interval stock data for Amazon and IBM show that our method significantly improves both prediction accuracy (RMSE, MAE) and financial performance (Sharpe Ratio, cumulative PnL). TF-GAN improves the Sharpe Ratio by up to 318\% compared to the original ForGAN, and achieves up to 295\% higher Sharpe Ratios compared to Fin-GAN across diverse financial loss functions. The proposed TF-GAN framework demonstrates that incorporating topological structure into the adversarial learning loop yields more robust and profitable predictions, offering a new direction for structure-aware financial forecasting.",10.1145/3768292.3770429,2025,,ACM
Dynamic Network-Based Two-Stage Time Series Forecasting for Affiliate Marketing,"In recent years, affiliate marketing has emerged as a revenue-sharing strategy where merchants collaborate with promoters to promote their products. It not only increases product exposure but also allows promoters to earn a commission. This paper addresses the pivotal yet under-explored challenge in affiliate marketing: accurately assessing and predicting the contributions of promoters in product promotion. We design a novel metric for evaluating the indirect contributions of the promoter, called propagation scale. Unfortunately, existing time series forecasting techniques fail to deliver accurate predictions due to the propagation scale being influenced by multiple factors and the inherent complexities arising from dynamic scenarios. To address this issue, we decouple the network structure from the node signals and propose a two-stage solution: initially, the basic self-sales and network structure prediction are conducted separately, followed by the synthesis of the propagation scale. Specifically, we design a graph convolution encoding scheme based on descendant neighbors and incorporate hypergraph convolution to efficiently capture complex promotional dynamics. Additionally, three auxiliary tasks are employed: self-sales prediction for base estimations, descendant prediction to synthesize propagation scale, and promoter activation prediction to mitigate high volatility issues. Extensive offline experiments on large-scale industrial datasets validate the superiority of our method. We further deploy our model on Alimama platform with over 100,000 promoters, achieving a 9.29\% improvement in GMV and a 5.89\% increase in sales volume.",10.1145/3746252.3761515,2025,,ACM
MSOFormer: Multi-scale Transformer with Orthogonal Embedding and Frequency Modeling for Multivariate Time Series Forecasting,"Multivariate Time Series Forecasting (MTSF) plays a critical role in diverse practical applications. Although Transformer-based models have recently achieved impressive results in this field, their performance is still hindered by three core challenges: complex temporal dependencies, diverse inter-variable correlations, and patterns that span multiple time scales. To address these issues, we propose MSOFormer-a Multi-scale Transformer with Orthogonal Embedding and Frequency Modeling. Specifically, the Dynamic Frequency Filter adaptively weights frequency components across variables based on input characteristics, enabling full-spectrum modeling and precise extraction of key frequency patterns. To improve inter-variable representation, we introduce Orthogonal Embedding, a novel projection strategy for queries and keys that enhances feature diversity in channel-wise self-attention. In addition, Multi-scale Patch Embedding captures temporal features across different scales, providing a comprehensive time series representation. To evaluate MTSF in cloud-native environments, we construct the first three Cloud Kafka cluster datasets, specifically curated for elastic message queue scaling scenarios. Extensive experiments across eleven real-world benchmark datasets demonstrate that MSOFormer consistently outperforms existing state-of-the-art methods, highlighting its effectiveness and broad applicability.",10.1145/3746252.3761143,2025,,ACM
Mitigating Data Redundancy to Revitalize Transformer-based Long-Term Time Series Forecasting System,"Long-term time-series forecasting (LTSF) is fundamental to various real-world applications, where Transformer-based models have become the dominant framework due to their ability to capture long-range dependencies. However, these models often experience overfitting due to data redundancy in rolling forecasting settings, limiting their generalization ability particularly evident in longer sequences with highly similar adjacent data. In this work, we introduce CLMFormer, a novel framework that mitigates redundancy through curriculum learning and a memory-driven decoder. Specifically, we progressively introduce Bernoulli noise to the training samples, which effectively breaks the high similarity between adjacent data points. This curriculum-driven noise introduction aids the memory-driven decoder by supplying more diverse and representative training data, enhancing the decoder’s ability to model seasonal tendencies and dependencies in the time-series data. To further enhance forecasting accuracy, we introduce a memory-driven decoder. This component enables the model to capture seasonal tendencies and dependencies in the time-series data and leverages temporal relationships to facilitate the forecasting process. Extensive experiments on six real-world LTSF benchmarks show that CLMFormer consistently improves Transformer-based models by up to 30\%, demonstrating its effectiveness in long-horizon forecasting.",10.1145/3735651,2025,,ACM
Deep Coupling Network for Multivariate Time Series Forecasting,"Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this article, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines.",10.1145/3653447,2024,,ACM
TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations,"Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance. The code is available at: https://github.com/Luoauoa/TimeCapsule.git.",10.1145/3711896.3737157,2025,,ACM
Beyond Fixed Variables: Expanding-variate Time Series Forecasting via Flat Scheme and Spatio-temporal Focal Learning,"Multivariate Time Series Forecasting (MTSF) has long been a key research focus. Traditionally, these studies assume a fixed number of variables, but in real-world applications, Cyber-Physical Systems often expand as new sensors are deployed, increasing variables in MTSF. In light of this, we introduce a novel task, Expanding-variate Time Series Forecasting (EVTSF). This task presents unique challenges, specifically (1) handling inconsistent data shapes caused by adding new variables, and (2) addressing imbalanced spatio-temporal learning, where expanding variables have limited observed data due to the necessity for timely operation. To address these challenges, we propose STEV, a flexible spatio-temporal forecasting framework. STEV includes a new Flat Scheme to tackle the inconsistent data shape issue, which extends the graph-based spatio-temporal modeling architecture into 1D space by flattening the 2D samples along the variable dimension, making the model variable-scale-agnostic while still preserving dynamic spatial correlations through a holistic graph. Additionally, we introduce a novel Spatio-temporal Focal Learning strategy that incorporates a negative filter to resolve potential conflicts between contrastive learning and graph representation, and a focal contrastive loss as its core to guide the framework to focus on optimizing the expanding variables. To evaluate the effectiveness of STEV, we benchmark EVTSF performance on three real-world datasets from various domains and compare it against three potential solutions employing state-of-the-art (SOTA) MTSF models tailored for EVSTF. Experimental results show that STEV significantly outperforms its competitors, especially in handling expanding variables. Notably, STEV, with only 5\% of observations during the expanding period, is on par with SOTA MTSF models trained with complete data. Further exploration of various expanding scenarios underscores the generalizability of STEV in real-world applications.",10.1145/3711896.3736854,2025,,ACM
ST-MTM: Masked Time Series Modeling with Seasonal-Trend Decomposition for Time Series Forecasting,"Forecasting complex time series is an important yet challenging problem that involves various industrial applications. Recently, masked time-series modeling has been proposed to effectively model temporal dependencies for forecasting by reconstructing masked segments from unmasked ones. However, since the semantic information in time series is involved in intricate temporal variations generated by multiple time series components, simply masking a raw time series ignores the inherent semantic structure, which may cause MTM to learn spurious temporal patterns present in the raw data. To capture distinct temporal semantics, we show that masked modeling techniques should address entangled patterns through a decomposition approach. Specifically, we propose ST-MTM, a masked time-series modeling framework with seasonal-trend decomposition, which includes a novel masking method for the seasonal-trend components that incorporates different temporal variations from each component. ST-MTM uses a period masking strategy for seasonal components to produce multiple masked seasonal series based on inherent multi-periodicity and a sub-series masking strategy for trend components to mask temporal regions that share similar variations. The proposed masking method presents an effective pre-training task for learning intricate temporal variations and dependencies. Additionally, ST-MTM introduces a contrastive learning task to support masked modeling by enhancing contextual consistency among multiple masked seasonal representations. Experimental results show that our proposed ST-MTM achieves consistently superior forecasting performance compared to existing masked modeling, contrastive learning, and supervised forecasting methods.",10.1145/3690624.3709254,2025,,ACM
UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting,"Multivariate time series forecasting plays a pivotal role in contemporary web technologies. In contrast to conventional methods that involve creating dedicated models for specific time series application domains, this research advocates for a unified model paradigm that transcends domain boundaries. However, learning an effective cross-domain model presents the following challenges. First, various domains exhibit disparities in data characteristics, e.g., the number of variables, posing hurdles for existing models that impose inflexible constraints on these factors. Second, the model may encounter difficulties in distinguishing data from various domains, leading to suboptimal performance in our assessments. Third, the diverse convergence rates of time series domains can also result in compromised empirical performance. To address these issues, we propose UniTime for effective cross-domain time series learning. Concretely, UniTime can flexibly adapt to data with varying characteristics. It also uses domain instructions and a Language-TS Transformer to offer identification information and align two modalities. In addition, UniTime employs masking to alleviate domain convergence speed imbalance issues. Our extensive experiments demonstrate the effectiveness of UniTime in advancing state-of-the-art forecasting performance and zero-shot transferability.",10.1145/3589334.3645434,2024,,ACM
ST-Hyper: Learning High-Order Dependencies Across Multiple Spatial-Temporal Scales for Multivariate Time Series Forecasting,"In multivariate time series (MTS) forecasting, many deep learning based methods have been proposed for modeling dependencies at multiple spatial (inter-variate) or temporal (intra-variate) scales. However, existing methods may fail to model dependencies across multiple spatial-temporal scales (ST-scales, i.e., scales that jointly consider spatial and temporal scopes). In this work, we propose ST-Hyper to model the high-order dependencies across multiple ST-scales through adaptive hypergraph modeling. Specifically, we introduce a Spatial-Temporal Pyramid Modeling (STPM) module to extract features at multiple ST-scales. Furthermore, we introduce an Adaptive Hypergraph Modeling (AHM) module that learns a sparse hypergraph to capture robust high-order dependencies among features. In addition, we interact with these features through tri-phase hypergraph propagation, which can comprehensively capture multi-scale spatial-temporal dynamics. Experimental results on six real-world MTS datasets demonstrate that ST-Hyper achieves the state-of-the-art performance, outperforming the best baselines with an average MAE reduction of 3.8\% and 6.8\% for long-term and short-term forecasting, respectively. Code is available at https://anonymous.4open.science/ST-Hyper-83E7.",10.1145/3746252.3761281,2025,,ACM
Seeing Sequences like Humans: Pattern Classification Driven Time-Series Forecasting via Vision Language Models,"Time-series forecasting is critical to highly data-dependent domains such as energy, healthcare, and transportation. Although Large Language Models have recently been explored for this task, their performance is hindered by a modality gap: numerical sequences poorly align with text-based inputs, and direct alignment often introduces noise. In contrast, human experts rarely predict directly from numbers; they first inspect line charts to recognize overall patterns and then apply simple models for forecasting. Inspired by this workflow, we propose VisMoE, a Vision-Language-Model-driven Mixture-of-Experts framework. In VisMoE, Each sequence is transformed into a line-chart image, enabling a VLM to classify it into distinct temporal regimes. Based on this classification, VisMoE routes the sequence to lightweight specialized experts operating alongside a global predictor, whose outputs are fused for final forecasts. This human-inspired design preserves semantic understanding, reduces modality misalignment, and improves computational efficiency. Extensive experiments across multiple benchmarks demonstrate that VisMoE achieves state-of-the-art forecasting accuracy while remaining highly efficient. Our code is available at https://github.com/Liu905169/VisMoE.",10.1145/3746252.3761199,2025,,ACM
Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting,"Spatiotemporal time series forecasting plays a key role in a wide range of real-world applications. While significant progress has been made in this area, fully capturing and leveraging spatiotemporal heterogeneity remains a fundamental challenge. Therefore, we propose a novel Heterogeneity-Informed Meta-Parameter Learning scheme. Specifically, our approach implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings, which can be viewed as a clustering process. Then, a novel spatiotemporal meta-parameter learning paradigm is proposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity. Based on these ideas, we develop a &lt;u&gt;H&lt;/u&gt;eterogeneity-&lt;u&gt;I&lt;/u&gt;nformed Spatiotemporal &lt;u&gt;M&lt;/u&gt;eta-&lt;u&gt;Net&lt;/u&gt;work (HimNet) for spatiotemporal time series forecasting. Extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance while exhibiting superior interpretability. Our code is available at &lt;u&gt;https://github.com/XDZhelheim/HimNet&lt;/u&gt;.",10.1145/3637528.3671961,2024,,ACM
Multiple Time Series Forecasting with Dynamic Graph Modeling,"Multiple time series forecasting plays an essential role in many applications. Solutions based on graph neural network (GNN) that deliver state-of-the-art forecasting performance use the relation graph which can capture historical correlations among time series. However, in real world, it is common that correlations among time series evolve across time, resulting in dynamic relation graph, where the future correlations may be different from those in history. To address this problem, we propose multiple time series forecasting with dynamic graph modeling (MTSF-DG) that is able to learn historical relation graphs and predicting future relation graphs to capture the dynamic correlations. We also propose a causal GNN to extract features from both kinds of relation graphs efficiently. Then we propose a reasoning network to explicitly learn the variant influence from historical timestamps to future timestamps for final forecasting. Extensive experiments on six benchmark datasets show that MTSF-DG consistently outperforms state-of-the-art baselines, and justify our design with dynamic relation graph modeling.",10.14778/3636218.3636230,2023,,ACM
Weakly Guided Adaptation for Robust Time Series Forecasting,"Robust multivariate time series forecasting is crucial in many cyberphysical and Internet of Things applications. Existing state-of-the-art robust forecasting models decompose time series into independent functions covering trends and periodicities. However, these independent functions fail to capture correlations among multiple time series, thereby reducing prediction accuracy. Moreover, existing robust forecasting models treat certain abrupt but normal changes, e.g., caused by holidays, as outliers because they occur infrequently and have data distributions that resemble those of outliers. This exacerbates model bias and reduces prediction accuracy. This paper aims to capture correlations across multiple time series and abrupt but normal changes, thereby improving prediction accuracy. We employ weak labels to partition the dataset into source and target domains. Then, we propose the Domain Adversarial Robust Forecaster (DARF). This forecasting model is based on adversarial domain adaptation and includes two novel modules: Correlated Robust Forecaster (CORF) and Domain Critic. Specifically, CORF constitutes an encoder-decoder framework proficient at robust multivariate time series forecasting, and Domain Critic works to reduce data bias. Extensive experiments and discussions show that DARF is capable of state-of-the-art forecasting accuracy.",10.14778/3636218.3636231,2023,,ACM
Graph Deep Factors for Probabilistic Time-series Forecasting,"Effective time-series forecasting methods are of significant importance to solve a broad spectrum of research problems. Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, a relational global model learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, a relational local model not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average. Furthermore, we target addressing the common nature of many time-series forecasting applications where time-series are provided in a streaming version; however, most methods fail to leverage the newly incoming time-series values and result in worse performance over time. In this article, we propose an online incremental learning framework for probabilistic forecasting. The framework is theoretically proven to have lower time and space complexity. The framework can be universally applied to many other machine learning-based methods.",10.1145/3543511,2023,,ACM
APAN: Asynchronous Propagation Attention Network for Real-time Temporal Graph Embedding,"To capture higher-order structural features, most GNN-based algorithms learn node representations incorporating k-hop neighbors' information. Due to the high time complexity of querying k-hop neighbors, most graph algorithms cannot be deployed in a giant dense temporal network to execute millisecond-level inference. This problem dramatically limits the potential of applying graph algorithms in certain areas, especially financial fraud detection. Therefore, we propose Asynchronous Propagation Attention Network, an asynchronous continuous time dynamic graph algorithm for real-time temporal graph embedding. Traditional graph models usually execute two serial operations: first graph querying and then model inference. Different from previous graph algorithms, we decouple model inference and graph computation to alleviate the damage of the heavy graph query operation to the speed of model inference. Extensive experiments demonstrate that the proposed method can achieve competitive performance while greatly improving the inference speed. The source code is published at a Github repository.",10.1145/3448016.3457564,2021,,ACM
TimelyGPT: Extrapolatable Transformer Pre-training for Long-term Time-Series Forecasting in Healthcare,"Motivation: Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success in Natural Language Processing and Computer Vision domains. However, the development of PTMs on healthcare time-series data is lagging behind. This underscores the limitations of the existing transformer-based architectures, particularly their scalability to handle large-scale time series and ability to capture long-term temporal dependencies.Methods: In this study, we present Timely Generative Pre-trained Transformer (TimelyGPT). TimelyGPT employs an extrapolatable position (xPos) embedding to encode trend and periodic patterns into time-series representations. It also integrates recurrent attention and temporal convolution modules to effectively capture global-local temporal dependencies.Materials: We evaluated TimelyGPT on two large-scale healthcare time series datasets corresponding to continuous biosignals and irregularly-sampled time series, respectively: (1) the Sleep EDF dataset consisting of over 1.2 billion timesteps; (2) the longitudinal healthcare administrative database PopHR, comprising 489,000 patients randomly sampled from the Montreal population.Results: In forecasting continuous biosignals, TimelyGPT achieves accurate extrapolation up to 6,000 timesteps of body temperature during the sleep stage transition, given a short look-up window (i.e., prompt) containing only 2,000 timesteps. For irregularly-sampled time series, TimelyGPT with a proposed time-specific inference demonstrates high top recall scores in predicting future diagnoses using early diagnostic records, effectively handling irregular intervals between clinical records. Together, we envision TimelyGPT to be useful in various health domains, including long-term patient health state forecasting and patient risk trajectory prediction. Availability: The open-sourced code is available at Github.",10.1145/3698587.3701364,2024,,ACM
GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing,"Multivariate time series forecasting (MTSF) is crucial for decision-making to precisely forecast the future values/trends, based on the complex relationships identified from historical observations of multiple sequences. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme of MTSF model as their powerful capability in mining spatial-temporal dependencies, but almost of them heavily rely on the assumption of historical data integrity. In reality, due to factors such as data collector failures and time-consuming repairment, it is extremely challenging to collect the whole historical observations without missing any variable. In this case, STGNNs can only utilize a subset of normal variables and easily suffer from the incorrect spatial-temporal dependency modeling issue, resulting in the degradation of their forecasting performance. To address the problem, in this paper, we propose a novel Graph Interpolation Attention Recursive Network (named GinAR) to precisely model the spatial-temporal dependencies over the limited collected data for forecasting. In GinAR, it consists of two key components, that is, interpolation attention and adaptive graph convolution to take place of the fully connected layer of simple recursive units, and thus are capable of recovering all missing variables and reconstructing the correct spatial-temporal dependencies for recursively modeling of multivariate time series data, respectively. Extensive experiments conducted on five real-world datasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when 90\% of variables are missing, it can still accurately predict the future values of all variables.",10.1145/3637528.3672055,2024,,ACM
A Distribution Graph Guided Network with Dual Track Self-Supervised Strategy for Tobacco Pest Time Series Forecasting,"Tobacco pest is one of the main factors that harm tobacco quality in tobacco factories, leading to economic losses. Accurate prediction of pest distribution is crucial for the management and production of tobacco factories. Nevertheless, conventional time series forecasting techniques prove inadequate in capturing sufficient information for fine-grained forecasting tasks involving district-variable-level and day-sampling-level tobacco pest datasets. This limitation arises from the lack of consideration for the knowledge pertaining to the migration and reproduction patterns of tobacco pests. In this work, a dual track self-supervised and distribution graph guided network (DTSSDGN) is proposed to handle this problem. First, a distribution graph guided feature extraction module is designed to help capture the internal and external patterns of pest distribution. Subsequently, a two-stage training strategy is devised, comprising a dual-track self-supervised training phase to acquire features that possess a comprehensive understanding of the pest distribution trend, followed by a fine-grained fine-tuning phase that leverages this knowledge to achieve accurate forecasting outcomes. The effectiveness and superiority of the proposed method are illustrated on a real tobacco pest distribution dataset.",10.1145/3704558.3707079,2025,,ACM
LightCTS: A Lightweight Framework for Correlated Time Series Forecasting,"Correlated time series (CTS) forecasting plays an essential role in many practical applications, such as traffic management and server load control. Many deep learning models have been proposed to improve the accuracy of CTS forecasting. However, while models have become increasingly complex and computationally intensive, they struggle to improve accuracy. Pursuing a different direction, this study aims instead to enable much more efficient, lightweight models that preserve accuracy while being able to be deployed on resource-constrained devices. To achieve this goal, we characterize popular CTS forecasting models and yield two observations that indicate directions for lightweight CTS forecasting. On this basis, we propose the LightCTS framework that adopts plain stacking of temporal and spatial operators instead of alternate stacking that is much more computationally expensive. Moreover, LightCTS features light temporal and spatial operator modules, called L-TCN and GL-Former, that offer improved computational efficiency without compromising their feature extraction capabilities. LightCTS also encompasses a last-shot compression scheme to reduce redundant temporal features and speed up subsequent computations. Experiments with single-step and multi-step forecasting benchmark datasets show that LightCTS is capable of nearly state-of-the-art accuracy at much reduced computational and storage overheads.",10.1145/3589270,2023,,ACM
Multi-Variate Time Series Forecasting on Variable Subsets,"We formulate a new inference task in the domain of multivariate time series forecasting (MTSF), called Variable Subset Forecast (VSF), where only a small subset of the variables is available during inference. Variables are absent during inference because of long-term data loss (eg. sensor failures) or high -&gt; low-resource domain shift between train / test. To the best of our knowledge, robustness of MTSF models in presence of such failures, has not been studied in the literature. Through extensive evaluation, we first show that the performance of state of the art methods degrade significantly in the VSF setting. We propose a non-parametric, wrapper technique that can be applied on top any existing forecast models. Through systematic experiments across 4 datasets and 5 forecast models, we show that our technique is able to recover close to 95\% performance of the models even when only 15\% of the original variables are present.",10.1145/3534678.3539394,2022,,ACM
TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods,"Time series are generated in diverse domains such as economic, traffic, health, and energy, where forecasting of future values has numerous important applications. Not surprisingly, many forecasting methods are being proposed. To ensure progress, it is essential to be able to study and compare such methods empirically in a comprehensive and reliable manner. To achieve this, we propose TFB, an automated benchmark for Time Series Forecasting (TSF) methods. TFB advances the state-of-the-art by addressing shortcomings related to datasets, comparison methods, and evaluation pipelines: 1) insufficient coverage of data domains, 2) stereotype bias against traditional methods, and 3) inconsistent and inflexible pipelines. To achieve better domain coverage, we include datasets from 10 different domains : traffic, electricity, energy, the environment, nature, economic, stock markets, banking, health, and the web. We also provide a time series characterization to ensure that the selected datasets are comprehensive. To remove biases against some methods, we include a diverse range of methods, including statistical learning, machine learning, and deep learning methods, and we also support a variety of evaluation strategies and metrics to ensure a more comprehensive evaluations of different methods. To support the integration of different methods into the benchmark and enable fair comparisons, TFB features a flexible and scalable pipeline that eliminates biases. Next, we employ TFB to perform a thorough evaluation of 21 Univariate Time Series Forecasting (UTSF) methods on 8,068 univariate time series and 14 Multivariate Time Series Forecasting (MTSF) methods on 25 datasets. The results offer a deeper understanding of the forecasting methods, allowing us to better select the ones that are most suitable for particular datasets and settings. Overall, TFB and this evaluation provide researchers with improved means of designing new TSF methods.",10.14778/3665844.3665863,2024,,ACM
Large Scale Financial Time Series Forecasting with Multi-faceted Model,"Data-driven approaches using deep neural networks have been successful in modeling complex financial time series and generating accurate predictions without requiring extensive domain knowledge. However, most of the existing models that assume independent and identically distributed (i.i.d.) data may not generalize well to novel situations or distributional shifts across or inside financial scenarios. To address this challenge, we introduce an invariant learning-based regularizer with relaxed bounds that expands the range of feasible solutions and mitigates over-convergence issues in Invariant Risk Minimization (IRM). In practice, the regularizer can be incorporated into both linear and nonlinear financial time series forecasting models. Experimental results on real-world large-scale financial datasets show that our proposed method enables more robust and adaptable financial forecasting models, enhancing the overall performance and generalizability of financial forecasting on both in-distribution and out-of-distribution (OOD) samples.",10.1145/3604237.3626868,2023,,ACM
RPMixer: Shaking Up Time Series Forecasting with Random Projections for Large Spatial-Temporal Data,"Spatial-temporal forecasting systems play a crucial role in addressing numerous real-world challenges. In this paper, we investigate the potential of addressing spatial-temporal forecasting problems using general time series forecasting models, i.e., models that do not leverage the spatial relationships among the nodes. We propose a all-Multi-Layer Perceptron (all-MLP) time series forecasting architecture called RPMixer. The all-MLP architecture was chosen due to its recent success in time series forecasting benchmarks. Furthermore, our method capitalizes on the ensemble-like behavior of deep neural networks, where each individual block within the network behaves like a base learner in an ensemble model, particularly when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby improving the overall performance of the network. Extensive experiments conducted on the largest spatial-temporal forecasting benchmark datasets demonstrate that the proposed method outperforms 14 alternative methods.",10.1145/3637528.3671881,2024,,ACM
Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Networks,"Accurate traffic forecasting is crucial for the development of Intelligent Transportation Systems (ITS), playing a pivotal role in modern urban traffic management. Traditional forecasting methods, however, struggle with the irregular traffic time series resulting from adaptive traffic signal controls, presenting challenges in asynchronous spatial dependency, irregular temporal dependency, and predicting variable-length sequences. To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) tailored for irregular traffic time series forecasting. Specifically, we first propose an Asynchronous Graph Diffusion Network to capture the spatial dependency between asynchronously measured traffic states regulated by adaptive traffic signals. After that, to capture the temporal dependency within irregular traffic state sequences, a personalized time encoding is devised to embed the continuous time signals. Then, we propose a Transformable Time-aware Convolution Network, which adapts meta-filters for time-aware convolution on the sequences with inconsistent temporal flow. Additionally, a Semi-Autoregressive Prediction Network, comprising a state evolution unit and a semiautoregressive predictor, is designed to predict variable-length traffic sequences effectively and efficiently. Extensive experiments on a newly established benchmark demonstrate the superiority of ASeer compared with twelve competitive baselines across six metrics.",10.1145/3637528.3671665,2024,,ACM
Deep Extreme Mixture Model for Time Series Forecasting,"Time Series Forecasting (TSF) has been a topic of extensive research, which has many real world applications such as weather prediction, stock market value prediction, traffic control etc. Many machine learning models have been developed to address TSF, yet, predicting extreme values remains a challenge to be effectively addressed. Extreme events occur rarely, but tend to cause a huge impact, which makes extreme event prediction important. Assuming light tailed distributions, such as Gaussian distribution, on time series data does not do justice to the modeling of extreme points. To tackle this issue, we develop a novel approach towards improving attention to extreme event prediction. Within our work, we model time series data distribution, as a mixture of Gaussian distribution and Generalized Pareto distribution (GPD). In particular, we develop a novel Deep eXtreme Mixture Model (DXtreMM) for univariate time series forecasting, which addresses extreme events in time series. The model consists of two modules: 1) Variational Disentangled Auto-encoder (VD-AE) based classifier and 2) Multi Layer Perceptron (MLP) based forecaster units combined with Generalized Pareto Distribution (GPD) estimators for lower and upper extreme values separately. VD-AE Classifier model predicts the possibility of occurrence of an extreme event given a time segment, and forecaster module predicts the exact value. Through extensive set of experiments on real-world datasets we have shown that our model performs well for extreme events and is comparable with the existing baseline methods for normal time step forecasting.",10.1145/3511808.3557282,2022,,ACM
Blurred Encoding for Trajectory Representation Learning,"Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLU rred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90\%. Our code is available at https://github.com/slzhou-xy/BLUE.",10.1145/3711896.3736861,2025,,ACM
Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting,"Recent studies have shown great promise in applying graph neural networks for multivariate time series forecasting, where the interactions of time series are described as a graph structure and the variables are represented as the graph nodes. Along this line, existing methods usually assume that the graph structure (or the adjacency matrix), which determines the aggregation manner of graph neural network, is fixed either by definition or self-learning. However, the interactions of variables can be dynamic and evolutionary in real-world scenarios. Furthermore, the interactions of time series are quite different if they are observed at different time scales. To equip the graph neural network with a flexible and practical graph structure, in this paper, we investigate how to model the evolutionary and multi-scale interactions of time series. In particular, we first provide a hierarchical graph structure cooperated with the dilated convolution to capture the scale-specific correlations among time series. Then, a series of adjacency matrices are constructed under a recurrent manner to represent the evolving correlations at each layer. Moreover, a unified neural network is provided to integrate the components above to get the final prediction. In this way, we can capture the pair-wise correlations and temporal dependency simultaneously. Finally, experiments on both single-step and multi-step forecasting tasks demonstrate the superiority of our method over the state-of-the-art approaches.",10.1145/3534678.3539274,2022,,ACM
Modeling Temporal Patterns with Dilated Convolutions for Time-Series Forecasting,"Time-series forecasting is an important problem across a wide range of domains. Designing accurate and prompt forecasting algorithms is a non-trivial task, as temporal data that arise in real applications often involve both non-linear dynamics and linear dependencies, and always have some mixtures of sequential and periodic patterns, such as daily, weekly repetitions, and so on. At this point, however, most recent deep models often use Recurrent Neural Networks (RNNs) to capture these temporal patterns, which is hard to parallelize and not fast enough for real-world applications especially when a huge amount of user requests are coming. Recently, CNNs have demonstrated significant advantages for sequence modeling tasks over the de-facto RNNs, while providing high computational efficiency due to the inherent parallelism. In this work, we propose HyDCNN, a novel hybrid framework based on fully Dilated CNN for time-series forecasting tasks. The core component in HyDCNN is a proposed hybrid module, in which our proposed position-aware dilated CNNs are utilized to capture the sequential non-linear dynamics and an autoregressive model is leveraged to capture the sequential linear dependencies. To further capture the periodic temporal patterns, a novel hop scheme is introduced in the hybrid module. HyDCNN is then composed of multiple hybrid modules to capture the sequential and periodic patterns. Each of these hybrid modules targets on either the sequential pattern or one kind of periodic patterns. Extensive experiments on five real-world datasets have shown that the proposed HyDCNN is better compared with state-of-the-art baselines and is at least 200\% better than RNN baselines. The datasets and source code will be published in Github to facilitate more future work.",10.1145/3453724,2021,,ACM
Dyn-GWN: Time-Series Forecasting using Time-varying Graphs with Applications to Finance and Traffic Prediction,"Spatio-temporal modeling is an essential lens to understand many real-world phenomena from traffic to finance. There has been exciting work that explores spatio-temporal modeling with temporal graph convolutional networks. Often these methods assume that the spatial structure is static. We propose a new model Dyn-GWN&nbsp;for spatio-temporal learning from time-varying graphs. Our model relies on a novel module called the Tensor Graph Convolutional Module&nbsp;(TGCM), which captures dynamic trends in graphs effectively in the time-varying graph representations. This module has two components: (i) it applies temporal dilated convolutions both on the time-varying graph adjacency space and the time-varying features. (ii) it aggregates the higher-level latent representations from both time-varying components through a proposed layer TGCL. Experiments demonstrate the efficacy of these model across time-series data from finance and traffic domains. Dyn-GWN&nbsp; can give up to better out-of-sample performance than prior methods that learn from time-varying graphs, e.g., EvolveGCN and TM-GCN. Interestingly, Dyn-GWN&nbsp; can be ∼ 300 \texttimes{",10.1145/3604237.3626864,2023,,ACM
Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting,"Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns.",10.1145/3534678.3539396,2022,,ACM
A Transferable Time Series Forecasting Service Using Deep Transformer Model for Online Systems,"Many real-world online systems expect to forecast the future trend of software quality to better automate operational processes, optimize software resource cost and ensure software reliability. To achieve that, all kinds of time series metrics collected from online software systems are adopted to characterize and monitor the quality of software services. To meet relevant software engineers’ requirements, we focus on time series forecasting and aim to provide an event-driven and self-adaptive forecasting service. In this paper, we present TTSF-transformer, a transferable time series forecasting service using deep transformer model. TTSF-transformer normalizes multiple metric frequencies to ensure the model sharing across multi-source systems, employs a deep transformer model with Bayesian estimation to generate the predictive marginal distribution, and introduces transfer learning and incremental learning into the training process to ensure the performance of long-term prediction. We conduct experiments on real-world time series metrics from two different types of game business in Tencent®. The results show that TTSF-transformer significantly outperforms other state-of-the-art methods and is suitable for wide deployment in large online systems.",10.1145/3551349.3560414,2023,,ACM
CTRL: Collaborative Temporal Representation Learning for Wind Power Forecasting,"Accurate wind power forecasting is crucial for grid stability and renewable energy integration, but existing methods struggle to capture complex temporal dependencies in wind data. This paper introduces Collaborative Temporal Representation Learning (CTRL), a novel deep learning model that leverages collaborative representation learning to enhance forecasting accuracy and robustness. CTRL integrates Reversible Instance Normalization (RevIN), RNN-based hidden state learning, and a specialized collaborative representation unit to capture multi-directional temporal dynamics across different time scales and variables. Experimental results on two real-world wind power datasets demonstrate that CTRL significantly outperforms 20 existing methods, including state-of-the-art deep learning approaches, achieving up to 9.67\% and 10.42\% improvement in forecasting accuracy, respectively. These findings highlight the potential of collaborative representation learning for advancing wind power forecasting and facilitating the effective integration of renewable energy resources.",10.1145/3711129.3711336,2025,,ACM
TransForeCaster: In-and-Cross Categorized Feature Integration in User Representation Learning,"This paper introduces TransForeCaster, a novel user representation learning approach to improving prediction accuracy in purchase and churn predictions via a two-stage feature integration process: In-Category Integration (ICI) and Cross-Category Integration (CCI). The ICI stage employs a Time-Series Feature Mixer (TSFM) to capture the temporal dynamics of features within the same categories, resulting in compact and continuous category representations. The CCI stage utilizes a Meta-Conditioned Transformer (MCT) to integrate the representations with multi-task learning, capturing complex relationships across categories and improving interpretability through attention mechanisms. Empirical evaluations of real-world datasets demonstrate significant improvements over conventional models, supported by qualitative analyses using feature importance assessments and UMAP visualizations. TransForeCaster's robustness is validated by its superior performance over other models in multiple in-house deployments across various games and applications. The source code is available at https://github.com/bagelcode-data-science-team/TransForeCaster.",10.1145/3701716.3715267,2025,,ACM
Conditional mutual information-based contrastive loss for financial time series forecasting,"We present a representation learning framework for financial time series forecasting. One challenge of using deep learning models for finance forecasting is the shortage of available training data when using small datasets. Direct trend classification using deep neural networks trained on small datasets is susceptible to the overfitting problem. In this paper, we propose to first learn compact representations from time series data, then use the learned representations to train a simpler model for predicting time series movements. We consider a class-conditioned latent variable model. We train an encoder network to maximize the mutual information between the latent variables and the trend information conditioned on the encoded observed variables. We show that conditional mutual information maximization can be approximated by a contrastive loss. Then, the problem is transformed into a classification task of determining whether two encoded representations are sampled from the same class or not. This is equivalent to performing pairwise comparisons of the training datapoints, and thus, improves the generalization ability of the encoder network. We use deep autoregressive models as our encoder to capture long-term dependencies of the sequence data. Empirical experiments indicate that our proposed method has the potential to advance state-of-the-art performance.",10.1145/3383455.3422550,2021,,ACM
DS-TPU: Dynamical System for on-Device Lifelong Graph Learning with Nonlinear Node Interaction,"Graph learning on dynamical systems has recently surfaced as an emerging research domain. By leveraging a novel electronic Dynamical System (DS), various graph learning challenges have been effectively tackled through a rapid, spontaneous natural annealing process. This method has attracted increasing attention due to its orders-of-magnitude improvements in speed and energy efficiency compared to traditional Graph Neural Network (GNN) approaches for inference tasks. However, (1) the current DS hardware only supports inference, missing its native solution for training; while relying on conventional hardware is likely more expensive than GNNs. (2) The current DS architecture only allows linear interactions among its nodes, limiting training accuracy.In this work, we present a Dynamical-System Training-Processing Unit (DS-TPU) developed through algorithm-architecture co-design to tackle the two major challenges: (1) An on-device lifelong learning mechanism that leverages feedback electric current as the loss function in response to the observed training data, allowing electron-speed refinement on the present model parameters. (2) A nonlinear DS node interaction mechanism constructed from Chebyshev polynomials to significantly improve the compatibility between the DS hardware and the embedded relation of graph data. Extensive evaluations using six real-world graph learning applications demonstrate that for accuracy, DS-TPU achieves 10.8\% MAE reduction over the best results of five widely used GNNs. In terms of training performance, the 5-Watt DS-TPU architecture achieves on-average 810 \texttimes{",10.1145/3695053.3731091,2025,,ACM
Lite-Mind: Towards Efficient and Robust Brain Representation Learning,"The limited data availability and the low signal-to-noise ratio of fMRI signals lead to the challenging task of fMRI-to-image retrieval. State-of-the-art MindEye remarkably improves fMRI-to-image retrieval performance by leveraging a large model, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to the final hidden layer of CLIP's Vision Transformer (ViT). However, significant individual variations exist among subjects, even under identical experimental setups, mandating the training of large subject-specific models. The substantial parameters pose significant challenges in deploying fMRI decoding on practical devices. To this end, we propose Lite-Mind, a lightweight, efficient, and robust brain representation learning paradigm based on Discrete Fourier Transform (DFT), which efficiently aligns fMRI voxels to fine-grained information of CLIP. We elaborately design a DFT backbone with Spectrum Compression and Frequency Projector modules to learn informative and robust voxel embeddings. Our experiments demonstrate that Lite-Mind achieves an impressive 94.6\% fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7\% fewer parameters than MindEye. Lite-Mind is also proven to be able to be migrated to smaller fMRI datasets and establishes a new state-of-the-art for zero-shot classification on the GOD dataset.",10.1145/3664647.3681229,2024,,ACM
Score-based Graph Learning for Urban Flow Prediction,"Accurate urban flow prediction (UFP) is crucial for a range of smart city applications such as traffic management, urban planning, and risk assessment. To capture the intrinsic characteristics of urban flow, recent efforts have utilized spatial and temporal graph neural networks to deal with the complex dependence between the traffic in adjacent areas. However, existing graph neural network based approaches suffer from several critical drawbacks, including improper graph representation of urban traffic data, lack of semantic correlation modeling among graph nodes, and coarse-grained exploitation of external factors. To address these issues, we propose DiffUFP, a novel probabilistic graph-based framework for UFP. DiffUFP&nbsp;consists of two key designs: (1) a semantic region dynamic extraction method that effectively captures the underlying traffic network topology, and (2) a conditional denoising score-based adjacency matrix generator that takes spatial, temporal, and external factors into account when constructing the adjacency matrix rather than simply concatenation in existing studies. Extensive experiments conducted on real-world datasets demonstrate the superiority of DiffUFP&nbsp;over the state-of-the-art UFP&nbsp;models and the effect of the two specific modules.",10.1145/3655629,2024,,ACM
DCdetector: Dual Attention Contrastive Representation Learning for Time Series Anomaly Detection,"Time series anomaly detection is critical for a wide range of applications. It aims to identify deviant samples from the normal sample distribution in time series. The most fundamental challenge for this task is to learn a representation map that enables effective discrimination of anomalies. Reconstruction-based methods still dominate, but the representation learning with anomalies might hurt the performance with its large abnormal loss. On the other hand, contrastive learning aims to find a representation that can clearly distinguish any instance from the others, which can bring a more natural and promising representation for time series anomaly detection. In this paper, we propose DCdetector, a multi-scale dual attention contrastive representation learning model. DCdetector utilizes a novel dual attention asymmetric design to create the permutated environment and pure contrastive loss to guide the learning process, thus learning a permutation invariant representation with superior discrimination abilities. Extensive experiments show that DCdetector achieves state-of-the-art results on multiple time series anomaly detection benchmark datasets. Code is publicly available at https://github.com/DAMO-DI-ML/KDD2023-DCdetector.",10.1145/3580305.3599295,2023,,ACM
ST-Norm: Spatial and Temporal Normalization for Multi-variate Time Series Forecasting,"Multi-variate time series (MTS) data is a ubiquitous class of data abstraction in the real world. Any instance of MTS is generated from a hybrid dynamical system with their specific dynamics normally unknown. The hybrid nature of such a dynamical system is a result of complex external impacts, which can be summarized as high-frequency and low-frequency from the temporal view, or global and local if we take the spatial view. These impacts also determine the forthcoming development of MTS making them paramount to capture in a time series forecasting task. However, conventional methods face intrinsic difficulties in disentangling the components yielded by each kind of impact from the raw data. To this end, we propose two kinds of normalization modules -- temporal and spatial normalization -- which separately refine the high-frequency component and the local component underlying the raw data. Moreover, both modules can be readily integrated into canonical deep learning architectures such as Wavenet and Transformer. Extensive experiments on three datasets are conducted to illustrate that, with additional normalization modules, the performance of the canonical architectures can be enhanced by a large margin in the application of MTS and achieves state-of-the-art results compared with existing MTS models.",10.1145/3447548.3467330,2021,,ACM
DySTAGE: Dynamic Graph Representation Learning for Asset Pricing via Spatio-Temporal Attention and Graph Encodings,"Current GNN-based asset price prediction models often focus on a fixed group of assets and their static relationships within the financial network. However, this approach overlooks the reality that the composition of asset pools and their interrelationships evolves over time, necessitating the development of a flexible framework capable of adapting to this dynamism. Accordingly, we propose DySTAGE, a framework with a universal formulation that transforms asset pricing time series into dynamic graphs, accommodating asset addition, deletion, and changes in correlations. Our framework includes a graph learning model specifically designed for this purpose. In our framework, assets at various historical time steps are structured as a sequence of dynamic graphs, where connections between assets reflect their long-term correlations. DySTAGE effectively captures both topological and temporal patterns. The Topological Module deploys Asset Influence Attention to learn global interrelationships among assets, further enhanced by Asset-wise Importance Encoding, Pair-wise Spatial Encoding, and Edge-wise Correlation Encoding. Meanwhile, the Temporal Module encapsulates node representations across the temporal dimension via the attention mechanism. We validate our approach through extensive experiments using three different real-world stock pricing data, demonstrating that DySTAGE surpasses popular benchmarks in return prediction, and offers profitable investment strategies. The code is publicly available under NJIT FinTech Lab’s GitHub1.",10.1145/3677052.3698680,2024,,ACM
Hierarchical Spatio-Temporal Graph Learning Based on Metapath Aggregation for Emergency Supply Forecasting,"Integrated Warehousing and Distribution Supply Networks (IWDSN) have shown their high efficiency in E-commerce. Efficient supply capacity prediction is crucial for logistics systems to maintain the delivery capacity to meet users' requirements. However, unforeseen events such as extreme weather and public health emergencies pose challenges in supply forecasting. Previous work mainly infers supply optimization based on the invariant topology of logistic networks, neglecting dynamic routing and distinct node effects reacting to emergencies. To address these challenges, the hierarchical relations among warehouses, sorting centers, and delivery stations in logistic networks are necessary to learn the diverse reactions. In this paper, we propose a hierarchical spatio-temporal graph learning model to predict the emergency supply capacity of IWDSN based on micro and macro graphs. The micro graph shows transportation connectivity while the macro graph shows the geographical correlation. Specifically, it consists of three components. (1) For micro graphs, a metapath aggregation strategy is designed to capture dynamic routing information on both route-view and event-view graphs. (2) For macro graphs, a bipartite graph learning approach to extract spatial representations. (3) For spatio-temporal feature fusion, the spatio-temporal joint forecasting module combines the temporal feature from the time-series encoder with hierarchical spatial features to predict the future supply capacity. The extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model, which achieves state-of-the-art performance compared with advanced baselines.",10.1145/3627673.3679854,2024,,ACM
METRO: a generic graph neural network framework for multivariate time series forecasting,"Multivariate time series forecasting has been drawing increasing attention due to its prevalent applications. It has been commonly assumed that leveraging latent dependencies between pairs of variables can enhance prediction accuracy. However, most existing methods suffer from static variable relevance modeling and ignorance of correlation between temporal scales, thereby failing to fully retain the dynamic and periodic interdependencies among variables, which are vital for long- and short-term forecasting. In this paper, we propose METRO, a generic framework with multi-scale temporal graphs neural networks, which models the dynamic and cross-scale variable correlations simultaneously. By representing the multivariate time series as a series of temporal graphs, both intra- and inter-step correlations can be well preserved via message-passing and node embedding update. To enable information propagation across temporal scales, we design a novel sampling strategy to align specific steps between higher and lower scales and fuse the cross-scale information efficiently. Moreover, we provide a modular interpretation of existing GNN-based time series forecasting works as specific instances under our framework. Extensive experiments conducted on four benchmark datasets demonstrate the effectiveness and efficiency of our approach. METRO has been successfully deployed onto the time series analytics platform of Huawei Cloud, where a one-month online test demonstrated that up to 20\% relative improvement over state-of-the-art models w.r.t. RSE can be achieved.",10.14778/3489496.3489503,2021,,ACM
GSL4Rec: Session-based Recommendations with Collective Graph Structure Learning and Next Interaction Prediction,"Users’ social connections have recently shown significant benefits to session-based recommendations, and graph neural networks have demonstrated great success in learning the pattern of information flow among users. However, the current paradigm presumes a given social network, which is not necessarily consistent with the fast-evolving shared interests and is expensive to collect. We propose a novel idea to learn the graph structure among users and make recommendations collectively in a coupled framework. This idea raises two challenges, i.e., scalability and effectiveness. We introduce a novel graph-structure learning framework for session-based recommendations&nbsp;(GSL4Rec) for solving both challenges simultaneously. Our framework has a two-stage strategy, i.e., the coarse neighbor screening and the self-adaptive graph structure learning, to enable the exploration of potential links among all users while maintaining a tractable amount of computation for scalability. We also propose a phased heuristic learning strategy to sequentially and synergistically train the graph learning part and recommendation part of GSL4Rec, thus improving the effectiveness by making the model easier to achieve good local optima. Experiments on five public datasets demonstrate that our proposed model significantly outperforms strong baselines, including state-of-the-art social network-based methods.",10.1145/3485447.3512085,2022,,ACM
Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection,"The early detection of potential failures in industrial machinery components is paramount for ensuring the reliability and safety of operations, thereby preserving Machine Condition Monitoring (MCM). This research addresses this imperative by introducing an innovative approach to Real-Time Acoustic Anomaly Detection. Our method combines semi-supervised temporal convolution with representation learning and a hybrid model strategy with Temporal Convolutional Networks (TCN) to handle various intricate anomaly patterns found in acoustic data effectively. The proposed model demonstrates superior performance compared to established research in the field, underscoring the effectiveness of this approach. Not only do we present quantitative evidence of its superiority, but we also employ visual representations, such as t-SNE plots, to further substantiate the model’s efficacy.",10.1145/3651671.3651693,2024,,ACM
Practical Skills Demand Forecasting via Representation Learning of Temporal Dynamics,"Rapid technological innovation threatens to leave much of the global workforce behind. Today's economy juxtaposes white-hot demand for skilled labor against stagnant employment prospects for workers unprepared to participate in a digital economy. It is a moment of peril and opportunity for every country, with outcomes measured in long-term capital allocation and the life satisfaction of billions of workers. To meet the moment, governments and markets must find ways to quicken the rate at which the supply of skills reacts to changes in demand. More fully and quickly understanding labor market intelligence is one route. In this work, we explore the utility of time series forecasts to enhance the value of skill demand data gathered from online job advertisements. This paper presents a pipeline which makes one-shot multi-step forecasts into the future using a decade of monthly skill demand observations based on a set of recurrent neural network methods. We compare the performance of a multivariate model versus a univariate one, analyze how correlation between skills can influence multivariate model results, and present predictions of demand for a selection of skills practiced by workers in the information technology industry.",10.1145/3514094.3534183,2022,,ACM
A Transformer-based Framework for Multivariate Time Series Representation Learning,"We present a novel framework for multivariate time series representation learning based on the transformer encoder architecture. The framework includes an unsupervised pre-training scheme, which can offer substantial performance benefits over fully supervised learning on downstream tasks, both with but even without leveraging additional unlabeled data, i.e., by reusing the existing data samples. Evaluating our framework on several public multivariate time series datasets from various domains and with diverse characteristics, we demonstrate that it performs significantly better than the best currently available methods for regression and classification, even for datasets which consist of only a few hundred training samples. Given the pronounced interest in unsupervised learning for nearly all domains in the sciences and in industry, these findings represent an important landmark, presenting the first unsupervised method shown to push the limits of state-of-the-art performance for multivariate time series regression and classification.",10.1145/3447548.3467401,2021,,ACM
"Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand \&amp; Uncertainties","This paper develops a graph reinforcement learning approach to online planning of the schedule and destinations of electric aircraft that comprise an urban air mobility (UAM) fleet operating across multiple vertiports. This fleet scheduling problem is formulated to consider time-varying demand, constraints related to vertiport capacity, aircraft capacity and airspace safety guidelines, uncertainties related to take-off delay, weather-induced route closures, and unanticipated aircraft downtime. Collectively, such a formulation presents greater complexity, and potentially increased realism, than in existing UAM fleet planning implementations. To address these complexities, a new policy architecture is constructed, primary components of which include: graph capsule conv-nets for encoding vertiport and aircraft-fleet states both abstracted as graphs; transformer layers encoding time series information on demand and passenger fare; and a Multi-head Attention-based decoder that uses the encoded information to compute the probability of selecting each available destination for an aircraft. Trained with Proximal Policy Optimization, this policy architecture shows significantly better performance in terms of daily averaged profits on unseen test scenarios involving 8 vertiports and 40 aircraft, when compared to a random baseline and genetic algorithm-derived optimal solutions, while being nearly 1000 times faster in execution than the latter.",10.1145/3605098.3635976,2024,,ACM
Attention Based Dynamic Graph Learning Framework for Asset Pricing,"Recent studies suggest that financial networks play an essential role in asset valuation and investment decisions. Unlike road networks, financial networks are neither given nor static, posing significant challenges in learning meaningful networks and promoting their applications in price prediction. In this paper, we first apply the attention mechanism to connect the ",10.1145/3459637.3482413,2021,,ACM
Towards Multi-Scenario Forecasting of Building Electricity Loads with Multimodal Data,"The rapid urbanization process has significantly increased building energy consumption and carbon emissions, making reliable electricity load forecasting crucial for energy management. However, accurate load forecasting faces three key challenges: (1) complex impact of multimodal data, (2) inter-building semantical relationships, and (3) uncertainty modeling of load patterns. To address these, we propose MMLoad, a novel diffusion-based multimodal framework for multi-scenario building load forecasting with three innovations: (i) a Multimodal Data Enhancement Pipeline generating rich building descriptions using LLMs and integrating temporal factors to analyze multimodal impacts; (ii) a Cross-modal Relation Encoder discovering latent interdependencies through hierarchical fusion, projecting buildings into a unified spatio-temporal (ST) embedding space; and (iii) a Scenario-Conditioned Diffusion Generator employing transformer-based denoising with Scenario-Adaptive Normalization (SAN) for diverse trajectory generation with uncertainty quantification. Experiments show MMLoad outperforms state-of-the-art baselines in accuracy while generating plausible future scenarios, establishing a new paradigm for multimodal learning in smart energy systems.",10.1145/3746027.3755775,2025,,ACM
Telecommunication Traffic Forecasting via Multi-task Learning,"Accurate telecommunication time series forecasting is critical for smart management systems of cellular networks, and has a special challenge in predicting different types of time series simultaneously at one base station (BS), e.g., the SMS, Calls, and Internet. Unlike the well-studied single target forecasting problem for one BS, this distributed multi-target forecasting problem should take advantage of both the intra-BS dependence of different types of time series at the same BS and the inter-BS dependence of time series at different BS. To this end, we first propose a model to learn the inter-BS dependence by aggregating the multi-view dependence, e.g., from the viewpoint of SMS, Calls, and Internet. To incorporate the interBS dependence in time series forecasting, we then propose a Graph Gate LSTM (GGLSTM) model that includes a graph-based gate mechanism to unite those base stations with a strong dependence on learning a collaboratively strengthened prediction model. We also extract the intra-BS dependence by an attention network and use it in the final prediction. Our proposed approach is evaluated on two real-world datasets. Experiment results demonstrate the effectiveness of our model in predicting multiple types of telecom traffic at the distributed base stations.",10.1145/3539597.3570440,2023,,ACM
Learning Dynamic Graphs from All Contextual Information for Accurate Point-of-Interest Visit Forecasting,"Forecasting the number of visits to Points-of-Interest (POI) in an urban area is critical for planning and decision making in various application domains, from urban planning and transportation management to public health and social studies. Although this forecasting problem can be formulated as a multivariate time-series forecasting task, current approaches cannot fully exploit the ever-changing multi-context correlations among POIs. Therefore, we propose Busyness Graph Neural Network (BysGNN), a temporal graph neural network designed to learn and uncover the underlying multi-context correlations between POIs for accurate visit forecasting. Unlike other approaches where only time-series data is used to learn a dynamic graph, BysGNN utilizes all contextual information and time-series data to learn an accurate dynamic graph representation. By incorporating all contextual, temporal, and spatial signals, we observe a significant improvement in our forecasting accuracy over state-of-the-art forecasting models in our experiments with real-world datasets across the United States.",10.1145/3589132.3625567,2023,,ACM
Capturing Structural Evolution in Financial Markets with Graph Neural Time Series Models,"This paper proposes a stock price prediction method based on a graph neural network architecture. The method is designed to address key characteristics of the stock market, including high nonlinearity, multivariable dependencies, and dynamically changing structural relationships. It constructs a dynamic stock graph to represent the evolving relationship network among individual stocks over time. A temporal-aware graph neural network module is designed to jointly model node features through structural propagation and temporal dependence. Specifically, the model incorporates multi-source heterogeneous information to build the dynamic graph structure. This enables explicit representation of the time-varying linkages between stocks within the graph. Graph convolution is then applied to extract structural features at each time step. A temporal module is used to model the evolution of these features over time. To validate the effectiveness of the method, the model is compared with existing graph-based and time-series models across multiple evaluation metrics. Ablation studies, robustness tests, and performance assessments under different market conditions are conducted to comprehensively analyze the model's behavior in various scenarios. Experimental results show that the proposed method achieves low prediction error while maintaining strong stability and generalization ability. It significantly improves the accuracy of modeling asset price trends in financial markets. This study provides a unified solution for structural and dynamic aspects of the stock prediction problem and extends the application scope of graph neural networks in financial time series analysis.",10.1145/3767052.3767086,2025,,ACM
Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation,"A Session-Based Recommendation (SBR) seeks to predict users’ future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model’s ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M3T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M2T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M3T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.",10.1145/3663760,2024,,ACM
Fine-grained Urban Heat Island Effect Forecasting: A Context-aware Thermodynamic Modeling Framework,"Climate change and rapid urbanization have led to the Urban Heat Island (UHI) effect, resulting in higher temperatures in metropolitan areas and negatively impacting urban communities. Accurate UHI forecasting is crucial for identifying high-risk periods and locations, especially in cities with vulnerable populations. Current methods are limited by data granularity and inadequate modeling of regional thermodynamics, which affects both accuracy and spatio-temporal granularity. In this paper, we propose DeepUHI, a data-driven context-aware framework for modeling local thermodynamics based on the heat equation, alongside the SeoulTemp dataset, the first multi-modal dataset for UHI effect predictions at the street level. Our framework utilizes a heat decomposition method to represent urban thermodynamics through thermodynamic cycles and thermal flows, effectively integrating urban environmental data. Extensive experiments show that our framework improves accuracy in UHI effect prediction and warning tasks, outperforming leading models. We have integrated DeepUHI into our SeoUHI platform to provide hourly street-level UHI forecasting for Seoul. The code, platform, and dataset are accessible at https://github.com/CityMind-Lab/DeepUHI.",10.1145/3711896.3736962,2025,,ACM
On Generalizing Static Node Embedding to Dynamic Settings,"Temporal graph embedding has been widely studied thanks to its superiority in tasks such as prediction and recommendation. Despite the advances in algorithms and novel frameworks such as deep learning, there has been relatively little work on systematically studying the properties of temporal network models and their cornerstones, the graph time-series representations that are used in these approaches. This paper aims to fill this gap by introducing a general framework that extends an arbitrary existing static embedding approach to handle dynamic tasks, and conducting a systematic study of seven base static embedding methods and six temporal network models. Our framework generalizes static node embeddings derived from the time-series representation of stream data to the dynamic setting by modeling the temporal dependencies with classic models such as the reachability graph. While previous works on dynamic modeling and embedding have focused on representing a stream of timestamped edges using a time-series of graphs based on a specific time-scale (eg, 1 month), we introduce the notion of an ε-graph time-series that uses a fixed number of edges for each graph, and show its superiority in practical settings over the standard solution. From the 42 methods that our framework subsumes, we find that leveraging the new ε-graph time-series representation and capturing temporal dependencies with the proposed reachability or summary graph tend to perform well. Furthermore, the new dynamic embedding methods based on our framework perform comparably and on average better than the state-of-the-art embedding methods designed specifically for temporal graphs in link prediction tasks.",10.1145/3488560.3498428,2022,,ACM
SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding,"Knowledge graphs (KGs) have been increasingly employed for link prediction and recommendation using real-world datasets. However, the majority of current methods rely on static data, neglecting the dynamic nature and the hidden spatio-temporal attributes of real-world scenarios. This often results in suboptimal predictions and recommendations. Although there are effective spatio-temporal inference methods, they face challenges such as scalability with large datasets and inadequate semantic understanding, which impede their performance. To address these limitations, this paper introduces a novel framework - Simple Spatio-Temporal Knowledge Graph (SSTKG), for constructing and exploring spatio-temporal KGs. To integrate spatial and temporal data into KGs, our framework exploited through a new 3-step embedding method. Output embeddings can be used for future temporal sequence prediction and spatial information recommendation, providing valuable insights for various applications such as retail sales forecasting and traffic volume prediction. Our framework offers a simple but comprehensive way to understand the underlying patterns and trends in dynamic KG, thereby enhancing the accuracy of predictions and the relevance of recommendations. This work paves the way for more effective utilization of spatio-temporal data in KGs, with potential impacts across a wide range of sectors.",10.1145/3589334.3645441,2024,,ACM
Long-Term Forecasting of Multivariate Urban Data via Decomposition and Spatio-Temporal Graph Analysis,"Long-term forecasting of multivariate urban data poses a significant challenge due to the complex spatiotemporal dependencies inherent in such datasets. This paper presents DST, a novel multivariate time-series forecasting model that integrates graph attention and temporal convolution within a Graph Neural Network (GNN) to effectively capture spatial and temporal dependencies, respectively. To enhance model performance, we apply a decomposition-based preprocessing step that isolates trend, seasonal, and residual components of the time series, enabling the learning of distinct graph structures for different time-series components. Extensive experiments on real-world urban datasets—including electricity demand, weather metrics, carbon intensity, and air pollution—demonstrate the effectiveness of DST across a range of forecast horizons, from several days to one month. Specifically, our approach achieves an average improvement of 2.89\% to 9.10\% in long-term forecasting accuracy over state-of-the-art time-series forecasting models.",10.1145/3736425.3770109,2025,,ACM
Conv-Attention Model Based on Multivariate Time Series Prediction: The Cyanobacteria Bloom Case,"Multivariate time series forecasting problems are an important part of research in various fields at all times, such as financial and stock markets, natural disasters, disease prevention. However, forecasting has always been difficult due to its own reasons or external factors. In this paper, we propose a brand-new Conv-Attention network (CANet) for harmful algal blooms prediction. To capture more spatial dimension feature information, the network extracts the context dependency from each time series, and at the same time obtains the impact score between the interacting time series. In the previous stage of training, the feature factors are acquired through different convolution kernels. Then attention mechanism is adopted to model the processes that depend on mutual influence. To further enhance the robustness of the network, the CANet incorporates simple MLP layer-assisted training. The experimental results show that our proposed network performs well under the evaluation of the performance index.",10.1145/3501409.3501591,2022,,ACM
On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper),"Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have not yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains, including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality, such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic large learning models (LLMs) can outperform task-specific fully supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image–based urban noise intensity classification, and remote sensing image scene classification), existing FMs still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing an FM for GeoAI is to address the multimodal nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal FM that can reason over various types of geospatial data through geospatial alignments. We conclude this article by discussing the unique risks and challenges to developing such a model for GeoAI.",10.1145/3653070,2024,,ACM
Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay,"Multi-variate Time Series (MTS) forecasting has made large strides (with very negligible errors) through recent advancements in neural networks, e.g., Transformers. However, in critical situations like predicting gaming overindulgence that affects one's mental well-being; an accurate forecast without a contributing evidence (explanation) is irrelevant. Hence, it becomes important that the forecasts are Interpretable - intermediate representation of the forecasted trajectory is comprehensible; as well as Explainable - attentive input features and events are accessible for a personalized and timely intervention of players at risk. While the contributing state of the art research on interpretability primarily focuses on temporally-smooth single-process driven time series data, our online multi-player gameplay data demonstrates intractable temporal randomness due to intrinsic orthogonality between player's game outcome and their intent to engage further. We introduce a novel deep Actionable Forecasting Network (AFN), which addresses the inter-dependent challenges associated with three exclusive objectives - 1) forecasting accuracy; 2) smooth comprehensible trajectory and 3) explanations via multi-dimensional input features while tackling the challenges introduced by our non-smooth temporal data, together in one single solution. AFN establishes a new benchmark via: (i) achieving 25\% improvement on the MSE of the forecasts on player data in comparison to the SOM-VAE based SOTA networks; (ii) attributing unfavourable progression of a player's time series to a specific future time step(s), with the premise of eliminating near-future overindulgent player volume by over 18\% with player specific actionable inputs feature(s) and (iii) proactively detecting over 23\% (100\% jump from SOTA) of the to-be overindulgent, players on an average, 4 weeks in advance.",10.1145/3637528.3671657,2024,,ACM
Research on the application of artificial intelligence algorithms in drought prediction,"With the aggravation of global warming, drought has caused more and more serious impact on society and national economy, so the accurate prediction of drought is also the most important thing to deal with the frequent drought problem. On the other hand, artificial intelligence technology has shown its advantages in various fields and has a broad application prospects, so it is gradually being used in drought prediction. In this paper, drought prediction algorithms in recent years are reviewed, and existing cases of drought prediction using different arithmetic models for different drought indices are studied. The advantages and disadvantages of different algorithms are compared, the challenges of drought prediction are summarized, and the future of drought prediction is prospected.",10.1145/3573428.3573753,2023,,ACM
Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution,"Traffic prediction is the cornerstone of intelligent transportation system. Accurate traffic forecasting is essential for the applications of smart cities, i.e., intelligent traffic management and urban planning. Although various methods are proposed for spatio-temporal modeling, they ignore the dynamic characteristics of correlations among locations on road network. Meanwhile, most Recurrent Neural Network based works are not efficient enough due to their recurrent operations. Additionally, there is a severe lack of fair comparison among different methods on the same datasets. To address the above challenges, in this article, we propose a novel traffic prediction framework, named Dynamic Graph Convolutional Recurrent Network (DGCRN). In DGCRN, hyper-networks are designed to leverage and extract dynamic characteristics from node attributes, while the parameters of dynamic filters are generated at each time step. We filter the node embeddings and then use them to generate dynamic graph, which is integrated with pre-defined static graph. As far as we know, we are first to employ a generation method to model fine topology of dynamic graph at each time step. Furthermore, to enhance efficiency and performance, we employ a training strategy for DGCRN by restricting the iteration number of decoder during forward and backward propagation. Finally, a reproducible standardized benchmark and a brand new representative traffic dataset are opened for fair comparison and further research. Extensive experiments on three datasets demonstrate that our model outperforms 15 baselines consistently. Source codes are available at .",10.1145/3532611,2023,,ACM
Mini-Game Lifetime Value Prediction in WeChat,"The LifeTime Value (LTV) prediction, which endeavors to forecast the cumulative purchase contribution of a user to a particular item, remains a vital challenge that advertisers are keen to resolve. A precise LTV prediction system enhances the alignment of user interests with meticulously designed advertisements, thereby generating substantial profits for advertisers. Nonetheless, this issue is complicated by the paucity of data typically observed in real-world advertising scenarios. The purchase rate among registered users is often as critically low as 0.1\%, resulting in a dataset where the majority of users make only several purchases. Consequently, there is insufficient supervisory signal for effectively training the LTV prediction model. An additional challenge emerges from the interdependencies among tasks with high correlation. It is a common practice to estimate a user's contribution to a game over a specified temporal interval. Varying the lengths of these intervals corresponds to distinct predictive tasks, which are highly correlated. For instance, predictions over a 7-day period are heavily reliant on forecasts made over a 3-day period, where exceptional cases can adversely affect the accuracy of both tasks. In order to comprehensively address the aforementioned challenges, we introduce an innovative framework denoted as Graph-Represented Pareto-Optimal LifeTime Value prediction (GRePO-LTV). Graph representation learning is initially employed to address the issue of data scarcity. Subsequently, Pareto-Optimization is utilized to manage the interdependence of prediction tasks. Our method is evaluated using a proprietary offline mini-game recommendation dataset in conjunction with an online A/B test. The implementation of our method results in a significant enhancement within the offline dataset. Moreover, the A/B test demonstrates encouraging outcomes, increasing average Gross Merchandise Value (GMV) by 8.4\%.",10.1145/3711896.3737248,2025,,ACM
COMET: NFT Price Prediction with Wallet Profiling,"As the non-fungible token (NFT) market flourishes, price prediction emerges as a pivotal direction for investors gaining valuable insight to maximize returns. However, existing works suffer from a lack of practical definitions and standardized evaluations, limiting their practical application. Moreover, the influence of users' multi-behaviour transactions that are publicly accessible on NFT price is still not explored and exhibits challenges. In this paper, we address these gaps by presenting a practical and hierarchical problem definition. This approach unifies both collection-level and token-level task and evaluation methods, which cater to varied practical requirements of investors. To further understand the impact of user behaviours on the variation of NFT price, we propose a general wallet profiling framework and develop a COmmunity enhanced Multi-bEhavior Transaction graph model, named COMET. COMET profiles wallets with a comprehensive view and considers the impact of diverse relations and interactions within the NFT ecosystem on NFT price variations, thereby improving prediction performance. Extensive experiments conducted in our deployed system demonstrate the superiority of COMET, underscoring its potential in the insight toolkit for NFT investors.",10.1145/3637528.3671621,2024,,ACM
Cost-effective Data Labelling for Graph Neural Networks,"Active learning (AL), that aims to label limited data samples to effectively train the model, stands as a very cost-effective data labelling strategy in machine learning. Given the state-of-the-art performance GNNs have achieved in graph-based tasks, it is critical to design proper AL methods for graph neural networks (GNNs). However, existing GNN-based AL methods require considerable supervised information to guide the AL process, such as the GNN model to use, and initially labelled nodes and labels of newly selected nodes. Such dependency on supervised information limits both flexibility and scalabilty. In this paper, we propose an unsupervised, scalable and flexible AL method - it incurs low memory footprints and time cost, is flexible to the choice of underlying GNNs, and operates without requiring GNN-model-specific knowledge or labels of selected nodes. Specifically, we leverage the commonality of existing GNNs to reformulate the unsupervised AL problem as the Aggregation Involvement Maximization (AIM) problem. The objective of AIM is to maximize the involvement or participation of all nodes during the feature aggregation process of GNNs for nodes to be labelled. In this way, the aggregated features of labelled nodes can be diversified to a large extent, thereby benefiting the training of feature transformation matrices which are major trainable components in GNNs. We prove that the AIM problem is NP-hard and propose an efficient solution with theoretical guarantees. Extensive experiments on public datasets demonstrate the effectiveness, scalability and flexibility of our method. Our study is highly relevant to the track ",10.1145/3589334.3645339,2024,,ACM
Entropy Causal Graphs for Multivariate Time Series Anomaly&nbsp;Detection,"Many multivariate time series anomaly detection frameworks have been proposed and widely applied. However, most of these frameworks do not consider intrinsic relationships between variables in multivariate time series data, thus ignoring the causal relationship among variables and degrading anomaly detection performance. This work proposes a novel framework called CGAD, an entropy causal graph for multivariate time series Anomaly Detection. CGAD utilizes transfer entropy to construct graph structures that unveil the underlying causal relationships among time series data. Weighted graph convolutional networks combined with causal convolutions are employed to model both the causal graph structures and the temporal patterns within multivariate time series data. Furthermore, CGAD applies anomaly scoring, leveraging median absolute deviation-based normalization to improve the robustness of the anomaly identification process. Extensive experiments demonstrate that CGAD outperforms state-of-the-art methods on real-world datasets with a 9\% average improvement in terms of three different multivariate time series anomaly detection metrics.",10.1145/3757922,2025,,ACM
Ranking on Dynamic Graphs: An Effective and Robust Band-Pass Disentangled Approach,"Ranking is an essential and practical task on dynamic graphs, which aims to prioritize future interaction candidates for given queries. While existing solutions achieve promising ranking performance, they leverage a single listwise loss to jointly optimize candidate sets, which leads to the gradient vanishing issue; and they employ neural networks to model complex temporal structures within a shared latent space, which fails to accurately capture multi-scale temporal patterns due to the frequency aliasing issue. To address these issues, we propose BandRank, a novel and robust band-pass disentangled ranking approach for dynamic graphs in the frequency domain. Concretely, we propose a band-pass disentangled representation (BPDR) approach, which disentangles complex temporal structures into multiple frequency bands and employs non-shared frequency-enhanced multilayer perceptrons (MLPs) to model each band independently. We prove that our BPDR approach ensures effective multi-scale learning for temporal structures by demonstrating its multi-scale global convolution property. Besides, we design a robust Harmonic Ranking (HR) loss to jointly optimize candidate sets and continuously track comparisons between real and virtual candidates, where we theoretically guarantee its ability to alleviate the gradient vanishing issue. Extensive experimental results show that our BandRank achieves an average improvement of 21.31\% against eight baselines while demonstrating superior robustness across different learning scenarios.",10.1145/3696410.3714943,2025,,ACM
HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting,"Time series forecasting is a critical and challenging task in practical application. Recent advancements in pre-trained foundation models for time series forecasting have gained significant interest. However, current methods often overlook the multi-scale nature of time series, which is essential for accurate forecasting. To address this, we propose HiMTM, a hierarchical multi-scale masked time series modeling with self-distillation for long-term forecasting. HiMTM integrates four key components: (1) hierarchical multi-scale transformer (HMT) to capture temporal information at different scales; (2) decoupled encoder-decoder (DED) that directs the encoder towards feature extraction while the decoder focuses on pretext tasks; (3) hierarchical self-distillation (HSD) for multi-stage feature-level supervision signals during pre-training; and (4) cross-scale attention fine-tuning (CSA-FT) to capture dependencies between different scales for downstream tasks. These components collectively enhance multi-scale feature extraction in masked time series modeling, improving forecasting accuracy. Extensive experiments on seven mainstream datasets show that HiMTM surpasses state-of-the-art self-supervised and end-to-end learning methods by a considerable margin of 3.16-68.54\%. Additionally, HiMTM outperforms the latest robust self-supervised learning method, PatchTST, in cross-domain forecasting by a significant margin of 2.3\%. The effectiveness of HiMTM is further demonstrated through its application in natural gas demand forecasting.",10.1145/3627673.3679741,2024,,ACM
Fusing Narrative Semantics for Financial Volatility Forecasting,"We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.",10.1145/3768292.3771256,2025,,ACM
Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask,"Time Series Representation Learning (TSRL) focuses on generating informative representations for various Time Series (TS) modeling tasks. Traditional Self-Supervised Learning (SSL) methods in TSRL fall into four main categories: reconstructive, adversarial, contrastive, and predictive, each with a common challenge of sensitivity to noise and intricate data nuances. Recently, diffusion-based methods have shown advanced generative capabilities. However, they primarily target specific application scenarios like imputation and forecasting, leaving a gap in leveraging diffusion models for generic TSRL. Our work, Time Series Diffusion Embedding (TSDE), bridges this gap as the first diffusion-based SSL TSRL approach. TSDE segments TS data into observed and masked parts using an Imputation-Interpolation-Forecasting (IIF) mask. It applies a trainable embedding function, featuring dual-orthogonal Transformer encoders with a crossover mechanism, to the observed part. We train a reverse diffusion process conditioned on the embeddings, designed to predict noise added to the masked part. Extensive experiments demonstrate TSDE's superiority in imputation, interpolation, forecasting, anomaly detection, classification, and clustering. We also conduct an ablation study, present embedding visualizations, and compare inference speed, further substantiating TSDE's efficiency and validity in learning representations of TS data.",10.1145/3637528.3671673,2024,,ACM
Temporal Implicit Multimodal Networks for Investment and Risk Management,"Many deep learning works on financial time-series forecasting focus on predicting future prices/returns of individual assets with numerical price-related information for trading, and hence propose models designed for univariate, single-task, and/or unimodal settings. Forecasting for investment and risk management involves multiple tasks in multivariate settings: forecasts of expected returns and risks of assets in portfolios, and correlations between these assets. As different sources/types of time-series influence future returns, risks, and correlations of assets in different ways, it is also important to capture time-series from different modalities. Hence, this article addresses financial time-series forecasting for investment and risk management in a multivariate, multitask, and multimodal setting. Financial time-series forecasting, however, is challenging due to the low signal-to-noise ratios typical in financial time-series, and as intra-series and inter-series relationships of assets evolve across time. To address these challenges, our proposed Temporal Implicit Multimodal Network (TIME) model learns implicit inter-series relationship networks between assets from multimodal financial time-series at multiple time-steps adaptively. TIME then uses dynamic network and temporal encoding modules to jointly capture such evolving relationships, multimodal financial time-series, and temporal representations. Our experiments show that TIME outperforms other state-of-the-art models on multiple forecasting tasks and investment and risk management applications.",10.1145/3643855,2024,,ACM
Network Filtering of Spatial-temporal GNN for Multivariate Time-series Prediction,"We propose an architecture for multivariate time-series prediction that integrates a spatial-temporal graph neural network with a filtering module which filters the inverse correlation matrix into a sparse network structure. In contrast with existing sparsification methods adopted in graph neural networks, our model explicitly leverages time-series filtering to overcome the low signal-to-noise ratio typical of complex systems data. We present a set of experiments, where we predict future sales volume from a synthetic time-series sales volume dataset. The proposed spatial-temporal graph neural network displays superior performances to baseline approaches with no graphical information, fully connected, disconnected graphs, and unfiltered graphs, as well as the state-of-the-art spatial-temporal GNN. Comparison of the results with Diffusion Convolutional Recurrent Neural Network (DCRNN) suggests that, by combining a (inferior) GNN with graph sparsification and filtering, one can achieve comparable or better efficacy than the state-of-the-art in multivariate time-series regression.",10.1145/3533271.3561678,2022,,ACM
TimesBERT: A BERT-Style Foundation Model for Time Series Understanding,"Time series analysis is crucial in diverse scenarios. Beyond forecasting, considerable real-world tasks are categorized into classification, imputation, and anomaly detection, underscoring different capabilities termed time series understanding in this paper. While GPT-style models have been positioned as foundation models for time series forecasting, the BERT-style architecture, which has made significant advances in natural language understanding, has not been fully unlocked for time series understanding, possibly attributed to the undesirable dropout of essential elements of BERT. In this paper, inspired by the shared multi-granularity structure between multivariate time series and multisentence documents, we design TimesBERT to learn generic representations of time series including temporal patterns and variate-centric characteristics. In addition to a natural adaptation of masked modeling, we propose a parallel task of functional token prediction to embody vital multi-granularity structures. Our model is pre-trained on 260 billion time points across diverse domains. Leveraging multi-granularity representations, TimesBERT achieves state-of-the-art performance across four typical downstream understanding tasks, outperforming task-specific models and language pre-trained backbones, positioning it as a versatile foundation model for time series understanding.",10.1145/3746027.3755238,2025,,ACM
Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools,"Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNing framework with Maskable stOck REpresentation to handle PM with CSPs through one-shot training in a global stock pool (GSP). Specifically, we first introduce a mechanism to mask out the representation of the stocks outside the target pool. Second, we learn meaningful stock representations through a self-supervised masking and reconstruction process. Third, a re-weighting mechanism is designed to make the portfolio concentrate on favorable stocks and neglect the stocks outside the target pool. Through extensive experiments on 8 subset stock pools of the US stock market, we demonstrate that EarnMore significantly outperforms 14 state-of-the-art baselines in terms of 6 popular financial metrics with over 40\% improvement on profit. Code is available in PyTorch1.",10.1145/3589334.3645615,2024,,ACM
Credit Card Transaction Trend Forecasting Based on Graph Neural Network,"Accurate prediction of customer transaction trend can provide effective technical support for banks in managing their credit card business. Customer transaction behaviors often involve multiple types of consumption, and existing forecasting methods typically concatenate multi-type features into a unified input, which inadequately accounts for structural differences and interactions among different transaction types. To address this issue, this paper proposes TTF-GNN, a credit card transaction trend forecasting model based on graph neural networks. The proposed method effectively explores customer behavioral characteristics in multi-type transaction scenarios by integrating type-aware embedding with time-varying sensitive graph construction. It jointly captures temporal dynamics and interdependencies among multiple transaction types through spatio-temporal graph convolution, thereby enabling accurate prediction of future trends. Experimental results on three public datasets demonstrate that the proposed method significantly outperforms several exiting forecasting models across multiple evaluation metrics, confirming its effectiveness and adaptability.",10.1145/3762249.3762299,2025,,ACM
Trending Now: Modeling Trend Recommendations,"Modern recommender systems usually include separate recommendation carousels such as ‘trending now’ to list trending items and further boost their popularity, thereby attracting active users. Though widely useful, such ‘trending now’ carousels typically generate item lists based on simple heuristics, e.g., the number of interactions within a time interval, and therefore still leave much room for improvement. This paper aims to systematically study this under-explored but important problem from the new perspective of time series forecasting. We first provide a set of rigorous definitions related to item trendiness and formulate the trend recommendation task as a one-step time series forecasting problem. We then propose a deep latent variable model, dubbed Trend Recommender (TrendRec), to forecast items’ future trends and generate trending item lists. Furthermore, we design associated evaluation protocols for trend recommendation. Experiments on real-world datasets from various domains show that our TrendRec significantly outperforms the baselines, verifying our model’s effectiveness.",10.1145/3604915.3608810,2023,,ACM
Self-supervised Learning for Accelerometer-based Human Activity Recognition: A Survey,"Self-supervised learning (SSL) has emerged as a promising alternative to purely supervised learning, since it can learn from labeled and unlabeled data using a pre-train-then-fine-tune strategy, achieving state-of-the-art performances across many research areas. The field of accelerometer-based human activity recognition (HAR) can benefit from SSL since unlabeled data can be collected cost-efficiently due to the ubiquitous nature of sensors embedded in smart devices, which is in contrast to labeled data, that require a costly annotation process. Motivated by the success of SSL and the lack of surveys on SSL for HAR, this survey comprehensively examines 52 SSL methods applied to HAR, and categorizes them into four SSL paradigms based on pre-training objectives. We discuss SSL strategies, evaluation protocols, and utilized datasets. We highlight limitations in current methodologies, including little large-scale pre-training, the absence of foundation models, as well as the scarcity of systematic domain shift experiments and domain knowledge utilization. Notably, the diversity in evaluation protocols across papers poses a considerable challenge when comparing methods. Future directions outlined in this survey include the development of an SSL framework for HAR to enable standardized benchmarking and large-scale pre-training, along with integrating domain knowledge to enhance model performance.",10.1145/3699767,2024,,ACM
From News to Returns: A Granger-Causal Hypergraph Transformer on the Sphere,"We propose the Causal Sphere Hypergraph Transformer (CSHT), a novel architecture for interpretable financial time-series forecasting that unifies Granger-causal hypergraph structure, Riemannian geometry, and causally masked Transformer attention. CSHT models the directional influence of financial news and sentiment on asset returns by extracting multivariate Granger-causal dependencies, which are encoded as directional hyperedges on the surface of a hypersphere. Attention is constrained via angular masks that preserve both temporal directionality and geometric consistency. Evaluated on S&amp;P 500 data from 2018 to 2023, including the 2020 COVID-19 shock, CSHT consistently outperforms baselines across return prediction, regime classification, and top-asset ranking tasks. By enforcing predictive causal structure and embedding variables in a Riemannian manifold, CSHT delivers both robust generalisation across market regimes and transparent attribution pathways from macroeconomic events to stock-level responses. These results suggest that CSHT is a principled and practical solution for trustworthy financial forecasting under uncertainty.",10.1145/3768292.3770414,2025,,ACM
Stock price prediction model integrating autoencoder and bidirectional LSTM——Optimization based on attention mechanism,"In recent years, financial time series forecasting methods based on deep neural network architectures have been proposed one after another, but there is significant heterogeneity in the performance of each model. This research systematically integrates the feature representation advantages of autoencoders (AE) and the time series modeling capabilities of bidirectional long short-term memory networks (BiLSTM) to construct a new framework for predicting stock market price trends. In terms of technical implementation, a data preprocessing mechanism based on stacked denoising autoencoders is first designed to effectively capture the non-stationary characteristics and implicit patterns of financial time series. Secondly, the bidirectional gated recurrent unit is innovatively embedded in the encoding-decoding architecture to achieve bidirectional time series dependency modeling of multi-dimensional market information, and then a parameter adaptive weighting mechanism is introduced to improve the contribution of prediction-related features through dynamic feature importance evaluation. The final prediction result is obtained through nonlinear mapping of the fully connected layer. Experimental results show that the hybrid model significantly outperforms other baseline models on two stock trading datasets.",10.1145/3745133.3745179,2025,,ACM
Decoupled Progressive Distillation for Sequential Prediction with Interaction Dynamics,"Sequential prediction has great value for resource allocation due to its capability in analyzing intents for next prediction. A fundamental challenge arises from real-world interaction dynamics where similar sequences involving multiple intents may exhibit different next items. More importantly, the character of volume candidate items in sequential prediction may amplify such dynamics, making deep networks hard to capture comprehensive intents. This article presents a sequential prediction framework with Decoupled Progressive Distillation (DePoD), drawing on the progressive nature of human cognition. We redefine target and non-target item distillation according to their different effects in the decoupled formulation. This can be achieved through two aspects: (1) Regarding how to learn, our target item distillation with progressive difficulty increases the contribution of low-confidence samples in the later training phase while keeping high-confidence samples in the earlier phase. And, the non-target item distillation starts from a small subset of non-target items from which size increases according to the item frequency. (2) Regarding whom to learn from, a difference evaluator is utilized to progressively select an expert that provides informative knowledge among items from the cohort of peers. Extensive experiments on four public datasets show DePoD outperforms state-of-the-art methods in terms of accuracy-based metrics.",10.1145/3632403,2023,,ACM
Graph Deep Factors for Forecasting with Applications to Cloud Resource Allocation,"Deep probabilistic forecasting techniques have recently been proposed for modeling large collections of time-series. However, these techniques explicitly assume either complete independence (local model) or complete dependence (global model) between time-series in the collection. This corresponds to the two extreme cases where every time-series is disconnected from every other time-series in the collection or likewise, that every time-series is related to every other time-series resulting in a completely connected graph. In this work, we propose a deep hybrid probabilistic graph-based forecasting framework called Graph Deep Factors (GraphDF) that goes beyond these two extremes by allowing nodes and their time-series to be connected to others in an arbitrary fashion. GraphDF is a hybrid forecasting framework that consists of a relational global and relational local model. In particular, we propose a relational global model that learns complex non-linear time-series patterns globally using the structure of the graph to improve both forecasting accuracy and computational efficiency. Similarly, instead of modeling every time-series independently, we learn a relational local model that not only considers its individual time-series but also the time-series of nodes that are connected in the graph. The experiments demonstrate the effectiveness of the proposed deep hybrid graph-based forecasting model compared to the state-of-the-art methods in terms of its forecasting accuracy, runtime, and scalability. Our case study reveals that GraphDF can successfully generate cloud usage forecasts and opportunistically schedule workloads to increase cloud cluster utilization by 47.5\% on average.",10.1145/3447548.3467357,2021,,ACM
Data Quality-based Gradient Optimization for Recurrent Neural Networks,"Time series forecasting holds significant value in various application scenarios. However, existing forecasting methods primarily focus on optimizing model architecture while neglecting the substantial impact of data quality on model learning. In this study, we aim to enhance model performance by optimizing data utilization based on data quality and propose a Data Quality-based Gradient Optimization (DQGO) method to facilitate training of recurrent neural networks. Firstly, we define sample quality as the matching degree between samples and model, and suggest using the attention entropy to calculate the sample quality through an attention mechanism. Secondly, we optimize the model's gradient vector by giving different weights to samples with different quality. Through experiments conducted on six datasets, the results demonstrate that DQGO significantly improves LSTM's performance. In certain cases, it even surpasses the state-of-the-art models.",10.1145/3589335.3651918,2024,,ACM
Nowcast-to-Forecast: Token-Based Multiple Remote Sensing Data Fusion for Precipitation Forecast,"Accurate short-term precipitation forecast is of social and economic significance for preventing severe weather damage. Deep learning has been rapidly adopted in nowcasting based on weather radar, which plays a key role in preventing dangerous weather conditions such as torrential rainfall. However, the limited observation range of the radar imposes constraints on shorter forecast lead times. Securing a sufficient lead time for timely flood warnings and emergency responses is crucial. Here, we propose a novel GAN-based framework that combines radar and satellite data to extend forecast lead time. First, we tokenize the satellite image to align with radar dimensions and combine the satellite and radar data. We then apply positional encoding to add positional information. Second, we design the self-conditioned generator to estimate distributions of various rainfall intensities. Finally, we employ Gaussian Fourier features to map the input noise into a continuous representation. The proposed framework realistically and accurately produces time series images of various precipitation types. Furthermore, our multisource data-driven system outperforms numerical weather prediction at forecasts of up to 6 hours in South Korea.",10.1145/3583780.3614702,2023,,ACM
A Survey on Recommender Systems Using Graph Neural Network,"The expansion of the Internet has resulted in a change in the flow of information. With the vast amount of digital information generated online, it is easy for users to feel overwhelmed. Finding the specific information can be a challenge, and it can be difficult to distinguish credible sources from unreliable ones. This has made recommender system (RS) an integral part of the information services framework. These systems alleviate users from information overload by analyzing users’ past preferences and directing only desirable information toward users. Traditional RSs use approaches like collaborative and content-based filtering to generate recommendations. Recently, these systems have evolved to a whole new level, intuitively optimizing recommendations using deep network models. graph neural networks (GNNs) have become one of the most widely used approaches in RSs, capturing complex relationships between users and items using graphs. In this survey, we provide a literature review of the latest research efforts done on GNN-based RSs. We present an overview of RS, discuss its generalized pipeline and evolution with changing learning approaches. Furthermore, we explore basic GNN architecture and its variants used in RSs, their applications, and some critical challenges for future research.",10.1145/3694784,2024,,ACM
KGDA: A Knowledge Graph Driven Decomposition Approach for Cellular Traffic Prediction,"Understanding and accurately predicting cellular traffic data is vital for communication operators and device users, as it facilitates efficient resource allocation and ensures superior service quality. However, large-scale cellular traffic data forecasting remains challenging due to intricate temporal variations and complex spatial relationships. This article proposes a Knowledge Graph Driven Decomposition Approach (KGDA) for precise cellular traffic prediction. The KGDA breaks down the impact of static environmental factors and dynamic autocorrelations of cellular traffic time series, enabling the capture of overall traffic changes and understanding of traffic dependence on past values. Specifically, we propose an urban knowledge graph to capture the static environmental context of base stations, mapping these entities into the same latent space while retaining static environmental knowledge. The cellular traffic is divided into a regular pattern and fluctuating residual components, with the KGDA comprising four modules: a Knowledge Graph Representation Learning model, a traffic regular pattern prediction module, a traffic residual dynamic prediction module, and an attentional fusion module. The first leverages graph neural networks to extract spatial contexts and predict regular patterns, the second utilizes the Bi-directional Long Short-Term Memory (Bi-LSTM) model to capture autocorrelations of traffic time series, and the final module integrates the patterns and residuals to produce the final prediction result. Comprehensive experiments demonstrate that our proposed model outperforms state-of-the-art models by more than 10\% in forecasting cellular traffic.",10.1145/3690650,2024,,ACM
GeoIndia V2: A Unified Graph and Language Model for Context-Aware Geocoding,"Geocoding in India presents unique challenges due to the unstructured, multilingual and diverse nature of its address systems. While recent advances in geospatial AI have explored the combination of spatial and semantic cues, existing methods often fall short in effectively integrating both dimensions for robust address resolution. In this work, we propose GeoIndia-V2, an enhanced version of GeoIndia [21], that unifies geospatial and semantic modeling through a novel fusion framework. Our unified model combines the Graphormer architecture [27] and a Pre-trained Transformer based Language Model (PTLM) that is trained from scratch on proprietary Indian address data, using our proposed Key Modulated Cross-Attention (KMCA) mechanism. KMCA enables deep cross-modal interaction between geospatial topology and linguistic structure and allows the model to reason contextually across both geographic and textual dimention, effectively handling the semantic intricacies of Indian addresses-including colloquial usage, inconsistent formatting, and multilinguality. We leverage last-mile e-commerce delivery data to construct a fine-grained graph of neighbourhood connectivity, enabling Graphormer to capture rich spatial relationships. Unlike prior methods that rely on self-loops, we generate graphs dynamically at inference time to exploit Graphormer's topological strength. Additionally, we introduce a generative decoding strategy for predicting hierarchical H3 cells. https://www.uber.com/en-IN/blog/h3/, moving beyond conventional bit-wise classification approaches. To the best of our knowledge, this is the first method to explicitly fuse graph-based geospatial learning with language-driven semantic modeling via cross-attention in the Indian geocoding context. Our approach significantly outperforms existing solutions and marks a substantial advancement toward building scalable real-world geocoding systems for complex address ecosystems like India.",10.1145/3746252.3761512,2025,,ACM
Long-Term Effect Estimation with Surrogate Representation,"There are many scenarios where short- and long-term causal effects of an intervention are different. For example, low-quality ads may increase short-term ad clicks but decrease the long-term revenue via reduced clicks. This work, therefore, studies the the problem of long-term effect where the outcome of primary interest, orprimary outcome, takes months or even years to accumulate. The observational study of long-term effect presents unique challenges. First, the confounding bias causes large estimation error and variance, which can further accumulate towards the prediction of primary outcomes. Second, short-term outcomes are often directly used as the proxy of the primary outcome, i.e., thesurrogate. Nevertheless, this method entails the strong surrogacy assumption that is often impractical. To tackle these challenges, we propose to build connections between long-term causal inference and sequential models in machine learning. This enables us to learnsurrogate representations that account for thetemporal unconfoundedness and circumvent the stringent surrogacy assumption by conditioning on the inferred time-varying confounders. Experimental results show that the proposed framework outperforms the state-of-the-art.",10.1145/3437963.3441719,2021,,ACM
PRO-MTL: Parameterized Route Optimization Using Multi-Task Learning,"In the current ridesharing scenario, finding a compatible passenger is highly challenging and largely dependent on chance. Existing algorithms prioritize the shortest route without considering future requests or traffic conditions, which reduces the likelihood of matching with another compatible passenger. This uncertainty leads to increased congestion along shortest routes and fewer ridesharing trips overall. This article proposes a route recommendation strategy that goes beyond the shortest route, aiming to address these issues. The proposed strategy results in higher demand, reduced congestion, broader coverage of points of interest, and an increased probability of finding compatible passengers during a trip. To achieve this, we introduce a time-series forecasting method leveraging a multi-task long short-term memory model to predict demand and traffic patterns in city-zone neighborhoods. These predictions are then used to recommend optimized routes. To evaluate our approach, we tested it on three datasets containing trip and traffic details from New York City, Los Angeles, and Shenzhen. Our model demonstrated 96\% accuracy and a 2\% RMSE loss in predicting the expected number of passengers. Furthermore, during route recommendations, we observed a 23\% increase in passenger count for 97\% of trips and a reduction in travel time for the shortest path for 60\% of trips. In light of the above experimentation, we believe that while our approach recommends a longer route than the shortest one (for 40\% of cases), it helps taxi drivers find compatible passengers on most trips which increases the profit of ridesharing services, and reduces the waiting time for passengers. The source code and dataset used in the paper is available at:",10.1145/3718092,2025,,ACM
RCCNet: A Spatial-Temporal Neural Network Model for Logistics Delivery Timely Rate Prediction,"In logistics service, the delivery timely rate is a key experience indicator, which is highly essential to the competitive advantage of express companies. Prediction on it enables intervention on couriers with low predicted results in advance, thus ensuring employee productivity and customer satisfaction. Currently, few related works focus on couriers’ level delivery timely rate prediction, and there are complex spatial correlations between couriers and road districts in the express scenario, which makes traditional real-time prediction approaches hard to utilize. To deal with this, we propose a deep spatial-temporal neural network, RCCNet to model spatial-temporal correlations. Specifically, we adopt Node2vec, which can encode the road network-based graph directly to capture spatial correlations between road districts. Further, we calculate couriers’ historical time-series similarity to build a graph and employ graph convolutional networks to capture the correlation between couriers. We also leverage historical sequential information with long short-term memory networks. We conduct experiments with real-world express datasets. Compared with other competitive baseline methods widely used in industry, the experiment results demonstrate its superior performance over multiple baselines.",10.1145/3690649,2024,,ACM
MARINA: An MLP-Attention Model for Multivariate Time-Series Analysis,"The proliferation of real-time monitoring applications such as Artificial Intelligence for IT Operations (AIOps) and the Internet of Things (IoT) has led to the generation of a vast amount of time-series data. To extract the underlying value of the data, both the industry and the academia are in dire need of efficient and effective methods for time-series analysis. To this end, in this paper, we propose a Multi-layer perceptron (&lt;u&gt;M&lt;/u&gt;LP)-&lt;u&gt;a&lt;/u&gt;ttention based multivariate time-se&lt;u&gt;ri&lt;/u&gt;es a&lt;u&gt;na&lt;/u&gt;lysis model MARINA. MARINA is designed to simultaneously learn the temporal and spatial correlations among multivariate time-series. Also, the model is versatile in that it is suitable for major time-series analysis tasks such as forecasting and anomaly detection. Through extensive comparisons with the representative multivariate time-series forecasting and anomaly detection algorithms, MARINA is shown to achieve state-of-the-art (SOTA) performance in both forecasting and anomaly detection tasks.",10.1145/3511808.3557386,2022,,ACM
Multi-Temporal Relationship Inference in Urban Areas,"Finding multiple temporal relationships among locations can benefit a bunch of urban applications, such as dynamic offline advertising and smart public transport planning. While some efforts have been made on finding static relationships among locations, little attention is focused on studying time-aware location relationships. Indeed, abundant location-based human activities are time-varying and the availability of these data enables a new paradigm for understanding the dynamic relationships in a period among connective locations. To this end, we propose to study a new problem, namely multi-Temporal relationship inference among locations (Trial for short), where the major challenge is how to integrate dynamic and geographical influence under the relationship sparsity constraint. Specifically, we propose a solution to Trial with a graph learning scheme, which includes a spatially evolving graph neural network (SEENet) with two collaborative components: spatially evolving graph convolution module (SEConv) and spatially evolving self-supervised learning strategy (SE-SSL). SEConv performs the intra-time aggregation and inter-time propagation to capture the multifaceted spatially evolving contexts from the view of location message passing. In addition, SE-SSL designs time-aware self-supervised learning tasks in a global-local manner with additional evolving constraint to enhance the location representation learning and further handle the relationship sparsity. Finally, experiments on four real-world datasets demonstrate the superiority of our method over several state-of-the-art approaches.",10.1145/3580305.3599440,2023,,ACM
ODGS: Dependency-Aware Scheduling for High-Level Synthesis with Graph Neural Network and Reinforcement Learning,"Scheduling determines the execution order and time of operations in a program. The order is related to operation dependencies, including data and resource dependencies. Data dependency is intrinsic in a program, showing operation data flow. Resource dependency is determined by scheduling methods, resolving operation resource contention. Existing scheduling methods focus on data dependency, rather than building and exploiting operation dependency graph (ODG) with extra resource dependency. As ODG contains all dependencies determining operation execution order, it provides global program information, facilitating efficient scheduling. In this work, we propose ODGS, a dependency-aware scheduling method for high-level synthesis with graph neural network (GNN) and reinforcement learning (RL). We adopt GNN to perceive accurate relations between operations. We use the relations to guide an RL agent in building a complete ODG. We perform feedback-guided iterative scheduling with ODG to converge to a high-quality solution. Experiments show that our method reduces 16.4\% latency and 26.5\% resource usage on average, compared with the latest RL-based method. Moreover, we reduce an average 2.9\% latency over the GNN-based method under the same resource usage. The same resource usage is obtained by improving the GNN-based method with manual resource constraint tuning. Without tuning, its basic version consumes an average 237.6\% more resources than our method.",10.1145/3721289,2025,,ACM
LLGformer: Learnable Long-range Graph Transformer for Traffic Flow Prediction,"Traffic prediction plays a pivotal role in intelligent transportation systems. Most existing studies only predict traffic flow for a specific time period based on traffic data from a short period, such as an hour, overlooking the influence of periodicity present in traffic data. Moreover, most of the existing advanced methods rely on manually constructed spatio-temporal graphs for joint modeling, or use pure spatial and pure temporal modules to separately model spatial and temporal features, which limits the learning of complex spatio-temporal patterns in traffic data due to structural inadequacies in the model. To address these issues, we propose a novel approach by constructing a learnable long-range spatio-temporal graph, which can better capture complex patterns in traffic data. We introduce a new model, LLGformer, which improves upon traditional Transformer-style models, facilitating more efficient learning of traffic flow data by integrating long-range historical information. Leveraging attention mechanisms on a spatiotemporal graph enables direct interaction of information across different time slices and locations. Additionally, we propose two optimization strategies to further boost the speed of training and inference. Extensive experiments on four real-world datasets show that the new model significantly outperforms state-of-the-art methods.",10.1145/3696410.3714596,2025,,ACM
FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification,"Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined time-domain augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the semantically relevant information of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: 1) the frequency component naturally encodes global features, 2) the orthogonal nature of the Fourier basis allows easier isolation and independent modifications of critical and unimportant information, and 3) a compact set of frequency components can preserve semantic integrity. To fully utilize the three properties, we propose the lightweight yet effective Frequency-Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose semantic-aware Identity Modification and semantic-agnostic Self-adaptive Modification to protect semantically relevant information in the critical frequency components and infuse variance into the unimportant ones respectively. Theoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets, including UCR and UEA archives, as well as five large-scale datasets on diverse applications. FreRA consistently outperforms ten leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets. The code is available at https://github.com/Tian0426/FreRA.",10.1145/3711896.3736969,2025,,ACM
ROTAN: A Rotation-based Temporal Attention Network for Time-Specific Next POI Recommendation,"The next Point-of-interest recommendation has attracted extensive research interest recently, which predicts users' subsequent movements. The main challenge is how to effectively capture users' personalized sequential transitions in check-in trajectory, and various methods have been developed. However, most existing studies ignore the temporal information when conducting the next POI recommendation. To fill this gap, we investigate a time-specific next POI recommendation task, which additionally incorporates the target time information. We propose a brand new Time2Rotation technique to capture the temporal information. Different from conventional methods, we represent timeslots as rotation vectors and then perform the rotation operations. Based on the Time2Rotation technique, we propose a novel rotation-based temporal attention network, namely ROTAN, for the time-specific next POI recommendation task. The ROTAN begins by building a collaborative POI transition graph, capturing the asymmetric temporal influence in sequential transitions. After that, it incorporates temporal information into the modeling of individual check-in trajectories, extracting separate representations for user preference and POI influence to reflect their distinct temporal patterns. Lastly, the target time is integrated to generate recommendations. Extensive experiments are conducted on three real-world datasets, which demonstrates the advantages of the proposed Time2Rotation technique and ROTAN recommendation model.",10.1145/3637528.3671809,2024,,ACM
Contrastive Predictive Coding for Human Activity Recognition,"Feature extraction is crucial for human activity recognition (HAR) using body-worn movement sensors. Recently, learned representations have been used successfully, offering promising alternatives to manually engineered features. Our work focuses on effective use of small amounts of labeled data and the opportunistic exploitation of unlabeled data that are straightforward to collect in mobile and ubiquitous computing scenarios. We hypothesize and demonstrate that explicitly considering the temporality of sensor data at representation level plays an important role for effective HAR in challenging scenarios. We introduce the Contrastive Predictive Coding (CPC) framework to human activity recognition, which captures the temporal structure of sensor data streams. Through a range of experimental evaluations on real-life recognition tasks, we demonstrate its effectiveness for improved HAR. CPC-based pre-training is self-supervised, and the resulting learned representations can be integrated into standard activity chains. It leads to significantly improved recognition performance when only small amounts of labeled training data are available, thereby demonstrating the practical value of our approach. Through a series of experiments, we also develop guidelines to help practitioners adapt and modify the framework towards other mobile and ubiquitous computing scenarios.",10.1145/3463506,2021,,ACM
Spatiotemporal Hypergraph Learning for Stock Return Sequence Prediction,"Financial markets are characterized by strong volatility, high noise, and intricate interdependencies among stocks, making accurate stock return prediction a challenging task. In this study, we propose a novel approach called Spatiotemporal Hypergraph Learning (STHL) for stock return sequence prediction. STHL integrates temporal characteristics and correlation-based spatial structures between stocks, enabling better prediction accuracy. We construct hypergraphs and graphs representing stock relationships using prior knowledge and data-driven methods. Hybrid graph learning techniques capture essential features, which, combined with temporal information, enhance prediction performance. The proposed multi-stock recommendation system provides investors with ranked stock recommendations, optimizing their investment decisions.",10.1145/3718751.3718862,2025,,ACM
SeLeP: Learning Based Semantic Prefetching for Exploratory Database Workloads,"Prefetching is a crucial technique employed in traditional databases to enhance interactivity, particularly in the context of data exploration. Data exploration is a query processing paradigm in which users search for insights buried in the data, often not knowing what exactly they are looking for. Data exploratory tools deal with multiple challenges such as the need for interactivity with no a priori knowledge being present to help with the system tuning. The state-of-the-art prefetchers are specifically designed for navigational workloads only, where the number of possible actions is limited. The prefetchers that work with SQL-based workloads, on the other hand, mainly rely on data logical addresses rather than the data semantics. They fail to predict complex access patterns in cases where the database size is substantial, resulting in an extensive address space, or when there is frequent co-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher that makes prefetching decisions for both types of workloads, based on the encoding of the data values contained inside the accessed blocks. Following the popular path of using machine learning approaches to automatically learn the hidden patterns, we formulate the prefetching task as a time-series forecasting problem and use an encoder-decoder LSTM architecture to learn the data access pattern. Our extensive experiments, across real-life exploratory workloads, demonstrate that SeLeP improves the hit ratio up to 40\% and reduces I/O time up to 45\% compared to the state-of-the-art, attaining 96\% hit ratio and 84\% I/O reduction on average.",10.14778/3659437.3659458,2024,,ACM
Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting,"Accurate workload forecasting is critical for efficient resource management in cloud computing systems, enabling effective scheduling and autoscaling. Despite recent advances with transformer-based forecasting models, challenges remain due to the non-stationary, nonlinear characteristics of workload time series and the long-term dependencies. In particular, inconsistent performance between long-term history and near-term forecasts hinders long-range predictions. This paper proposes a novel framework leveraging self-supervised multiscale representation learning to capture both long-term and near-term workload patterns. The long-term history is encoded through multiscale representations while the near-term observations are modeled via temporal flow fusion. These representations of different scales are fused using an attention mechanism and characterized with normalizing flows to handle non-Gaussian/non-linear distributions of time series. Extensive experiments on 9 benchmarks demonstrate superiority over existing methods.",10.1145/3627673.3680072,2024,,ACM
ProST: Prompt Future Snapshot on Dynamic Graphs for Spatio-Temporal Prediction,"Spatio-temporal prediction focuses on jointly modeling spatial correlations and temporal evolution and has a wide range of applications. Due to the heterogeneity of spatio-temporal data, accurate prediction relies on effectively integrating topological structures and sequential patterns. Although recurrent graph learning methods excel at capturing dynamic graph patterns, explicitly inferring future snapshots from historical dynamic graphs remains a significant challenge. Recently, prompt-based graph learning has shown the potential to improve future snapshot inference by leveraging node or task-specific prompts. However, these methods fail to fully capture edge information resulting in incomplete and less accurate representations of future snapshot structures. To bridge this gap, we propose ProST, a framework that Prompts future snapshots on dynamic graphs for Spatio-Temporal prediction, which leverages dynamic graph pre-training to generate a premise graph containing historical graph information and then employs prompts on the premise graph to infer explicit future snapshots. Specifically, this framework comprises three steps: Firstly, dynamic graph pre-training is performed using multi-granularity evolution graph convolution to obtain the premise graph with both local and global features of dynamic graphs. Secondly, prompt subgraphs are used to prompt node pairs and edge features within the premise graph. The subgraph prompt aggregation mechanism propagates this information to generate future snapshots. Finally, we freeze the parameters of the pre-trained model and update the subgraph prompt parameters using meta-learning to adapt to downstream spatio-temporal prediction tasks. Extensive experiments on real-world datasets validate that ProST achieves state-of-the-art performance.",10.1145/3690624.3709273,2025,,ACM
A Transferable Spatio-temporal Learning Framework for Cross-city Logistics Demand Prediction,"In logistic systems, demand prediction is an essential task providing the basis for improving the quality of terminal services, such as pick-up and delivery efficiency. However, the geographical scope of operations across multiple cities brings challenges due to the sparsity of user behavior data, hindering accurate predictions. Despite cross-city prediction methods potentially solving this problem by relying on the label of overlapping users in different cities, annotating these overlapping users is expensive. Additionally, the dynamic and diverse nature of user behaviors complicates feature transfer between cities. In this work, we define the logistics demand prediction problem as forecasting pick-up and delivery demand for zones, the smallest operational units in logistics systems, in different cities. To address the challenge, we propose TSTL, a Transferable Spatio-Temporal Learning framework for cross-city logistics prediction with sparse user data. TSTL advances existing methods from two aspects: (1) User-level invariant representation module extracts consistent user representations for overlapping and non-overlapping users across cities. (2) User-zone graph aggregation module enhances user embeddings by integrating dynamic interactions, such as logistics behaviors, into inherent user relations. Finally, the multi-city transfer module fine-tunes model parameters for city-invariant knowledge adoption and predicts future logistics demand. We implement and evaluate TSTL on one of the largest logistics systems. Extensive offline experiments and real-world deployment demonstrate the effectiveness of TSTL.",10.1145/3711896.3737186,2025,,ACM
Analyzing the Impact of Credit Card Fraud on Economic Fluctuations of American Households Using an Adaptive Neuro-Fuzzy Inference System,"Credit card fraud is assuming growing proportions as a major threat to the financial position of American household, leading to unpredictable changes in household economic behavior. To solve this problem, in this paper, a new hybrid analysis method is presented by using the Enhanced ANFIS. The model proposes several advances of the conventional ANFIS framework and employs a multi-resolution wavelet decomposition module and a temporal attention mechanism. The model performs discrete wavelet transformations on historical transaction data and macroeconomic indicators to generate localized economic shock signals. The transformed features are then fed into a deep fuzzy rule library which is based on Takagi-Sugeno fuzzy rules with adaptive Gaussian membership functions. The model proposes a temporal attention encoder that adaptively assigns weights to multi-scale economic behavior patterns, increasing the effectiveness of relevance assessment in the fuzzy inference stage and enhancing the capture of long-term temporal dependencies and anomalies caused by fraudulent activities. The proposed method differs from classical ANFIS which has fixed input–output relations since it integrates fuzzy rule activation with the wavelet basis selection and the temporal correlation weights via a modular training procedure. Experimental results show that the RMSE was reduced by 17.8\% compared with local neuro-fuzzy models and conventional LSTM models.",10.1145/3766918.3766929,2025,,ACM
DuroNet: A Dual-robust Enhanced Spatial-temporal Learning Network for Urban Crime Prediction,"Urban crime is an ongoing problem in metropolitan development and attracts general concern from the international community. As an effective means of defending urban safety, crime prediction plays a crucial role in patrol force allocation and public safety. However, urban crime data is a macro result of crime patterns overlapped by various irrelevant factors that cause inhomogeneous noises—local outliers and irregular waves. These noises might obstruct the learning process of crime prediction models and result in a deviation of performance. To tackle the problem, we propose a novel paradigm of &lt;underline&gt;Du&lt;/underline&gt;al-&lt;underline&gt;ro&lt;/underline&gt;bust Enhanced Spatial-temporal Learning &lt;underline&gt;Net&lt;/underline&gt;work&nbsp;(DuroNet), an encoder-decoder architecture that possesses an adaptive robustness for reducing the effect of outliers and waves. The robustness is mainly reflected on two aspects. One is a locality enhanced module that employs local temporal context information to smooth the deviation of outliers and dynamic spatial information to assist in understanding normal points. The other is a self-attention-based pattern representation module to weaken the effect of irregular waves by learning attentive weights. Finally, extensive experiments are conducted on two real-world crime datasets before and after adding Gaussian noises. The results demonstrate the superior performance of our DuroNet over the state-of-the-art methods.",10.1145/3432249,2021,,ACM
Learning Universal Multi-level Market Irrationality Factors to Improve Stock Return Forecasting,"Recent years have witnessed the perfect encounter of deep learning and quantitative trading has achieved great success in stock investment. Numerous deep learning-based models have been developed for forecasting stock returns, leveraging the powerful representation capabilities of neural networks to identify patterns and factors influencing stock prices. These models can effectively capture general patterns in the market, such as stock price trends, volume-price relationships, and time variations. However, the impact of special irrationality factors -- such as market sentiment, speculative behavior, market manipulation, and psychological biases -- has not been fully considered in existing deep stock forecasting models due to their relative abstraction as well as lack of explicit labels and data description. To fill this gap, we propose UMI, a Universal multi-level Market Irrationality factor model to enhance stock return forecasting. The UMI model learns factors that can reflect irrational behaviors in market from both individual stock and overall market levels. For the stock-level, UMI construct an estimated rational price for each stock, which is cointegrated with the stock's actual price. The discrepancy between the actual and the rational prices serves as a factor to indicate stock-level irrational events. Additionally, we define market-level irrational behaviors as anomalous synchronous fluctuations of stocks within a market. Using two self-supervised representation learning tasks, i.e., sub-market comparative learning and market synchronism prediction, the UMI model incorporates market-level irrationalities into a market representation vector, which is then used as the market-level irrationality factor. We also developed a forecasting model that captures both temporal and relational dependencies among stocks, accommodating the UMI factors. Extensive experiments on U.S. and Chinese stock markets with competitive baselines demonstrate our model's effectiveness and the universality of our factors in improving various forecasting models. We provide our code at https://github.com/lIcIIl/UMI.",10.1145/3690624.3709328,2025,,ACM
Characterizing and Forecasting Urban Vibrancy Evolution: A Multi-View Graph Mining Perspective,"Urban vibrancy describes the prosperity, diversity, and accessibility of urban areas, which is vital to a city’s socio-economic development and sustainability. While many efforts have been made for statically measuring and evaluating urban vibrancy, there are few studies on the evolutionary process of urban vibrancy, yet we know little about the relationship between urban vibrancy evolution and sophisticated spatiotemporal dynamics. In this article, we make use of multi-sourced urban data to develop a data-driven framework, U-Evolve, to investigate urban vibrancy evolution. Specifically, we first exploit the spatiotemporal characteristics of urban areas to create multi-view time-dependent graphs. Then, we analyze the contextual features and graph patterns of multi-view time-dependent graphs in terms of informing future urban vibrancy variations. Our analysis validates the informativeness of multi-view time-dependent graphs for characterizing and informing future urban vibrancy evolution. After that, we construct a feature based model to forecast future urban vibrancy evolution and quantify each feature’s importance. Moreover, to further enhance the forecasting effectiveness, we propose a graph learning based model to capture spatiotemporal autocorrelation of urban areas based on multi-view time-dependent graphs in an end-to-end manner. Finally, extensive experiments on two metropolises, Beijing and Shanghai, demonstrate the effectiveness of our forecasting models. The U-Evolve framework has also been deployed in the production environment to deliver real-world urban development and planning insights for various cities in China.",10.1145/3568683,2023,,ACM
Unsupervised Temporal Encoding for Stock Price Prediction through Dual-Phase Learning,"This paper proposes a two-stage self-supervised pretraining modeling method for stock price sequence prediction in financial markets. The method is designed to address challenges such as limited labeled data, complex structural patterns, and non-stationary temporal features. The framework consists of two phases: pretraining and fine-tuning. In the pretraining phase, two self-supervised tasks are constructed. One captures long-term trends, while the other models short-term fluctuations. In the fine-tuning phase, the learned representations are used for regression prediction to improve the model's ability to fit future price movements. In the encoder design, the method integrates multi-layer temporal sequence modeling units. This enables multi-granularity semantic extraction and structure-aware representation learning. For the experimental part, a dataset is built based on Tesla's historical stock data from 2010 to 2024. The model is systematically evaluated under different time windows, hidden dimensions, sampling frequencies, and perturbation settings. The experimental results show that the proposed method outperforms existing baseline models across multiple metrics. It effectively captures temporal dependencies while maintaining strong prediction stability and robustness. This study validates the effectiveness of the two-stage architecture in financial time series modeling. It also demonstrates the practical potential of self-supervised learning in low-supervision financial prediction tasks.",10.1145/3770177.3770306,2025,,ACM
An Information Cascade Prediction Algorithm Based on Time Series,"The prediction of information cascades is a crucial task in data mining, which aims to understand the patterns of information diffusion at macroscopic and microscopic levels. The objective of the macro level is to predict the popularity of information cascades in the future. However, the current macro information cascade prediction algorithms produce a fixed popularity prediction value for a specific future time, which lacks flexibility. In this paper, we propose a novel information cascade prediction algorithm, named CasInformer. This algorithm views information cascades as a sequence of cascaded graph snapshots and employs time series prediction to make inferences. CasInformer enhances the selection method of cascaded snapshots and utilizes diverse information to encode supplementary data, which significantly enhances prediction accuracy compared to existing algorithms. CasInformer can predict the cascading popularity at multiple different times to obtain the future trend of information cascading popularity, which is more practical in real scenarios. Experimental results on real datasets show that CasInformer has achieved significant improvement in both prediction accuracy and prediction ability compared to existing research.",10.1145/3696409.3700258,2024,,ACM
Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals,"Multi-modal time series data is common in web technologies like the Internet of Things (IoT). Existing methods for multi-modal time series representation learning aim to disentangle the modality-shared and modality-specific latent variables. Although achieving notable performances on downstream tasks, they usually assume an orthogonal latent space. However, the modality-specific and modality-shared latent variables might be dependent on real-world scenarios. Therefore, we propose a general generation process, where the modality-shared and modality-specific latent variables are dependent, and further develop a Multi-modAl TEmporal Disentanglement (MATE) model. Specifically, our MATE model is built on a temporally variational inference architecture with the modality-shared and modality-specific prior networks for the disentanglement of latent variables. Furthermore, we establish identifiability results to show that the extracted representation is disentangled. More specifically, we first achieve the subspace identifiability for modality-shared and modality-specific latent variables by leveraging the pairing of multi-modal data. Then we establish the component-wise identifiability of modality-specific latent variables by employing sufficient changes of historical latent variables. Extensive experimental studies on 12 datasets show a general improvement in different downstream tasks, highlighting the effectiveness of our method in real-world scenarios.",10.1145/3696410.3714931,2025,,ACM
A Co-training Approach for Noisy Time Series Learning,"In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning1.",10.1145/3583780.3614759,2023,,ACM
Dynamic Hotel Pricing at Online Travel Platforms: A Popularity and Competitiveness Aware Demand Learning Approach,"Dynamic pricing, which suggests the optimal prices based on the dynamic demands, has received considerable attention in academia and industry. On online hotel booking platforms, room demand fluctuates due to various factors, notably hotel popularity and competition. In this paper, we propose a dynamic pricing approach with popularity and competitiveness-aware demand learning. Specifically, we introduce a novel demand function that incorporates popularity and competitiveness coefficients to comprehensively model the price elasticity of demand. We develop a dynamic demand prediction network that focuses on learning these coefficients in the proposed demand function, enhancing the interpretability and accuracy of price suggestion. The model is trained in a multi-task framework that effectively leverages the correlations of demands among groups of similar hotels to alleviate data sparseness in room-level occupancy prediction. Comprehensive experiments conducted on real-world datasets validate the superiority of our method over state-of-the-art baselines in both demand prediction and dynamic pricing. Our model has been successfully deployed on a popular online travel platform, serving tens of millions of users and hoteliers.",10.1145/3637528.3671921,2024,,ACM
Enhancing Dependency Dynamics in Traffic Flow Forecasting via Graph Risk Bootstrap,"Graph neural networks, as well as attention mechanisms, have gained widespread popularity for traffic flow forecasting due to their capacity to incorporate the complicated interactions behind flow dynamics. However, existing solutions either formulate a graph-based skeleton with narrow (e.g., static) interaction capture or build the spatiotemporal (e.g., dynamic) attention without proper comprehension of diverse risks, which inevitably burdens the generalization of high-accuracy traffic trends. In this study, we introduce Gboot (Graph bootstrap) enhancement framework for traffic flow forecasting. Gboot takes the traffic flow forecasting problem from a dependency dynamic learning perspective by treating each traffic sensor as the graph node while regarding the observed flows at each sensor as the node feature. In addition to exposing the explicit spatial connectivity behind traffic flows, we hierarchically devise temporal-aware and factual-aware graph learning blocks to consider temporal interactive dynamics and factual interactive dynamics. The former shows the trend dependencies behind flow signals and the latter uncovers different views of traffic situations (e.g., current observation vs. historical observation). More importantly, we present a Dual-view Bootstrap (DvBoot) mechanism in Gboot, which includes both risk-free and risk-aware stands. DvBoot attempts to flexibly align these two views in the latent space to enhance the generalization capability of capturing dynamic dependencies. Experiments on several real-world traffic datasets demonstrate the superiority of our Gboot over representative approaches.",10.1145/3678717.3691237,2024,,ACM
Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series,"Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at .",10.1145/3516367,2022,,ACM
Towards Predicting Urban Land Use Changes: A Dynamic Graph Alignment Perspective,"Urban land use, intrinsically linked to people’s daily activities, undergoes continuous evolution, presenting a complex interplay that remains partially understood. To bridge this gap, our study leverages fine-grained human mobility data to predict these changes, adopting a novel approach that conceptualizes “community-level” land use shifts as a regression problem and represents citywide changes through dynamic graphs. We harness recent advancements in graph neural networks (GNNs), which, despite their success in various applications, face challenges in directly predicting land use changes due to the temporal mismatch between the slow evolution of urban land and the immediacy of human mobility data. Our research stands out by introducing a temporal skeleton for dynamic GNNs to synchronize human activity graphs with urban land use changes, a dynamic heterogeneous GNN approach for integrating diverse human activity data to capture essential temporal dependencies, and a novel algorithm powered by causal inference to elucidate the primary factors influencing land use predictions at the community level, all of which contribute to a training process informed by the generated causal graph. Empirically validated on three real-world datasets, our model demonstrates a performance leap over state-of-the-art baselines, marking a pivotal step toward understanding and predicting the dynamics of urban land use.",10.1145/3712702,2025,,ACM
Research on Long-Term ENSO Prediction Method Based on Adaptive Spatio-Temporal Attention Network Using K-MEANS Clustering Algorithm,The El Ni\~{n,10.1145/3727353.3727401,2025,,ACM
SrVARM: State Regularized Vector Autoregressive Model for Joint Learning of Hidden State Transitions and State-Dependent Inter-Variable Dependencies from Multi-variate Time Series,"Many applications, e.g., healthcare, education, call for effective methods methods for constructing predictive models from high dimensional time series data where the relationship between variables can be complex and vary over time. In such settings, the underlying system undergoes a sequence of unobserved transitions among a finite set of hidden states. Furthermore, the relationships between the observed variables and their temporal dynamics may depend on the hidden state of the system. To further complicate matters, the hidden state sequences underlying the observed data from different individuals may not be aligned relative to a common frame of reference. Against this background, we consider the novel problem of jointly learning the state-dependent inter-variable relationships as well as the pattern of transitions between hidden states from multi-variate time series data. To solve this problem, we introduce the State-Regularized Vector Autoregressive Model (SrVARM) which combines a state-regularized recurrent neural network to learn the dynamics of transitions between discrete hidden states with an augmented autoregressive model which models the inter-variable dependencies in each state using a state-dependent directed acyclic graph (DAG). We propose an efficient algorithm for training SrVARM by leveraging a recently introduced reformulation of the combinatorial problem of optimizing the DAG structure with respect to a scoring function into a continuous optimization problem. We report results of extensive experiments with simulated data as well as a real-world benchmark that show that SrVARM outperforms state-of-the-art baselines in recovering the unobserved state transitions and discovering the state-dependent relationships among variables.",10.1145/3442381.3450116,2021,,ACM
Popularity-aware Distributionally Robust Optimization for Recommendation System,"Collaborative Filtering (CF) has been widely applied for personalized recommendations in various industrial applications. However, due to the training strategy of Empirical Risk Minimization, CF models tend to favor popular items, resulting in inferior performance on sparse users and items. To enhance the CF representation learning of sparse users and items without sacrificing the performance of popular items, we propose a novel Popularity- aware Distributionally Robust Optimization (PDRO) framework. In particular, PDRO emphasizes the optimization of sparse users/items, while incorporating item popularity to preserve the performance of popular items through two modules. First, an implicit module develops a new popularity-aware DRO objective, paying more attention to items that will potentially become popular over time. Second, an explicit module that directly predicts the popularity of items to help the estimation of user-item matching scores. We apply PDRO to a micro-video recommendation scenario and implement it on two representative backend models. Extensive experiments on a real-world industrial dataset, as well as two public benchmark datasets, validate the efficacy of our proposed PDRO. Additionally, we perform an offline A/B test on the industrial dataset, further demonstrating the superiority of PDRO in real-world application scenarios.",10.1145/3583780.3615492,2023,,ACM
Automated Contrastive Learning Strategy Search for Time Series,"In recent years, Contrastive Learning (CL) has become a predominant representation learning paradigm for time series. Most existing methods manually build specific CL Strategies (CLS) by human heuristics for certain datasets and tasks. However, manually developing CLS usually requires excessive prior knowledge about the data, and massive experiments to determine the detailed CL configurations. In this paper, we present an Automated Machine Learning (AutoML) practice at Microsoft, which automatically learns CLS for time series datasets and tasks, namely Automated Contrastive Learning (AutoCL). We first construct a principled search space of size over 3 \texttimes{",10.1145/3627673.3680086,2024,,ACM
Prospective Multi-Graph Cohesion for Multivariate Time Series Anomaly Detection,"Anomaly detection in high-dimensional time series data is pivotal for numerous industrial applications. Recent advances in multivariate time series anomaly detection (TSAD) have increasingly leveraged graph structures to model inter-variable relationships, typically employing Graph Neural Networks (GNNs). Despite their promising results, existing methods often rely on a single graph representation, which are insufficient for capturing the complex, diverse relationships inherent in multivariate time series. To address this, we propose the Prospective Multi-Graph Cohesion (PMGC) framework for multivariate TSAD. PMGC exploits spatial correlations by integrating a long-term static graph with a series of short-term instance-wise dynamic graphs, regulated through a graph cohesion loss function. Our theoretical analysis shows that this loss function promotes diversity among dynamic graphs while aligning them with the stable long-term relationships encapsulated by the static graph. Additionally, we introduce a ",10.1145/3701551.3703494,2025,,ACM
A Universal Model for Human Mobility Prediction,,10.1145/3690624.3709236,2025,,ACM
Improving Streaming Cryptocurrency Transaction Classification via Biased Sampling and Graph Feedback,"We show that knowledge of wallet addresses from the current time state of a blockchain network, such as Bitcoin, increases the performance of illicit activity detection. Based on this finding we introduce two new methods for the sampling of classifier training data so that precedence is given to transaction information from the recent past and the current time state. This sampling enables streaming classification in which a decision on the class of a transaction needs to be made based on data seen to date. Our new approach provides insight into how the dynamics of the blockchain network plays a central role in the detection of illicit transactions, and is independent of the classifier choice. Our proposed sampling methods enable graph convolution network (GCN) and random forest (RF) classifiers to better adapt to changes in the network due to significant events, such as the closure of a large ‘Darknet’ marketplace. We introduce Graphlet spectral correlation analysis for exposing the effect of such network re-organisation due to major events. Finally, based on our analysis, we propose a new two-stage random forest classifier that feeds back intermediate predictions of neighbours to improve the classification decision. Our methodology enables practical streaming classification, even in the scenario of very limited information on the feature space of each transaction.",10.1145/3485832.3485913,2021,,ACM
Dynamic and Multi-faceted Spatio-temporal Deep Learning for Traffic Speed Forecasting,"Dynamic Graph Neural Networks (DGNNs) have become one of the most promising methods for traffic speed forecasting. However, when adapting DGNNs for traffic speed forecasting, existing approaches are usually built on a static adjacency matrix (no matter predefined or self-learned) to learn spatial relationships among different road segments, even if the impact of two road segments can be changeable dynamically during a day. Moreover, the future traffic speed cannot only be related with the current traffic speed, but also be affected by other factors such as traffic volumes. To this end, in this paper, we aim to explore these dynamic and multi-faceted spatio-temporal characteristics inherent in traffic data for further unleashing the power of DGNNs for better traffic speed forecasting. Specifically, we design a dynamic graph construction method to learn the time-specific spatial dependencies of road segments. Then, a dynamic graph convolution module is proposed to aggregate hidden states of neighbor nodes to focal nodes by message passing on the dynamic adjacency matrices. Moreover, a multi-faceted fusion module is provided to incorporate the auxiliary hidden states learned from traffic volumes with the primary hidden states learned from traffic speeds. Finally, experimental results on real-world data demonstrate that our method can not only achieve the state-of-the-art prediction performances, but also obtain the explicit and interpretable dynamic spatial relationships of road segments.",10.1145/3447548.3467275,2021,,ACM
DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions,"Prediction of couriers' delivery timely rates in advance is essential to the logistics industry, enabling companies to take preemptive measures to ensure the normal operation of delivery services. This becomes even more critical during anomaly conditions like the epidemic outbreak, during which couriers' delivery timely rate will decline markedly and fluctuates significantly. Existing studies pay less attention to the logistics scenario. Moreover, many works focusing on prediction tasks in anomaly scenarios fail to explicitly model abnormal events, e.g., treating external factors equally with other features, resulting in great information loss. Further, since some anomalous events occur infrequently, traditional data-driven methods perform poorly in these scenarios. To deal with them, we propose a deep spatial-temporal attention model, named DeepSTA. To be specific, to avoid information loss, we design an anomaly spatio-temporal learning module that employs a recurrent neural network to model incident information. Additionally, we utilize Node2vec to model correlations between road districts, and adopt graph neural networks and long short-term memory to capture the spatial-temporal dependencies of couriers. To tackle the issue of insufficient training data in abnormal circumstances, we propose an anomaly pattern attention module that adopts a memory network for couriers' anomaly feature patterns storage via attention mechanisms. The experiments on real-world logistics datasets during the COVID-19 outbreak in 2022 show the model outperforms the best baselines by 12.11\% in MAE and 13.71\% in MSE, demonstrating its superior performance over multiple competitive baselines.",10.1145/3583780.3614671,2023,,ACM
UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web,"Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1\% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.",10.1145/3589334.3645378,2024,,ACM
On Hierarchical Disentanglement of Interactive Behaviors for Multimodal Spatiotemporal Data with Incompleteness,"Multimodal spatiotemporal data (MST) consists of multiple simultaneous spatiotemporal modalities that interact with each other in a dynamic manner. Due to the complexity of MST and the recent desire for the explainability of artificial intelligent systems, disentangled representation learning for MST (DisentMST) has become a significant task, which aims to learn disentangled representations that can expose the underlying spatial semantics, temporal dynamic patterns, and inter-modality interaction modes of the complex MST. One limitation of existing approaches is that they might fail to tolerate the real-world incomplete MST data, where missing information might break the cross-modal spatiotemporal dynamics and bring noise and ambiguity to the learning process. Another limitation is that no existing work systematically reveals the structure of different types of disentangled information. To tackle the two limitations, we define a novel two-level hierarchically structured disentanglement task for MST, which reveals informative and structured disentangled representations for MST as well as digests the real-world MST with incompleteness. We propose a new framework, BiDisentMST, which leverages Gaussian Processes and Graph Factorization on the latent space to achieve our purposes. The experimental results demonstrate the effectiveness of our proposed framework compared with baselines with respect to disentanglement and imputation results.",10.1145/3580305.3599448,2023,,ACM
MentorPDM: Learning Data-Driven Curriculum for Multi-Modal Predictive Maintenance,"Predictive Maintenance (PDM) systems are essential for preemptive monitoring of sensor signals to detect potential machine component failures in industrial assets such as bearings in rotating machinery. Existing PDM systems face two primary challenges: 1) Irregular Signal Acquisition, where data collection from the sensors is intermittent, and 2) Signal Heterogeneity, where the full spectrum of sensor modalities is not effectively integrated. To address these challenges, we propose a Curriculum Learning Framework for Multi-Modal Predictive Maintenance - MentorPDM. MentorPDM consists of 1) a graph-augmented pretraining module that captures intrinsic and structured temporal correlations across time segments via a temporal contrastive learning objective and 2) a bi-level curriculum learning module that captures task complexities for weighing the importance of signal modalities and samples via modality and sample curricula. Empirical results from MentorPDM show promising performance with better generalizability in PDM tasks compared to existing benchmarks. The efficacy of the MentorPDM model will be further demonstrated in real industry testbeds and platforms.",10.1145/3690624.3709388,2025,,ACM
Graph Anomaly Detection with Few Labels: A Data-Centric Approach,"Anomalous node detection in a static graph faces significant challenges due to the rarity of anomalies and the substantial cost of labeling their deviant structure and attribute patterns. These challenges give rise to data-centric problems, including extremely imbalanced data distributions and intricate graph learning, which significantly impede machine learning and deep learning methods from discerning the patterns of graph anomalies with few labels. While these issues remain crucial, much of the current research focuses on addressing the induced technical challenges, treating the shortage of labeled data as a given. Distinct from previous efforts, this work focuses on tackling the data-centric problems by generating auxiliary training nodes that conform to the original graph topology and attribute distribution. We categorize this approach as data-centric, aiming to enhance existing anomaly detectors by training them on our synthetic data. However, the methods for generating nodes and the effectiveness of utilizing synthetic data for graph anomaly detection remain unexplored in the realm. To answer these questions, we thoroughly investigate the denoising diffusion model. Drawing from our observations on the diffusion process, we illuminate the shifts in graph energy distribution and establish two principles for designing denoising neural networks tailored to graph anomaly generation. From the insights, we propose a diffusion-based graph generation method to synthesize training nodes, which can be promptly integrated to work with existing anomaly detectors. The empirical results on eight widely-used datasets demonstrate our generated data can effectively enhance the nine state-of-the-art graph detectors' performance.",10.1145/3637528.3671929,2024,,ACM
ASTNet: Asynchronous Spatio-Temporal Network for Large-Scale Chemical Sensor Forecasting,"The chemical industry is faced with the urgent challenge of effectively harnessing the vast amounts of time-series data generated by thousands of sensors, which is essential for forecasting chemical states, achieving accurate real-time control of production processes. Traditional forecasting methods suffer from high computational latency and struggle with the complexity of spatiotemporal dependencies. As a result, modeling this data becomes challenging. This paper introduces a novel approach, referred to as ASTNet, designed to address these challenges. ASTNet integrates an asynchronous spatiotemporal modeling framework that combines temporal and spatial encoders, enabling concurrent learning of temporal and spatial dependencies while reducing computational latency. Additionally, it introduces a gated graph fusion mechanism that adaptively combines static (meta) and evolving (dynamic) sensor graphs, enhancing the handling of heterogeneous sensor data and spatial correlations. Extensive experiments on three real-world chemical sensor datasets demonstrate that ASTNet outperforms SOTA methods in terms of both prediction accuracy and computational efficiency, making ASTNet successfully deployed in chemical engineering industrial scenarios.",10.1145/3711896.3737194,2025,,ACM
Robust Spatio-Temporal Graph Neural Network for Electricity Consumption Forecasting,"Precise electricity consumption forecasting is pivotal in the energy schedule of new electric power systems. It is also significant for improving robustness of smart power grid. Existing multivariate time series predictions have made effective achievements in modeling sequential tendency and periodicity, but they lack of considering time series noises due to data sensing or transferring. Therefore, we focus on a robust approach to capture intricate correlations of multivariate time series data for forecasting. Specifically, we exploit gated dilated causal convolution as projection layer to capture latent semantic information from a temporal perspective. Furthermore, we combine time series decomposition and adaptive normalization to learn latent representations of each time series. Finally, we devise spatio-temporal modeling for capturing heterogeneous correlations. Extensive experiments are implemented on real-scenario public datasets. The performances show the effectiveness of proposed approach for electricity consumption forecasting.",10.1145/3697355.3697401,2024,,ACM
Explainable Stock Price Movement Prediction using Contrastive Learning,"Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of ",10.1145/3627673.3679544,2024,,ACM
No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models,"Modern IoT deployments for environmental sensing produce high volume spatiotemporal data to support downstream tasks such as forecasting, typically powered by machine learning models. While existing filtering and strategic deployment techniques optimize collected data volume at the edge, they overlook how variations in sampling frequencies and spatial coverage affect downstream model performance. In many forecasting models, incorporating data from additional sensors denoise predictions by providing broader spatial contexts. This interplay between sampling frequency, spatial coverage and different forecasting model architectures remain underexplored. This work presents a systematic study of forecasting models - classical models (VAR), neural networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs), and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under varying spatial sensor nodes density and sampling intervals using real-world temperature data in a wireless sensor network. Our results show that STGNNs are effective when sensor deployments are sparse and sampling rate is moderate, leveraging spatial correlations via encoded graph structure to compensate for limited coverage. In contrast, TSFMs perform competitively at high frequencies but degrade when spatial coverage from neighboring sensors is reduced. Crucially, the multivariate TSFM Moirai outperforms all models by natively learning cross-sensor dependencies. These findings offer actionable insights for building efficient forecasting pipelines in spatio-temporal systems. All code for model configurations, training, dataset, and logs are open-sourced for reproducibility.1",10.1145/3736425.3771958,2025,,ACM
ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for Multivariate Time Series Analysis,"Designing effective models for learning time series representations is foundational for time series analysis. Many previous works explore time series representation modeling approaches and make progress in this area. Despite their effectiveness, they lack adaptive perception of local patterns in temporally dependent basic units and fail to capture the multi-scale dependency among these units. Instead of relying on prevalent methods centered around self-attention mechanisms, we propose ConvTimeNet, a hierarchical pure convolutional model designed for time series analysis. ConvTimeNet introduces a deformable patch layer that adaptively perceives local patterns of temporally dependent basic units in a data-driven manner. Based on the extracted local patterns, hierarchical pure convolutional blocks are designed to capture dependency relationships among the representations of basic units at different scales. Moreover, a large kernel mechanism is employed to ensure that convolutional blocks can be deeply stacked, thereby achieving a larger receptive field. In this way, local patterns and their multi-scale dependencies can be effectively modeled within a single model. Extensive experiments comparing a wide range of different types of models demonstrate that pure convolutional models still exhibit strong viability, effectively addressing the aforementioned two challenges and showing superior performance across multiple tasks. The code is available for reproducibility. https://github.com/Mingyue-Cheng/ConvTimeNet",10.1145/3701716.3715214,2025,,ACM
Integrating System State into Spatio Temporal Graph Neural Network for Microservice Workload Prediction,"Microservice architecture has become a driving force in enhancing the modularity and scalability of web applications, as evidenced by the Alipay platform's operational success. However, a prevalent issue within such infrastructures is the suboptimal utilization of CPU resources due to inflexible resource allocation policies. This inefficiency necessitates the development of dynamic, accurate workload prediction methods to improve resource allocation. In response to this challenge, we present STAMP, a &lt;u&gt;S&lt;/u&gt;patio &lt;u&gt;T&lt;/u&gt;emporal Gr&lt;u&gt;a&lt;/u&gt;ph Network for &lt;u&gt;M&lt;/u&gt;icroservice Workload &lt;u&gt;P&lt;/u&gt;rediction. STAMP is designed to comprehensively address the multifaceted interdependencies between microservices, the temporal variability of workloads, and the critical role of system state in resource utilization. Through a graph-based representation, STAMP effectively maps the intricate network of microservice interactions. It employs time series analysis to capture the dynamic nature of workload changes and integrates system state insights to enhance prediction accuracy. Our empirical analysis, using three distinct real-world datasets, establishes that STAMP exceeds baselines by achieving an average boost of 5.72\% in prediction precision, as measured by RMSE. Upon deployment in Alipay's microservice environment, STAMP achieves a 33.10\% reduction in resource consumption, significantly outperforming existing online methods. This research solidifies STAMP as a validated framework, offering meaningful contributions to the field of resource management in microservice architecture-based applications.",10.1145/3637528.3671508,2024,,ACM
BigST: Linear Complexity Spatio-Temporal Graph Neural Network for Traffic Forecasting on Large-Scale Road Networks,"Spatio-Temporal Graph Neural Network (STGNN) has been used as a common workhorse for traffic forecasting. However, most of them require prohibitive quadratic computational complexity to capture long-range spatio-temporal dependencies, thus hindering their applications to long historical sequences on large-scale road networks in the real-world. To this end, in this paper, we propose BigST, a linear complexity spatio-temporal graph neural network, to efficiently exploit long-range spatio-temporal dependencies for large-scale traffic forecasting. Specifically, we first propose a scalable long sequence feature extractor to encode node-wise long-range inputs (e.g., thousands of time-steps in the past week) into low-dimensional representations encompassing rich temporal dynamics. The resulting representations can be pre-computed and hence significantly reduce the computational overhead for prediction. Then, we build a linearized global spatial convolution network to adaptively distill time-varying graph structures, which enables fast runtime message passing along spatial dimensions in linear complexity. We empirically evaluate our model on two large-scale real-world traffic datasets. Extensive experiments demonstrate that BigST can scale to road networks with up to one hundred thousand nodes, while significantly improving prediction accuracy and efficiency compared to state-of-the-art traffic forecasting models.",10.14778/3641204.3641217,2024,,ACM
Hypergraph Neural Networks to Predict Stock Movements By Exploring Higher-order Relationships,"Predicting stock price movements can be framed as a classification task, where the goal is to anticipate whether a stock will increase, decrease, or remain stable. Most existing approaches rely solely on the movement patterns of individual stocks or stock pairs, overlooking the more complex, higher-order connections that exist among groups of stocks. In practice, stocks are often interrelated in higher orders, for example, by belonging to the same industry sector or being jointly held within the same investment fund. To address this, we compare 4 hypergraph neural network-based approaches to make spatio-temporal predictions for stock movement prediction, which explicitly leverages these higher-order dependencies. We use two heterogeneous hypergraphs, where one hypergraph represents sector-based associations and the other one represents fund-holding relationships among stocks. In general, we found the hierarchical hypergraph attention mechanism and temporal attention to be effective in achieving better performance. A hierarchical hypergraph attention mechanism models these relationships by weighting the contributions of stock nodes, hyperedges, and even the hypergraphs themselves. Temporal attention captures time-dependent dynamics of both stock and sector sequences, effectively accounting for the influence of past states. Experiments on real-world datasets demonstrate that the methods specializing in hypergraph integration achieve superior performance compared to existing methods, both in terms of predictive accuracy and profitability.",10.1145/3768292.3770389,2025,,ACM
Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion,"Multimodal Knowledge Graphs (MKGs), which organize visual-text factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all images/objects are relevant to text input, which hinders the applicability to diverse real-world scenarios. In this paper, we propose a hybrid transformer with multi-level fusion to address those issues. Specifically, we leverage a hybrid transformer architecture with unified input-output for diverse multimodal knowledge graph completion tasks. Moreover, we propose multi-level fusion, which integrates visual and text representation via coarse-grained prefix-guided interaction and fine-grained correlation-aware fusion modules. We conduct extensive experiments to validate that our MKGformer can obtain SOTA performance on four datasets of multimodal link prediction, multimodal RE, and multimodal NER1. https://github.com/zjunlp/MKGformer.",10.1145/3477495.3531992,2022,,ACM
Relation-aware Meta-learning for E-commerce Market Segment Demand Prediction with Limited Records,"E-commerce business is revolutionizing our shopping experiences by providing convenient and straightforward services. One of the most fundamental problems is how to balance the demand and supply in market segments to build an efficient platform. While conventional machine learning models have achieved great success on data-sufficient segments, it may fail in a large-portion of segments in E-commerce platforms, where there are not sufficient records to learn well-trained models. In this paper, we tackle this problem in the context of market segment demand prediction. The goal is to facilitate the learning process in the target segments by leveraging the learned knowledge from data-sufficient source segments. Specifically, we propose a novel algorithm, RMLDP, to incorporate a multi-pattern fusion network (MPFN) with a meta-learning paradigm. The multi-pattern fusion network considers both local and seasonal temporal patterns for segment demand prediction. In the meta-learning paradigm, transferable knowledge is regarded as the model parameter initialization of MPFN, which are learned from diverse source segments. Furthermore, we capture the segment relations by combining data-driven segment representation and segment knowledge graph representation and tailor the segment-specific relations to customize transferable model parameter initialization. Thus, even with limited data, the target segment can quickly find the most relevant transferred knowledge and adapt to the optimal parameters. We conduct extensive experiments on two large-scale industrial datasets. The results justify that our RMLDP outperforms a set of state-of-the-art baselines. Besides, RMLDP has been deployed in Taobao, a real-world E-commerce platform. The online A/B testing results further demonstrate the practicality of RMLDP.",10.1145/3437963.3441750,2021,,ACM
Jointly Modeling Spatio–Temporal Dependencies and Daily Flow Correlations for Crowd Flow Prediction,"Crowd flow prediction is a vital problem for an intelligent transportation system construction in a smart city. It plays a crucial role in traffic management and behavioral analysis, thus it has raised great attention from many researchers. However, predicting crowd flows timely and accurately is a challenging task that is affected by many complex factors such as the dependencies of adjacent regions or recent crowd flows. Existing models mainly focus on capturing such dependencies in spatial or temporal domains and fail to model relations between crowd flows of distant regions. We notice that each region has a relatively fixed daily flow and some regions (even very far away from each other) may share similar flow patterns which show strong correlations among them. In this article, we propose a novel model named Double-Encoder which follows a general encoder–decoder framework for multi-step citywide crowd flow prediction. The model consists of two encoder modules named ST-Encoder and FR-Encoder to model spatial-temporal dependencies and daily flow correlations, respectively. We conduct extensive experiments on two real-world datasets to evaluate the performance of the proposed model and show that our model consistently outperforms state-of-the-art methods.",10.1145/3439346,2021,,ACM
MulSTE: A Multi-view Spatio-temporal Learning Framework with Heterogeneous Event Fusion for Demand-supply Prediction,"Recently, integrated warehouse and distribution logistics systems are widely used in E-commerce industries to adjust to constantly changing customer demands. It makes the prediction of purchase demand and delivery supply capacity a crucial problem to streamline operations and improve efficiency. The interaction between such demand and supply not only relies on their economic relationships but also on consumer psychology caused by daily events, such as epidemics, promotions, and festivals. Although existing studies have made great efforts in the joint prediction of demand and supply considering modeling the demand-supply interactions, they seldom refer to the impacts of diverse events. In this work, we propose MulSTE, a Multi-view Spatio-Temporal learning framework with heterogeneous Event fusion. Firstly, an Event Fusion Representation (EFR) module is designed to fuse the textual, numerical, and categorical heterogeneous information for emergent and periodic events. Secondly, a Multi-graph Adaptive Convolution Recurrent Network (MGACRN) is developed as the spatio-temporal encoder (ST-Encoder) to capture the evolutional features of demand, supply, and events. Thirdly, the Event Gated Demand-Supply Interaction Attention (EGIA) module is designed to model the demand-supply interactions during events. The evaluations are conducted on two real-world datasets collected from JD Logistics and public websites. The experimental results show that our method outperforms state-of-the-art baselines in various metrics.",10.1145/3637528.3672030,2024,,ACM
Spatiotemporal disease case prediction using contrastive predictive coding,"Time series prediction models have played a vital role in guiding effective policymaking and response during the COVID-19 pandemic by predicting future cases and deaths at the country, state, and county levels. However, for emerging diseases, there is not sufficient historic data to fit traditional supervised prediction models. In addition, such models do not consider human mobility between regions. To mitigate the need for supervised models and to include human mobility data in the prediction, we propose Spatial Probabilistic Contrastive Predictive Coding (SP-CPC) which leverages Contrastive Predictive Coding (CPC), an unsupervised time-series representation learning approach. We augment CPC to incorporate a covariate mobility matrix into the loss function, representing the relative number of individuals traveling between each county on a given day. The proposal distribution learned by the algorithm is then sampled by the Metropolis-Hastings algorithm to give a final prediction of the number of COVID-19 cases. We find that the model applied to COVID-19 data can make accurate short-term predictions, more accurate than ARIMA and simple time-series extrapolation methods, one day into the future. However, for longer-term prediction windows of seven or more days into the future, we find that our predictions are not as competitive and require future research.",10.1145/3557995.3566122,2022,,ACM
Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting,"Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the predicted time series in terms of both the temporal trending and the complex spatial-temporal dependencies. Compared with traditional approaches that handle step-wise predictive errors independently, our approach can produce more realistic and robust forecasts. Experiments on six benchmark traffic forecasting datasets and theoretical analysis both demonstrate the superiority and the state-of-the-art performance of TrendGCN. Source code is available at https://github.com/juyongjiang/TrendGCN.",10.1145/3583780.3614868,2023,,ACM
Bloom-LLM: Privacy-Preserving Large Language Model for Load Forecasting,"Accurate energy load forecasting is essential for optimising power systems across buildings, cities, and smart grids. Recently, large language models (LLMs) have shown remarkable capability in capturing complex temporal patterns in energy consumption data, outperforming both traditional and deep learning techniques. However, their reliance on detailed smart meter (SM) data poses significant privacy risks, as such fine-grained information is susceptible to inference attacks. To overcome these challenges, we introduce Privacy-Preserving Time-LLM, an innovative forecasting framework that combines LLM architectures with SM data encoded via Differentially Private Bloom Filters (DP-BF). This encoding safe-guards sensitive consumption data while preserving high predictive performance. Designed for secure cloud deployment, the framework reduces privacy risks associated with honest-but-curious service providers. It employs Low-Rank Adaptation (LoRA) for efficient fine-tuning and utilises Rotary Position Embedding (RoPE) to model temporal dependencies without accessing raw time-series inputs. We benchmark our approach against the widely used differentially private training method DP-SGD. Experimental results demonstrate that the Time-LLM trained on DP-BF-Encoded SM data consistently outperforms its DP-SGD counterpart, reducing forecasting error by approximately 29\% on average, highlighting an improved balance between privacy and utility. Compared to a state-of-the-art CNN baseline, our method achieves nearly 52\% better forecasting accuracy on DP-BF-Encoded data while maintaining up to 99\% membership privacy. Moreover, under adversarial attacks, models trained with DP-BF-Encoding show over 80\% reduced vulnerability relative to models trained on raw data, significantly enhancing robustness and stability. To the best of our knowledge, this is the first differentially private LLM-based framework for energy load forecasting using DP-BF-Encoding. It opens new possibilities for privacy-preserving analytics in smart grid environments, with extensibility to other time-series applications such as occupancy detection and demand disaggregation.",10.1145/3736425.3770103,2025,,ACM
Generative Imputation with Multi-level Causal Consistency for Variable Subset Forecasting,"Variable Subset Forecasting (VSF) poses critical challenges in time series analysis when entire variables become unavailable during inference. Existing imputation methods relying on inter-variable correlations fail catastrophically in VSF due to two inherent limitations: (1) Missing variable collapse, where the complete absence of certain variables invalidates correlation-based dependency learning, and (2) Temporal covariate shift, where time-evolving data distributions destabilize correlation patterns learned from training data. To address these fundamental issues, we propose Generative Imputation with Multi-level Causal Consistency (GIMCC ), establishing causality-driven imputation as the first principled solution for VSF. Our key innovation lies in enforcing causal invariance through dual consistency constraints: global causal isomorphism ensures the imputed variables preserve the ground-truth causal graph structure of the complete system, while local causal subgraph alignment maintains consistency between observed variables and their causal neighborhood dependencies. By decoupling causality from spurious correlations, GIMCC provides time-invariant imputation signals robust to distribution shifts, which explicitly preserves causal relationships via multivariate spectral convolutions. Extensive experiments across five real-world domains demonstrate that GIMCC achieves average improvements of 20-60\% in MAE/RMSE over correlation-based imputation baselines, remarkably outperforming full-variable training ( Oracle ) in temporal covariate shift scenarios. Our work bridges the critical gap between causal analysis and practical forecasting systems under variable absence, offering theoretically grounded guarantees for real-world deployment.",10.1145/3711896.3736980,2025,,ACM
NRFormer: Nationwide Nuclear Radiation Forecasting with Spatio-Temporal Transformer,"Nuclear radiation, which refers to the energy emitted from atomic nuclei during decay, poses significant risks to human health and environmental safety. Recently, advancements in monitoring technology have facilitated the effective recording of nuclear radiation levels and related factors, such as weather conditions. The abundance of monitoring data enables the development of accurate and reliable nuclear radiation forecasting models, which play a crucial role in informing decision-making for individuals and governments. However, this task is challenging due to the imbalanced distribution of monitoring stations over a wide spatial range and the non-stationary radiation variation patterns. In this study, we introduce NRFormer, a novel framework tailored for the nationwide prediction of nuclear radiation variations. By integrating a non-stationary temporal attention module, an imbalance-aware spatial attention module, and a radiation propagation prompting module, NRFormer collectively captures complex spatio-temporal dynamics of nuclear radiation. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed framework against 11 baselines. NRFormer has been deployed online to provide 1-24-day nuclear radiation forecasts, empowering individuals and governments with timely, data-driven decisions for emergency response and public safety. Our framework is designed for general applicability and can be readily adapted for deployment in other regions. The deployed system is available at https://NRFormer.github.io and the dataset and code of the predictive model are available at https://github.com/usail-hkust/NRFormer.",10.1145/3711896.3737252,2025,,ACM
FEDDGCN: A Frequency-Enhanced Decoupling Dynamic Graph Convolutional Network for Traffic Flow Prediction,"As a core task in Intelligent Transportation Systems (ITS), traffic flow prediction is essential for resource allocation and real-time route planning. Effectively capturing complex temporal correlations and dynamic spatial dependencies in traffic flow data is critical yet challenging for accurate prediction. However, existing approaches are still limited by the insufficient capability for spatial-temporal pattern decoupling and the underutilization of frequency domain information. To address these issues, we propose a novel Frequency-Enhanced Dynamic Decoupling Graph Convolutional Network (FEDDGCN), which introduces a gated decoupling mechanism integrating temporal and spatial embeddings to decouple traffic flow into prominent periodic and perturbative component. It also achieves effective pattern separation by incorporating frequency domain analysis with Fourier filters. Furthermore, a dual-branch spatial-temporal learning module, employing a divide-and-conquer strategy, is designed to achieve separate modeling for the two distinct components. Specially, the dynamic graph convolution modules are utilized to learn spatial dependencies and temporal and frequency attention mechanisms further capture complex temporal correlations for prominent periodic and perturbative components.Extensive experiments on multiple real-world datasets demonstrate that FEDDGCN achieves superior predictive performance compared with state-of-the-art methods.",10.1145/3746252.3761048,2025,,ACM
LLM4DyG: Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs?,"In an era marked by the increasing adoption of Large Language Models (LLMs) for various tasks, there is a growing focus on exploring LLMs' capabilities in handling web data, particularly graph data. Dynamic graphs, which capture temporal network evolution patterns, are ubiquitous in real-world web data. Evaluating LLMs' competence in understanding spatial-temporal information on dynamic graphs is essential for their adoption in web applications, which remains unexplored in the literature. In this paper, we bridge the gap via proposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic graphs, to the best of our knowledge, for the first time. Specifically, we propose the LLM4DyG benchmark, which includes nine specially designed tasks considering the capability evaluation of LLMs from both temporal and spatial dimensions. Then, we conduct extensive experiments to analyze the impacts of different data generators, data statistics, prompting techniques, and LLMs on the model performance. Finally, we propose Disentangled Spatial-Temporal Thoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal understanding abilities. Our main observations are: 1) LLMs have preliminary spatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph tasks show increasing difficulties for LLMs as the graph size and density increase, while not sensitive to the time span and data generation mechanism, 3) the proposed DST2 prompting method can help to improve LLMs' spatial-temporal understanding abilities on dynamic graphs for most tasks. The data and codes are publicly available at Github.",10.1145/3637528.3671709,2024,,ACM
Bi-Modal Learning for Networked Time Series,"Understanding human mobility patterns is a complex challenge that requires modeling both node-oriented time series (e.g., population) and edge-oriented time series (e.g., population flows) within graph topologies across time. While previous methods have focused on either node-oriented time series or interactions, the synergistic integration of these two modalities has proven difficult to achieve. In this paper, we propose BINTS (BI-modal learning for Networked Time Series), a novel bi-modal learning framework that employs soft contrastive learning along the temporal axis. BINTS captures modality similarities and temporal patterns by simultaneously learning from evolving node-oriented time series and interactions, solving the limitations of single-modality approaches. To evaluate our method, we curate comprehensive multi-modal human mobility datasets spanning diverse locations and times. Our experimental results demonstrate that BINTS significantly outperforms existing forecasting models by capturing synergies across different data modalities. Overall, we establish BINTS as a powerful technique for holistically understanding and forecasting complex mobility dynamics. For reproducibility, the source code of our framework is available at https://github.com/kaist-dmlab/BINTS.",10.1145/3711896.3736856,2025,,ACM
FinD3: A Dual 3D State Space Model with Dynamic Hypergraph for Financial Stock Prediction,"The financial market plays a crucial role in the modern economy by influencing capital allocation, corporate valuation, and investor behavior. However, its complex dependencies and non-stationary dynamics present significant challenges for financial stock prediction. Previous predictive approaches are typically categorized into Univariate Time Series (UTS) and Multivariate Time Series (MTS) paradigms. UTS methods overlook both cross-feature and cross-stock influences, while MTS methods can only capture one of these simultaneously. Although some recent approaches claim to model 3D Multivariate Time Series (3D-MTS) dependencies, they often discard substantial information and fail to capture the dynamics of the stock market. To address these limitations, we propose FinD3, a Financial 3D model using Dual cubic state spaces and Dynamic hypergraphs. To extract the inherent complex relationships in 3D-MTS, we propose a novel Dual Cubic State Space Model (DCSSM) to capture both cross-feature and cross-stock patterns. Furthermore, to more accurately reflect the dynamics of the stock market, we present an Evolving Hypergraph Attention (EHA) module, which captures dynamic changes in financial markets and updates the hypergraph based on a priori hypergraph. Experimental results demonstrate that FinD3 achieves state-of-the-art performance in quantitative trading performance on two real-world stock market datasets, offering a promising solution to practical quantitative trading challenges. The code is available at: https://github.com/decisionintelligence/FinD3.",10.1145/3746252.3761239,2025,,ACM
Diffusion Graph Model for Time Series Anomaly Detection via Anomaly-aware Graph Sparsification and Augmentation,"Unsupervised methods, particularly reconstruction-based methods have become the dominant approach for multivariate time series anomaly detection (TSAD), which distinguish between normal and abnormal series based on the magnitude of the reconstruction error. However, in this process, the heterophilic connections (normal \l{",10.1145/3701716.3717376,2025,,ACM
TARNet: Task-Aware Reconstruction for Time-Series Transformer,"Time-series data contains temporal order information that can guide representation learning for predictive end tasks (e.g., classification, regression). Recently, there are some attempts to leverage such order information to first pre-train time-series models by reconstructing time-series values of randomly masked time segments, followed by an end-task fine-tuning on the same dataset, demonstrating improved end-task performance. However, this learning paradigm decouples data reconstruction from the end task. We argue that the representations learnt in this way are not informed by the end task and may, therefore, be sub-optimal for the end-task performance. In fact, the importance of different timestamps can vary significantly in different end tasks. We believe that representations learnt by reconstructing important timestamps would be a better strategy for improving end-task performance. In this work, we propose TARNet, Task-Aware Reconstruction Network, a new model using Transformers to learn task-aware data reconstruction that augments end-task performance. Specifically, we design a data-driven masking strategy that uses self-attention score distribution from end-task training to sample timestamps deemed important by the end task. Then, we mask out data at those timestamps and reconstruct them, thereby making the reconstruction task-aware. This reconstruction task is trained alternately with the end task at every epoch, sharing parameters in a single model, allowing the representation learnt through reconstruction to improve end-task performance. Extensive experiments on tens of classification and regression datasets show that TARNet significantly outperforms state-of-the-art baseline models across all evaluation metrics.",10.1145/3534678.3539329,2022,,ACM
Towards Spatio-temporal Sea Surface Temperature Forecasting via Dynamic Personalized Graph Network,"Sea surface temperature (SST) is uniquely important to the Earth’s atmosphere since its dynamics are a major force in shaping local and global climate and profoundly affect our ecosystems. Accurate forecasting of SST brings significant economic and social implications, for example, better preparation for extreme weather such as severe droughts or tropical cyclones months ahead. However, such a task faces unique challenges due to the intrinsic complexity and uncertainty of ocean systems. Recently, deep learning techniques, such as graphical neural networks (GNN), have been applied to address this task. While such techniques achieve certain levels of success, they often have significant limitations in exploring dynamic spatio-temporal dependencies between signals. To solve this problem, this paper proposes a novel graph convolution network architecture with static and dynamic learning layers for SST forecasting. Specifically, two adaptive adjacency matrices are firstly constructed to respectively model the stable long-term and short-term evolutionary patterns hidden in the multivariate SST signals. Then, a personalized convolution layer is designed to fuse these information. The developed network can be learned in an end-to-end manner. Our experiments on real SST datasets demonstrate the state-of-the-art performances of the proposed approach on the forecasting task.",10.1145/3582515.3609561,2023,,ACM
Analyzing Multimodal Sentiment Via Acoustic- and Visual-LSTM With Channel-Aware Temporal Convolution Network,"The emotion of human is always expressed in a multimodal perspective. Analyzing multimodal human sentiment remains challenging due to the difficulties of the interpretation in inter-modality dynamics. Mainstream multimodal learning architectures tend to design various fusion strategies to learn inter-modality interactions, which barely consider the fact that the language modality is far more important than the acoustic and visual modalities. In contrast, we learn inter-modality dynamics in a different perspective via acoustic- and visual-LSTMs where language features play dominant role. Specifically, inside each LSTM variant, a well-designed gating mechanism is introduced to enhance the language representation via the corresponding auxiliary modality. Furthermore, in the unimodal representation learning stage, instead of using RNNs, we introduce ‘channel-aware’ temporal convolution network to extract high-level representations for each modality to explore both temporal and channel-wise interdependencies. Extensive experiments demonstrate that our approach achieves very competitive performance compared to the state-of-the-art methods on three widely-used benchmarks for multimodal sentiment analysis and emotion recognition.",10.1109/taslp.2021.3068598,2021,,ACM
AMFR: Attentive Multi-Frequency Regressor for High-Precision Numerical Prediction in Large Language Models,"Across diverse benchmarks, large language models set new performance standards., but they are still struggling with high-precision numerical prediction tasks, because large language models are not sensitive to high-precision numbers and often have accuracy problems when faced with thousands of digits. To solve this problem, we propose a novel output layer structure, the Attentional Multi-Frequency Regressor (AMFR). Unlike the traditional linear regression head that simply maps hidden states, AMFR first projects the hidden representation into a multi-frequency space and constructs multi-scale frequency features using learnable sine-cosine basis functions; it then adaptively fuses the frequency components through an integrated attention mechanism to generate more refined high-precision numerical predictions. Experimental results show that AMFR significantly reduces the prediction error in high-precision numerical regression tasks such as molecular property prediction and time series prediction, effectively capturing important information at different frequencies. Our work provides an effective way to improve the performance of large language models in numerical reasoning tasks.",10.1145/3768184.3768253,2025,,ACM
Transformer-Based Financial Fraud Detection with Cloud-Optimized Real-Time Streaming,"As the financial industry becomes more interconnected and reliant on digital systems, fraud detection systems must evolve to meet growing threats. Cloud-enabled Transformer models present a transformative opportunity to address these challenges. By leveraging the scalability, flexibility, and advanced AI capabilities of cloud platforms, companies can deploy fraud detection solutions that adapt to real-time data patterns and proactively respond to evolving threats. Using the Graph self-attention Transformer neural network module, we can directly excavate gang fraud features from the transaction network without constructing complicated feature engineering. Finally, the fraud prediction network is combined to optimize the topological pattern and the temporal transaction pattern to realize the high-precision detection of fraudulent transactions. The results of anti-fraud experiments on credit card transaction data show that the proposed model outperforms the 7 baseline models on all evaluation indicators: In the transaction fraud detection task, the average accuracy (AP) increased by 20\% and the area under the ROC curve (AUC) increased by 2.7\% on average compared with the benchmark graph attention neural network (GAT), which verified the effectiveness of the proposed model in the detection of credit card fraud transactions.",10.1145/3724154.3724271,2025,,ACM
LLM4HAR: Generalizable On-device Human Activity Recognition with Pretrained LLMs,"A long-standing challenge for pushing sensor-based human activity recognition (HAR) to industrial usage is the distribution shift between training data and testing data: significant variations in data distribution lead to a notable decline in performance. Recently, Large Language Models (LLMs) have demonstrated exceptional generalization capability, which provides a new opportunity to mitigate the distribution shift problem of HAR. However, since LLMs are inherently designed and trained on textual data, their potential to enhance generalization in HAR applications remains an open question. In this paper, we introduce LLM4HAR, a novel LLM-based model to improve cross-domain HAR. LLM4HAR consists of three main modules: (i) the Sensor Data Adaptation module, which aligns IMU signals with LLMs via sensor embedding(ii) the Sensor Knowledge Learning module, which injects sensor knowledge into LLMs for activity recognition, and (iii) the Efficiency Enhancement module, which employs a partial training strategy and reduces the model size by more than 10 times. Extensive evaluations show that LLM4HAR outperforms the existing methods by 13.82\% in average F1 score, demonstrating the feasibility and effectiveness of transferring knowledge from pretrained LLMs to enhance HAR. Further, LLM4HAR has been adopted by JD Logistics to support downstream applications such as Courier Welfare Improvement and Map Data Generation.",10.1145/3711896.3737226,2025,,ACM
D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams,"Large quantities of social activity data, such as weekly web search volumes and the number of new infections with infectious diseases, reflect peoples' interests and activities. It is important to discover temporal patterns from such data and to forecast future activities accurately. However, modeling and forecasting social activity data streams is difficult because they are high-dimensional and composed of multiple time-varying dynamics such as trends, seasonality, and interest diffusion. In this paper, we propose D-Tracker, a method for continuously capturing time-varying temporal patterns within social activity tensor data streams and forecasting future activities. Our proposed method has the following properties: (a) Interpretable: it incorporates the partial differential equation into a tensor decomposition framework and captures time-varying temporal patterns such as trends, seasonality, and interest diffusion between locations in an interpretable manner; (b) Automatic: it has no hyperparameters and continuously models tensor data streams fully automatically; (c) Scalable: the computation time of D-Tracker is independent of the time series length. Experiments using web search volume data obtained from GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data Repository show that our method can achieve higher forecasting accuracy in less computation time than existing methods while extracting the interest diffusion between locations. Our source code and datasets are available at https://github.com/Higashiguchi-Shingo/D-Tracker.",10.1145/3690624.3709192,2025,,ACM
SSD-TS: Exploring the Potential of Linear State Space Models for Diffusion Models in Time Series Imputation,"Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability for uncertainty estimation and denoising diffusion probabilistic models (DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1) The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity. 2) The architecture of denoising modules can not handle the dependencies in the time series data effectively. To address the first challenge, we explore the potential of state space model, namely Mamba, as the backbone denoising module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for time series data modeling. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple real-world datasets. Our datasets and code are available at https://github.com/decisionintelligence/SSD-TS/",10.1145/3711896.3737135,2025,,ACM
CE-FCM: Convolution-Enhanced Fuzzy Cognitive Map for Multivariate Time Series Prediction,"In the realm of time series tasks, fuzzy cognitive maps (FCMs) have demonstrated their potency as a robust model for predicting system states and representing knowledge in an interpretable manner. Recent research efforts have been directed towards enriching the core FCM framework by integrating features like temporal aspects, uncertainty, or fuzzy rules to improve interpretability. Moreover, attempts have been made to integrate fuzzy neural networks or wavelets to enhance the accuracy of time series predictions. However, striking a balance between precision and interpretability in predictions across diverse domains remains a significant challenge. To address the need for capturing spatial relationships between nodes, we introduce graph convolutional networks for predicting multivariate time series. In this work, we propose an innovative extension of FCM, termed fuzzy cognitive map enhanced by deep graph convolution (CE-FCM), and validate its efficacy across four publicly available datasets. Our findings affirm that CE-FCM furnishes pivotal insights for constructing interpretable predictors, thereby offering valuable utility for real-world applications.",10.1145/3679409.3679427,2024,,ACM
Traffic Flow Prediction Using Spatio-Temporal Graph Neural Networks Based on Hybrid Adaptive Feature Enhancement,"Aiming at the poor adaptation of most current models to dynamic maps and the difficulty in capturing long-term spatio-temporally relevant features, this paper proposes a hybrid adaptive feature-enhanced graph neural network (HAFEGNN) model. To address these challenges, we propose a new approach based on graph neural networks that integrates multiple state-of-the-art enhancement feature representation mechanisms. The model enhances the representation of dynamic spatio-temporal features by integrating multi-scale convolution, channel self-attention and spatial self-attention mechanisms. On top of that, temporal self-attention mechanism is also introduced to focus on learning long-term dependencies, which leads to better understanding of patterns in historical data and making more accurate predictions. The model further incorporates Dynamic Graph Convolutional Recurrent Network (DGCRN) to capture spatio-temporal dynamics. To enhance the adaptability to dynamic graph structures, it integrates spatial location embedding with graph attention mechanisms to form a spatially aware module, which improves the prediction accuracy. Our experimental evaluation on the widely used PeMS04 and PeMS08 datasets demonstrates the effectiveness of the proposed HAFEGNN. The model achieves significant improvements in key metrics such as MAE, RMSE, and MAPE, outperforming existing state-of-the-art methods and validating its ability to handle complex traffic data. This study provides a new solution for traffic flow prediction and demonstrates its potential in handling complex traffic data.",10.1145/3747227.3747240,2025,,ACM
LENS: Large Pre-trained Transformer for Exploring Financial Time Series Regularities,"Modeling large-scale time series has gained significant attention in recent years. However, its direct application in finance remains challenging due to substantial differences in data characteristics across domains. Specifically, financial systems feature inherent stochasticity and low signal-to-noise ratios, rendering traditional methods and pre-training approaches ineffective. This underscores the urgent need for a foundation model tailored to financial time series. To bridge this gap, we propose LENS, a pre-trained model for this domain. LENS effectively captures the complexity of financial stochastic systems through a carefully crafted model architecture and mitigates noise during pre-training by using an invertible embedding module. We provide a rigorous theoretical explanation of the model’s effectiveness and validate its performance through extensive experiments. Pre-trained on a dataset comprising 100 billion financial observations, LENS achieves exceptional results across a wide range of critical downstream tasks. Moreover, our work offers practical insights into developing pre-trained time series models in high-noise environments, paving the way for further advancements in this pivotal research domain.",10.1145/3768292.3770349,2025,,ACM
Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback,"In microservice systems, the identification of root causes of anomalies is imperative for service reliability and business impact. This process is typically divided into two phases: (i)constructing a service dependency graph that outlines the sequence and structure of system components that are invoked, and (ii) localizing the root cause components using the graph, traces, logs, and Key Performance Indicators (KPIs) such as latency. However, both phases are not straightforward due to the highly dynamic and complex nature of the system, particularly in large-scale commercial architectures like Microsoft Exchange.In this paper, we propose a new framework that employs Hierarchical Reinforcement Learning from Human Feedback (HRLHF) to address these challenges. Our framework leverages the static topology of the microservice system and efficiently employs the feedback of engineers to reduce uncertainty in the discovery of the service dependency graph. The framework utilizes reinforcement learning to reduce the number of queries required from O(N2) to O(1), enabling the construction of the dependency graph with high accuracy and minimal human effort. Additionally, we extend the discovered dependency graphs to window causal graphs that capture the characteristics of time series over a specified time period, resulting in improved root cause analysis accuracy and robustness. Evaluations on both real datasets from Microsoft Exchange and synthetic datasets with injected anomalies demonstrate superior performance on various metrics compared to state-of-the-art methods. It is worth mentioning that, our framework has been integrated as a crucial component in Microsoft M365 Exchange service.",10.1145/3580305.3599934,2023,,ACM
HDM-GNN: A Heterogeneous Dynamic Multi-view Graph Neural Network for Crime Prediction,"Smart cities have drawn a lot of interest in recent years, which employ Internet of Things (IoT)-enabled sensors to gather data from various sources and help enhance the quality of residents’ life in multiple areas, e.g. public safety. Accurate crime prediction is significant for public safety promotion. However, the complicated spatial-temporal dependencies make the task challenging, due to two aspects: 1) spatial dependency of crime includes correlations with spatially adjacent regions and underlying correlations with distant regions, e.g. mobility connectivity and functional similarity; 2) there are near-repeat and long-range temporal correlations between crime occurrences across time. Most existing studies fall short in tackling with multi-view correlations, since they usually treat them equally without consideration of different weights for these correlations. In this paper, we propose a novel model for region-level crime prediction named as Heterogeneous Dynamic Multi-view Graph Neural Network (HDM-GNN). The model can represent the dynamic spatial-temporal dependencies of crime with heterogeneous urban data, and fuse various types of region-wise correlations from multiple views. Global spatial dependencies and long-range temporal dependencies can be derived by integrating the multiple GAT modules and Gated CNN modules. Extensive experiments are conducted to evaluate the effectiveness of our method using several real-world datasets. Results demonstrate that our method outperforms state-of-the-art baselines. All the code are available at https://github.com/ZJUDataIntelligence/HDM-GNN.",10.1145/3665141,2024,,ACM
The 10th ACM SIGSPATIAL International Workshop on Analytics for Big Spatial Data (BigSpatial 2022),"Analysis and management of big data are important areas of research for data researchers and scientists. Both the industry and governmental agencies have invested tremendous resources and effort in the area of big data analysis and management in the past decade. Within the realm of big data, spatial and spatio-temporal data are still one of the fastest-growing types of data. With advances in remote sensors, sensor networks, and the proliferation of location sensing devices in daily life activities and common business practices, the generation of disparate, dynamic, and geographically distributed spatiotemporal data has continued to explode in recent years. In addition, significant progress in ground, air, and space-borne sensor technologies has led to unprecedented access to earth science data for scientists from different disciplines. For example, NASA recently collected its 10 millionth Landsat image [4] and the volume of satellite imagery being collected has reached the petabyte scale. Analysis of this large-scale data poses new challenges to researchers.",10.1145/3632268.3632281,2023,,ACM
LSTM-Copula Hybrid Approach for Forecasting Risk in Multi-Asset Portfolios,"This study proposes a multi-asset portfolio risk prediction model that integrates Long Short-Term Memory (LSTM) networks with Copula functions. The model is designed to capture both the temporal dynamics of financial asset returns and the nonlinear dependencies among assets. LSTM is used to model the marginal distributions of individual asset return series. Copula functions are employed to describe the joint distribution structure across multiple assets. This allows for accurate prediction of key portfolio risk metrics such as Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR). In the experimental design, several baseline models are constructed for performance comparison. Further analyses are conducted to assess the model's risk prediction ability under varying numbers of assets and to evaluate risk coverage across different confidence intervals. The experimental results show that the proposed LSTM-Copula model outperforms mainstream methods across multiple evaluation metrics. It demonstrates higher robustness and predictive accuracy, particularly in high-dimensional and sparse data settings. This approach offers a novel path for financial risk management by combining statistical modeling with deep learning. It provides strong empirical results and holds substantial practical value for applications in complex financial environments.",10.1145/3746972.3746978,2025,,ACM
DETECTive: Machine Learning-driven Automatic Test Pattern Prediction for Faults in Digital Circuits,"Due to the continuous technology scaling and the ever-increasing complexity and size of the hardware designs, manufacturing defects have become a key obstacle in meeting end-user demand. Despite decades of research, traditional test-generation techniques often struggle to scale to massive and complex designs. Such scalability issues stem from the numerous backtracking the traditional test generation techniques perform before converging to a test pattern. In this work, we present DETECTive that leverages deep learning on graphs to learn fault characteristics and predict test pattern(s) to expose faults without requiring backtracking. DETECTive is trained on small circuits, and its learned knowledge is transferable to predict test patterns for circuits that contain up to 29 \texttimes{",10.1145/3649476.3658696,2024,,ACM
WHEN: A Wavelet-DTW Hybrid Attention Network for Heterogeneous Time Series Analysis,"Given its broad applications, time series analysis has gained substantial research attention but remains a very challenging task. Recent years have witnessed the great success of deep learning methods, eg., CNN and RNN, in time series classification and forecasting, but heterogeneity as the very nature of time series has not yet been addressed adequately and remains the performance ",10.1145/3580305.3599549,2023,,ACM
SolarMAE: A Unified framework for Regional Centralized and Distributed Solar Power Forecasting with Weather Pre-training,"The recent surge in solar plant installations has notably decreased the reliance on fossil fuels while also presenting significant challenges to power grid. Therefore, the accurate forecasting of centralized and distributed solar power has become critically important. Although site-specific forecasting models typically perform better for utility-scale solar power plants, the model maintenance can be troublesome as the number of solar plants grows. Furthermore, the rapid growth and difficulties in real-time data collection associated with distributed solar systems exacerbate the complexity of regional gross solar power forecasting. To address these issues, we propose SolarMAE, a unified regional solar power forecasting framework enabling end-to-end precise forecasting for both centralized and distributed solar systems. It adopts masked autoencoder (MAE) pre-training strategy for numerical weather prediction (NWP) reconstruction at first, aiming to derive spatiotemporal correlations within meteorological variables, and then fine-tunes a temporal convolutional neural network which predicts future solar power generation. Experiments show that this framework outperforms state-of-the-art centralized or distributed solar power forecasting methods in accuracy, and significantly reduces model maintenance cost. It also demonstrates strong few-shot learning capabilities, which is particularly useful for the cold start problem of newly installed solar plants. The unified solar power forecasting system has been deployed in a province in eastern China, serving solar systems with over 73 GW gross installed capacity and more than 400 centralized solar plants.",10.1145/3746252.3761543,2025,,ACM
Transformer-Based Risk Monitoring for Anti-Money Laundering with Transaction Graph Integration,"This study addresses the growing complexity of transaction behaviors and the highly concealed nature of money laundering paths in current financial AML scenarios. It proposes a Transformer-based risk monitoring model for anti-money laundering. The approach is grounded in transaction sequence modeling and integrates the structural information of transaction graphs. A context-aware classifier is introduced to enable accurate identification and risk scoring of high-risk accounts. The model first applies feature embedding and positional encoding to each transaction. It then uses multiple Transformer layers to capture long-range behavioral dependencies. At the same time, it incorporates account interaction information from the graph structure. This enhances the model's ability to detect abnormal transaction chains across accounts. At the output stage, a classifier that fuses sequential semantics with graph context is used to determine the overall money laundering risk of each account. Multiple experiments were conducted on the publicly available Elliptic dataset. Results show that the proposed method outperforms existing mainstream models on evaluation metrics such as AUC, F1-Score, and Accuracy. It also demonstrates stronger discriminative power and greater stability in identifying high-risk accounts. Further analysis of model depth sensitivity and case-based verification supports the model's effectiveness in real-world complex transaction environments. The proposed method offers a more adaptable technical solution for financial institutions dealing with large-scale suspicious behavior detection tasks.",10.1145/3762249.3762309,2025,,ACM
DPP: A Dual-Phase Processing Method for Cross-Cultural Humor Detection,"Multimodal humor detection has become an active research area in the field of artificial intelligence. This paper presents the solution for the MuSe-Humor sub-challenge of cross-cultural humor detection. The goal of the MuSe-Humor sub-challenge is to predict whether humor exists in a given dataset, which includes data from various modalities such as text, audio, and video. The training data consists of German recordings and their transcriptions, while the test data is in English. This cross-cultural testing introduces new challenges, distinguishing it from ordinary multimodal humor detection tasks. To address this issue, we propose a method called Dual-Phase Processing (DPP). The proposed method first preprocesses the text data using a large language model to extract more effective features for humor detection from the raw data. It also partially addresses cross-cultural differences through bilingual annotation. Finally, by applying composite temporal smoothing to the results after decision-level fusion of the three modalities, the accuracy of humor prediction is greatly improved. The experimental results on the official test set demonstrate the effectiveness of our model. Our model achieves an impressive AUC score of 0.9366 on the test set, far surpassing the baseline and securing the first-place ranking.",10.1145/3689062.3689080,2024,,ACM
A Cross Domain Method for Customer Lifetime Value Prediction in Supply Chain Platform,"Accurate customer LifeTime Value (LTV) predictions are crucial for customer relationship management, especially in Supply Chain Platforms (SCP), which involve effectively managing the service resources in business decision-making. Previous LTV prediction methods usually rely on ample historical customer data, which is not available in the early stages of a customer's lifecycle. It makes the modeling of the historical customer data a difficult task due to the data sparsity. Besides, the long-tail distribution of customer LTV also brings new challenges to the prediction of LTV. To tackle the above issues, we propose CDLtvS, a novel Cross Domain method for customer Lifetime value prediction in SCP. It leverages rich cross-domain information from upstream platforms to enhance LTV predictions in downstream platforms. Firstly, CDLtvS pre-trains the customer representations by an LTV modeling framework named LtvS in source and target domains separately. Specifically, LtvS incorporates the Expert Mask Network (ExMN), which not only effectively models the long-tail distribution of LTV in single-domain but also resolves cross-domain learning model bias resulting from this distribution. Then, the various-level alignment mechanism is introduced to keep the consistency of knowledge transferring from source to target domains on both sparse and non-sparse data. Comprehensive experiments on real-world data from JD, one of the world's largest supply chain platforms, demonstrate that CDLtvS achieves a normalized mean average error of 0.3378 in LTV prediction, outperforming 16.3\% to the baseline. Additionally, the improvements of ≥2.3\% across various data sparsity levels (0\% -- 80\%) provide valuable insights into cross-domain LTV modeling.",10.1145/3589334.3645391,2024,,ACM
Disentangled Dynamic Graph Attention Network for Out-of-Distribution Sequential Recommendation,"Sequential recommendation, leveraging user-item interaction histories to provide personalized and timely suggestions, has drawn significant research interest recently. With the power of exploiting spatio-temporal dynamics, Dynamic Graph Neural Networks (DyGNNs) show great potential in sequential recommendation by modeling the dynamic relationship between users and items. However, spatio-temporal distribution shifts naturally exist in out-of-distribution sequential recommendation, where both user-item relationships and temporal sequences demonstrate pattern shifts. The out-of-distribution scenarios may lead to the failure of existing DyGNNs in handling spatio-temporal distribution shifts in sequential recommendation, given that the patterns they exploit tend to be variant w.r.t labels under distribution shifts. In this article, we propose Disentangled Intervention-based Dynamic graph Attention networks with Invariance Promotion (I-DIDA) to handle spatio-temporal distribution shifts in sequential recommendation by discovering and utilizing invariant patterns, i.e., structures and features whose predictive abilities are stable across distribution shifts. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns. By utilizing the disentangled patterns, we design a spatio-temporal intervention mechanism to create multiple interventional distributions and an environment inference module to infer the latent spatio-temporal environments, and minimize the invariance loss to leverage the invariant patterns with stable predictive abilities under distribution shifts. Extensive experiments demonstrate the superiority of our method over state-of-the-art sequential recommendation baselines under distribution shifts.",10.1145/3701988,2024,,ACM
Synthesizing Multimodal Electronic Health Records via Predictive Diffusion Models,"Synthesizing electronic health records (EHR) data has become a preferred strategy to address data scarcity, improve data quality, and model fairness in healthcare. However, existing approaches for EHR data generation predominantly rely on state-of-the-art generative techniques like generative adversarial networks, variational autoencoders, and language models. These methods typically replicate input visits, resulting in inadequate modeling of temporal dependencies between visits and overlooking the generation of time information, a crucial element in EHR data. Moreover, their ability to learn visit representations is limited due to simple linear mapping functions, thus compromising generation quality. To address these limitations, we propose a novel EHR data generation model called EHRPD. It is a diffusion-based model designed to predict the next visit based on the current one while also incorporating time interval estimation. To enhance generation quality and diversity, we introduce a novel time-aware visit embedding module and a pioneering predictive denoising diffusion probabilistic model (P-DDPM). Additionally, we devise a predictive U-Net (PU-Net) to optimize P-DDPM. We conduct experiments on two public datasets and evaluate EHRPD from fidelity, privacy, and utility perspectives. The experimental results demonstrate the efficacy and utility of the proposed EHRPD in addressing the aforementioned limitations and advancing EHR data generation.",10.1145/3637528.3671836,2024,,ACM
Enhancing Spatial-Temporal Prediction Models with Dynamic Causal Graphs,"Spatial-temporal prediction has become an important task in many applications, such as traffic forecasting. Due to the spatial-temporal nature of data, most state-of-the-art methods heavily depend on graph neural networks to model the inherent spatial relationships. However, most of them process the spatial data by applying the prior adjacency knowledge or learning a static adaptive adjacency matrix. Thus, their prediction performance is limited on dynamic situations where the spatial dependencies change w.r.t time. Furthermore, considering the stochastic training process, learning an adaptive adjacency matrix from scratch also makes it difficult for the neural network to achieve stable parameters and performance. To address the above challenges, this paper proposes three practical extensions that incorporate dynamic causal knowledge into the training of graph convolution networks. We first analyze the dynamic causal graphs between traffic nodes with one dynamic causal discovery algorithm in each extended model. Subsequently, the spatial module employs dynamic causal graphs to reveal the evolving connections among nodes. Extensive experiments demonstrate that our method has successfully enhanced state-of-the-art traffic forecasting models on two benchmarks.",10.1145/3777547,2025,,ACM
A Survey of Learning-based Method Name Prediction,"The choice of method names significantly influences code comprehension and maintenance, posing a considerable challenge, especially for novice developers. Automating the prediction of appropriate method names based on the method code body has emerged as a promising approach to address this challenge. In recent years, numerous machine/deep learning (ML/DL)-based method name prediction (MNP) techniques have been proposed. However, a systematic review of these techniques is currently lacking, hindering future researchers from understanding the research status, development trends, challenges, and opportunities in this field. To fill this gap, in this paper, we conduct a systematic literature review on learning-based MNP studies. Specifically, we first perform a thorough review of the literature concerning publication venue, publication year, and contribution types. This analysis enables us to discern trends in studies related to MNP. Second, we depict the general workflow of learning-based MNP techniques, which involves three consecutive subprocesses: context extraction, context preprocessing, and context-based prediction. Subsequently, we investigate contemporary techniques/solutions applied in the three subprocesses. Third, we scrutinize the widely used experimental databases, evaluation metrics, and replication packages utilized in MNP studies. Moreover, we summarize existing empirical studies on MNP to facilitate a quick understanding of their focus and findings for subsequent researchers. Finally, based on a systematic review and summary of existing work, we outline several open challenges and opportunities in MNP that remain to be addressed in future work.",10.1145/3771999,2025,,ACM
Decomposed Attention Segment Recurrent Neural Network for Orbit Prediction,"As the focus of space exploration shifts from national agencies to private companies, the interest in space industry has been steadily increasing. With the increasing number of satellites, the risk of collisions between satellites and space debris has escalated, potentially leading to significant property and human losses. Therefore, accurately modeling the orbit is critical for satellite operations. In this work, we propose the Decomposed Attention Segment Recurrent Neural Network (DASR) model, adding two key components, Multi-Head Attention and Tensor Train Decomposition, to SegRNN for orbit prediction. The DASR model applies Multi-Head Attention before segmenting at input data and before the input of the GRU layers. In addition, Tensor Train (TT) Decomposition is applied to the weight matrices of the Multi-Head Attention in both the encoder and decoder. For evaluation, we use three real-world satellite datasets from the Korea Aerospace Research Institute (KARI), which are currently operating: KOMPSAT-3, KOMPSAT-3A, and KOMPSAT-5 satellites. Our proposed model demonstrates superior performance compared to other SOTA baseline models. We demonstrate that our approach has 94.13\% higher predictive performance than the second-best model in the KOMPSAT-3 dataset, 89.79\% higher in the KOMPSAT-3A dataset, and 76.71\% higher in the KOMPSAT-5 dataset.",10.1145/3637528.3671546,2024,,ACM
GNN Graph Classification for Time Series: A New Perspective on Climate Change Analysis,"The use of Graph Neural Networks (GNNs) in time series analysis represents a rising field of study, particularly in the context of GNN Graph Classification, a technique traditionally applied in disciplines such as biology and chemistry. Our research repurposes GNN Graph Classification for the analysis of time series for climate data, focusing on two distinct methodologies: the city-graph method, which effectively captures static temporal snapshots, and the sliding window graph method, adept at tracking dynamic temporal changes. This innovative application of GNN Graph Classification within time series data enables the uncovering of nuanced data trends. We demonstrate how GNNs can construct meaningful graphs from time series data, showcasing their versatility across different analytical contexts. A key finding is GNNs’ adeptness at adapting to changes in graph structure, which significantly improves outlier detection. This enhances our understanding of climate patterns and suggests broader applications of GNN Graph Classification in analyzing complex data systems beyond traditional time series analysis. Our research seeks to fill a gap in current studies by providing an examination of GNNs in climate change analysis, highlighting the potential of these methods in capturing and interpreting intricate data trends.",10.1145/3674029.3674059,2024,,ACM
Prediction of Impacts of Digital Transformation on Business Performance using LSTM model,"The impacts of digital transformation on the business performance of enterprises are examined using the LSTM models in the present work. Corporate giants like Alibaba, Huawei, and Tencent have, by embracing digital transformation and introducing technological solutions like cloud computing and artificial intelligence (AI), improved their decision-making and business efficiency. To predict the impacts of these digital technologies on business performance, the long short-term memory (LSTM) model provides a solution. In the present work, an LSTM model is employed to predict the business performance of some large enterprises in China and it is revealed that the models achieve a high accuracy in prediction, with an R2 of 0.99 and an accuracy of 97\% for the prediction of Huawei at an embedding size of 40. With a focus on the hyperparameter tuning and dropout rates, we find that increasing the units of the LSTM model can improve the prediction accuracy, but the returns reduce when the units are beyond 150. Our LSTM model provides a practical solution for business performance prediction under the impact of digital transformation.",10.1145/3736426.3736434,2025,,ACM
Loss or Gain: Hierarchical Conditional Information Bottleneck Approach for Incomplete Time Series Classification,"Incomplete time series classification is both practically valuable and challenging as missing values in time series data are prevalent in real-world scenarios. Current approaches suffer from two major limitations. First, they overemphasize the consistency of data reconstruction during missing value imputation while neglecting the task-effectiveness of the imputed results for the classification. Second, they fail to systematically establish a synergistic optimization mechanism between data imputation and feature representation. To address these challenges, we propose a Hierarchical Conditional Information Bottleneck (HCIB) framework, which achieves incomplete time series classification through end-to-end joint optimization. Specifically, at the data imputation level, we re-examine the dual effects of missing data: the loss of critical information (Loss) versus the gain in interference suppression (Gain), elucidating this duality through bias-variance trade-off theory. Building on this analysis, we propose a task-information sufficiency criterion and extend the information bottleneck theory into a task-driven imputation framework by incorporating label information as a conditional constraint. At the feature representation level, we construct a hierarchical information bottleneck architecture to learn compressed yet informative temporal representations from the task-oriented imputed data. Furthermore, we derive the optimizable objective function for HCIB and design specialized neural network architectures for time series. Comprehensive experiments on multivariate and univariate time series datasets across multiple domains consistently demonstrate that the proposed method achieves significant improvements in classification performance compared to SOTA approaches.",10.1145/3711896.3737033,2025,,ACM
Multi-view Self-Supervised Contrastive Learning for Multivariate Time Series,"Learning semantic-rich representations from unlabeled time series data with intricate dynamics is a notable challenge. Traditional contrastive learning techniques predominantly focus on segment-level augmentations through time slicing, a practice that, while valuable, often results in sampling bias and suboptimal performance due to the loss of global context. Furthermore, they typically disregard the vital frequency information to enrich data representations. To this end, we propose a novel self-supervised general-purpose framework called Temporal-Frequency and Contextual Consistency (TFCC). Specifically, this framework first performs two instance-level augmentation families over the entire series to capture nuanced representations alongside critical long-term dependencies. Then, TFCC advances by initiating dual cross-view forecasting tasks between the original series and its augmented counterpart in both time and frequency domains to learn robust representations. Finally, three specially designed consistency modules 'temporal, frequency, and temporal-frequency' aid in further developing discriminative representations on top of the learned robust representations. Extensive experiments on multiple benchmarks demonstrate TFCC's superiority over the state-of-the-art classification and forecasting methods and exhibit exceptional efficiency in semi-supervised and transfer learning scenarios.",10.1145/3664647.3681095,2024,,ACM
Fairness-Aware Graph Neural Networks: A Survey,"Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. We categorize these techniques by whether they focus on improving fairness in the pre-processing, in-processing (during training), or post-processing phases. We discuss how such techniques can be used together whenever appropriate and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics, including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.",10.1145/3649142,2024,,ACM
Decoupling Spatio-Temporal Prediction: When Lightweight Large Models Meet Adaptive Hypergraphs,"Spatio-temporal prediction is a pivotal task with broad applications in traffic management, climate monitoring, energy scheduling, etc. However, existing methodologies often struggle to balance model expressiveness and computational efficiency, especially when scaling to large real-world datasets. To tackle these challenges, we propose STH-SepNet (Spatio-Temporal Hypergraph Separation Networks), a novel framework that decouples temporal and spatial modeling to enhance both efficiency and precision. Therein, the temporal dimension is modeled using lightweight large language models, which effectively capture low-rank temporal dynamics. Concurrently, the spatial dimension is addressed through an adaptive hypergraph neural network, which dynamically constructs hyperedges to model intricate, higher-order interactions. A carefully designed gating mechanism is integrated to seamlessly fuse temporal and spatial representations. By leveraging the fundamental principles of low-rank temporal dynamics and spatial interactions, STH-SepNet offers a pragmatic and scalable solution for spatio-temporal prediction in real-world applications. Extensive experiments on large-scale real-world datasets across multiple benchmarks demonstrate the effectiveness of STH-SepNet in boosting predictive performance while maintaining computational efficiency. This work may provide a promising lightweight framework for spatio-temporal prediction, aiming to reduce computational demands and while enhancing predictive performance. Our code is avaliable at https://github.com/SEU-WENJIA/ST-SepNet-Lightweight-LLMs-Meet-Adaptive-Hypergraphs.",10.1145/3711896.3736904,2025,,ACM
Leveraging LLMs for Semantic Correlation Enhancement in Spatial-temporal Imputation,"Spatial-temporal imputation remains a challenging problem in transportation, environment and healthcare, where the missing value is filled based on spatial, temporal, and cross correlations. Previous research mainly focused on feature-level correlation integration and comprehension with the hand-crafted enhancement strategy. Meanwhile, the recently prevalent large language models (LLMs) provide token-level understanding for language linguistics, and whether they could be applied for spatial-temporal correlation enhancement is under exploration. To this end, we proposed an LLM-native framework STOMA to fully utilize the intrinsic relevance. We designed semantic enhancing methods by converting the complex correlations, e.g. spatial correlation in network, temporal correlation with periodicity and cross correlation from human behavior, into the embedded tokens. Specifically, we reform dynamic time warping as an asymmetric correlation constructor for complex dynamics. We adapt the proposed backbone along with the spatial-temporal fine-tuning technique, and the empirical results demonstrate the effectiveness of our methods over recent LLM-inspired methods evaluating on real-world datasets.",10.1145/3776557,2025,,ACM
Generalizable Recommender System During Temporal Popularity Distribution Shifts,"Many modern recommender systems represent user and item attributes as embedding vectors, relying on them for accurate recommendations. However, entangled embeddings often capture not only intrinsic property factors (e.g., user interest in item property) but also popularity factors (e.g., user conformity to item popularity) indistinguishably. These embeddings, influenced by popularity distribution, may face challenges when the popularity distribution at test time differs from historical distribution. Existing remedies in the literature involve disentangled embedding learning, which aims to separately capture intrinsic and popularity factors, demonstrating plausible generalization during popularity distribution shifts. However, we highlight that these methods often overlook a crucial aspect of popularity shifts-their temporal nature-in both training and inference phases. To address this, we propose Temporal Popularity distribution shift generalizABle recommender system (TPAB), a novel disentanglement framework incorporating temporal popularity. TPAB introduce a new (1) temporal-aware embedding design for users and items. Within this design, (2) popularity coarsening and (3) popularity bootstrapping are proposed to enhance generalization further. We also provide theoretical analysis showing that the bootstrapping loss eliminates the effect of popularity on the learned model. During inference, we infer test-time popularity and corresponding embeddings, using them alongside property embeddings for prediction. Extensive experiments on real-world datasets validate TPAB, showcasing its outstanding generalization ability during temporal popularity distribution shifts.",10.1145/3690624.3709299,2025,,ACM
Comparative Analysis of Deep Learning-based Anomaly Detection Models for GPS Spoofing Detection,"As autonomous vehicles (AVs) become vital to modern systems, their vulnerability to cyber-attacks, especially GPS spoofing, presents a significant security threat. This study addresses these challenges by applying a suite of machine learning models to enhance the detection of anomalous GPS signals. We concentrate on autoencoder-based architectures, training models like LSTM-VAE, LSTM-AE, MLP-VAE, MLP-AE, Stacked-LSTM-VAE, and Stacked-LSTM-AE exclusively with authentic GPS data. This strategy improves spoofed signal detection by recognizing deviations from normal patterns through reconstruction error analysis. Our comparative analysis highlights the distinct capabilities of these models in distinguishing between authentic and spoofed signals, with the MLP-AE and Stacked-LSTM models showing notable performance differences. The MLP-AE model demonstrated significant detection abilities with an accuracy of 95.40\%, precision of 93.09\%, and ROC-AUC score of 94.35\%. Similarly, Stacked-LSTM models employing deeper learning structures proved highly effective in managing complex noisy data, crucial for high-stakes applications like AV navigation. The results highlight the potential of combining autoencoder models with MLP or Stacked-LSTM to enhance AV security against GPS spoofing, affirming the value of unsupervised learning for anomaly detection.",10.1145/3649601.3698743,2025,,ACM
Attention-Based Multi-Asset Order Flow Networks for Enhanced Mid-Price Prediction,"Financial markets are complex adaptive systems where assets continuously influence each other through dynamic and nonlinear interactions. Accurate mid-price forecasting in high-frequency trading (HFT) depends on capturing these market-wide dynamics. While order flow imbalance (OFI) features have proven more effective than raw limit order book (LOB) data for short-term forecasting, most existing models remain limited to single-asset dynamics, ignoring informative signals from related instruments. We propose OF-MATNet, a deep learning-based multi-asset forecasting framework that leverages OFI data from multiple Nasdaq-listed assets. Our approach captures nonlinear cross-asset dependencies through a Transformer-based architecture with multi-axis attention mechanisms over time, assets, and order book levels, enhanced with positional encoding. Informative peer assets for each target are selected using rolling-window Granger causality tests conducted during the training phase, enabling the model to exploit statistically validated cross-asset influences. Experiments on 110 assets show that OF-MATNet significantly outperforms both our single-asset baseline (OF-SATNet) and state-of-the-art models such as DeepLOB, BINCTABL, and TLOB. OF-MATNet achieves consistent R2 improvements in over 90\% of cases, with larger gains for assets highly influenced by peers or at longer prediction horizons. Further analysis reveals that temporal attention contributes most to forecasting, but cross-asset and level-wise information are critical in enhancing accuracy. These findings underscore the practical value of modeling nonlinear cross-asset relationships for strategic financial decision-making.",10.1145/3768292.3770430,2025,,ACM
Coronary Heart Disease Prediction Technique Based on Self-Attention Mechanism and Contrastive Learning,"Cardiovascular disease remains one of the leading causes of mortality worldwide, with coronary heart disease(CHD) being a predominant form of cardiac pathology. Electrocardiogram (ECG) is widely employed for cardiac disease detection; however, accurate interpretation of ECG signals requires substantial clinical expertise. To address this challenge, this paper proposes a novel approach that combines Butterworth filtering and​continuous wavelet transform (CWT) to extract time-frequency domain features from ECG signals. Subsequently, a self-attention mechanism and contrastive learning framework are utilized to pre-train an ECG time-frequency feature extractor, ultimately enabling the development of a dedicated prediction network for CHD diagnosis. The proposed method is rigorously evaluated using ECG data from the publicly available MIMIC-III dataset. Experimental results demonstrate exceptional performance, achieving 90\% accuracy and 90\% F1-score in CHD prediction, outperforming existing models such as convolutional neural networks (CNNs).",10.1145/3745034.3745131,2025,,ACM
An Ocean Time Series Prediction Framework Based on Improved PSO with Multiscale Learning,"Accurate prediction of marine time series data is of great practical significance for the protection of marine ecosystems and the sustainable utilization of marine resources. Marine time series data, such as those containing marine parameters such as chlorophyll, turbidity, CDOM, etc., are characterized by high complexity and significant time periodicity. In this paper, oriented to the real ocean time series data prediction scenarios, we design an ocean time series prediction framework based on improved PSO and multi-scale learning for the problems of different inter- and intra-series correlations between ocean time series data on different time scales and the need to set the hyper-parameters individually on different datasets. The framework firstly extracts the significant periodicity in ocean time series data by frequency domain analysis technique and decomposes it to multiple time scales. Secondly, an adaptive graph convolutional network is incorporated to allow correlations between sequences to be independently explored and learned at different time scales, while a self-attention mechanism is incorporated to accurately capture correlations and dependencies within the time series. Finally, an adaptive and dynamic particle swarm optimization algorithm (ANDPSO) is proposed, which reduces the risk of the algorithm falling into a local optimal solution and helps the framework to select the key hyperparameters through the dynamic improvement of inertia weights and learning factors as well as the introduction of population diversity judgment mechanism. Experimental results show that the prediction performance of the framework outperforms the baseline model on a real ocean time series dataset, and ablation experiments are conducted to confirm the indispensability of each component, aiming to provide support for real ocean time series prediction scenarios.",10.1145/3705677.3705678,2025,,ACM
Cyber Social Threats: A Data-centric AI Perspective,"With the proliferation of social media platforms, cyber social threats such as fake news, hate speech, and cyberbullying have increased significantly. With the availability of abundant data for building machine learning models, artificial intelligence (AI) is making a deep impact in almost every domain, including detecting and mitigating cyber social threats on social media platforms. As the role of data in AI has significantly intensified in recent years, the concept of data-centric AI has emerged, gradually shifting the research focus from improving model design to enhancing the quality and quantity of data. In this paper, we first present the limitations of model-centric AI in the context of cyber social threats, then discuss the existing literature that uses data-centric AI techniques to detect and mitigate cyber social threats. We finally present the major challenges that social media data presents to deal with cyber social threats using data-centric AI and describe future research opportunities.",10.1145/3696673.3723071,2025,,ACM
TF-MERC: Integrating Time-Frequency Information for Multimodal Emotion Recognition in Conversation,"Multimodal emotion recognition in conversations aims to accurately detect emotions by integrating audio, text, and video modalities, playing an important role in various systems. Existing approaches utilize convolutional and recurrent networks to learn short-term emotional information from individual modalities, or employ graph and attention mechanisms to integrate long-term emotional information from multiple modalities. These methods effectively combine emotional information within the conversational content in the time domain.However, psychological research shows that emotional information are not only conveyed in the time domain but also in the frequency domain (e.g., pitch and speech rate). To capture emotions from a more comprehensive perspective, we propose TF-MERC, a framework that integrates both time and frequency domains.TF-MERC uses a multi-domain alignment module to learn modality information within the time or frequency domains. It then employs FATransformer to deeply integrate the multimodal associations between the time and frequency domains, providing a more comprehensive approach for emotion prediction.Experimental results show that TF-MERC outperforms state-of-the-art methods, achieving superior performance across multiple datasets.",10.1145/3731715.3733447,2025,,ACM
Dynamic Graph Convolutional Transformer for Short-term Wind Speed Forecasting,"Wind speed forecasting is still a challenging problem, especially considering the correlations of spatial and temporal domains. However, the changing properties of spatial dependencies over time are ignored in most existing algorithms. In this paper, we propose a novel spatio-temporal machine learning algorithm, named Dynamic Graph Convolutional Transformer (DGCT), for wind speed forecasting. The key contribution of the proposed method is that graph convolutional networks are embedded into self-attention layers of Transformer to capture spatio-temporal correlations to improve the accuracy of forecasting. For the changing properties of spatial dependencies, we model the spatial dependencies as a mixture of global and localized patterns, which are represented by static and dynamic matrices respectively. Moreover, an auxiliary network is designed to generate the dynamic matrix, which further improve the forecasting accuracy. Experiments on two real-world datasets demonstrate that the proposed method outperformed other existing methods consistently.",10.1145/3594315.3594385,2023,,ACM
ASTGCL: Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction,"With the rise of intelligent urban systems, traffic flow prediction has emerged as a vital element within intelligent transportation frameworks. Graph neural networks (GNNs) are crucial for traffic flow prediction due to the non-Euclidean nature of traffic networks. Most GNN-based approaches depend on predefined adjacency matrices, frequently failing to model complex global dependencies. Additionally, these methods primarily use supervised learning, which is highly dependent on data quality. However, traffic data often suffers from missing values caused by sensor malfunctions, hindering effective feature extraction. To overcome these limitations, a novel framework called Adaptive Spatio-Temporal Graph-enhanced Contrastive Learning for Traffic Flow Prediction (ASTGCL) is introduced to improve prediction performance. Specifically, ASTGCL implements two data augmentation strategies: first, it employs an adaptive, learnable adjacency matrix to enhance the predefined matrix, enabling the model to capture both local and global topological features; second, it integrates three traffic data augmentation techniques to reduce the influence of data noise on prediction accuracy. The enhanced adjacency matrix and augmented traffic data are then utilized in a spatio-temporal contrastive learning process to extract higher-order spatio-temporal features from the traffic flow data. Experiments conducted on four real-world datasets reveal that ASTGCL surpasses baseline models, confirming the efficacy of the proposed framework.",10.1145/3746709.3746760,2025,,ACM
ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations,"Neural ordinary differential equations (NODEs) presented a new paradigm to construct (continuous-time) neural networks. While showing several good characteristics in terms of the number of parameters and the flexibility in constructing neural networks, they also have a couple of well-known limitations: i) theoretically NODEs learn homeomorphic mapping functions only, and ii) sometimes NODEs show numerical instability in solving integral problems. To handle this, many enhancements have been proposed. To our knowledge, however, integrating attention into NODEs has been overlooked for a while. To this end, we present a novel method of attentive dual co-evolving NODE (ACE-NODE): one main NODE for a downstream machine learning task and the other for providing attention to the main NODE. Our ACE-NODE supports both pairwise and elementwise attention. In our experiments, our method outperforms existing NODE-based and non-NODE-based baselines in almost all cases by non-trivial margins.",10.1145/3447548.3467419,2021,,ACM
Context-aware Event Forecasting via Graph Disentanglement,"Event forecasting has been a demanding and challenging task throughout the entire human history. It plays a pivotal role in crisis alarming and disaster prevention in various aspects of the whole society. The task of event forecasting aims to model the relational and temporal patterns based on historical events and makes forecasting to what will happen in the future. Most existing studies on event forecasting formulate it as a problem of link prediction on temporal event graphs. However, such pure structured formulation suffers from two main limitations: 1) most events fall into general and high-level types in the event ontology, and therefore they tend to be coarse-grained and offers little utility which inevitably harms the forecasting accuracy; and 2) the events defined by a fixed ontology are unable to retain the out-of-ontology contextual information.To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextual information. First, the categorical context provides supplementary fine-grained information to the coarse-grained events. Second and more importantly, the context provides additional information towards specific situation and condition, which is crucial or even determinant to what will happen next. However, it is challenging to properly integrate context into the event forecasting framework, considering the complex patterns in the multi-context scenario. Towards this end, we design a novel framework named Separation and Collaboration Graph Disentanglement (short as SeCoGD) for context-aware event forecasting. In the separation stage, we leverage the context as a prior guidance to disentangle the event graph into multiple sub-graphs, followed by a context-specific module to model the relational-temporal patterns within each context. In the collaboration stage, we design a cross-context module to retain the collaborative associations among multiple contexts. Since there is no available dataset for this novel task, we construct three large- scale datasets based on GDELT. Experimental results demonstrate hat our model outperforms a list of SOTA methods. The dataset and code are released via https://github.com/yecchen/SeCoGD.",10.1145/3580305.3599285,2023,,ACM
Are Time Series Foundation models good for Energy Anomaly Detection?,"Smart energy meters generate large volumes of fine-grained time series data that captures building’s energy consumption patterns. This data can be leveraged to detect anomalous energy consumption patterns and reduce energy waste in buildings. Traditional anomaly detection methods for smart meter data rely on statistical and machine learning techniques, which often struggle to model complex temporal patterns, require extensive feature engineering, and have poor scalability. Foundation models for time series, which are pretrained on massive volumes of time series data from diverse domains, have recently emerged as a versatile and scalable tool for time series analysis. They are capable of handling multiple tasks, including anomaly detection, and demonstrating superior performance compared to traditional models in various domains. Despite their potential for cross-domain applications, their applicability to the energy domain and their performance compared to traditional machine learning models remain largely unexplored.Therefore, in this paper, we analyze the applicability and performance of Time Series Foundation Models (TSFMs) for unsupervised energy anomaly detection. Specifically, we compare the performance of two widely used state-of-the-art TSFMs, TimeGPT and MOMENT, against existing anomaly detection techniques in the literature: (a) two statistical methods (Interquartile Range (IQR) and Modified Z-Score (mZ-Score)), (b) two unsupervised machine learning techniques (Isolation Forest and Local Outlier Factor), and (c) a deep learning-based technique, Variational Autoencoder (VAE). Our experimental results, conducted using the LEAD 1.0 dataset, which consists of annotated hourly energy readings of 200 buildings, show that MOMENT outperforms both traditional statistical methods and unsupervised machine learning methods. Our results reveal that fine-tuning of MOMENT marginally improves its performance. VAE trained from scratch surpasses TSFMs in performance despite having a smaller model size. We also analyze the trade-off between performance, scalability, and compute requirements of these models. Our analysis also provides new research directions for using TSFMs in the energy domain.",10.1145/3679240.3734633,2025,,ACM
TransChem: Effective Pre-training Enhances Molecular Property Prediction,"In this paper, we introduce TransChem, a novel architecture designed to tackle a wide range of downstream tasks in chemistry. TransChem leverages a pre-train fine-tune scheme. For pre-training, we utilize 2 million molecules from the ZINC15 database. We evaluate TransChem on six benchmark datasets from MoleculeNet, demonstrating its superior performance over state-of-the-art methods that employ pre-training and models that rely on hand-crafted features. We demonstrate that properly designed pre-training objectives can steer the learning process and allow TransChem to capture subtle relationships between atoms and generate informative representations, even when the pre-training dataset is relatively small.",10.1145/3688671.3688745,2024,,ACM
A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis,"Time series data, including univariate and multivariate ones, are characterized by unique composition and complex multi-scale temporal variations. They often require special consideration of decomposition and multi-scale modeling to analyze. Existing deep learning methods on this best fit to univariate time series only, and have not sufficiently considered sub-series modeling and decomposition completeness. To address these challenges, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer, which learns to explicitly decompose and represent the input time series in its different layers. To handle the multi-scale temporal patterns and multivariate dependencies, we propose a novel temporal patching approach to model the time series as multi-scale patches, and employ MLPs to capture intra- and inter-patch variations and channel-wise correlations. In addition, we propose a novel loss function to constrain both the mean and the autocorrelation of the decomposition residual for better decomposition completeness. Through extensive experiments on various real-world datasets for five common time series analysis tasks, we demonstrate that MSD-Mixer consistently and significantly outperforms other state-of-the-art algorithms with better efficiency.",10.14778/3654621.3654637,2024,,ACM
Predicting Long-term Dynamics of Complex Networks via Identifying Skeleton in Hyperbolic Space,"Learning complex network dynamics is fundamental for understanding, modeling, and controlling real-world complex systems. Though great efforts have been made to predict the future states of nodes on networks, the capability of capturing long-term dynamics remains largely limited. This is because they overlook the fact that long-term dynamics in complex network are predominantly governed by their inherent low-dimensional manifolds, i.e., skeletons. Therefore, we propose the &lt;u&gt;D&lt;/u&gt;ynamics-&lt;u&gt;I&lt;/u&gt;nvariant &lt;u&gt;Sk&lt;/u&gt;eleton Neural &lt;u&gt;Net&lt;/u&gt;work (DiskNet), which identifies skeletons of complex networks based on the renormalization group structure in hyperbolic space to preserve both topological and dynamics properties. Specifically, we first condense complex networks with various dynamics into simple skeletons through physics-informed hyperbolic embeddings. Further, we design graph neural ordinary differential equations to capture the condensed dynamics on the skeletons. Finally, we recover the skeleton networks and dynamics to the original ones using a degree-based super-resolution module. Extensive experiments across three representative dynamics as well as five real-world and two synthetic networks demonstrate the superior performances of the proposed DiskNet, which outperforms the state-of-the-art baselines by an average of 10.18\% in terms of long-term prediction accuracy. Code for reproduction is available at: https://github.com/tsinghua-fib-lab/DiskNet.",10.1145/3637528.3671968,2024,,ACM
Pretraining Large Brain Language Model for Active BCI: Silent Speech,"This paper explores silent speech decoding in active brain-computer interface (BCI) systems, which offer more natural and flexible communication than traditional BCI applications. We collected a new silent speech dataset of over 120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing 24 commonly used English words for language model pretraining and decoding. Following the recent success of pretraining large models with self-supervised paradigms to enhance EEG classification performance, we propose Large Brain Language Model (LBLM) pretrained to decode silent speech for active BCI. To pretrain LBLM, we propose Future Spectro-Temporal Prediction (FSTP) pretraining paradigm to learn effective representations from unlabeled EEG data. Unlike existing EEG pretraining methods that mainly follow a masked-reconstruction paradigm, our proposed FSTP method employs autoregressive modeling in temporal and frequency domains to capture both temporal and spectral dependencies from EEG signals. After pretraining, we finetune our LBLM on downstream tasks, including word-level and semantic-level classification. Extensive experiments demonstrate significant performance gains of the LBLM over fully-supervised and pretrained baseline models. For instance, in the difficult cross-session setting, our model achieves 47.2\% accuracy on semantic-level classification and 42.3\% in word-level classification, outperforming baseline methods substantially. Our research advances silent speech decoding in active BCI systems, offering an innovative solution for EEG language model pretraining and a new dataset for fundamental research.",10.1145/3746027.3754810,2025,,ACM
Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention,"Forecasting graph-based, time-dependent data has broad practical applications but presents challenges. Effective models must capture both spatial and temporal dependencies in the data, while also incorporating auxiliary information to enhance prediction accuracy. In this article, we identify limitations in current state-of-the-art models regarding temporal dependency handling. To overcome this, we introduce GSA-Forecaster, a new deep learning model designed for forecasting in graph-based, time-dependent contexts. GSA-Forecaster utilizes graph sequence attention, a new attention mechanism proposed in this article, to effectively manage temporal dependencies. GSA-Forecaster integrates the data’s graph structure directly into its architecture, addressing spatial dependencies. Additionally, it incorporates auxiliary information to refine its predictions further. We validate its performance using real-world graph-based, time-dependent datasets, where it demonstrates superior effectiveness compared to existing state-of-the-art models.",10.1145/3721435,2025,,ACM
Experience: A Comparative Analysis of Multivariate Time-Series Generative Models: A Case Study on Human Activity Data,"Human activity recognition (HAR) is an active research field that has seen great success in recent years due to advances in sensory data collection methods and activity recognition systems. Deep artificial intelligence (AI) models have contributed to the success of HAR systems lately, although still suffering from limitations such as data scarcity, the high costs of labelling data instances, and datasets’ imbalance and bias. The temporal nature of human activity data, represented as time series data, impose an additional challenge to using AI models in HAR, because most state-of-the-art models do not account for the time component of the data instances. These limitations have inspired the time-series research community to design generative models for sequential data, but very little work has been done to evaluate the quality of such models. In this work, we conduct a comparative quality analysis of three generative models for time-series data, using a case study in which we aim to generate sensory human activity data from a seed public dataset. Additionally, we adapt and clearly explain four evaluation methods of synthetic time-series data from the literature and apply them to assess the quality of the synthetic activity data we generate. We show experimentally that high-quality human activity data can be generated using deep generative models, and the synthetic data can thus be used in HAR systems to augment real activity data. We also demonstrate that the chosen evaluation methods effectively ensure that the generated data meets the essential quality benchmarks of realism, diversity, coherence, and utility. Our findings suggest that using deep generative models to produce synthetic human activity data can potentially address challenges related to data scarcity, biases, and expensive labeling. This holds promise for enhancing the efficiency and reliability of HAR systems.",10.1145/3688393,2024,,ACM
DisMS-TS: Eliminating Redundant Multi-scale Features for Time Series Classification,"Real-world time series typically exhibit complex temporal variations, making the time series classification task notably challenging. Recent advancements have demonstrated the potential of multi-scale analysis approaches, which provide an effective solution for capturing these complex temporal patterns. However, existing multi-scale analysis-based time series prediction methods fail to eliminate redundant scale-shared features across multi-scale time series, resulting in the model over- or under-focusing on scale-shared features. To address this issue, we propose a novel end-to-end Disentangled Multi-Scale framework for Time Series classification (DisMS-TS). The core idea of DisMS-TS is to eliminate redundant shared features in multi-scale time series, thereby improving prediction performance. Specifically, we propose a temporal disentanglement module to capture scale-shared and scale-specific temporal representations, respectively. Subsequently, to effectively learn both scale-shared and scale-specific temporal representations, we introduce two regularization terms that ensure the consistency of scale-shared representations and the disparity of scale-specific representations across all temporal scales. Extensive experiments conducted on multiple datasets validate the superiority of DisMS-TS over its competitive baselines, with the accuracy improvement up to 9.71\%.",10.1145/3746027.3754842,2025,,ACM
Interpretable Cascading Mixture-of-Experts for Urban Traffic Congestion Prediction,"Rapid urbanization has significantly escalated traffic congestion, underscoring the need for advanced congestion prediction services to bolster intelligent transportation systems. As one of the world's largest ride-hailing platforms, DiDi places great emphasis on the accuracy of congestion prediction to enhance the effectiveness and reliability of their real-time services, such as travel time estimation and route planning. Despite numerous efforts have been made on congestion prediction, most of them fall short in handling heterogeneous and dynamic spatio-temporal dependencies (e.g., periodic and non-periodic congestions), particularly in the presence of noisy and incomplete traffic data. In this paper, we introduce a Congestion Prediction Mixture-of-Experts, CP-MoE, to address the above challenges. We first propose a sparsely-gated Mixture of Adaptive Graph Learners (MAGLs) with congestion-aware inductive biases to improve the model capacity for efficiently capturing complex spatio-temporal dependencies in varying traffic scenarios. Then, we devise two specialized experts to help identify stable trends and periodic patterns within the traffic data, respectively. By cascading these experts with MAGLs, CP-MoE delivers congestion predictions in a more robust and interpretable manner. Furthermore, an ordinal regression strategy is adopted to facilitate effective collaboration among diverse experts. Extensive experiments on real-world datasets demonstrate the superiority of our proposed method compared with state-of-the-art spatio-temporal prediction models. More importantly, CP-MoE has been deployed in DiDi to improve the accuracy and reliability of the travel time estimation system.",10.1145/3637528.3671507,2024,,ACM
ST-FLAM: Evaluating Performance of Deep Learning Models on Mobility Patterns for EVD Forecasting based on Spatio-Temporal Feature Learning,"Ebola Virus Disease (EVD) is a highly contagious and fatal disease that poses a serious threat to public health and security. Accurate and timely forecasting of EVD outbreaks is essential for effective prevention and control measures. However, traditional epidemiological models often fail to capture the complex and dynamic nature of human mobility, which plays a key role in EVD transmission. In this paper, we propose a novel framework for EVD forecasting based on spatio-temporal feature learning called ST-FLAM. We use various types of mobility data, such as phone records, Global Positioning System (GPS) traces, and social media posts, to extract meaningful and representative features that reflect the mobility patterns of individuals and populations. Next, we employ ST-FLAM architectures, which incorporate Graph Neural Networks (GNN) and Long Short Term Memory (LSTM), to establish connections and dependencies between mobility features and EVD cases in both space and time. We evaluate the performance of our framework on real-world datasets from the 2014–2016 West Africa EVD outbreak and the 2015–2016 EVD and human mobility in Sierra Leone. We compare our framework with baseline methods to handle traditional epidemiological challenges during an outbreak. We conduct ablation studies and analyse the impact of different mobility data sources, feature extraction methods, and deep learning architectures on EVD forecasting accuracy. Our results show that our framework outperforms the baselines and achieves state-of-the-art performance in EVD forecasting. We also demonstrate that our framework can provide interpretable and actionable insights for EVD prevention and control.",10.1145/3711650.3711665,2025,,ACM
Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation for Wide-Area SST Prediction,"Accurate prediction of Sea Surface Temperature (SST) is of high importance in marine science, benefiting applications ranging from ecosystem protection to extreme weather forecasting and climate analysis. Wide-area SST usually shows diverse SST patterns in different sea areas due to the changes of temperature zones and the dynamics of ocean currents. However, existing studies on SST prediction often focus on small-area predictions and lack the consideration of diverse SST patterns. Furthermore, SST shows an annual periodicity, but the periodicity is not strictly adherent to an annual cycle. Existing SST prediction methods struggle to adapt to this non-strict periodicity. To address these two issues, we proposed the Cross-Region Graph Convolutional Network with Periodicity Shift Adaptation (RGCN-PSA) model which is equipped with the Cross-Region Graph Convolutional Network module and the Periodicity Shift Adaption module. The Cross-Region Graph Convolutional Network module enhances wide-area SST prediction by learning and incorporating diverse SST patterns. Meanwhile, the periodicity Shift Adaptation module accounts for the annual periodicity and enable the model to adapt to the possible temporal shift automatically. We conduct experiments on two real-world SST datasets, and the results demonstrate that our RGCN-PSA model obviously outperforms baseline models in terms of prediction accuracy. The code of RGCN-PSA model is available at .",10.1145/3735646,2025,,ACM
Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey,"Machine Learning (ML) workflows—spanning data preprocessing and feature engineering, model selection and hyperparameter optimization, and workflow evaluation—are increasingly embedded in complex software systems. Building these workflows manually demands substantial ML expertise, domain knowledge, and engineering effort. Automated ML (AutoML) frameworks address parts of this challenge but often suffer from constrained search spaces, limited adaptability, and low interpretability. Recent advances in Large Language Models (LLMs) have opened new opportunities to automate and enhance ML workflows by leveraging their capabilities in language understanding, reasoning, interaction, and code generation, posing new practical and theoretical challenges for software engineering (SE). This survey provides the first SE-oriented, stage-wise review of LLM-based ML workflow automation. We introduce a taxonomy covering all three workflow stages, systematically compare and analyze state-of-the-art methods, and synthesize both stage-specific and cross-stage trends. Our analysis yields SE-oriented implications, including the need for robust verification, quality management, context-aware deployment, and risk mitigation, alongside ensuring key quality attributes such as usability, modularity, traceability, and performance. The findings also call for adapting development models, rethinking lifecycle boundaries, and formalizing uncertainty handling to address the probabilistic and collaborative nature of LLM-assisted workflow generation. We further identify major open challenges and outline future research directions to guide the reliable and effective adoption of LLMs in ML workflow development. Our artifacts are publicly available at .",10.1145/3773084,2025,,ACM
A Graph-Based Framework for Temporal and Causal Analysis of Sentiments,"This research aims to develop a novel framework that uncovers the causal influence of global events on public sentiment through temporal graph modeling and neural causal inference. Global events, such as pandemics, elections, and economic crises, profoundly affect public sentiments, shaping social behaviors and economic outcomes. Traditional models often fall short in capturing the complex, dynamic, and non-linear relationships between these events and sentiments. This article presents the Neural Temporal Causal Graph Network (NTCGN), a unified framework that integrates temporal graph neural networks with a Causal Attention Network (CAN) to model and interpret these relationships. NTCGN constructs a temporal graph from event data and sentiment-labeled texts, learning dependencies and causal influences through advanced neural architectures. A thorough comparative analysis with state-of-the-art models such as Logistic Regression, SVM, LSTM, and transformer-based models demonstrates NTCGN’s superior performance. Experimental evaluation using the Sentiment140 and Global Database of Events, Language and Tone (GDELT) 2.0 datasets shows NTCGN achieving an accuracy of 0.798 and an F1 score of 0.795, outperforming these baseline models. The model’s causal inference capabilities are validated using the Causal Impact Score (CIS) and Causal Discovery Precision (CDP), highlighting its reliability in identifying true causal links. Visualizations of attention maps and causal pathways enhance interpretability, demonstrating how specific events influence public sentiments. This work provides a robust and interpretable tool for analyzing event-driven sentiment dynamics in real-world applications.",10.1145/3759440,2025,,ACM
Identifying Contemporaneous and Lagged Dependence Structures by Promoting Sparsity in Continuous-time Neural Networks,"Continuous-time dynamics models, e.g., neural ordinary differential equations, enable accurate modeling of underlying dynamics in time-series data. However, employing neural networks for parameterizing dynamics makes it challenging for humans to identify dependence structures, especially in the presence of delayed effects. In consequence, these models are not an attractive option when capturing dependence carries more importance than accurate modeling, e.g., in tsunami forecasting.In this paper, we present a novel method for identifying dependence structures in continuous-time dynamics models. We take a two-step approach: (1) During training, we promote weight sparsity in the model's first layer during training. (2) We prune the sparse weights after training to identify dependence structures. In evaluation, we test our method in scenarios where the exact dependence-structures of time-series are known. Compared to baselines, our method is more effective in uncovering dependence structures in data even when there are delayed effects. Moreover, we evaluate our method to a real-world tsunami forecasting, where the exact dependence structures are unknown beforehand. Even in this challenging scenario, our method still effective learns physically-consistent dependence structures and achieves high accuracy in forecasting.",10.1145/3627673.3679751,2024,,ACM
A Universal Sets-level Optimization Framework for Next Set Recommendation,"Next Set Recommendation (NSRec), encompassing related tasks such as next basket recommendation and temporal sets prediction, stands as a trending research topic. Although numerous attempts have been made on this topic, there are certain drawbacks: (i) Existing studies are still confined to utilizing objective functions commonly found in Next Item Recommendation (NIRec), such as binary cross entropy and BPR, which are calculated based on individual item comparisons; (ii) They place emphasis on building sophisticated learning models to capture intricate dependency relationships across sequential sets, but frequently overlook pivotal dependency in their objective functions; (iii) Diversity factor within sequential sets is frequently overlooked. In this research, we endeavor to unveil a universal and Sets-level optimization framework for Next Set Recommendation (SNSRec), offering a holistic fusion of diversity distribution and intricate dependency relationships within temporal sets. To realize this, the following contributions are made: (i) We directly model the temporal set in a sequence as a cohesive entity, leveraging the Structured Determinantal Point Process (SDPP), wherein the probabilistic DPP distribution prioritizes collections of structures (sequential sets) instead of individual items; (ii) We introduce a co-occurrence representation to discern and acknowledge the importance of different sets; (iii) We propose a sets-level optimization criterion, which integrates the diversity distribution and dependency relations across the entire sequence of sets, guiding the model to recommend relevant and diversified set. Extensive experiments on real-world datasets show that our approach consistently outperforms previous methods on both relevance and diversity.",10.1145/3627673.3679610,2024,,ACM
"A Comprehensive Benchmark on Spectral GNNs: The Impact on Efficiency, Memory, and Effectiveness","With recent advancements in graph neural networks (GNNs), spectral GNNs have received increasing popularity by virtue of their ability to retrieve graph signals in the spectral domain. These models feature uniqueness in efficient computation as well as rich expressiveness, which stems from advanced management and profound understanding of graph data. However, few systematic studies have been conducted to assess spectral GNNs, particularly in benchmarking their efficiency, memory consumption, and effectiveness in a unified and fair manner. There is also a pressing need to select spectral models suitable for learning specific graph data and deploying them to massive web-scale graphs, which is currently constrained by the varied model designs and training settings.In this work, we extensively benchmark spectral GNNs with a focus on the spectral perspective, demystifying them as spectral graph filters. We analyze and categorize 35 GNNs with 27 corresponding filters, spanning diverse formulations and utilizations of the graph data. Then, we implement the filters within a unified spectral-oriented framework with dedicated graph computations and efficient training schemes. In particular, our implementation enables the deployment of spectral GNNs over million-scale graphs and various tasks with comparable performance and less overhead. Thorough experiments are conducted on the graph filters with comprehensive metrics on effectiveness and efficiency, offering novel observations and practical guidelines that are only available from our evaluations across graph scales. Different from the prevailing belief, our benchmark reveals an intricate landscape regarding the effectiveness and efficiency of spectral graph filters, demonstrating the potential to achieve desirable performance through tailored spectral manipulation of graph data.",10.1145/3749156,2025,,ACM
Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion,"Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.",10.1145/3589132.3625641,2023,,ACM
A Multi-Modal Knowledge-Enhanced Framework for Vessel Trajectory Prediction,"Accurate vessel trajectory prediction facilitates improved navigational safety, routing, and environmental protection. However, existing prediction methods are challenged by the irregular sampling time intervals of the vessel tracking data from the global AIS system and the complexity of vessel movement. These aspects complicate model learning and generalization. To address these challenges and improve vessel trajectory prediction, we propose Multi-modAl Knowledge-Enhanced fRamework (MAKER) for vessel trajectory prediction. To contend better with the irregular sampling time intervals, MAKER features a Large language model-guided Knowledge Transfer (LKT) module that leverages pre-trained language models to transfer trajectory-specific contextual knowledge effectively. To enhance the ability to learn complex trajectory patterns, MAKER incorporates a Knowledge-based Self-paced Learning (KSL) module. This module employs kinematic knowledge to progressively integrate complex patterns during training, allowing for adaptive learning and enhanced generalization. Experimental results on two vessel trajectory datasets show that MAKER can improve the prediction accuracy of state-of-the-art methods by 12.08\%—17.86\%.",10.1145/3748777.3748784,2025,,ACM
Tide: A Time-Wise Causal Debiasing Framework for Generative Dynamic Link Prediction,"Dynamic link prediction aims to predict the future links in dynamic graphs. Existing generative dynamic link prediction studies utilize the global degree distribution for mitigating the over-estimation problem, which can model the time-invariant features while neglecting the time-varying features, resulting in capturing inaccurate evolution patterns. However, such time related features are intrinsically coupled, which makes simultaneously and independently modeling both features infeasible. Motivated by these issues, we propose a Time-wise causal debiasing framework (Tide) for generative dynamic link prediction, which does not resort to any extra trainable modules. Instead, to obtain the time-invariant features, we first utilize a time-invariant deconfounded learning mechanism for decoupling the prediction score with the degree distribution. To leverage the time-varying features, we intervene in the model during the inference stage by a predicted future degree distribution, aiming to make the accurate predictions for dynamic graphs. Experiments conducted on four public datasets under both inductive and transductive settings present that our Tide enhanced models can outperform their corresponding vanilla versions by up to 21.42\% and 27.73\% in terms of NDCG and Jaccard, respectively.",10.1145/3746252.3761182,2025,,ACM
Long Short-term Dynamic Graph Neural Networks: for short-term intense rainfall forecasting,"In practice, accurate and timely forecasting of short-term intense rainfall is critical, but the problem is extremely difficult because to its complicated spatial-temporal association. Although several spatial-temporal series forecasting methods have been used to rainfall prediction, these models continue to suffer from inadequate modeling of data’s complicated intrinsic connection. We provide a new short-term intense rainfall prediction model that use two graph generators to model data correlations under distinct semantics, followed by a graph convolution module for information integration to fully extract data spatial-temporal information. Finally, a variant of recurrent neural network is employed to extract the temporal dependence. The experimental results on both datasets show that the model can model the spatial and temporal dependence across the data more effectively than the baseline model, and further improve the model’s predictive performance for short-term intense rainfall.",10.1145/3578741.3578757,2023,,ACM
Transportation Flow Prediction Based on Graph Attention Echo State Network,"Abstract—Traffic flow prediction is of great importance in applications such as traffic management and urban planning. The complex spatial and temporal dependence of traffic flow between different roads poses a great challenge for accurate real-time traffic flow prediction. Traditional traffic flow prediction methods rely on the assumption of data smoothness, and the prediction accuracy decreases significantly in the face of complex, variable and large amount of traffic flow data. Spatio-temporal prediction models based on graph neural networks and recurrent neural networks can achieve better prediction accuracy, but there are still some problems, such as the need for a known static graph structure, inadequate spatial extraction and long training time of the model. To improve traffic flow prediction accuracy and real-time performance, this paper proposes a novel end-to-end deep learning framework called graph attention echo state network (GAESN), which uses attention mechanism and echo state network to extract spatio-temporal features. Experimental results on four real traffic flow datasets show that our proposed model achieves 17.35, 21.34, 24.12 and 17.31 in mean absolute error(MAE); 29.31, 32.67, 37.51and 26.84 in root mean square error(RMSE); 16.76\%, 15.44\%, 10.33\% and 10.94\% in mean absolute percentage error(MAPE), respectively. Compared with other existing models, this model reduces the number of parameters to be trained and the time required for model training, and also improves the accuracy of traffic flow prediction.",10.1145/3603781.3603907,2023,,ACM
Attention based Deep Hybrid Networks for Traffic Flow Prediction using Google Maps Data,"Accurate traffic flow prediction is a keystone for building intelligent traffic management systems which have gained attention from researchers because of the availability of the massive volume of traffic data and advances in deep learning technologies. However, there are many cities in the world, that suffer from terrible traffic congestion but there are no infrastructure facilities to collect traffic data. To address this problem we develop a tool that collects traffic data from Google Maps without using its paid API. After that, we proposed an Attention-based Deep Hybrid network (ADHN) for traffic flow prediction using Google map data. The proposed ADHN combines two Convolutional Long Short-Term Memory (ConvLSTM) to capture dynamic spatial temporal dependencies of the traffic flow and applies attention mechanism on traffic features. The experiment result shows that our proposed ADHN can provide higher prediction accuracy compared with the other state-of-the-art approaches. Our code and data are available at https://github.com/Moshiurcse13/trafficDataCollectionTool.",10.1145/3589883.3589894,2023,,ACM
Community Trend Prediction on Heterogeneous Graph in E-commerce,"In online shopping, ever-changing fashion trends make merchants need to prepare more differentiated products to meet the diversified demands, and e-commerce platforms need to capture the market trend with a prophetic vision. For the trend prediction, the attribute tags, as the essential description of items, can genuinely reflect the decision basis of consumers. However, few existing works explore the attribute trend in the specific community for e-commerce. In this paper, we focus on the community trend prediction on the item attribute and propose a unified framework that combines the dynamic evolution of two graph patterns to predict the attribute trend in a specific community. Specifically, we first design a community-attribute bipartite graph at each time step to learn the collaboration of different communities. Next, we transform the bipartite graph into a hypergraph to exploit the associations of different attribute tags in one community. Lastly, we introduce a dynamic evolution component based on the recurrent neural networks to capture the fashion trend of attribute tags. Extensive experiments on three real-world datasets in a large e-commerce platform show the superiority of the proposed approach over several strong alternatives and demonstrate the ability to discover the community trend in advance.",10.1145/3488560.3498522,2022,,ACM
MSTEM: Masked Spatiotemporal Event Series Modeling for Urban Undisciplined Events Forecasting,"Urban undisciplined events (UUE) are of increasing concern to urban officials because they reduce the quality of life and cause societal disorder. How to accurately predict future occurrences is a key point in preventing these events. However, existing supervised methods struggle to perform well on sparse UUEs while self-supervised MAE-based methods adopt a traditional random masking strategy which leads to limited performance on UUE forecasting. Fortunately, we have designed an innovative spatiotemporal masking strategy and its corresponding pre-training task called &lt;u&gt;M&lt;/u&gt;asked &lt;u&gt;S&lt;/u&gt;patio-&lt;u&gt;T&lt;/u&gt;emporal &lt;u&gt;E&lt;/u&gt;vent Series &lt;u&gt;M&lt;/u&gt;odeling (MSTEM). Through Cluster-assisted region masking, MSTEM efficiently distributes masked regions evenly among different clusters, enhancing the model's ability to capture spatial correlation and heterogeneity while addressing sparse region distribution of UUEs. Frequency-enhanced patch masking helps the model to sufficiently extract the temporal features of UUEs by reconstructing multiple views. Additionally, we propose future merge and cluster label modeling to enhance the extraction of spatiotemporal dependencies, thereby improving the performance of MSTEM on downstream prediction tasks. Experimental evaluations on four real-world datasets including crimes and disorderly conduct show that our masked autoencoder with MSTEM outperforms most of the state-of-the-art baselines.",10.1145/3627673.3679810,2024,,ACM
Seeing the Unseen: Learning Basis Confounder Representations for Robust Traffic Prediction,"Traffic prediction is essential for intelligent transportation systems and urban computing. It aims to establish a relationship between historical traffic data X and future traffic states Y by employing various statistical or deep learning methods. However, the relations of X → Y are often influenced by external confounders that simultaneously affect both X and Y, such as weather, accidents, and holidays. Existing deep-learning traffic prediction models adopt the classic front-door and back-door adjustments to address the confounder issue. However, these methods have limitations in addressing continuous or undefined confounders, as they depend on predefined discrete values that are often impractical in complex, real-world scenarios. To overcome this challenge, we propose the Spatial-Temporal sElf-superVised confoundEr learning (STEVE) model. This model introduces a basis vector approach, creating a base confounder bank to represent any confounder as a linear combination of a group of basis vectors. It also incorporates self-supervised auxiliary tasks to enhance the expressive power of the base confounder bank. Afterward, a confounder-irrelevant relation decoupling module is adopted to separate the confounder effects from direct X → Y relations. Extensive experiments across four large-scale datasets validate our model's superior performance in handling spatial and temporal distribution shifts and underscore its adaptability to unseen confounders. Our model implementation is available at https://github.com/bigscity/STEVE_CODE.",10.1145/3690624.3709201,2025,,ACM
Spatio-Temporal Deep Fusion Graph Convolutional Networks for Crime Prediction,"Effective crime prediction plays a key role in sustaining the stability of society. In recent years, researchers have proposed a number of prediction methods that extract spatial and temporal features separately and fuse afterward. However, the strict distinction between spatial feature extraction and temporal feature extraction can result in the loss of useful information. To this end, we propose a spatio-temporal deep fusion graph convolution network (STDGCN), which embodies the intra-region spatio-temporal features and the inter-region spatio-temporal associations on a single graph. STDGCN performs the convolution without distinguishing between space and time to simultaneously extract spatio-temporal features. Our evaluations of two real-world datasets demonstrate the effectiveness of STDGCN.",10.1145/3583788.3583799,2023,,ACM
Prediction of the Number of Postgraduate Entrance Examination Applicants Based on LSTM and Statistical Analysis Method,"In recent years, with the expansion of higher education institutions year by year, the total number of fresh undergraduates has been rapidly increasing. This paper proposes a prediction algorithm for the number of undergraduates who will enter graduate school through long short-term memory (LSTM) based on the current development trend of graduate school and the number of admissions to graduate school in recent years.Firstly, the parameters that have the greatest influence on the prediction of the number of applicants for the examinations are statistically analyzed, and then a deep learning prediction model based on LSTM is built to predict the number of applicants for the examinations, and the results are displayed in the visualization interface. The experimental results show that the trained LSTM model works better than the Support Vector Machine (SVM) results. The prediction model will be provided to students before registering for the exam, which is of practical significance to facilitate students to make reasonable decisions.",10.1145/3606043.3606045,2023,,ACM
BiST: A Lightweight and Efficient Bi-Directional Model for Spatiotemporal Prediction,"While existing spatiotemporal prediction models have shown promising performance, they often rely on the assumption of input-label spatiotemporal consistency, and their high complexity raises concerns about scalability. To enhance both efficiency and performance, we integrate label information into the learning process and propose a spatiotemporal dynamic theory that outlines a bi-directional learning paradigm. Building on this paradigm, we design BiST, a lightweight yet effective Bi-directional Spatio-Temporal prediction model. BiST incorporates two key processes: a forward spatiotemporal learning process and a backward correction process. The forward process utilizes MLP layers exclusively to model input correlations and generate base prediction. In the backward process, we implement a spatiotemporal decoupling module, which can learn the residual modeling deviation between input and label representations from a decoupled perspective. After smoothing the residual with a diffusion module, we can obtain the correction term to correct the base predictions. This innovative design enables BiST to achieve competitive performance while remaining lightweight. We evaluate BiST against 26 baselines across 13 datasets, including a large-scale dataset with ten thousand nodes and a longrange dataset spanning 20 years. An impressive experimental result demonstrates that BiST achieves a 8.13\% improvement in performance compared to state-of-the-art models while consuming only 1.86\% of the training time and 7.36\% of the memory usage.",10.14778/3725688.3725697,2025,,ACM
HAG-MTF: Higher-Order Adaptive Generative Graph for Massive Traffic Forecasting in Industry 5.0,"With the evolution of urban smart transportation, the complexity of urban traffic networks escalates, emphasizing the importance of large-scale traffic data prediction in traffic management and urban planning. Traditional spatiotemporal graph models, such as Graph-WaveNet and MTGCN, face exponentially increasing computational complexity as the spatial dimensions expand. To address this challenge, we propose a novel Higher-order Adaptive Generative graph for Massive Traffic Forecasting (HAG-MTF) approach, which utilizes generative AI and high-order graph structures to model the intricate spatial dependencies in large-scale traffic data. The HAG-MTF incorporates a high-order dimensionality reduction module to optimize traffic node processing, utilizing prior graph relationships to generate a fusion graph that dynamically incorporates neighborhood information for efficient, localized graph convolution. The model further incorporates the high-order spatiotemporal relationship extraction module (H-net), enhancing the capacity and speed of traffic data processing while boosting prediction accuracy for complex spatial structures. Furthermore, HAG-MTF introduces a fusion loss function that hierarchically balances multiple objectives, ensuring both precision and computational efficiency. HAG-MTF adaptively handles large-scale real-world traffic data, meeting the needs of traffic controllers and urban planners for predicting massive datasets in practical settings. It supports efficient, flexible interactions via parameter tuning and model outputs, ultimately integrating human insights into traffic analysis and decision-making. This dynamic human-machine collaboration differs from non-Industry 5.0 approaches, which rely on purely automated systems without human input. Those lead to inflexible, brittle conclusions and recommendations, neglecting shifts in traffic patterns driven by human behavior. Extensive experiments on real-world traffic datasets demonstrate that HAG-MTF significantly improves processing efficiency for high-complexity spatial data while delivering precise, human-informed predictions through generative AI-driven operations.",10.1145/3772723,2025,,ACM
Short-term Load Forecasting Method of Power Distribution Station Area Integrating Multiple Temporal Characteristics,"In order to solve the problem of short term power load forecasting and improve the accuracy of load forecasting in distribution station area, a short term power load forecasting model integrating multiple temporal series characteristics is proposed in this paper. Firstly, we solve the problems of missing and outliers in acquired load and weather data through data preprocessing. Then, we consider the historical load, weather, working day/holiday and other factors, then explore the long-short term, periodicity and particularity of the load and weather information. After that, we establish the short-term power load prediction feature model of the platform area. In addition, we use the deep residual network as the basic structure to eliminate the overfitting problem caused by the deep network. Experiments show that the proposed method has smaller prediction error compared with the existing methods.",10.1145/3635638.3635641,2024,,ACM
CausalMob: Causal Human Mobility Prediction with LLMs-derived Human Intentions toward Public Events,"Large-scale human mobility exhibits spatial and temporal patterns that can assist policymakers in decision making. Although traditional prediction models attempt to capture these patterns, they are often affected by nonperiodic public events, such as disasters and occasional celebrations. Since regular human mobility patterns are affected by these events, estimating their causal effects is critical to accurate mobility predictions. News articles provide unique perspectives on these events, though processing them is a challenge. In this study, we propose a causality based prediction model, CausalMob, to analyze the causal effects of public events. We first utilize large language models (LLMs) to extract human intentions from news and transform them into features that act as causal treatments. Next, the model learns representations of spatio-temporal regional covariates from multiple data sources to serve as confounders for causal inference. Finally, we present a causal effect estimation framework to ensure that event features remain independent of confounders during prediction. Based on large-scale real-world data, the experimental results show that the proposed model excels in human mobility prediction, outperforming state-of-the-art models.",10.1145/3690624.3709231,2025,,ACM
Oxygen Uptake Estimation during Cardiopulmonary Exercise Testing Using Temporal Fusion Networks,Accurate measurement of oxygen uptake ( (dot{mathrm{V,10.1145/3728370,2025,,ACM
TempASD: Temporal Anomalous Subgraph Discovery in Large-Scale Dynamic Financial Networks,"In this paper, we investigate the discovery of temporal anomalous subgraphs in large-scale financial networks, aiming to identify abnormal transaction behaviors among users over time. This task is crucial for the real-time detection of transaction anomalies in financial networks, such as money laundering and trading fraud. However, it poses significant challenges due to the diverse distribution of transactions, the dynamic nature of temporal networks, and the absence of theoretical foundation. To tackle these challenges, we introduce a novel Temporal Anomalous Subgraph Discovery (TempASD) algorithm with theoretical analysis. First, we propose a temporal candidate detection module that quickly pinpoints abnormal candidates by detecting anomalies in both the temporal structure and transaction distribution. Then, we introduce a carefully crafted reinforcement-learning-based refiner to optimize these candidates toward the most abnormal directions. We conducted extensive evaluations against thirteen advanced competitors. TempASD achieves an average improvement of 7x in abnormal degree compared to the state-of-the-art and is efficient in large-scale dynamic financial networks.",10.1145/3711896.3737149,2025,,ACM
Multi-Attribute Spatial-temporal Graph Convolutional Network for Taxi Demand Forecasting,"Accurate forecasting taxi demand help reduce waiting time for drivers and passengers as well as ease traffic congestion. However, most of the current research work has mostly ignored the impact of historical cab inflows and potential spatial dependencies between different regions on taxi demand. In view of this, this paper integrates several attributes affecting taxi demand and develops a multi-attribute spatial-temporal graphical convolutional network model (MASTGCN) with the expectation of accurately predicting the MASTGCN model is designed to accurately predict the demand for rental cars. Specifically, the MASTGCN model is designed with four components, which model the temporal dependence of taxi demand on the demand series at the near moment, the daily demand series, the historical taxi inflow series, and the daily demand series, respectively. The components are designed to model the temporal dependence of taxi demand on proximity demand series, daily demand series, historical cab inflow series, and the potential spatial dependence among different regions. To demonstrate the effectiveness of the MASTGCN model, we compare it with five benchmark models commonly used for traffic forecasting and three metrics, RMSE, MAE and MAPE, are used for evaluation. The experimental results show that the MASTGCN model, which incorporates multiple attributes, can more accurately the multiattribute MASTGCN model can predict taxi demand more accurately.",10.1145/3565291.3565301,2022,,ACM
PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection,"With the proliferation of mobile sensing techniques, huge amounts of time series data are generated and accumulated in various domains, fueling plenty of real-world applications. In this setting, time series anomaly detection is practically important. It endeavors to identify deviant samples from the normal sample distribution in time series. Existing approaches generally assume that all the time series is available at a central location. However, we are witnessing the decentralized collection of time series due to the deployment of various edge devices. To bridge the gap between the decentralized time series data and the centralized anomaly detection algorithms, we propose a &lt;u&gt;P&lt;/u&gt;arameter-&lt;u&gt;e&lt;/u&gt;fficient &lt;u&gt;F&lt;/u&gt;ederated &lt;u&gt;A&lt;/u&gt;nomaly &lt;u&gt;D&lt;/u&gt;etection framework named PeFAD with the increasing privacy concerns. PeFAD for the first time employs the pre-trained language model (PLM) as the body of the client's local model, which can benefit from its cross-modality knowledge transfer capability. To reduce the communication overhead and local model adaptation cost, we propose a parameter-efficient federated training module such that clients only need to fine-tune small-scale parameters and transmit them to the server for update. PeFAD utilizes a novel anomaly-driven mask selection strategy to mitigate the impact of neglected anomalies during training. A knowledge distillation operation on a synthetic privacy-preserving dataset that is shared by all the clients is also proposed to address the data heterogeneity issue across clients. We conduct extensive evaluations on four real datasets, where PeFAD outperforms existing state-of-the-art baselines by up to 28.74\%.",10.1145/3637528.3671753,2024,,ACM
TriD-MAE: A Generic Pre-trained Model for Multivariate Time Series with Missing Values,"Multivariate time series(MTS) is a universal data type related to various real-world applications. Data imputation methods are widely used in MTS applications to deal with the frequent data missing problem. However, these methods inevitably introduce biased imputation and training-redundancy problems in downstream training. To address these challenges, we propose TriD-MAE, a generic pre-trained model for MTS data with missing values. Firstly, we introduce TriD-TCN, an end-to-end module based on TCN that effectively extracts temporal features by integrating dynamic kernel mechanisms and a time-flipping trick. Building upon that, we designed an MAE-based pre-trained model as the precursor of specialized downstream models. Our model cooperates with a dynamic positional embedding mechanism to represent the missing information and generate transferable representation through our proposed encoder units. The overall mixed data feed-in strategy and weighted loss function are established to ensure adequate training of the whole model. Comparative experiment results in time series prediction and classification manifest that our TriD-MAE model outperforms the other state-of-the-art methods within six real-world datasets. Moreover, ablation and interpretability experiments are delivered to verify the validity of TriD-MAE's",10.1145/3583780.3615097,2023,,ACM
GraphSparseNet: A Novel Method for Large Scale Traffic Flow Prediction,"Traffic flow forecasting is a critical spatio-temporal data mining task with wide-ranging applications in intelligent route planning and dynamic traffic management. Recent advancements in deep learning, particularly through Graph Neural Networks (GNNs), have significantly enhanced the accuracy of these forecasts by capturing complex spatio-temporal dynamics. However, the scalability of GNNs remains a challenge due to their exponential growth in model complexity with increasing nodes in the graph. Existing methods to address this issue, including sparsification, decomposition, and kernel-based approaches, either do not fully resolve the complexity issue or risk compromising predictive accuracy. This paper introduces GraphSparseNet (GSNet), a novel framework designed to improve both the scalability and accuracy of GNN-based traffic forecasting models. GraphSparseNet is comprised of two core modules: the Feature Extractor and the Relational Compressor. These modules operate with linear time and space complexity, thereby reducing the overall computational complexity of the model to a linear scale. Our extensive experiments on multiple real-world datasets demonstrate that GraphSparseNet not only significantly reduces training time by 3.51x compared to state-of-the-art linear models but also maintains high predictive performance.",10.14778/3734839.3734862,2025,,ACM
Leveraging ResNet CNN and XGBoost for Enhanced Bitcoin Price Forecasting,"This research proposes a novel approach for forecasting cryptocurrency prices, specifically Bitcoin which dominates the market. Accurately predicting cryptocurrency values is challenging due to their highly volatile nature. The proposed hybrid model uses ResNet Convolutional Neural Network to encode Bitcoin price time series data into discriminative representations. These representations capture long-range dependencies using XGBoost regression. Additionally, wavelet denoising is applied to filter noise from the price data. The combined ResNet-XGBoost-Wavelet model achieves satisfactory results for Bitcoin price forecasting and has practical applications for developing quantitative trading strategies. While incorporating sentiment analysis and additional influencing factors could further improve predictions, this work presents a competitive approach for minimizing investment risks and maximizing profits in the complex domain of cryptocurrency markets.",10.1145/3639631.3639648,2024,,ACM
Graph Neural Networks in IoT: A Survey,"The Internet of Things (IoT) boom has revolutionized almost every corner of people’s daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source codes from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at GNN4IoT.",10.1145/3565973,2023,,ACM
3DGCN: 3-Dimensional Dynamic Graph Convolutional Network for Citywide Crowd Flow Prediction,"Crowd flow prediction is an essential task benefiting a wide range of applications for the transportation system and public safety. However, it is a challenging problem due to the complex spatio-temporal dependence and the complicated impact of urban structure on the crowd flow patterns. In this article, we propose a novel framework, 3-Dimensional Graph Convolution Network (3DGCN), to predict citywide crowd flow. We first model it as a dynamic spatio-temporal graph prediction problem, where each node represents a region with time-varying flows, and each edge represents the origin–destination (OD) flow between its corresponding regions. As such, OD flows among regions are treated as a proxy for the spatial interactions among regions. To tackle the complex spatio-temporal dependence, our proposed 3DGCN can model the correlation among graph spatial and temporal neighbors simultaneously. To learn and incorporate urban structures in crowd flow prediction, we design the GCN aggregator to be learned from both crowd flow prediction and region function inference at the same time. Extensive experiments with real-world datasets in two cities demonstrate that our model outperforms state-of-the-art baselines by 9.6\%∼19.5\% for the next-time-interval prediction.",10.1145/3451394,2021,,ACM
SUSTeR: Sparse Unstructured Spatio Temporal Reconstruction on Traffic Prediction,"Mining spatio-temporal correlation patterns for traffic prediction is a well-studied field. However, most approaches are based on the assumption of the availability of and accessibility to a sufficiently dense data source, which is rather the rare case in reality. Traffic sensors in road networks are generally highly sparse in their distribution: fleet-based traffic sensing is sparse in space but also sparse in time. There are also other traffic application, besides road traffic, like moving objects in the marine space, where observations are sparsely and arbitrarily distributed in space. In this paper, we tackle the problem of traffic prediction on sparse and spatially irregular and non-deterministic traffic observations. We draw a border between imputations and this work as we consider high sparsity rates and no fixed sensor locations. We advance correlation mining methods with a Sparse Unstructured Spatio Temporal Reconstruction (SUSTeR) framework that reconstructs traffic states from sparse non-stationary observations. For the prediction the framework creates a hidden context traffic state which is enriched in a residual fashion with each observation. Such an assimilated hidden traffic state can be used by existing traffic prediction methods to predict future traffic states. We query these states with query locations from the spatial domain.",10.1145/3589132.3625631,2023,,ACM
Liquidity takers behavior representation through a contrastive learning approach,"Thanks to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyze agents’ behaviors in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilize the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behavior types within each cluster.",10.1145/3604237.3626851,2023,,ACM
Session-Based News Recommendation from Temporal User Commenting Dynamics,"With the increase in volume of daily online news items, it is more and more difficult for readers to identify news articles relevant to their interests. Thus, effective recommendation systems are critical for an effective user news consumption experience. Existing news recommendation methods usually rely on the news click history to model user interest. However, there are other signals about user behaviors, such as user commenting activity, which have not been used before. We propose a recommendation algorithm that predicts articles a user may be interested in, given her historical sequential commenting behavior on news articles. We show that following this sequential user behavior the news recommendation problem falls into in the class of session-based recommendation. The techniques in this class seek to model users' sequential and temporal behaviors. While we seek to follow the general directions in this space, we face unique challenges specific to news in modeling temporal dynamics, e.g., users' interests shift over time, users comment irregularly on articles, and articles are perishable items with limited lifespans. We propose a recency-regularized neural attentive framework for session-based news recommendation. The proposed method is able to capture the temporal dynamics of both users and news articles, while maintaining interpretability. We design a lag-aware attention and a recency regularization to model the time effect of news articles and comments. We conduct extensive empirical studies on 3 real-world news datasets to demonstrate the effectiveness of our method.",10.1109/asonam55673.2022.10068595,2023,,ACM
Deep Pipeline Embeddings for AutoML,"Automated Machine Learning (AutoML) is a promising direction for democratizing AI by automatically deploying Machine Learning systems with minimal human expertise. The core technical challenge behind AutoML is optimizing the pipelines of Machine Learning systems (e.g. the choice of preprocessing, augmentations, models, optimizers, etc.). Existing Pipeline Optimization techniques fail to explore deep interactions between pipeline stages/components. As a remedy, this paper proposes a novel neural architecture that captures the deep interaction between the components of a Machine Learning pipeline. We propose embedding pipelines into a latent representation through a novel per-component encoder mechanism. To search for optimal pipelines, such pipeline embeddings are used within deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters of the pipeline embedding network using existing evaluations of pipelines on diverse collections of related datasets (a.k.a. meta-datasets). Through extensive experiments on three large-scale meta-datasets, we demonstrate that pipeline embeddings yield state-of-the-art results in Pipeline Optimization.",10.1145/3580305.3599303,2023,,ACM
Deep Transfer Learning Across Cities for Mobile Traffic Prediction,"Precise citywide mobile traffic prediction is of great significance for intelligent network planning and proactive service provisioning. Current traffic prediction approaches mainly focus on training a well-performed model for the cities with a large amount of mobile traffic data. However, for the cities with scarce data, the prediction performance will be greatly limited. To tackle this problem, in this paper we propose a novel cross-city deep transfer learning framework named CCTP for citywide mobile traffic prediction in cities with data scarcity. Specifically, we first present a novel spatial-temporal learning model and pre-train the model by abundant data of a source city to obtain prior knowledge of mobile traffic dynamics. We then devise an efficient generative adversarial network (GAN) based cross-domain adapter for distribution alignment between target data and source data. To deal with data scarcity issue in some clusters of target city, we further design an inter-cluster transfer learning strategy for performance enhancement. Extensive experiments conducted on real-world mobile traffic datasets demonstrate that our proposed CCTP framework can achieve superior performance in citywide mobile traffic prediction with data scarcity.",10.1109/tnet.2021.3136707,2021,,ACM
MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation,"Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.",10.1145/3583780.3614962,2023,,ACM
Automated Spatio-Temporal Synchronous Modeling with Multiple Graphs for Traffic Prediction,"Traffic prediction plays an important role in many intelligent transportation systems. Many existing works design static neural network architecture to capture complex spatio-temporal correlations, which is hard to adapt to different datasets. Although recent neural architecture search approaches have addressed this problem, it still adopts a coarse-grained search with pre-defined and fixed components in the search space for spatio-temporal modeling. In this paper, we propose a novel neural architecture search framework, entitled AutoSTS, for automated spatio-temporal synchronous modeling in traffic prediction. To be specific, we design a graph neural network (GNN) based architecture search module to capture localized spatio-temporal correlations, where multiple graphs built from different perspectives are jointly utilized to find a better message passing way for mining such correlations. Further, we propose a convolutional neural network (CNN) based architecture search module to capture temporal dependencies with various ranges, where gated temporal convolutions with different kernel sizes and convolution types are designed in search space. Extensive experiments on six public datasets demonstrate that our model can achieve 4\%-10\% improvements compared with other methods.",10.1145/3511808.3557243,2022,,ACM
ImputeFormer: Low Rankness-Induced Transformers for Generalizable Spatiotemporal Imputation,"Missing data is a pervasive issue in both scientific and engineering tasks, especially for the modeling of spatiotemporal data. Existing imputation solutions mainly include low-rank models and deep learning models. The former assumes general structural priors but has limited model capacity. The latter possesses salient expressivity, but lacks prior knowledge of the underlying spatiotemporal structures. Leveraging the strengths of both two paradigms, we demonstrate a low rankness-induced Transformer to achieve a balance between strong inductive bias and high expressivity. The exploitation of the inherent structures of spatiotemporal data enables our model to learn balanced signal-noise representations, making it generalizable for a variety of imputation tasks. We demonstrate its superiority in terms of accuracy, efficiency, and versatility in heterogeneous datasets, including traffic flow, solar energy, smart meters, and air quality. Promising empirical results provide strong conviction that incorporating time series primitives, such as low-rankness, can substantially facilitate the development of a generalizable model to approach a wide range of spatiotemporal imputation problems.",10.1145/3637528.3671751,2024,,ACM
Event Prediction in the Big Data Era: A Systematic Survey,"Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.",10.1145/3450287,2021,,ACM
DARKER: Efficient Transformer with Data-Driven Attention Mechanism for Time Series,"Transformer-based models have facilitated numerous applications with superior performance. A key challenge in transformers is the quadratic dependency of its training time complexity on the length of the input sequence. A recent popular solution is using random feature attention (RFA) to approximate the costly vanilla attention mechanism. However, RFA relies on only a single, fixed projection for approximation, which does not capture the input distribution and can lead to low efficiency and accuracy, especially on time series data. In this paper, we propose DARKER, an efficient transformer with a novel DAta-dRiven KERnel-based attention mechanism. To precisely present the technical details, this paper discusses them with a fundamental time series task, namely, time series classification (tsc). First, the main novelty of DARKER lies in approximating the softmax kernel by learning multiple machine learning models with trainable weights as multiple projections offline, moving beyond the limitation of a fixed projection. Second, we propose a projection index (called pIndex) to efficiently search the most suitable projection for the input for training transformer. As a result, the overall time complexity of DARKER is linear with the input length. Third, we propose an indexing technique for efficiently computing the inputs required for transformer training. Finally, we evaluate our method on 14 real-world and 2 synthetic time series datasets. The experiments show that DARKER is 3\texttimes{",10.14778/3681954.3681996,2024,,ACM
Real Time Index and Search Across Large Quantities of GNN Experts for Low Latency Online Learning,"Online learning is a powerful technique that allows models to adjust to concept drift in dynamically changing graphs. This approach is crucial for large mobility-based companies like Grab, where batch-learning methods fail to keep up with the large amount of training data. Our work focuses on scaling graph neural network mixture of expert (MoE) models for real-time traffic speed prediction on road networks, while meeting high accuracy and low latency requirements. Conventional spatio-temporal and incremental MoE frameworks struggle with poor inference accuracy and linear time complexity when scaling experts, for the latter, leading to prohibitively high latency in model updates. To address this issue, we introduce the Indexed Router, a novel method that categorizes experts into a structured hierarchy called the indexed tree. This approach reduces the time to scale and search N number of experts from O(N) to O(log N), making it ideal for online learning under tight service level agreements. Our experiments show that these time savings do not compromise inference accuracy, and our Indexed Router outperforms state-of-the-art spatio-temporal and incremental MoE models in terms of traffic speed prediction accuracy on real-life GPS traces from Grab's database and publicly available records. In summary, the Indexed Router enables MoE models to scale across large numbers of experts with low latency, while accurately identifying the relevant experts for inference.",10.1145/3580305.3599893,2023,,ACM
Uncertainty-Aware Probabilistic Travel Time Prediction for On-Demand Ride-Hailing at DiDi,"Travel Time Estimation (TTE) aims to accurately forecast the expected trip duration from an origin to a destination. As one of the world's largest ride-hailing platforms, DiDi answers billions of TTE queries per day. The quality of TTE directly decides the customer's experience and the effectiveness of passenger-to-driver matching. However, existing studies mainly regard TTE as a deterministic regression problem and focus on improving the prediction accuracy of a single label, which overlooks the travel time uncertainty induced by various dynamic contextual factors. To this end, in this paper, we propose a probabilistic framework, ProbTTE, for uncertainty-aware travel time prediction. Specifically, the framework first transforms the single-label regression task to a multi-class classification problem to estimate the implicit travel time distribution. Moreover, we propose an adaptive local label-smoothing scheme to capture the ordinal inter-class relationship among soft travel time labels. Furthermore, we construct a route-wise log-normal distribution regularizer to absorb prior knowledge from large-scale historical trip data. By explicitly considering the travel uncertainty, the proposed approach not only improves the TTE accuracy but also provides additional travel time information to benefit downstream tasks in ride-hailing. Extensive experiments on real-world datasets demonstrate the superiority of the proposed framework compared with state-of-the-art travel time prediction algorithms. In addition, ProbTTE has been deployed in production at DiDi in late 2022 to empower various order dispatching services, and improves passenger and driver experiences significantly.",10.1145/3580305.3599925,2023,,ACM
MSDR: Multi-Step Dependency Relation Networks for Spatial Temporal Forecasting,"Spatial temporal forecasting plays an important role in improving the quality and performance of Intelligent Transportation Systems. This task is rather challenging due to the complicated and long-range spatial temporal dependencies in traffic network. Existing studies typically employ different deep neural networks to learn the spatial and temporal representations so as to capture the complex and dynamic dependencies. In this paper, we argue that it is insufficient to capture the long-range spatial dependencies from the implicit representations learned by temporal extracting modules. To address this problem, we propose Multi-Step Dependency Relation (MSDR), a brand new variant of recurrent neural network. Instead of only looking at the hidden state from only one latest time step, MSDR explicitly takes those of multiple historical time steps as the input of each time unit. We also develop two strategies to incur the spatial information into the dependency relation embedding between multiple historical time steps and the current one in MSDR. On the basis of it, we propose the Graph-based MSDR (GMSDR) framework to support general spatial temporal forecasting applications by seamlessly integrating graph-based neural networks with MSDR. We evaluate our proposed approach on several popular datasets. The results show that the proposed GMSDR framework outperforms state-of-the-art methods by an obvious margin.",10.1145/3534678.3539397,2022,,ACM
TrajLearn: Trajectory Prediction Learning using Deep Generative Models,"Trajectory prediction aims to estimate an entity’s future path using its current position and historical movement data, benefiting fields like autonomous navigation, robotics, and human movement analytics. Deep learning approaches have become key in this area, utilizing large-scale trajectory datasets to model movement patterns, but face challenges in managing complex spatial dependencies and adapting to dynamic environments. To address these challenges, we introduce TrajLearn, a novel model for trajectory prediction that leverages generative modeling of higher-order mobility flows based on hexagonal spatial representation. TrajLearn predicts the next k steps by integrating a customized beam search for exploring multiple potential paths while maintaining spatial continuity. We conducted a rigorous evaluation of TrajLearn, benchmarking it against leading state-of-the-art approaches and meaningful baselines. The results indicate that TrajLearn achieves significant performance gains, with improvements of up to ~40\% across multiple real-world trajectory datasets. In addition, we evaluated different prediction horizons (i.e., various values of k), conducted resolution sensitivity analysis, and performed ablation studies to assess the impact of key model components. Furthermore, we developed a novel algorithm to generate mixed-resolution maps by hierarchically subdividing hexagonal regions into finer segments within a specified observation area. This approach supports selective detailing, applying finer resolution to areas of interest or high activity (e.g., urban centers) while using coarser resolution for less significant regions (e.g., rural or uninhabited areas), effectively reducing data storage requirements and computational overhead. We promote reproducibility and adaptability by offering complete code, data, and detailed documentation with flexible configuration options for various applications.",10.1145/3729226,2025,,ACM
Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models,"Existing anomaly detection models for time series are primarily trained with normal-point-dominant data and would become ineffective when anomalous points intensively occur in certain episodes. To solve this problem, we propose a new approach, called DiffAD, from the perspective of time series imputation. Unlike previous prediction- and reconstruction-based methods that adopt either partial or complete data as observed values for estimation, DiffAD uses a density ratio-based strategy to select normal observations flexibly that can easily adapt to the anomaly concentration scenarios. To alleviate the model bias problem in the presence of anomaly concentration, we design a new denoising diffusion-based imputation method to enhance the imputation performance of missing values with conditional weight-incremental diffusion, which can preserve the information of observed values and substantially improves data generation quality for stable anomaly detection. Besides, we customize a multi-scale state space model to capture the long-term dependencies across episodes with different anomaly patterns. Extensive experimental results on real-world datasets show that DiffAD performs better than state-of-the-art benchmarks.",10.1145/3580305.3599391,2023,,ACM
T-DPSOM: an interpretable clustering method for unsupervised learning of patient health states,"Generating interpretable visualizations of multivariate time series in the intensive care unit is of great practical importance. Clinicians seek to condense complex clinical observations into intuitively understandable critical illness patterns, like failures of different organ systems. They would greatly benefit from a low-dimensional representation in which the trajectories of the patients' pathology become apparent and relevant health features are highlighted. To this end, we propose to use the latent topological structure of Self-Organizing Maps (SOMs) to achieve an interpretable latent representation of ICU time series and combine it with recent advances in deep clustering. Specifically, we (a) present a novel way to fit SOMs with probabilistic cluster assignments (PSOM), (b) propose a new deep architecture for probabilistic clustering (DPSOM) using a VAE, and (c) extend our architecture to cluster and forecast clinical states in time series (T-DPSOM). We show that our model achieves superior clustering performance compared to state-of-the-art SOM-based clustering methods while maintaining the favorable visualization properties of SOMs. On the eICU data-set, we demonstrate that T-DPSOM provides interpretable visualizations of patient state trajectories and uncertainty estimation. We show that our method rediscovers well-known clinical patient characteristics, such as a dynamic variant of the Acute Physiology And Chronic Health Evaluation (APACHE) score. Moreover, we illustrate how it can disentangle individual organ dysfunctions on disjoint regions of the two-dimensional SOM map.",10.1145/3450439.3451872,2021,,ACM
Improved Customer Lifetime Value Prediction With Sequence-To-Sequence Learning and Feature-Based Models,"The prediction of the Customer Lifetime Value (CLV) is an important asset for tool-supported marketing by customer relationship managers. Since standard methods based on purchase recency, frequency, and past profit and revenue statistics often have limited predictive power, advanced machine learning (ML) techniques were applied to this task in recent years. However, existing approaches are often not fully capable of modeling certain temporal patterns that can be commonly found in practice, such as periodic purchasing behavior of customers. To address these shortcomings, we propose a novel method for CLV prediction based on a combination of several ML techniques. At its core, our method consists of a tailored deep learning approach based on encoder–decoder sequence-to-sequence recurrent neural networks with augmented temporal convolutions. This model is then combined with gradient boosting machines (GBMs) and a set of novel features in a hybrid framework. Empirical evaluations based on real-world data from a larger e-commerce company and a public dataset from the domain of online retail show that already the sequence-based model leads to competitive performance results. Stacking it with the GBM model is synergistic and further improves accuracy, indicating that the two models capture different patterns in the data.",10.1145/3441444,2021,,ACM
Forecasting Interaction Order on Temporal Graphs,"Link prediction is a fundamental task for graph analysis and the topic has been studied extensively for static or dynamic graphs. Essentially, the link prediction is formulated as a binary classification problem about two nodes. However, for temporal graphs, links (or interactions) among node sets appear in sequential orders. And the orders may lead to interesting applications. While a binary link prediction formulation fails to handle such an order-sensitive case. In this paper, we focus on such an interaction order prediction problem among a given node set on temporal graphs. For the technical aspect, we develop a graph neural network model named Temporal ATtention network (TAT), which utilizes the fine-grained time information on temporal graphs by encoding continuous real-valued timestamps as vectors. For each transformation layer of the model, we devise an attention mechanism to aggregate neighborhoods' information based on their representations and time encodings attached to their specific edges. We also propose a novel training scheme to address the permutation-sensitive property of the problem. Experiments on several real-world temporal graphs reveal that TAT outperforms some state-of-the-art graph neural networks by 55\% on average under the AUC metric.",10.1145/3447548.3467341,2021,,ACM
CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining,"The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83\% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.",10.1145/3659597,2024,,ACM
HiGRN: A Hierarchical Graph Recurrent Network for Global Sea Surface Temperature Prediction,"Sea surface temperature (SST) is one critical parameter of global climate change, and accurate SST prediction is important to various applications, e.g., weather forecasting, fishing directions, and disaster warnings. The global ocean system is unified and complex, and the SST patterns in different oceanic regions are highly diverse and correlated. However, existing data-driven SST prediction methods mainly consider the local patterns within a certain oceanic region, e.g., El Nino region and the Black sea. It is challenging but necessary to model the global SST correlations rather than that in a specific region to enhance the prediction accuracy of SST. In this work, we proposed a new method called Hierarchical Graph Recurrent Network&nbsp;(HiGRN) to address the issue. First, to learn the dynamic and diverse local SST patterns of specific locations, we design an adaptive node embedding with self-learned parameters to learn various SST patterns. Then we develop a hierarchical cluster generator to aggregate the locations with similar patterns into regional clusters and utilize a graph convolution network to learn the spatial correlations among these clusters. Finally, we introduce a multi-level attention mechanism to fuse the local patterns and regional correlations, and the output is fed into a recurrent network to achieve SST predictions. Extensive experiments on two real-world datasets show that our method largely outperforms the state-of-the-art SST prediction methods. The source code is available at .",10.1145/3597937,2023,,ACM
"Algorithms in future capital markets: a survey on AI, ML and associated algorithms in capital markets","This paper reviews Artificial Intelligence (AI), Machine Learning (ML) and associated algorithms in future Capital Markets. New AI algorithms are constantly emerging, with each 'strain' mimicking a new form of human learning, reasoning, knowledge, and decisionmaking. The current main disrupting forms of learning include Deep Learning, Adversarial Learning, Transfer and Meta Learning. Albeit these modes of learning have been in the AI/ML field more than a decade, they now are more applicable due to the availability of data, computing power and infrastructure. These forms of learning have produced new models (e.g., Long Short-Term Memory, Generative Adversarial Networks) and leverage important applications (e.g., Natural Language Processing, Adversarial Examples, Deep Fakes, etc.). These new models and applications will drive changes in future Capital Markets, so it is important to understand their computational strengths and weaknesses. Since ML algorithms effectively self-program and evolve dynamically, financial institutions and regulators are becoming increasingly concerned with ensuring there remains a modicum of human control, focusing on Algorithmic Interpretability/Explainability, Robustness and Legality. For example, the concern is that, in the future, an ecology of trading algorithms across different institutions may 'conspire' and become unintentionally fraudulent (cf. LIBOR) or subject to subversion through compromised datasets (e.g. Microsoft Tay). New and unique forms of systemic risks can emerge, potentially coming from excessive algorithmic complexity. The contribution of this paper is to review AI, ML and associated algorithms, their computational strengths and weaknesses, and discuss their future impact on the Capital Markets.",10.1145/3383455.3422539,2021,,ACM
Time-Series Event Prediction with Evolutionary State Graph,"The accurate and interpretable prediction of future events in time-series data often requires the capturing of representative patterns (or referred to as states) underpinning the observed data. To this end, most existing studies focus on the representation and recognition of states, but ignore the changing transitional relations among them. In this paper, we present evolutionary state graph, a dynamic graph structure designed to systematically represent the evolving relations (edges) among states (nodes) along time. We conduct analysis on the dynamic graphs constructed from the time-series data and show that changes on the graph structures (e.g., edges connecting certain state nodes) can inform the occurrences of events (i.e., time-series fluctuation). Inspired by this, we propose a novel graph neural network model, Evolutionary State Graph Network (EvoNet), to encode the evolutionary state graph for accurate and interpretable time-series event prediction. Specifically, EvoNet models both the node-level (state-to-state) and graph-level (segment-to-segment) propagation, and captures the node-graph (state-to-segment) interactions over time. Experimental results based on five real-world datasets show that our approach not only achieves clear improvements compared with 11 baselines, but also provides more insights towards explaining the results of event predictions.",10.1145/3437963.3441827,2021,,ACM
Probabilistic framework for modeling event shocks to financial time series,"In financial market, certain types of stochastic events are intrinsically impactful to the prediction of financial times series, such as stock return, while few existing research attempts have been made to incorporate stochastic event modeling to time series modeling in a principled way. In this paper, we present a pioneering study that fills this gap. In particular, we introduce a generic probabilistic model that captures 1) the inter-dependencies among stochastic events, and 2) the impact of these events on time series. To this end, we extend multivariate Hawkes process (MHP) and proximal graphical event model (PGEM) and apply this framework to modeling two financial events, companies' quarterly revenue releases and updates of consensus prediction of quarterly revenue, and their impacts on the mean and correlation structures of future stock return. Our model not only improves prediction of financial time series, but also promotes AI trust for finance by revealing the causal relationship among the events. Extensive experimental results based on real financial market data validate the effectiveness of our models in learning event impact and improving investment decision by incorporating stochastic event impacts.",10.1145/3490354.3494407,2022,,ACM
"(Vision Paper) A Vision for Spatio-Causal Situation Awareness, Forecasting, and Planning","Successfully tackling many urgent challenges in socio-economically critical domains, such as public health and sustainability, requires a deeper understanding of causal relationships and interactions among a diverse spectrum of spatio-temporally distributed entities. In these applications, the ability to leverage spatio-temporal data to obtain causally based situational awareness and to develop informed forecasts to provide resilience at different scales is critical. While the promise of a causally grounded approach to these challenges is apparent, the core data technologies needed to achieve these are in the early stages and lack a framework to help realize their potential. In this article, we argue that there is an urgent need for a novel paradigm of spatio-causal research built on computational advances in spatio-temporal data and model integration, causal learning and discovery, large scale data- and model-driven simulations, emulations, and forecasting, as well as spatio-temporal data-driven and model-centric operational recommendations, and effective causally driven visualization and explanation. We thus provide a vision, and a road map, for spatio-causal situation awareness, forecasting, and planning.",10.1145/3672556,2024,,ACM
Identifying bad software changes via multimodal anomaly detection for online service systems,"In large-scale online service systems, software changes are inevitable and frequent. Due to importing new code or configurations, changes are likely to incur incidents and destroy user experience. Thus it is essential for engineers to identify bad software changes, so as to reduce the influence of incidents and improve system re- liability. To better understand bad software changes, we perform the first empirical study based on large-scale real-world data from a large commercial bank. Our quantitative analyses indicate that about 50.4\% of incidents are caused by bad changes, mainly be- cause of code defect, configuration error, resource contention, and software version. Besides, our qualitative analyses show that the current practice of detecting bad software changes performs not well to handle heterogeneous multi-source data involved in soft- ware changes. Based on the findings and motivation obtained from the empirical study, we propose a novel approach named SCWarn aiming to identify bad changes and produce interpretable alerts accurately and timely. The key idea of SCWarn is drawing support from multimodal learning to identify anomalies from heterogeneous multi-source data. An extensive study on two datasets with various bad software changes demonstrates our approach significantly outperforms all the compared approaches, achieving 0.95 F1-score on average and reducing MTTD (mean time to detect) by 20.4\%∼60.7\%. In particular, we shared some success stories and lessons learned from the practical usage.",10.1145/3468264.3468543,2021,,ACM
"Social Network Analysis: A Survey on Measure, Structure, Language Information Analysis, Privacy, and Applications","The rapid growth in popularity of online social networks provides new opportunities in computer science, sociology, math, information studies, biology, business, and more. Social network analysis (SNA) is a paramount technique supporting understanding social relationships and networks. Accordingly, certain studies and reviews have been presented focusing on information dissemination, influence analysis, link prediction, and more. However, the ultimate aim is for social network background knowledge and analysis to solve real-world social network problems. SNA still has several research challenges in this context, including users’ privacy in online social networks. Inspired by these facts, we have presented a survey on social network analysis techniques, visualization, structure, privacy, and applications. This detailed study has started with the basics of network representation, structure, and measures. Our primary focus is on SNA applications with state-of-the-art techniques. We further provide a comparative analysis of recent developments on SNA problems in the sequel. The privacy preservation with SNA is also surveyed. In the end, research challenges and future directions are discussed to suggest to researchers a starting point for their research.",10.1145/3539732,2023,,ACM
Modeling Temporal Patterns of Cyberbullying Detection with Hierarchical Attention Networks,"Cyberbullying is rapidly becoming one of the most serious online risks for adolescents. This has motivated work on machine learning methods to automate the process of cyberbullying detection, which have so far mostly viewed cyberbullying as one-off incidents that occur at a single point in time. Comparatively less is known about how cyberbullying behavior occurs and evolves over time. This oversight highlights a crucial open challenge for cyberbullying-related research, given that cyberbullying is typically defined as intentional acts of aggression via electronic communication that occur repeatedly and persistently. In this article, we center our discussion on the challenge of modeling temporal patterns of cyberbullying behavior. Specifically, we investigate how temporal information within a social media session, which has an inherently hierarchical structure (e.g., words form a comment and comments form a session), can be leveraged to facilitate cyberbullying detection. Recent findings from interdisciplinary research suggest that the temporal characteristics of bullying sessions differ from those of non-bullying sessions and that the temporal information from users’ comments can improve cyberbullying detection. The proposed framework consists of three distinctive features: (1) a hierarchical structure that reflects how a social media session is formed in a bottom-up manner; (2) attention mechanisms applied at the word- and comment-level to differentiate the contributions of words and comments to the representation of a social media session; and (3) the incorporation of temporal features in modeling cyberbullying behavior at the comment-level. Quantitative and qualitative evaluations are conducted on a real-world dataset collected from Instagram, the social networking site with the highest percentage of users reporting cyberbullying experiences. Results from empirical evaluations show the significance of the proposed methods, which are tailored to capture temporal patterns of cyberbullying detection.",10.1145/3441141,2021,,ACM
Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud,"Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.",10.1145/3626246.3653378,2024,,ACM
High-dimensional Multivariate Time Series Forecasting using Self-Organizing Maps and Fuzzy Time Series,"Machine learning models that follow the FTS (Fuzzy Time Series) approach stand out as data-driven non-parametric models of easy implementation and high accuracy, which can be applied to uni-variate and multivariate time series. However, this approach encounters difficulties when dealing with databases of many variables, given the explosion of rules that are generated for the construction of models. Usually filter and wrapper techniques (e.g. Boruta test) and data projection techniques (e.g. Principal Component Analysis) are used. The present work proposes a methodology for tackling this issue by projecting the original high-dimensional data into a low dimensional embedding space using self-organizing Kohonnen maps and later using the Weighted Multivariate FTS method (WMVFTS) for rule discovery and forecasting. The results obtained showed good values of RMSE and MAPE, illustrating the validity and potential of the method.",10.1109/fuzz45933.2021.9494496,2021,3,IEEE
Toward Digital Twin: Leveraging Pre-training Approaches for Multivariate Time Series Forecasting,"Time series forecasting has been an active research area, particularly in the context of Digital Twin (DT) systems. Despite the excellent results yielded by pre-trained models in Natural Language Processing (NLP) and Computer Vision (CV), only a few studies have researched pre-training strategies for time series forecasting networks within DT systems. Recent studies demonstrate that transfer learning across multiple time series datasets does not always provide promising results, making self-supervised pre-training directly on the downstream dataset a temporarily considered optimal solution. To the best of our knowledge, the only general pre-training task in the time series field is the Masked Autoencoder. However, this approach may lead to redundant representations for downstream forecasting within DT systems. Therefore, we propose three pre-training tasks specially designed for time series forecasting within DT frameworks: Inverse Forecasting (IF), Coarser Forecasting (CF), and Anomaly Forecasting (AF). These tasks are respectively designed to capture bidirectional dependency, reduce noise, and augment data, all crucial aspects in enhancing the predictive capabilities of DT systems. By integrating the three tasks, we obtain a composite pre-training task which generally improves the forecasting results of time series models within DT systems across multiple datasets. This work contributes to the ongoing efforts to improve the accuracy and efficiency of DT systems, paving the way for more robust and reliable digital representations of physical systems.",10.1109/iceict57916.2023.10245025,2023,2,IEEE
LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting,"Modern Internet of Things (IoT) systems generate massive, heterogeneous multivariate time series data. Accurate Multivariate Time Series Forecasting (MTSF) of such data is critical for numerous applications. However, existing methods almost universally employ a shared embedding layer that processes all channels identically, creating a representational bottleneck that obscures valuable channel-specific information. To address this challenge, we introduce a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into a shared base component capturing common patterns and channel-specific auxiliary components modeling unique deviations. Within this decomposition, we empirically observe that the auxiliary components tend to exhibit low-rank and clustering characteristics, a structural pattern that is significantly less apparent when using purely independent embeddings. Consequently, we design LightSAE, a parameter-efficient embedding module that operationalizes these observed characteristics through low-rank factorization and a shared, gated component pool. Extensive experiments across 9 IoT-related datasets and 4 backbone architectures demonstrate LightSAE’s effectiveness, achieving MSE improvements of up to 22.8% with only 4.0% parameter increase. Code is available at https://github.com/EDM314/LightSAE.",10.1109/jiot.2025.3631505,2025,,IEEE
Dwtformer: Wavelet decomposition Transformer with 2D Variation for Long-Term Series Forecasting,"Benefiting from the boom in deep learning and natural language processing, RNNs, CNNs and Transformers have significantly improved the accuracy of multivariate long time series prediction, which focus on how to discover the long-term dependence of long time series and how to capture the overall trend of time series. But They ignore the complex intrinsic features of the series (the characteristics of intra-period and inter-period variations). Based on the observation of the multi-periodicity of time series, this study extends the analysis of time series to a higher space by decomposing a complex 1D time series into a set of 2D tensors based on multiple frequencies. Through this transformation, we connect the time series prediction to the computer vision so we can get more effective techniques which can be employed to extract complex temporal variations from the transformed 2D tensors. To address these issues, this paper proposes to combine the Transformer with a wavelet decomposition-based 2D feature learning module. The 2D feature learning module captures the complex period variations of the time series and the Transformer captures the long-term historical details. To more fully learn the periodic features, this paper proposes Dwtformer by referring to the auto-correlation mechanism in Autoformer. Experiments on four benchmark datasets show that compared to state-of-the-art methods, Dwtformer can reduce multivariate time series prediction errors by 14.9%.",10.1109/itnec56291.2023.10082078,2023,3,IEEE
A Multistep Multivariate Fuzzy-Based Time-Series Forecasting on Internet of Things Data,"Multistep ahead time series forecasting is essential in Internet of Things (IoT) applications in smart cities and smart homes to make accurate future predictions and precise decision making. Thus, this study introduces a novel multiple-input single-output (MISO) forecasting method called Multistep Embedding-based fuzzy time series (MS-EFTS), designed to predict high-dimensional nonstationary time series data. As a first-order approach, it employs a direct strategy that integrates an embedding transformation with a weighted multivariate FTS (WMVFTS) model. This combination allows for effective predictions over long-term horizons within low-dimensional, learned continuous representations. The effectiveness of the proposed MS-EFTS is assessed using three high-dimensional IoT time series in this investigation. The obtained results showcase the superior performance of the proposed method compared to some deep learning forecasting methods, including LSTM, BiLSTM, TCN, and CNN-LSTM, in terms of accuracy, parsimony, and efficiency.",10.1109/jiot.2025.3549715,2025,2,IEEE
STNet: Spatial-Temporal Transformers are Effective for Multivariate Time Series Forecasting,"The recent boom of Transformer-based models have enhanced state-of-the-art results of multivariate time series (MTS) forecasting. However, MTS forecasting remains a challenging problem, primarily because of the intricate temporal patterns and obscured spatial correlations. Existing models are not only computationally expensive in modeling long-term temporal dependencies, but more importantly, fail to adequately capture the interrelations among variables. To address these problems, we propose STNet, a Spatial-Temporal Transformer Network with self-supervised pre-training scheme for MTS forecasting. In STNet, the MTS are formalized as a data-driven graph structure, which is learned through the training process to extract the latent patterns within the spatial dependencies of the data. Then we encode the structural information of the graph into the spatial Transformer encoder to help STNet better model refined spatial dependencies. A patch-level Transformer encoder is implemented to efficiently enhance locality and comprehensively capture semantic information pertaining to temporal dependencies. Moreover, the pre-training model generates rich contextual information, which consistently leads to reliable outcomes in transfer performance for downstream tasks. Extensive experiments conducted on five real-world benchmark datasets show the proposed STNet improves the prediction accuracy by 5.0%-25.2% compared to previous state-of-the-arts.",10.1109/ijcnn64981.2025.11228192,2025,,IEEE
RecVAE-GBRT: Memory-Fused XGBoost for Time-Series Forecasting,"Time series forecasting is a crucial task for control and decision in various fields. Recent efforts focus on integrating complex deep learning techniques, such as RNN or Transformer, into sequential models. However, these solutions are often criticized due to their excessive complexity. Inspired by the effectiveness of Gradient Boosted Regression Trees (GBRT) methods (such as XGBoost) on tabular datasets, this study proposes a hybrid method for time series forecasting. In this method, we design a memory mechanism for GBRT, namely, Recursive Variational AutoEncoder (RecVAE), which can generate compressed representations of historical sequences by recursively summarizing a section of input time series and preceding internal outputs into current internal outputs. This compensates for the limitation of the GBRT in incorporating long historical sequences for time series forecasting. The resulting memory-fused forecasting model, namely, RecVAE-GBRT, is tested on 4 real-world time series datasets. The results indicate that it generates competitive results compared to Transformer-based time series forecasting methods, all happening at the same level of computation efficiency or better.",10.1109/ijcnn60899.2024.10650508,2024,2,IEEE
Time Series Forecasting with Multi-scale Decomposition and Fourier Neural Operators,"Time series forecasting has a wide range of applications in weather forecasting, energy price prediction, and many other fields. However, real-world time series data are often inherently non-stationary, which makes modeling time series data challenging. Existing research methods typically use seasonal-trend decomposition to disentangle time series data, and then leverage Transformer and other model structures to learn complex, evolving temporal variations.However, we observe that single seasonal-trend decomposition is often insufficient, and time series data exhibit different pattern regularities at different sampling scales. To address this, we propose a novel method that performs multi-scale seasonal-trend decomposition and aggregates features from fine to coarse scales to fully exploit semantic information. Furthermore, we draw inspiration from ensemble learning and employ Fourier neural operator-based backbone networks at different scales, with the predictions from multiple scales aggregated as the final output prediction. Extensive experiments demonstrate that our proposed model achieves superior prediction performance than state-of-the-art models on multiple public datasets.",10.1109/cisat62382.2024.10695364,2024,,IEEE
Robust Time Series Contrastive Representation Learning via Explicit Seasonal-Trend Disentanglement,"We address universal self-supervised representation learning for time series under label scarcity and distribution shifts. A key challenge is that prevalent encode-then-decompose pipelines only implicitly separate seasonal and trend signals, which mixes noise across components and degrades robustness, especially with sudden jumps or stochastic movements. In this work, we propose an explicit, decomposition-aware contrastive framework: original time series are split via a Fourier transform into seasonal (high-frequency) and trend (low-frequency) components. Seasonality is modeled by a frequency-enhanced attention encoder with amplitude-induced augmentations; trend is captured by a tree-structured causal convolution encoder with random perturbations to handle non-stationary drift. The two views are trained contrastively and then fused with lightweight fine-tuning, delivering state-of-the-art accuracy, improved robustness to jumps, and interpretable attributions.",10.1109/access.2025.3621317,2025,,IEEE
Domain Generalization for Time-Series Forecasting via Extended Domain-Invariant Representations,"Time-series forecasting is crucial for IoT applications, but generalizing across domains is challenging due to distinct data distributions and dynamics. Most domain generalization methods work well for image processing and classification, but they struggle with time-series forecasting. This is because they solely learn domain-invariant representations of input data, ignoring variations in the output space across domains. This oversight can lead to inaccurate forecasts when outputs in new domains exhibit different distributions or temporal patterns. In this work, we present a new approach to improve the time-series forecasting model generalization by extracting domain-invariant representations from both input and output data. Experiments demonstrate the effectiveness of our approach, achieving significant improvements in forecasting accuracy across multiple test domains. Compared to state-of-the-art methods, our approach delivers up to an 8% increase in accuracy.",10.1109/aiot63253.2024.00031,2024,1,IEEE
IL-DiffTSF: Invertible Latent Diffusion for Probabilistic Time Series Forecasting,"Internet of Things (IoT) devices generate large volumes of time series data that are often volatile and complex, making probabilistic time series forecasting (TSF) essential for modeling the distribution of future outcomes. Recently, diffusion-based TSF methods have gained attention for their ability to learn complex distributions. However, they typically apply the diffusion process directly in the time domain, which may struggle to capture complex temporal dependencies, thus limiting the full potential of the diffusion process. Besides, they obtain probabilistic forecasts by sampling multiple plausible outcomes from the learned distribution, which is time-consuming and less effective. To solve these problems, we propose Invertible Latent Diffusion for probabilistic Time Series Forecasting (IL-DiffTSF), a novel approach based on a latent diffusion model. Specifically, we design an invertible latent projection between time series and latent space, where a conditional diffusion process is applied. This design ensures bidirectional consistency and minimal information loss, enabling more accurate TSF. Moreover, instead of sampling-based probabilistic forecasting, IL-DiffTSF represents uncertainties by directly learning a mapping from latent representations to prediction errors, achieving faster and more reliable uncertainty estimates. Experiments on univariate and multivariate benchmarks validate the efficiency and effectiveness of IL-DiffTSF. The code for this project is available at https://github.com/vanerkz/IL-DiffTSF.",10.1109/jiot.2025.3636872,2025,,IEEE
iBACon: imBalance-Aware Contrastive Learning for Time Series Forecasting,"Time series forecasting (TSF) has gained significant attention as a widely explored research area in diverse applications. Existing methods, which focus on improvements in the most common scenarios, focus little on performance in rare cases. Despite their scarce occurrences in the data, these rare samples are more challenging and easily overlooked by models, significantly contributing to the total loss. In this paper, we propose a novel approach (dubbed iBACon) that overcomes this limitation by employing imbalance-aware contrastive learning and trend-seasonal decomposition architecture, specifically designed to solve TSF. To this end, we first introduce the Input-Output Difference (IOD) metric as a pseudo-label and reveal the data imbalance phenomenon in TSF. This label continuity inherently provides a meaningful distance between targets, implying a similarity between nearby targets in both label and feature spaces. Based on this similarity, the proposed imbalance-aware contrastive loss aims to reshape feature embeddings to facilitate knowledge dissemination among challenging samples and learn specific predictive features. Finally, when combined with our trend-seasonal decomposition network, iBACon significantly improves TSF accuracy. Experiments show that iBACon enhances overall average accuracy and substantially improves the 1-3% most challenging samples.",10.1109/tkde.2025.3589693,2025,,IEEE
Data-driven Latent Graph Structure Learning for Diagnosis of Alzheimer’s Syndrome,"Complex systems often have a latent graph structure. Studying the underlying graph structure will help us to analyze the mechanisms of complex phenomena. However, it is a challenging problem to learn effective graph structures from the data and apply them to downstream tasks. In this paper, we propose an end-to-end graph learning approach for Alzheimer’s syndrome diagnosis based on functional magnetic resonance imaging (fMRI) data of brain regions, which is completely data-driven. The interactions between time-series of each brain region are represented as graph structures, and a multi-head attention mechanism is used to update the representations of the nodes. Then, the graph structures are obtained from the feature sampling of the edges. Finally, the learned graph structure is combined with the left-out time-series data features and the node prior to completing the classification task of the brain network. In comparison with the latest research methods, our approach achieves higher classification accuracy.",10.1109/icpr56361.2022.9956713,2022,,IEEE
SFLGNN: Power Load Forecasting Based on Spectral-Frequency Learning and Graph Neural Network,"With the continuous development of modern power systems, accurate power load forecasting has gradually become a key issue in energy management. Compared to deep learning models, existing statistical-based prediction models are not well suited to learn how to represent power load data and mine the rich information in the data. In addition, power load data needs to consider both intra-series temporal correlation and inter-series correlation. Recently, attempts have been made to capture both correlations simultaneously, but most of the studies capture only temporal correlations in the time domain and use predefined a priori as inter-sequence relationships. In this paper, SFLGNN (Spectral-Frequency Learning Based Graph Neural Network) is designed for power load forecasting. SFLGNN effectively solves the problem by capturing both variable correlation and inter-sequence correlation using graph neural networks, and extracts important features through CP decomposition with multi-attention mechanism. In addition, SFLGNN enhances representation learning through Spectral-Frequency Learning. We performed comparative experiments, ablation experiments, and hyper-parameter sensitivity experiments on our collected dataset. The experiments demonstrate the effectiveness of our proposed model in the power load forecasting task.",10.1109/iccs62594.2024.10795826,2024,,IEEE
Contrastive Representation Learning for Time Series via Compound Consistency and Hierarchical Contrasting,"In this paper, a novel contrastive representation learning framework for time series data is proposed. The framework is designed to learn general representations of time series at various semantic levels and is capable of transferring across different datasets. The framework incorporates two key components. Firstly, a hierarchical contrasting method is used to consider both the temporal and instance dimensions of the time series and captures information at different levels through maximum pooling at corresponding timestamps, enabling the model to learn fine-grained and multi-scale time-stamped representations for time series prediction tasks. Secondly, a compound consistency constraint is leveraged, which combines transformation consistency and temporal-frequency consistency, to effectively learn a universal representation of the time series, thereby ensuring its transferability across different datasets. Additionally, the framework considers both the temporal and frequency information of the time series, and uses an adaptive wavelet transform to obtain the frequency domain representation while maintaining temporal alignment, facilitating the contrast of temporal-frequency consistency. Finally, the proposed framework is evaluated through extensive experiments on time series prediction tasks and compared with existing models on four public datasets. The results show that the linear regressor trained with the representations learned by the proposed model outperforms existing time series prediction models in terms of prediction accuracy and transferability.",10.1109/ddcls58216.2023.10166246,2023,,IEEE
SimEXT: Self-supervised Representation Learning for Extreme Values in Time Series,"Forecasting extreme values in time series is an important but challenging problem as the extreme values are rarely observed even when a large amount of historical data is available. The modeling of extreme values requires a specific focus on estimating the tail distribution of the time series, whose statistical properties may differ from the distribution of its non-extreme values. To overcome this challenge, we present a novel self-supervised learning framework, SimEXT, to learn a robust representation of the time series that preserves the fidelity of its tail distribution. The framework employs a combination of contrastive learning and a reconstruction-based autoencoder architecture to facilitate robust representation learning of the temporal patterns associated with the extreme events. SimEXT also incorporates a wavelet-based data augmentation technique with a distribution-based loss function to prioritize the learning of extreme value distribution. We provide probabilistic guarantees on the wavelet-based augmentation that enables the wavelet coefficients to be perturbed during data augmentation without significantly altering the extreme values of the time series. Experimental results on real-world datasets show that SimEXT can effectively learn a robust representation of the time series to boost the performance of downstream tasks for forecasting block maxima values.",10.1109/icdm58522.2023.00119,2023,,IEEE
Representation Learning and Knowledge Distillation for Lightweight Domain Adaptation,"In industrial machine learning applications, insufficient data, lack of labeling, distribution shift between subsets, varying operational conditions, etc. result in poor generalizing performance by pre-trained neural network models across domains. In contrast to image detection tasks, time series dataset contain critical domain-specific characteristics that must be learned by the corresponding networks. Naively aligning the learned representations during the adaptation process increases the risk of losing these key information, thus resulting in poor performance. This paper proposes a lightweight domain adaptation method involving representation learning and knowledge distillation (RepLKD). A separate network is pre-trained to learn valuable information from the target data in its latent space with the help of a reconstructor. In the adaptation stage, we use maximum mean discrepancy to minimize the difference in distributions between the source and target latent space. Additionally, we implement knowledge distillation to encourage the target network to generate source-like latent embedding and penalize only when an upper-bound condition is not fulfilled to prevent over-regularization and loss of domain-specific features. Finally, we test our proposed method on 12 cross-domain scenarios with the C-MAPSS dataset and compare the efficacy of our method against existing literature methods.",10.1109/cai59869.2024.00214,2024,,IEEE
A Review for Pre-Trained Transformer-Based Time Series Forecasting Models,"Transformer-based models have proven their superiority against recurrent networks in time series forecasting. Enhancing transformer-based forecasting models via pretraining tasks is a novel approach in the literature. In this paper, we are reviewing the most recent papers about pretraining aspects of time series as well as pretraining tasks that are used in transformer-based architectures.",10.1109/itms59786.2023.10317721,2023,,IEEE
Improving Time-Series Classification Accuracy Based on Temporal Feature Representation Learning Using CRU-LSTM Autoencoder,"Time-series data consists of a sequence of observations recorded in chronological order, where the data changes over time. This type of data exhibits various characteristics, such as temporal volatility, trends, and seasonality. Recently, a new layer structure called Correlation Recurrent Units (CRU) has been proposed to capture not only temporal variability but also trends and seasonality in time-series data. In this study, we propose an end-to-end model that utilizes a CRU autoencoder to learn temporal feature representations and address time-series classification problems simultaneously. To validate the performance of our proposed model, we conducted comparative experiments using 30 time-series classification datasets from six different types. The experimental results showed that the proposed model outperformed the baseline models in 20 out of the 30 time-series datasets. This indicates that the proposed approach effectively captures various temporal features in time-series data and improves the performance of time-series classification tasks.",10.1109/cogmi58952.2023.00033,2023,1,IEEE
A Deep Learning Framework for Non-stationary Time Series Prediction,"In non-stationary time series, there are data bursts, which brings challenges to accurately predict data. This paper proposes a deep learning framework for non-stationary time series prediction. In this framework, the first-order and second-order difference and decomposition of the original time series are first made respectively, so as to generate five new time series, which are as the input of the framework. Then, a prediction model is constructed sequentially by GRU (gated recurrent unit) and FCN (fully-connected network) networks to predict and fit data. Finally, a two-stage training mode is designed, which first predicts the trend and component, and then fits with the cycle to produce the prediction data. The experiments are tested on the public air quality dataset, and the results show that our approach can accurately predict the non-stationary time series, especially overcomes the lag, and achieves better performance than typical statistics methods and deep learning models.",10.1109/cvidliccea56201.2022.9824863,2022,11,IEEE
MTAP-DK: Multivariate Time-Series Anomaly Prediction with Domain Knowledge,"Predicting anomalies of mobile equipment plays an important role in performing preventive maintenance, alleviating major economic losses and personal safety issues. Previous studies basically adopted data-driven models for anomaly prediction or detection of industrial equipment, ignoring the importance of domain knowledge. The domain knowledge can more accurately and theoretically capture the complex relationship among features. However, building the deep learning models incorporating domain knowledge is very difficult due to the following challenges. First, the domain knowledge is often different from the actual state of the equipment, so it is difficult to obtain knowledge information that conforms to the real situation. Second, domain knowledge is difficult to directly and effectively be applied to deep learning models due to its diverse representations. In this paper, we propose a Multivariate Time-Series Anomaly Prediction with Domain Knowledge (MTAP-DK) to address these issues. Specifically, we firstly propose a knowledge extraction module, which can extract the domain equations that conform to the actual situation with the domain knowledge and historical data. Secondly, we design a domain guidance module to guide and constrain the graph neural network from the knowledge level, to improve its capabilities to express the relationship among features. Thirdly, we predict future data based on the graph incorporating knowledge information. Finally, the prediction is reconstructed by the multi-scale convolution reconstruction method, and the abnormal information is inferred according to the reconstruction error.",10.1109/ijcnn55064.2022.9892923,2022,,IEEE
Characterizing Disease Spreading via Visibility Graph Embedding,"Gaining timely insights on real-world emergency events, such as infectious disease outbreaks, is critical for developing appropriate response strategies. In this work, we propose a data-driven approach to study the spreading dynamics of the global Covid-19 pandemic. Specifically, we aim to identify a set of most “similar” geographic regions as proxies for making predictions on a targeted location. Example predictions include the number of new cases, number of hospitalizations, and number of deaths. Such predictions can be made at different levels of regional granularities, including city, county, and state levels. Our approach starts by transforming regional time series into graph representations using the natural visibility graph (NVG) model in order to capture their intrinsic trends and properties. These graphs are then projected onto a common embedding space using graph-level network embedding techniques. Essentially, each time series is converted as a data point in a feature embedding space, where spatial proximity indicates similarity among time series. Given a targeted region, our approach can identify the most “relevant” geographic regions by finding its k-nearest neighbors in the embedding space. Subsequently, appropriate response strategies and policies (e.g., school shutdown, indoor dining restriction) can be adapted based on the success or failure experiences from relevant regions. Our approach will potentially provide valuable insights in mitigating the spreading of infectious disease.",10.1109/bigdata52589.2021.9671810,2021,,IEEE
A Large-Scale Ensemble Learning Framework for Demand Forecasting,"Demand forecasting is a crucial component of supply chain management for revenue optimization and inventory planning. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful ensemble framework capable of accurately predicting future demand for a diverse range of items. Forchestra consists of two parts: 1) base predictors and 2) a neural conductor. For a given time series, each base predictor outputs its respective forecast based on historical observations. On top of the base predictors, the neural conductor adaptively assigns the importance weight for each predictor by looking at the representation vector provided by a representation module. Finally, Forchestra aggregates the predictions by the weights and constructs a final prediction. In contrast to previous ensemble approaches, the neural conductor and all base predictors of Forchestra are trained in an end-to-end manner; this allows each base predictor to modify its reaction to different inputs, while supporting other predictors and constructing a final prediction jointly. We empirically show that the model size is scalable to up to 0.8 billion parameters ($\approx$400-layer LSTM). The proposed method is evaluated on our proprietary E-Commerce (100K) and the public M5(30K) datasets, and it outperforms existing forecasting models with a significant margin. In addition, we observe that our framework generalizes well to unseen data points when evaluated in a zeroshot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional ensemble approaches. The code is available at https://github.com/young-j-parld22-ICDM-Forchestra.",10.1109/icdm54844.2022.00048,2022,2,IEEE
CoGenT: A Unified Contrastive-Generative Framework for Time Series Classification,"Self-supervised learning (SSL) for multivariate time series mainly includes two paradigms: contrastive methods that excel at distinguishing between different examples, and generative approaches that learn the overall data distributions. While effective individually, their complementary potential remains unexplored. We propose a Contrastive-Generative Time series framework (CoGenT), the first framework to unify these paradigms through joint contrastive-generative optimization. Co-GenT addresses fundamental limitations of both approaches: it overcomes contrastive learning’s sensitivity to high intra-class similarity in temporal data while reducing generative methods’ dependence on large datasets. We evaluate CoGenT on six diverse time series datasets. The results show consistent improvements, with up to 59.2& and 14.27& F1 gains over standalone SimCLR and MAE, respectively. Our analysis reveals that the CoGenT preserves high accuracy while acquiring structural reliability. These findings establish a foundation for hybrid SSL in time series analysis. Code at https://github.com/DL4mHealth/cogent/.",10.1109/tai.2025.3637168,2025,,IEEE
From Uniform Models To Generic Representations: Stock Return Prediction With Pre-training,"The emergence of deep learning has cast new light on the century-old problem of stock return prediction. For single stock return prediction, incorporating peripheral data such as cross sectional information has become the de facto standard for target horizons denoted in hours and above. However, such approach is not directly applicable to predicting short-term stock returns due to their strong stochastic nature. Little has been reported in public domain on how to utilize the rich exogenous data in short-term scenarios effectively. We propose a representation learning solution based on a pretrain-finetune framework. To help models learn high-quality feature extractors, we further propose to use triplet loss as a novel pre-train task. We present a new sample selection criterion and three versions of triplet selection in this context: “easy sample”, “multiple samples”, and “hard sample”. Experiment results using the proposed method demonstrate significant improvement over standard approaches. We also share some insight on how to apply triplet loss effectively in the context of short-term stock return prediction. Specifically, we demonstrate that using regression labels to select triplets is more effective than using embedding similarity. The proposed training framework is model-agnostic and shows great performance improvements in various settings.",10.1109/ijcnn55064.2022.9892697,2022,3,IEEE
IProbeTrans: A Long-Term Series Forecasting Method Based on Self-Supervised Learning,"Long-term time series forecasting (LTSF) is essential for domains like meteorology and finance, requiring accurate predictions over many time points. While Transformer-based models have shown promise in capturing long-term dependencies, they face challenges due to potential information loss and quadratic scaling of time complexity, impacting efficiency. Thus, this work proposes a forecasting method called iProbTrans, which uses inverted embedding and probsparse self-attention to capture temporal representations and correlations between variables. It outperforms transformer-based methods on multivariate datasets, reducing MSE and MAE by 9.6% and 6.6%, respectively, compared to the FEDformer baseline. A self-supervised learning approach is proposed, decomposing time series into patches and applying random masking to reduce computational costs. This model, trained on mean squared error loss for mask reconstruction, improves upon supervised learning by reducing MSE and MAE by 26.3% and 27.5%. It excels in capturing long-term dependencies, enhancing generalization, and offers a solution to the limitations of Transformer-based methods in LTSF.",10.1109/acait63902.2024.11021826,2024,,IEEE
TimesFNP: Contrastive Learning for Financial Domain with Noise-Resilient Prediction,"Long-term time series forecasting is a long-standing research topic in financial scenarios. Recent studies have shown that Transformer models have great potential in time series forecasting. However, time series in financial scenarios contain complex noise disturbances. To address this issue, we propose a new framework called TimesFNP, which aims to improve the noise resistance of long-term time series forecasting in financial scenarios based on contrastive learning methods. Specifically, first, we introduce a noise-based data augmentation method to simulate the noise components in financial scenarios. Second, we fully consider the potential correlations between different companies in long-term time series forecasting tasks and represent the time series features at the company level. Remarkably, our framework demonstrates significant improvements over state-of-the-art algorithms in time series forecasting, achieving performance enhancements of at least $\mathbf{8. 5 7 \%}$ in MSE and $\mathbf{4. 4 2 \%}$ in MAE",10.1109/iccai66501.2025.00111,2025,,IEEE
Ranking Neighborhood and Class Prototype Contrastive Learning for Time Series,"Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. Existing contrastive learning methods conduct augmentations and maximize their similarity. However, they ignore the similarity of adjacent timestamps and suffer from the problem of sampling bias. In this paper, we propose a self-supervised framework for learning generalizable representations of time series, called $\mathbf {R}$Ranking n$\mathbf {E}$E ighborhood and cla$\mathbf {S}$Ss prototyp$\mathbf {E}$E contr$\mathbf {A}$Astive $\mathbf {L}$Learning (RESEAL). It exploits information about similarity ranking to learn an embedding space, ensuring that positive samples are ranked according to their temporal order. Additionally, RESEAL introduces a class prototype contrastive learning module. It contrasts time series representations and their corresponding centroids as positives against truly negative pairs from different clusters, mitigating the sampling bias issue. Extensive experiments conducted on several multivariate and univariate time series tasks (i.e., classification, anomaly detection, and forecasting) demonstrate that our representation framework achieves significant improvement over existing baselines of self-supervised time series representation.",10.1109/tbdata.2024.3495509,2025,1,IEEE
A Novel Approach of ESN Reservoir Structure Learning for Improved Predictive Performance,"This paper presents a novel method to enhance the predictive performance of the Echo State Network (ESN) model by adopting reservoir topology learning. ESNs are a type of Recurrent Neural Network (RNN) that have demonstrated considerable potential in various applications, but they can be challenging to train and optimize due to their random initialization. To improve the learning capabilities of ESNs and enhance their effectiveness in a broad range of predictive tasks, we utilize a structure learning algorithm. The proposed approach modifies the ESN reservoir's connectivity by applying techniques such as reversing, deleting, and adding new connections. We evaluate our proposal performance using both synthetic and real datasets, and our results indicate that it can substantially improve predictive accuracy compared to traditional ESNs.",10.1109/iscc58397.2023.10218132,2023,1,IEEE
Multivariate Time-Series Modeling and Forecasting With Parallelized Convolution and Decomposed Sparse-Transformer,"Many real-world scenarios require accurate predictions of time series, especially in the case of long sequence time-series forecasting (LSTF), such as predicting traffic flow and electricity consumption. However, existing time-series prediction models encounter certain limitations. First, they struggle with mapping the multidimensional information present in each time step to high dimensions, resulting in information coupling and increased prediction difficulty. Second, these models fail to effectively decompose the intertwined temporal patterns within the time series, which hinders their ability to learn more predictable features. To overcome these challenges, we propose a novel end-to-end LSTF model with parallelized convolution and decomposed sparse-Transformer (PCDformer). PCDformer achieves the decoupling of input sequences by parallelizing the convolutional layers, enabling the simultaneous processing of different variables within the input sequence. To decompose distinct temporal patterns, PCDformer incorporates a temporal decomposition module within the encoder–decoder structure, effectively separating the input sequence into predictable seasonal and trend components. Additionally, to capture the correlation between variables and mitigate the impact of irrelevant information, PCDformer utilizes a sparse self-attention mechanism. Extensive experimentation conducted on five diverse datasets demonstrates the superior performance of PCDformer in LSTF tasks compared to existing approaches, particularly outperforming encoder–decoder-based models.",10.1109/tai.2024.3410934,2024,,IEEE
Grouped Graph Neural Networks for Anomaly Detection in Time Series,"Anomaly detection in time series data (e.g., sensor data) is becoming a fundamental research problem that has various applications. Due to the complex inter-sensor relationships, it is challenging to detect anomalous events such as system faults and attacks hidden the high-dimensional time series. Recent advancements in deep learning approaches such as Graph Neural Networks (GNN) have greatly improved anomaly detection performance in time series data. However, existing methods do not learn the dependence relationships between sensors and groups of sensors and may not efficiently detect anomalous events in time series. In this paper, we propose a novel approach GGNN (short for Grouped Graph Neural Networks) that combines a structure learning approach with graph neural networks. In particular, GGNN learns the graph structure containing groups of sensors, which are represented by virtual nodes. In addition, we use the learned graph structure and attention weights to explain the detected anomalies. The experiments on three real world datasets show our superiority in detection accuracy, anomaly diagnosis, and model interpretation compared with state-of-the-art methods.",10.1109/ijcnn60899.2024.10649927,2024,1,IEEE
Scaling Up Multivariate Time Series Pre-Training with Decoupled Spatial-Temporal Representations,"Data scale has been acknowledged as a crucial factor for enhancing the generalization and effectiveness of pre-training models. While existing methods of multivariate time series pre-training are primarily limited to a single specific dataset, scaling to a larger scenario that includes multiple diverse datasets (e.g., multi-region data) remains a substantial challenge. In this paper, we present a novel Decoupled Spatial-Temporal Representation Learning (DeSTR) framework to serve as the backbone network for investigating the data scaling capability of multivariate time series pre-training architectures. Specifically, DeSTR utilizes two separate encoders to capture both the temporal dynamics within each time series and the spatial correlations among multiple variables. The obtained representations of distinct modalities are then fed into a Spatial-Guided Temporal Transformer to equip the temporal features with spatial discriminative information. Moreover, we employ masked autoencoding as the foundational pre-training framework and introduce spacetime-agnostic augmentation to improve robustness and facilitate implicit spatiotemporal modeling. Finally, we successfully pre-train a unified time series representation learning framework on real-world datasets from three different cities. Extensive experiments are carried out on various downstream tasks to validate the performance of DeSTR, compared with three categories of state-of-the-art baselines: deep sequential models, spatial-temporal graph neural networks, and time series representation learning methods. The results clearly demonstrate the advantages of scaling multivariate time series pre-training to multiple datasets, highlighting the effectiveness of DeSTR as a general spatiotemporal learner.",10.1109/icde60146.2024.00057,2024,5,IEEE
Hybrid Deep Learning and XGBoost Models for Enhanced Energy Forecasting: A Comparative Analysis,"Energy forecasting is vital for the optimization of power distribution and, subsequently, the management of grids. This paper examines a range of time series forecasting approaches for energy data that include classical statistical methods (ARIMA), gradient boosting-XGBoost, deep learning architectures (CycleNet, xLSTMTime), and the novel hybrid combinations proposed. Using a comprehensive dataset from the U.S. Energy Information Administration (125,000 records over two years), we implement and compare such models over several performance metrics. Our novel contribution is a weighted ensemble methodology that optimal combines deep learning and gradient boosting predictions. The proposed hybrid model combines XGBoost and LSTM predictions and therefore achieves a $\mathrm{R}^{2}$ score of 0.9842 (0.9821-0.9863), 5.3% improvements in RMSE compared to the isolated modeling and 3.7% over current benchmarks. This work further proves while deep learning is clearly adept at grasping temporal dependencies, gradient boosting brings a good deal to the picture when used in an integrated modality due to their multifactorial advantages. The applicability and practicability of hybrid models by means of a detailed analysis of computational efficiencies and deployment considerations.",10.1109/temsconglobal64363.2025.11238333,2025,,IEEE
A Neural Network Architecture for Spatiotemporal PM2.5 Forecasting,"PM2.5 concentrations have been increasing at an alarming rate, making it critical to precisely estimate their regional and temporal distributions. The task is complicated by the non-linear property of PM2.5 and the large number of geological and climatic elements that influence PM2.5 concentrations, as well as the difficulty inherent in modelling their varying spatiotemporal association. Conventional physical and statistical forecasting techniques fail at incorporating several variables and discovering intricate correlations, essential for reliable predictions. This paper proposes a graph neural network capable of modelling PM2.5 concentrations on real-world data by leveraging PM2.5 transport, domain knowledge and considering spatial correlation, by reworking PM2.5 historical data, meteorological and weather forecast data into graph data and employing graph isomorphism networks, similar to the Weisfeiler Lehman graph isomorphism test for powerful graph representation learning, an attention mechanism, and a dedicated recurrent neural network to model temporal distributions, to provide accurate forecasting.",10.1109/ic3sis54991.2022.9885669,2022,,IEEE
Research on Financial Time Series Risk Assessment Model Based on Computer Deep Learning,"Financial risk assessment plays a crucial role in the financial market, as it enables risk quantification and management, further risk identification and warning, and provides reference for investment decision support and systematic risk prevention. In the current trend of big data, it has become possible to collect a large amount of financial time series data, which contains a lot of useful features that need to be mined and analyzed. Therefore, based on the research of multivariate financial time series, this article proposes a financial time series risk identification method based on GCN-LSTM-CLUSTING. Specifically, we perform patch segmentation on multivariate time series to extract relationships between different patch nodes using GCN, followed by extracting long time series dependencies using LSTM, and utilizing end-to-end regression models to extract features from small time series. Finally, clustering methods are used to cluster the potential features of the time series and identify anomalous financial time series. The experimental results show that the method proposed in this paper has a good recognition rate and can effectively identify abnormal financial time series.",10.1109/icmiii62623.2024.00088,2024,,IEEE
GRL-ITransformer: An Intelligent Method for Multi-Wind-Turbine Wake Analysis Based on Graph Representation Learning With Improved Transformer,"The importance of examining the wake effect of wind farms for optimizing their layout and augmenting their power generation efficiency is immense. Considering that the establishment of extensive wind farms often leads to a significant number of turbines being positioned downstream of preceding ones, it significantly diminishes their power generation efficiency. In our study, we propose a graph representation learning model with improved Transformer (GRL-ITransformer) to better integrate feature information, so that the model can capture the dynamic time relationship of different variables and establish its spatial relationship, striving to enhance the precision in predicting wind turbine wake field. Different from the previous way involving handling reduced-order and separating prediction process, we combine the reduced-order technique with the proposed model to make the model more efficiently and intelligently determine the number of modes required for model prediction. After that, the data driven method is employed to update the parameters, and the superiority of GRL-ITransformer is highlighted by analyzing and comparing with the existing five classical intelligent algorithms (belongs to four categories). The comprehensive results show that GRL-ITransformer has excellent performance in wind turbine wake field prediction and reconstruction, and always possesses the lowest error for a series of error evaluation indexes among all models.",10.1109/access.2025.3549035,2025,,IEEE
Empowering PHM Applications with Time Series Foundation Models: A Unified Multi-Task Learning Approach,"Currently, small, task-specific models dominate the development of Prognostics and Health Management (PHM) applications. However, these isolated models often struggle to address the diverse and fragmented requirements present in real industrial environments. The emergence of time-series foundation models has attracted considerable attention, providing a more flexible and effective approach for PHM applications. This study explores how time-series foundation models can enhance PHM applications. Using a typical aero-engine degradation dataset as the research context, we propose a novel unified multi-task learning approach that leverages pre-trained time-series foundation models. Specifically, we utilize these foundation models as the basis for time-series representation learning to tackle various PHM tasks. To accommodate the diverse requirements of these tasks, we design specialized output heads tailored for multi-task learning objectives. The pre-trained foundation model is then fine-tuned with specific datasets to develop localized task-specific models. We validate our approach through case studies using the C-MAPSS datasets. The experimental results demonstrate the feasibility and effectiveness of foundation models for the development of PHM applications.",10.1109/case58245.2025.11163911,2025,,IEEE
Earthquake Magnitude Prediction using Spatia-temporal Features Learning Based on Hybrid CNN- BiLSTM Model,"Earthquakes are a very catastrophic natural event that occurs due to sudden changes in the earth's crust, leading to human, financial, and environmental losses in society. Therefore, employing an efficient and dependable method for earthquake prediction can significantly reduce casualties. In this regard, we proposed a deep neural network called the hybrid convolutional neural network and bi-directional long-short-term memory (HC-BiLSTM) to predict the mean magnitude of the future earthquake in a specific area of Japan. To achieve this goal, we suggest a strategy based on four key steps: the division of areas, the preprocessing, the spatial and temporal feature learning, and the prediction. In the division of areas step, The part of Japan is divided into 49 smaller areas to better predict the next earthquake's location. The preprocessing step uses the zero-order hold method in the time series of the mean magnitude of the earthquake. In the next step, the learning spatial and temporal characteristics between earthquake data include three layers of CNN and pooling and two layers of LSTM. Finally, the prediction step has two fully connected layers that combine information supplied by HC-BiLSTMs to predict the mean magnitude for the earthquake next month. As a result, using a comparative method, this study demonstrates the superiority of the proposed method over other common earthquake prediction methods.",10.1109/icspis54653.2021.9729358,2021,12,IEEE
NRL4AQF: Noise-Resistant Learning for Long-Sequence Air Quality Forecasting using Cross-Time Embedding,"Recently, deep learning (DL) has greatly advanced data analysis, including time-series forecasting. Recurrent neural networks (RNNs) are commonly used for DL-based forecasting, but they face limitations in capturing complex, long-range dependencies, especially with cross-dimensional input data. To address these challenges, transformer-based architectures have been introduced, offering improved performance for long-range predictions. However, they still struggle with modeling long input sequences and managing noise in temporal feature learning. To overcome these issues, we propose the NRL4AQF (Noise-Resistant Learning for Air Quality Forecasting) model, a novel denoising transformer-based approach for time-series forecasting. By combining cross-dimensional transformer-based embeddings with a radial basis function neural network (RBFNN), NRL4AQF effectively reduces noise and captures more accurate temporal patterns. Applied to long-sequence air quality forecasting, the model achieves superior results compared to traditional and state-of-the-art DL techniques, as demonstrated by experiments on a real-world dataset.",10.1109/atc63255.2024.10908270,2024,1,IEEE
Is Single Enough? A Joint Spatiotemporal Feature Learning Framework for Multivariate Time Series Prediction,"A fuzzy cognitive map (FCM) is a simple but effective tool for modeling and predicting time series. This article focuses on the problem of multivariate time series prediction (TSP), which is essential and challenging in data mining. Although several FCM-based approaches have been designed to solve this problem, their feature extraction module designed for single mode falls short in capturing the nonlinear spatiotemporal dependencies among variates, thereby resulting in low prediction accuracy in forecasting multivariate time series, which shows that the single mode learning is not enough. Therefore, in this article, we propose a joint spatiotemporal feature learning framework for multivariate TSP, where a mix-resolution spatial module consisting of multiple sparse autoencoders (SAEs) is designed to extract the feature series with different spatial resolutions, and a mix-order spatiotemporal module concluding multiple high-order FCMs (HFCMs) is designed to model the spatiotemporal dynamics of these feature series. Finally, the outputs of the two modules are concatenated to predict future values. We refer to this framework as the spatiotemporal FCM (STFCM). Especially, an efficient learning algorithm is designed to update the integral weights of STFCM based on the batch gradient descent algorithm when it deems necessary. We validate the performance of the STFCM on four real-world datasets. Compared with the existing state-of-the-art (SOTA) methods, the experimental results not only show the advantages of the two designed modules in the STFCM but also show the excellent performance of the STFCM.",10.1109/tnnls.2022.3216107,2024,14,IEEE
A Survey on Time-Series Pre-Trained Models,"Time-Series Mining (TSM) is an important research area since it shows great potential in practical applications. Deep learning models that rely on massive labeled data have been utilized for TSM successfully. However, constructing a large-scale well-labeled dataset is difficult due to data annotation costs. Recently, pre-trained models have gradually attracted attention in the time series domain due to their remarkable performance in computer vision and natural language processing. In this survey, we provide a comprehensive review of Time-Series Pre-Trained Models (TS-PTMs), aiming to guide the understanding, applying, and studying TS-PTMs. Specifically, we first briefly introduce the typical deep learning models employed in TSM. Then, we give an overview of TS-PTMs according to the pre-training techniques. The main categories we explore include supervised, unsupervised, and self-supervised TS-PTMs. Further, extensive experiments involving 27 methods, 434 datasets, and 679 transfer learning scenarios are conducted to analyze the advantages and disadvantages of transfer learning strategies, Transformer-based models, and representative TS-PTMs. Finally, we point out some potential directions of TS-PTMs for future work.",10.1109/tkde.2024.3475809,2024,40,IEEE
CATS: Contrastive learning for Anomaly detection in Time Series,"Anomaly detection (AD) plays a critical role in a wide variety of big data applications, including cybersecurity, monitoring, and network systems. It consists in finding patterns in time series data that indicate unexpected events such as faults or defects. Traditional AD approaches, predominantly based on reconstruction techniques, often yield suboptimal performance, particularly when anomalies are present in the training set. Conversely, contrastive learning (CL) has shown significant performance in image processing tasks and is increasingly applied in time series data classification and forecasting. However, traditional CL frameworks are not well-adapted for time series AD due to two key challenges. First, AD is typically performed only on normal instances, and thus CL does not benefit from knowledge about anomalous instances. Second, the temporal nature of time series data is often neglected when computing time series similarity, thereby hindering the effective learning of time series representation.To overcome these limitations, we propose CATS, a novel approach that leverages a temporal similarity measure to learn time series representations. Moreover, through negative data augmentation, CATS generates a more realistic distribution of anomalies, which enables anomaly-informed CL. Extensive experiments conducted on six real-world datasets demonstrate that CATS outperforms existing AD methods. Our results highlight the efficacy of CATS in enhancing time series AD performance in big data environment across various application domains.",10.1109/bigdata62323.2024.10825476,2024,1,IEEE
Intraday Wind Power Forecasting by Ensemble of Overlapping Historical Numerical Weather Predictions,"The numerical weather prediction (NWP) is crucial to improve intraday wind power forecasting (WPF) accuracy. However, conventional WPF methods relied solely on a latest reported single NWP, overlooking hidden information from sequentially reported multiple historical NWPs that are partially overlapped over time. Additionally, it's challenging to tackle intraday WPF as it involves both ultra-short-term and short-term horizons with different characteristics. Therefore, a novel spatio-temporal representation learning network is proposed for intraday WPF by ensemble of overlapping historical NWPs. Initially, an integrated mask-reconstruction representation learning pretraining strategy is employed to extract hidden representations of historical wind power measurements and overlapping historical NWPs, providing contextual information for the subsequent intraday WPF task. Then, the output layer is trained and end-to-end fine-tuning of the entire network is conducted to adapt to the specific forecasting task. Moreover, a multi-task learning strategy based on hard parameter sharing is adopted to ensure balanced predictive accuracy across each of forecasted wind farms. Case study and detailed ablation tests based on 5 real-world wind farms demonstrate that the proposed method enhances the forecasting accuracy of most wind farms by leveraging spatio-temporal correlation, achieving the best average performance across all time horizons compared to the baseline models.",10.1109/tste.2024.3521384,2025,2,IEEE
Self-Supervised Generative Pre-Trained Model with a Learnable Mask Network for Industrial Time Series Prediction,"Industrial time series prediction (ITSP) is an indispensable part of predictive control in modern industry. Recently, supervised deep learning-based methods have provided solutions with sufficient annotated data. However, there is massive unlabeled data with complex temporal features in modern industrial production, resulting in poor performance of these methods. To address this problem, a self-supervised generative pre-trained model with a learnable mask network (SSGPM-LMN) is proposed in this paper. First, the multivariate time series are made into patches channel-independently. Then, these patches are fed into a Transformer encoder with the learnable mask-reconstruction paradigm, drawing mask indices with high temporal features by calculating the cosine similarity in low-dimensional feature space to better learn general representations. Furthermore, a two-step fine-tuning strategy, including linear probing and full fine-tuning, is adopted for various downstream scenarios. Finally, extensive experimental results on case studies of ITSP and transfer learning indicate that our SSGPM-LMN achieves superior performance.",10.1109/smc54092.2024.10831502,2024,,IEEE
Self-Supervised Time Series Classification Method Based on FRFT Cross-Channel Fusion,"Recently, self-supervised representation learning has been widely applied to various time series tasks (e.g., electric device classification). However, building models for large-scale time series classification remains challenging due to the high cost of labeling time series data, which requires specialized expertise. Additionally, many datasets consist solely of unlabeled data or contain only a small number of labeled samples. Existing solutions for traditional time series tasks are not directly applicable to modern complex temporal problems due to two unique characteristics: (i) long-term temporal dependencies and (ii) complex cross-channel interactions. To address these challenges, we propose TC-FrC, a self-supervised time series classification model that leverages seasonal-trend decomposition for data augmentation and incorporates contrastive losses based on both temporal features and the Fractional Fourier Transform (FRFT). Specifically, we: (i) design a sparse attention mechanism within the temporal contrastive module to enhance feature extraction and improve robustness in long-term time series data, (ii) introduce a seasonal-trend decomposition approach to mitigate inter-class feature confusion, and (iii) develop a cross-channel FRFT-based feature fusion module, which transforms contextual features from the time domain to the fractional domain. We extensively evaluate TC-FrC on seven publicly available datasets, including HAR, Sleep-EDF, and Epilepsy, among others. Experimental results demonstrate that our method outperforms state-of-the-art baselines across various evaluation metrics.",10.1109/ijcnn64981.2025.11229038,2025,,IEEE
Adaptive Graph Convolution Neural Differential Equation for Spatio-Temporal Time Series Prediction,"Multivariate time series prediction has aroused widely research interests during decades. However, the spatial heterogeneity and temporal evolution characteristics bring much challenges for high-dimensional time series prediction. In this paper, a novel adaptive graph convolution module is introduced to automatically learn the spatial correlation of multivariate time series and a Koopman-based neural differential equation is proposed to simulate the nonlinear system state evolution. In detail, the correlation between multivariate time series is revealed by the consine similarity of node embedding to infer the potential relationship between nodes and the spatio-temporal feature fusion module is utilized. The LSTM-based network is adopted as Koopman operator to reveal the latent states of spatio-temporal time series and the reversible assumption is imposed on the Koopman operator. Furthermore, the Euler-trapezoidal integration are utilized to simulate the temporal dynamics and multiple-step prediction is carried out in the latent space from the perspective of dynamical differential equation. The proposed model could explicitly discover the spatial correlation by adaptive graph convolution and reveal the temporal dynamics by neural differential equation, which make the modeling more interpretable. Simulation results show the effectiveness on spatio-temporal dynamic discovery and prediction performance.",10.1109/tkde.2024.3383895,2025,3,IEEE
Research on Commodities Constraint Optimization Based on Graph Neural Network Prediction,"Business intelligence makes good sale prediction crucial in any commercial activity as it has a significant impact on production and supply plan. However, practical commercial data presents explicit constraints, that how to get the optimal forecasts of commodity sales under the constraints is a vital problem many researchers face. The present research proposes a prediction model which combines graph convolution neural network and node bipartite graph. Firstly, the node bipartite graph algorithm is used to merge the constraint graph and the store graph, obtaining the “store-constraint bipartite graph”. Secondly, a graph convolutional neural network integrating GRU and AR is utilized to extract temporal features (X). Finally, a fully connected network is applied to predict the optimal solution (Y) after constraint optimization. The former can effectively learn complex features of stores, meanwhile, the later combines the constraint conditions with the store, which can effectively predict the sales of goods under the constraint conditions. In terms of model performance, we compared the proposed model with the classical method such as SVR, LSTM, ARIMA. RMSE, MSE, MAE and MAPE are used for evaluation indexes, and the results show that MAPE for one month’s sales of some product from both datasets is 7.75%.",10.1109/access.2023.3302923,2023,1,IEEE
SMCL: Towards Semi-Supervised Automatic Modulation Recognition via Semantic Mask Contrastive Learning,"Automatic modulation recognition (AMR) is essential for ensuring the physical-layer security for Internet of things (IoT) networks. Despite advancements in deep learning, most current AMR methods rely heavily on a large number of labeled samples to achieve high recognition accuracy. However, acquiring labeled samples can be costly and impractical in many real-world scenarios due to privacy concerns and economic constraints. In contrast, unlabeled data is often abundant and readily available. This paper presents a novel semi-supervised AMR framework that addresses the challenge of label scarcity by leveraging semantic mask contrastive learning (SMCL). Through a self-supervised modulation semantic mask contrastive prediction task within IQ sequence, our method learns subtle modulation features directly from unlabeled radio signals. It is important to note that SMCL requires neither data augmentation nor representation domain transformation. Sufficient experiments on public datasets have demonstrated our method outperforms existing semi-supervised and supervised methods when using the same number of labeled samples. SMCL effectively enables the representation learning of unlabeled radio signals, overcoming the limitations posed by the lack of sufficient labeled data and providing a solid technical foundation for the development of signal-based IoT large language models (IoT-LLMs).",10.1109/jiot.2025.3630897,2025,,IEEE
A Multilevel Deep Fusion Framework for FeO Content Prediction in Sintering Process,"Iron ore sintering is a critical procedure in steel production, and the content of ferrous oxide (FeO) in the finished sinter directly reflects sintering quality. This key indicator is commonly obtained by data-driven soft sensor modeling technology. However, existing methods struggle to fully utilize the multisource and heterogeneous characteristics of the sintering dataset, and this may limit the improvement of FeO prediction accuracy. To address this issue, this paper proposes a multilevel deep fusion framework (MDFF) for detecting FeO content in the sintering process. This novel framework integrates a multilevel fusion of multisource heterogeneous data, i.e., data-level, feature-level, and decision-level. First, shallow features are extracted from images based on expert experience for data-level fusion. Then, multiscale encoding network and shared representation learning network are used for feature extraction and fusion. Finally, the prediction results of shared representations and modality-specific features are combined at the decision level to realize real-time sensing of FeO content. The proposed MDFF fully exploits the intrinsic correlations between multisource information at multiple levels, and experimental results on real sintering datasets further prove its accuracy and stability.",10.1109/cac63892.2024.10864891,2024,,IEEE
Energy usage prediction with ensemble graph convolutional recurrent neural networks: case study of Greek islands,"This study investigates the use of graph convolutional and recurrent neural networks to forecast energy consumption on five Greek islands. The model is trained on historical energy usage data, using graph convolutional networks (GCNs) with graphs constructed from power production and their geographical location which their results are averaged. The evaluation metrics mean absolute error (MAE), mean squared error (MSE), and mean absolute percentage error (MAPE) were utilised to measure the accuracy of the proposed prediction algorithms. The results show that all the suggested EGCRNN models with LSTM, Bi-LSTM, and GRU demonstrated excellent performance, strong model fit, and enhanced predictions of energy consumption. In particular, models which utilise long-short term memory (LSTM) and gated recurrence units (GRU) followed with better prediction in one model each, Thira and Rhodes, respectively.",10.1049/icp.2024.4680,2024,,IEEE
Multi-attention based Feature Embedding for Irregular Asynchronous Time Series Modelling,"Forecasting time series values based on historic covariates has been an active area of research in statistics and machine learning. With the availability of computation resources and big data infrastructure supporting massive volume, velocity and variety, the algorithms have evolved from classic statistical learning to neural-network driven loss minimisation techniques. While state of the art attention and self-attention-transformers have shown promise of improved performance with sufficient training data, most of them fail to generalise to different problems of time-series modelling (such as classification and extremum forecasting) with asynchronously sampled covariates. This paper introduces the concept of a generalised time series embedding and transfer learning for time series (analogous to token-to-vector or image-to-vector embeddings in language and vision models respectively) that allow joint training with a unified interface. The major benefit of this work is a unified embedding model employing multi-attention for feature representation which enables benchmark performance against state of the art models from recent literature.",10.1109/iecon51785.2023.10312633,2023,,IEEE
Kolmogorov—Arnold Networks: Overview of Architectures and Use Cases,"Kolmogorov-Arnold Networks (KANs) are an emerging class of neural network architectures grounded in the Kolmogorov-Arnold representation theorem, offering a sym-bolic and interpretable approach to modeling complex, high-dimensional functions. By replacing traditional activation functions with learnable univariate splines, KANs deliver enhanced expressiveness, parameter efficiency, and transparency. This survey provides a comprehensive overview of KAN developments, including foundational designs and specialized variants tailored to time series, graphs, scientific computing, image analysis, and biomedicine. We highlight the strengths of KANs in bridging the gap between symbolic reasoning and data-driven learning, while also discussing challenges such as computational overhead and spline optimization complexity. Through detailed architec-tural taxonomy and real-world application examples, this paper positions KANs as a compelling framework for interpretable, high-performance machine learning.",10.1109/iccsc66714.2025.11135248,2025,,IEEE
AI-based Gas Turbine Multi-Component Health Prognosis via Recurrent Expansion of Gas Path Parameters,"Investigating Gas Turbine (GT) degradation based on Gas Path Parameters (GPPs) is essential for its maintenance and operation. Monitoring GPPs is crucial for early detection of degradation, enabling timely maintenance interventions and preventing potential failures. Integrating physics-based thermodynamic models with representation learning significantly improves predictive maintenance studies and provides a solution to challenges posed by expensive and impractical accelerated aging experiments. However, this integration also presents challenges in managing both data complexity and data drift. In this context, this article aims to address these gaps by extending and improving previous research through (i) exclusive use of GPPs; (ii) the implementation of advanced data preprocessing techniques; and (iii) the use of innovative representation learning strategies. Specifically, it introduces ProgMachina, a tool for data quality analysis in prognosis studies that addresses issues related to data complexity in GPPs. Furthermore, to diversify the feature space and improve the adaptability of representation learning to degradation patterns, this paper proposes using Multiverse Recurrent Expansion with Multiple Repeats (MV-REMR) approach, which is based on a series of Recurrent Neural Networks (RNNs). For evaluation, this study incorporates cross-validation and multiple metrics while comparing against multiple RNNs and state-of-the-art works, demonstrating stable and promising performance, making it a suitable choice for GT prognosis tasks.",10.1109/iccad60883.2024.10554011,2024,2,IEEE
Multivariate Time-Series Anomaly Detection Based on Dynamic Graph Neural Networks and Self-Distillation in Industrial Internet of Things,"Time-series anomaly detection is critical to securing the Industrial Internet of Things (IIoT). Although numerous deep learning-based methods have been proposed, these methods fail to consider the interdependencies between different dimensions of the data and often neglect the dynamic changes in these dependencies. Moreover, these methods utilize only the global features from the last layer of the network for anomaly detection. However, local features can capture subtle variations in the data, which are crucial for accurately detecting anomalies. To alleviate these problems, this article proposes a novel framework for detecting time-series anomalies, including four parts, namely, the graph structure learning module, the dynamic graph module, the anomaly scoring module, and the self-distillation. The graph structure learning module generates different graph structures based on the inputs, which will be used in the dynamic graph module. The dynamic graph module employs dynamic graph neural networks to capture the complex relationships within time series from both temporal and spatial dimensions. The anomaly scoring module obtains anomaly scores from predictions and observed values, and the model makes anomaly judgments based on these scores. Additionally, self-distillation enhances model performance by utilizing mutual learning between the teacher and student models, thereby integrating local and global information for better anomaly detection. We carry out a series of experiments on IIoT datasets, which verify the performance of the framework. The experimental results of the proposed method outperform other methods, demonstrating the advantage of our framework.",10.1109/jiot.2024.3520362,2025,2,IEEE
Medium-Term Jointly Load Forecasting via an Enhanced KAN-Based MTL Framework,"Electricity load forecasting involves predicting future power demand based on historical data and related factors. Accurate forecasting is crucial for energy distribution and system management. This study introduces a novel multi-task learning (MTL) framework that integrates Kolmogorov-Arnold Networks (KAN) with a multi-head self-attention (MHSA) with a both hard and soft parameter sharing strategy to effectively merge different types of inputs for joint load forecasting. The KAN layer is tasked with cross-feature learning and output fitting while the MHSA mechanism captures the temporal information from multiple perspectives, aiming to facilitate comprehensive nonlinear feature learning. Experimental results show that the proposed method can attains better forecasting accuracy, with an average mean absolute percentage error of 3.842% for 10-day medium-term forecasts.",10.1109/appeec61255.2024.10922466,2024,,IEEE
The New Abnormal: Network Anomalies in the AI Era,"Anomaly detection aims at finding unexpected patterns in data. It has been used in several problems in computer networks, from the detection of port scans and distributed denial‐of‐service (DDoS) attacks to the monitoring of time series collected from Internet monitoring systems. Data‐driven approaches and machine learning have seen widespread application on anomaly detection too, and this trend has been accelerated by the recent developments on Artificial Intelligence (AI) research. This chapter summarizes ongoing recent progresses on anomaly detection research. In particular, we evaluate how developments on AI algorithms bring new possibilities for anomaly detection. We cover new representation learning techniques such as Generative Artificial Networks and Autoencoders, as well as techniques that can be used to improve models learned with machine learning algorithms, such as reinforcement learning. We survey both research works and tools implementing AI algorithms for anomaly detection. We found that the novel algorithms, while successful in other fields, have hardly been applied to networking problems. We conclude the chapter with a case study that illustrates a possible research direction.",10.1002/9781119675525.ch11,2021,,IEEE
Vector Representation and Machine Learning for Short-Term Photovoltaic Power Prediction,"Short-term photovoltaic (PV) energy production forecasting is critical for managing grid-connected systems and energy trading. Machine learning models are widely used for accurate prediction, and this study proposes using Time2Vec as an embedding for a transformer-based neural network architecture. Experiments on two PV power plants in India showed significant improvements comparing our proposed architecture to MLP, LSTM, and the persis-tence model, which is a standard baseline prediction in this type of forecasting, with over 20 % improvements in some horizons. These findings demonstrate the effectiveness of the proposed approach for short-term PV forecasting using machine learning models.",10.1109/smc53992.2023.10394456,2023,3,IEEE
Anomaly detection for steam turbine based on dual-attention autoencoder,"Anomaly detection plays an essential role in routine operation and maintenance of steam turbine. Due to vague parameter correlation, various working condition, and nonstationary industry process, there still remain challenges in building representation models to detect abnormal working condition accurately and sensitively. To alleviate this problem, this paper proposes an autoencoder(AE) approach with dual-attention mechanism, including parameter attention and temporal attention, to learn data distribution under the normal working condition. In dual-attention mechanism, parameter attention mechanism exerts varying weight to parameters referring to their current significance, and temporal attention mechanism improves information integration by utilizing the hidden state of gated recurrent unit(GRU) cells. Based on the output of AE, box-cox transformation and three-sigma rule of thumb determine the dynamic threshold. The proposed approach is evaluated through experiments on steam turbine from a real case. The experiment result demonstrates it outperforms the state-of-the-art baselines for advanced alarm time and better stability.",10.1049/icp.2022.3129,2022,,IEEE
Learning Low-Dimensional Representation for O-RAN Testing via Transformer-ESN,"Open Radio Access Network (O-RAN) architectures enhance flexibility for 6G and NextG networks. However, it also brings significant challenges in O-RAN testing with evaluating abundant, high-dimensional key performance indicators (KPIs). In this paper, we introduce a novel two-stage framework to learn temporally-aware low-dimensional representations of O-RAN testing KPIs. To be specific, stage one employs an information-theoretic H-score to train a hybrid self-attentive transformer and echo state network (ESN) reservoir, called Transformer-ESN, capturing temporal dynamics and producing task-aligned 8-dimensional embeddings. Stage two evaluates these embeddings by training a lightweight multilayer perceptron (MLP) predictor exclusively on them for key target KPIs such as reference signal received quality (RSRQ) and spectral efficiency. Using real-world O-RAN testbed data (video streaming with interference), our approach demonstrates a significant advantage specifically when training samples are very limited. In this scenario, the low-dimensional representations learned from the Transformer-ESN yield mean square error (MSE) reductions of up to 41.9% for RSRQ and 29.9% for spectral efficiency compared to predictions from the original high-dimensional data. The framework exhibits high efficiency for O-RAN testing, significantly reducing testing complexities for O-RAN systems.",10.1109/mass66014.2025.00030,2025,1,IEEE
Attack Detection and Location Using State Forecasting in Multivariate Time Series of ICS,"ICS (industrial control systems) security researches have paid a great effort on anomaly detection base on the analyzes of communication protocols, network dataflow, sensor time series. However, few research have been done to recognize cyber attacks as well as the localization, which make active security control impossible. Actually, to recognize cyber attacks is crucial for ICS security control. In this paper, we proposed a novel multivariate time series attack detection and location framework based on adaptive state space formulation and forecasting. To dynamically describe systems' state transition characteristics, a graph structure learning scheme was designed based on Attention mechanism. Furthermore, to achieve state forecasting of systems, an improved Kalman filter with Transformer mechanism was proposed. Experiments on datasets from real industrial scenario demonstrated the effectiveness, and proved that the proposed method achieved higher location accuracy than the state-of-the-art methods.",10.1109/tnse.2025.3555764,2025,,IEEE
WirMAE: Learning Well-Logging Interval Representations via Masked Autoencoders for Gas Hydrate Reservoir Characterization,"Reservoir characterization (identification and parameter estimation) is critical for gas hydrate exploration and development. While machine learning (ML) techniques excel at capturing complex relationships in well-logging reservoir characterization, existing research mainly focuses on end-to-end supervised learning approaches relying on costly labeled data and lacking multitask learning capabilities. In this article, we introduce a self-supervised learning (SSL) framework to learn general representations of large-scale unlabeled Well-Logging Interval Representations via Masked Autoencoders (WirMAE). By incorporating channel-based attention mechanisms and a masked reconstruction pretraining strategy for variable tokens, WirMAE effectively extracts intrinsic multivariate correlations within logging data, enabling the generation of various missing log curves. The model is validated on data from globally distributed hydrate with diverse accumulation patterns. Compared to supervised deep learning methods and classical ML models, fine-turned WirMAE achieves superior reservoir identification accuracy (average  $F1$ -score: 0.864) using only 1% labeled data in complex geological settings. Combined with domain expertise, WirMAE yields precise estimation of key reservoir parameters such as hydrate saturation and permeability, outperforming conventional petrophysical methods. Additionally, embedding visualizations and attention analyses reveal the inner workings of the model and its consistency with expert-driven geological interpretations. Our findings highlight the potential of SSL for advancing more accurate and transparent intelligent reservoir characterization using well-log data, indicating that the application of WirMAE could be extended to broader hydrocarbon reservoirs in the future.",10.1109/tgrs.2025.3577988,2025,,IEEE
A causal graph-based framework for satellite health monitoring,"In satellite operations, one of the essential tasks is to monitor the health status of the systems, which involves forecasting telemetry data that reflects the state of health. The application of data-driven approaches in system monitoring has led to significant improvements in health monitoring and anomaly detection. However, existing methods fail to fully leverage the complex inter-sensor relationships present in satellites. They do not explicitly exploit the structure of these relationships to predict the expected behavior of telemetry time series either. To address these limitations, this paper introduces a novel health monitoring framework for artificial satellites that combines causal graphs and deep learning. In the causality learning phase, we propose a method that integrates mRMR (Maximum Relevance Minimum Redundancy) and PCMCI (Peter-Clark Momentary Conditional Independence) to construct an efficient and accurate causal discovery approach for learning causal graphs for high-dimensional telemetry data. Subsequently, we design a graph attention-based neural network that incorporates these causal graphs into a deep network for prediction. Experimental evaluation on two datasets from satellite attitude control systems and power systems demonstrates the superior performance of our proposed method in accurately predicting health status compared to baseline approaches. Furthermore, the experiments highlight the interpretability-enhancing role of causal graphs, which is beneficial for health monitoring and anomaly detection.",10.1109/icphm57936.2023.10194125,2023,,IEEE
Deep Collaborative Intelligence-Driven Traffic Forecasting in Green Internet of Vehicles,"Accompanied with the development of green wireless communication, the green Internet of Vehicles (GIoV) has been a latent solution for future transportation. Among them, intelligent traffic forecasting for key nodes in GIoV is a significant research topic. Much research had been devoted to this issue, and graph learning-based approaches seemed to be a promising solution. However, existing research works concentrated more on graph-structured features in GIoV yet neglected global reliability. To deal with such issue, this work combines both deep embedding and graph embedding together and proposes a deep collaborative intelligence-driven traffic forecasting model in GIoV. By establishing more reliable feature spaces for traffic flow prediction, forecasting efficiency is expected to be promoted. Specifically, deep embedding is utilized to generate more abstract representation for basic features of road networks, and graph embedding is employed to update feature representation for different timestamps. Their collaboration contributes to considerable reliability. In addition, experiments are also conducted on a real-world dataset, and the results indicate that forecasting deviation receives about 15%-25% reduction.",10.1109/tgcn.2022.3193849,2023,62,IEEE
Anomaly Detection for Small Hydropower Based on Deep Spatio-Temporal Modeling,"Anomaly detection in small hydropower plays a crucial role in small hydropower data-driven condition monitoring systems, contributing to improved equipment durability and reduced operational and maintenance expenses. Benefiting from advancements in the industrial internet, various sensors in small hydropower stations generate co-evolving time-series data with distinct characteristics at any given moment, which are recorded in the small hydropower condition monitoring system. The joint modeling of variable associations and temporal dependencies in small hydropower multivariate time-series data presents significant challenges for anomaly detection tasks. This study characterizes the complex relationships within small hydropower data as a combination of temporal dependencies and inter-feature correlations. To address these, it introduces a novel anomaly detection framework for multivariate time series, integrating adaptive graph structure learning, graph attention mechanisms, and temporal feature pyramid networks to effectively capture spatiotemporal dependencies. The proposed method aims to dynamically capture the most significant relationships, enabling timely detection of potential anomalies for more reliable small hydropower station monitoring. Experimental results on real-world sensor datasets from small hydropower stations show that the proposed method outperforms traditional approaches in anomaly detection, with superior capability in modeling the spatiotemporal dependencies inherent in multivariate time-series data.",10.1109/icmtim65484.2025.11040954,2025,,IEEE
TransGlow: Attention-augmented Transduction model based on Graph Neural Networks for Water Flow Forecasting,"The hydrometric prediction of water quantity is useful for a variety of applications, including water management, flood forecasting, and flood control. However, the task is difficult due to the dynamic nature and limited data of water systems. Highly interconnected water systems can significantly affect hydrometric forecasting. Consequently, it is crucial to develop models that represent the relationships between other system components. In recent years, numerous hydrological applications have been studied, including streamflow prediction, flood forecasting, and water quality prediction. Existing methods are unable to model the influence of adjacent regions between pairs of variables. In this paper, we propose a spatiotemporal forecasting model that augments the hidden state in Graph Convolution Recurrent Neural Network (GCRN) encoder-decoder using an efficient version of the attention mechanism. The attention layer allows the decoder to access different parts of the input sequence selectively. Since water systems are interconnected and the connectivity information between the stations is implicit, the proposed model leverages a graph learning module to extract a sparse graph adjacency matrix adaptively based on the data. Spatiotemporal forecasting relies on historical data. In some regions, however, historical data may be limited or incomplete, making it difficult to accurately predict future water conditions. Further, we present a new benchmark dataset of water flow from a network of Canadian stations on rivers, streams, and lakes. Experimental results demonstrate that our proposed model TransGlow significantly outperforms baseline methods by a wide margin.",10.1109/icmla58977.2023.00092,2023,3,IEEE
Time Series Prediction Problems Under Covariate Drift,"In the real world, time series data are ubiquitous, and the prediction task of time series data is very important. Most real-world time series data do not satisfy the assumption of independent and identical distribution (i.i.d.) due to environmental changes, that is, the distribution of the training datasets is different from the distribution of the test datasets, $P(X_{i})= P(X_{j})$, but the conditional distribution is usually considered to be unchanged, $P(y\vert x_{i})= P(y\vert x_{j})$. In this case, it is defined as covariate drift. However, most of the existing prediction algorithms are based on the assumption of i.i.d., so these algorithms have great limitations in the prediction of time series data under covariant drift. Therefore, the AEIF-MLP model is proposed, a time series data prediction model based on MLP and causal structures. The model mainly consists of two modules. Based on the principle of maximum entropy, we propose an adaptive environment segmentation module to separate different environments in the training datasets. Based on the causal structure, we propose an invariant feature learning module to learn common invariant features in different environments to train the model to deal with test datasets of unknown distribution. In summary, this method solves the problem of time series prediction under covariate drift. The validity of the model is verified by drift data sets in different environments for the first time, and the validity of the model is further verified on two real data sets.",10.1109/ddcls61622.2024.10606927,2024,,IEEE
Online Topology Identification of Higher-Order Cell Structures,"Topology identification in cellular complexes is a central challenge in Topological Signal Processing, yet existing methods face major limitations: they fail to generalize to graph learning and inadequately capture the connectivity patterns of cellular complexes. Moreover, most approaches are limited to offline learning with batch data, restricting their applicability in dynamic or non-stationary data environments. We propose a unified framework that explicitly distinguishes between simple and general cycles, enabling seamless generalization across graphs, simplicial complexes, and cellular complexes. Our framework also bridges offline and online learning through a state-space formulation. Based on this, we introduce an online topology identification algorithm and demonstrate its effectiveness through preliminary experiments on synthetic datasets.",10.1109/mlsp62443.2025.11204205,2025,,IEEE
Forecasting Application Counts in Talent Acquisition Platforms: Harnessing Multimodal Signals using LMs,"As recruitment and talent acquisition have become more and more competitive, recruitment firms have become more sophisticated in using machine learning (ML) methodologies for optimizing their day to day activities. But, most of published ML based methodologies in this area have been limited to the tasks like candidate matching, job to skill matching, job classification and normalization. In this work, we discuss a novel task in the recruitment domain, namely, application count forecasting, motivation of which comes from designing of effective outreach activities to attract qualified applicants. We show that existing auto-regressive based time series forecasting methods perform poorly for this task. Henceforth, we propose a multimodal LM-based model which fuses job-posting metadata of various modalities through a simple encoder. Experiments from large real-life datasets from CareerBuilder LLC show the effectiveness of the proposed method over existing state-of-the-art methods.",10.1109/bigdata62323.2024.10825459,2024,,IEEE
Graph-Time Convolutional Neural Networks: Architecture and Theoretical Analysis,"Devising and analysing learning models for spatiotemporal network data is of importance for tasks including forecasting, anomaly detection, and multi-agent coordination, among others. Graph Convolutional Neural Networks (GCNNs) are an established approach to learn from time-invariant network data. The graph convolution operation offers a principled approach to aggregate information and offers mathematical analysis by exploring tools from graph signal processing. This analysis provides insights into the equivariance properties of GCNNs; spectral behaviour of the learned filters; and the stability to graph perturbations, which arise from support perturbations or uncertainties. However, extending the convolutional learning and respective analysis to the spatiotemporal domain is challenging because spatiotemporal data have more intrinsic dependencies. Hence, a higher flexibility to capture jointly the spatial and temporal dependencies is required to learn meaningful higher-order representations. Here, we leverage product graphs to represent the spatiotemporal dependencies in the data and introduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled architecture. We also introduce a parametric product graph to learn the spatiotemporal coupling. The convolution principle further allows a similar mathematical tractability as for GCNNs. In particular, the stability result shows GTCNNs are stable to spatial perturbations. owever, there is an implicit trade-off between discriminability and robustness; i.e., the more complex the model, the less stable. Extensive numerical results on benchmark datasets corroborate our findings and show the GTCNN compares favorably with state-of-the-art solutions. We anticipate the GTCNN to be a starting point for more sophisticated models that achieve good performance but are also fundamentally grounded.",10.1109/tpami.2023.3311912,2023,16,IEEE
Attention-Based Deep Learning Model for Prediction of Major Adverse Cardiovascular Events in Peritoneal Dialysis Patients,"Major adverse cardiovascular events (MACE) encompass pivotal cardiovascular outcomes such as myocardial infarction, unstable angina, and cardiovascular-related mortality. Patients undergoing peritoneal dialysis (PD) exhibit specific cardiovascular risk factors during the treatment, which can escalate the likelihood of cardiovascular events. Hence, the prediction and key factor analysis of MACE have assumed paramount significance for peritoneal dialysis patients. Current pathological methodologies for prognosis prediction are not only costly but also cumbersome in effectively processing electronic health records (EHRs) data with high dimensionality, heterogeneity, and time series. Therefore in this study, we propose the CVEformer, an attention-based neural network designed to predict MACE and analyze risk factors. CVEformer leverages the self-attention mechanism to capture temporal correlations among time series variables, allowing for weighted integration of variables and estimation of the probability of MACE. CVEformer first captures the correlations among heterogeneous variables through attention scores. Then, it analyzes the correlations within the time series data to identify key risk variables and predict the probability of MACE. When trained and evaluated on data from a large cohort of peritoneal dialysis patients across multiple centers, CVEformer outperforms existing models in terms of predictive performance.",10.1109/jbhi.2023.3338729,2024,5,IEEE
Cloudformer: Contrastive Learning Based Cloud Workload Prediction,"During the last 3 years, researchers have endeavored to extend the efficacy of contrastive learning (CL) towards addressing the challenges inherent in cloud workload prediction, which has demonstrated considerable success in the domains of Computer Vision (CV) and Natural Language Processing(NLP). However, due to the distinctive temporal characteristics of serialized workload information, relying solely on empirical guidance from other domains may prove insufficient for cloud workload prediction. Therefore, we systematically investigated three key components of CL, including: 1) designing backbone encoder for feature extraction, 2) designing methods for extracting negative samples for contrast, and 3) designing the CL loss. We found that inappropriate construction of negative samples may introduce excessive pseudo-negative samples, which neither preserve temporal characteristics nor provide sufficient discriminative features. Additionally, focusing solely on the discrimination between positive and negative samples in the CL loss may not be adequate for enabling the model to learn the temporal patterns of serialized workload information. To address these problems, we propose a novel self-supervised model named Cloudformer. Specifically, we first constructed a CL network based on the Transformer architecture using a pre-train-finetune framework. Following this, we proposed a method to filter pseudo-negative samples based on differential cosine similarity, aimed at assisting the model in more effectively distinguishing between positive and negative samples. Additionally, we introduced the BatchNCE loss, combining MSE loss with InfoNCE loss as a joint optimization objective for CL, effectively enhancing the predictive capability of the model. The experimental results indicate that Cloudformer is capable of learning high-quality patterns in serialized workload sequences and achieves more advanced performance in short sequence prediction tasks.",10.1109/icet61945.2024.10672804,2024,1,IEEE
Causality-Aware Multi-Graph Convolutional Networks With Critical Node Dynamics for Electric Vehicle Charging Station Load Forecasting,"Accurately forecasting the load of electric vehicle charging stations (EVCSs) is crucial for optimizing grid operations and facilitating EV integration, yet existing methods struggle to capture the intricate spatio-temporal dependencies and the impact of influential EVCSs within charging networks. To address this, we propose a novel framework, Causality-Aware Dynamic Multi-Graph Convolutional Network (CADGN), a multi-graph convolutional network that integrates causal inference and critical node modeling. It consists of two core modules: the Causality-Aware Graph Learning Module (CAGLM) uncovers and represents causal relationships between EVCSs, while the Critical Relationship Graph Learning Module (CRGLM) dynamically models the evolving connections among critical EVCS nodes. Temporal patterns extracted from these modules are then fused to generate accurate load predictions. Extensive experiments using real-world datasets of hourly charging data from multiple cities demonstrate CADGN’s superiority over state-of-the-art EVCS load forecasting models, particularly for short-term and mid-term horizons. Notably, our model achieves an average 4.7% reduction in Mean Absolute Error (MAE) compared to Graph WaveNet across all datasets and prediction horizons, highlighting the practical benefits of considering both causal and critical relationships for enhanced grid operations and EV integration. These results emphasize the importance of incorporating causality and the identification of critical relationships in the EVCS load forecast to achieve higher accuracy.",10.1109/tsg.2025.3570955,2025,1,IEEE
Knowledge Base-Guided Modeling of ICS Device Behavior for Status Prediction,"Predicting device status in Industrial Control Systems (ICS) is important for ensuring operational efficiency and preventing costly failures. Traditional univariate forecasting models grapple with the complexities inherent in multivariate time series data characterized by high interdependencies among devices. This study pioneers a novel methodology, which can fuse of linear model principles with graph embedding techniques (GCNs), for device behavior modeling. Specifically, we innovatively establish a device behavior knowledge base and exploits graph embedding algorithms to decipher both the spatial-temporal intricacies and underlying correlations embedded within extensive sensor data collections. The behavior knowledge base employs statistical methodologies like Pearson correlation to derive an adjacency matrix, which can facilitate the model’s realization of the static structure and dynamic interaction of device features. Moreover, to enhance predictive precision, we synthesize the strengths of linear model interpretations with the nuanced insights derived from graph-based feature learning. GCNs, serving as the backbone for learning sophisticated inter-device relations within this knowledge base, significantly influence the efficacy of device status prediction. Linear models are strategically utilized to distill time-dependent features from individual device sequences, overcoming scalability limitations associated with Recurrent Neural Networks (RNNs) when handling extended observation periods. Extensive experiments on real word dataset are conducted to validate our model’s performance. Experimental results illustrate that the proposed method achieves high performance on status prediction of ICS device.",10.1109/dsc63484.2024.00081,2024,,IEEE
A Dynamic Evolving Fuzzy System for Streaming Data Prediction,"This article proposes a dynamic evolving fuzzy system (DEFS) for streaming data prediction. DEFS utilizes the enhanced data potential and prediction errors of individual local models as the main criteria for fuzzy rule generation. A vital feature of the proposed system is its novel rule merging scheme that can self-adjust its tolerance toward the degree of similarity between two similar fuzzy rules according to the size of the rule base. To better handle the shifts and drifts in the data patterns, a novel rule quality measure based on both the utility values and the prediction accuracy of individual fuzzy rules is further introduced to help DEFS identify these less activated fuzzy rules with poorer descriptive capabilities and, thereby, maintaining a healthier fuzzy rule base by removing these stale rules. Very importantly, the thresholds used by DEFS are self-adaptive toward the input data. The adaptive thresholds can help DEFS to precisely capture the underlying structure and dynamically changing patterns of streaming data, enabling the system to perform accurate approximation reasoning. Numerical examples based on several popular benchmark problems show the superior performance of DEFS over the state-of-the-art evolving fuzzy systems. The prediction performance of the proposed method is at least 2.88% better than the best-performing comparative EFSs on each individual regression benchmark problem considered in this study, and the average performance improvement across all the numerical experiments is approximately 30%.",10.1109/tfuzz.2024.3395643,2024,22,IEEE
Remaining Useful Life Prediction for Bearings Based on Generative Pretrained Transformer,"Accurate prediction of bearing remaining useful life (RUL) is crucial for ensuring the safe operation of critical equipment. To address the limitations of existing methods, including insufficient generalization capability caused by reliance on single datasets and increased deployment costs due to the requirement for customized prediction heads for different operating conditions, a novel solution is proposed in this paper. Specifically,mixed dataset pre-training dataset is constructed to expand the training scale, enabling the model to learn more generalizable degradation trend representations. Meanwhile, a multi-scale transformer architecture integrated with autoregressive decoding is adopted, where hierarchical temporal feature extraction and iterative residual learning are synergistically optimized to achieve progressive refinement of prediction results. Experimental results demonstrate that the proposed method significantly outperforms baseline models in both prediction accuracy and robustness, with the RMSE metric being reduced by $8.6 \%$ (reaching 0.0317) compared to the suboptimal PatchTST model, while the MAE metric is decreased by $\mathbf{4 9. 9 \%}$ (optimized to $\mathbf{0. 0 2 4 6}$) relative to conventional Transformer architectures.",10.1109/icbdse65491.2025.11220134,2025,,IEEE
Towards Spatio-Temporal Aware Real Location Restoration for Signaling Data,"This study introduces the novel problem of Real Location Restoration, aimed at reconstructing accurate user trajectories from the coarse-grained mobile signaling data. To tackle this problem, we propose the Spatio-Temporal Aware framework for Signaling Data (STASD), a pioneering approach that encodes the complex spatiotemporal relationships of cellular trajectories. Leveraging a unique global transition graph, STASD captures high-order spatial relationships to effectively mitigate the Ping Pong Effect, a common issue in signaling data analysis. Our extensive experiments showcase the framework’s capability to accurately restore real-world trajectories, significantly advancing the field of mobile data analysis by providing a novel method to interpret and utilize signaling data for detailed location insights.",10.1109/yac63405.2024.10598525,2024,,IEEE
Advanced Learning Techniques for Short-Term Atmospheric Predictions: An Overview,"Atmospheric Prediction is a complex task influenced by various factors such as temperature, pressure, air movement, moisture, and the earth’s rotation. Achieving accurate forecasts with high geographical resolution poses significant challenges, requiring substantial computational resources. This study focuses on nowcasting meteorological radar images. Deep learning has emerged as a promising approach for unsupervised representation learning, with next-frame prediction being a particularly intriguing research area in computer vision. This approach involves predicting future images based on prior image information, with applications ranging from robot decision-making to autonomous driving. This review presents the latest advancements in next-frame prediction networks specifically tailored for atmosphere data nowcasting. These networks can be categorized into two main approaches: Machine Learners and deep learners. The study comprehensively analyzes and compare various strategies based on their advantages and limitations, highlighting the benefits and drawbacks of each method. Additionally, potential research directions that hold promise for future investigations in this field are discussed. By identifying the most significant challenges and opportunities, the study aims to inspire further advancements in deep learning methods for atmosphere data nowcasting. Overall, this study provides a comprehensive overview of the current state-of-the-art deep learning techniques for nowcasting atmosphere data, shedding light on their potential applications and suggesting avenues for future research.",10.1109/icacrs58579.2023.10405022,2023,,IEEE
CGF: A Category Guidance Based PM$_{2.5}$ Sequence Forecasting Training Framework,"PM$_{2.5}$2.5 concentration forecasting is important yet challenging. First, complicated local fluctuations in PM$_{2.5}$2.5 concentrations disturb modeling global trends. Second, forecasting errors are often accumulated through an autoregressive process. To contend with the two challenges, we propose a Category Guidance based PM${_{2.5}}$2.5 sequence Forecasting training framework (CGF) to enhance the performance of existing PM${_{2.5}}$2.5 concentration forecasting models. CGF contains a Category based Representation Learning (CRL) module and a Category based Self-paced Learning (CSL) module, both of which utilize PM${_{2.5}}$2.5 category information that is easily obtained and publicly available. First, CRL employs category information to guide forecasting models to produce more robust hidden representations that are insensitive to local fluctuations, thus alleviating the negative impact of local fluctuations. Second, CSL adaptively selects real PM${_{2.5}}$2.5 concentration values versus autoregressive PM${_{2.5}}$2.5 forecast values when training forecasting models, helping alleviate error accumulations. The CGF framework is applied to existing PM${_{2.5}}$2.5 forecasting models, and the experimental results on two real-world datasets demonstrate that CGF is able to consistently improve the accuracy of existing forecasting models. Furthermore, to validate the generality of CGF, we conduct extensional experiments in two other time-series prediction tasks, including exchange rate forecasting and electricity forecasting. The experimental results also verify the effectiveness of CGF.",10.1109/tkde.2023.3253703,2023,6,IEEE
AI Algorithms in Networks,"This chapter presents the application of diverse machine learning (ML) techniques in various key areas of networking across different network technologies. It considers a heterogeneous network with base stations, small base stations, and users distributed according to independent Poisson point processes. The chapter presents different aspects of using ML algorithms for self‐organizing cellular networks. It discusses the data sources and strong drivers for the adoption of the data analytics, and the role of ML and artificial intelligence in making the system intelligent with regard to being self‐aware, self‐adaptive, proactive, and prescriptive. The chapter also discusses a topology‐aware, dynamic, and autonomous system for managing resources in network function virtualization based on the concept of graph neural networks. The chapter also considers network slicing in a more complex setup. Network representation learning aims to learn latent, low‐dimensional representations of network vertices, while preserving network topology structure, vertex content, and other side information.",10.1002/9781119790327.ch7,2022,,IEEE
Super Resolution Graph With Conditional Normalizing Flows for Temporal Link Prediction,"Temporal link prediction on dynamic graphs has attracted considerable attention. Most methods focus on the graph at each timestamp and extract features for prediction. As graphs are directly compressed into feature matrices, the important latent information at each timestamp has not been well revealed. Eventually, the acquisition of dynamic evolution-related patterns is rendered inadequately. In this paper, inspired by the process of Super-Resolution (SR), a novel deep generative model SRG (Super Resolution Graph) is proposed. We innovatively introduce the concepts of the Low-Resolution (LR) graph, which is a single adjacent matrix at a timestamp, and the High-Resolution (HR) graph, which includes the link status of surrounding snapshots. Specifically, two major aspects are considered regarding the construction of the HR graph. For edges, we endeavor to obtain an extensive information transmission description that affects the current link status. For nodes, similar to the SR process, the neighbor relationship among nodes is maintained. In this form, we could predict the link status from a new perspective: Under the supervision of the graph moving average strategy, the conditional normalizing flow effectively realizes the transformation between LR and HR graphs. Extensive experiments on six real-world datasets from different applications demonstrate the effectiveness of our proposal.",10.1109/tkde.2023.3295367,2024,3,IEEE
Design and Development of Deep Learning Framework for Recognition of Calisthenics Movement,"Calisthenics movement recognition has also received considerable interest in recent years given its applications to fitness monitoring, coaching, and rehabilitation. Classic systems to recognize exercises like push-ups, pull-ups, and squats typically employ isolated computer vision methods or shallow deep networks such as CNNs. Those current systems have significant disadvantages in representing fine-grained spatiotemporal patterns, leading to poor recognition performance and challenges to cope with variations in movement execution and style. These limitations reduce model generalization and lead to inconsistent recognition with approximate accuracy rates, precision and other performance metrics. To overcome these limitations, in this paper, research introduces a propoed deep learning architecture that combined model, a strong spatiotemporal feature learning. The CNN layers capture dense spatial representations of every video frame, whereas the GRU layer models temporal patterns throughout movement sequences. Comprehensive experiments on a large-scale as well as exercises filtered from the Kinetics-400 action recognition dataset self-collected and publicly available calisthenics dataset, as well as exercises filtered from the Kinetics-400 action recognition dataset, demonstrate that our proposed CNN+GRU architecture substantially enhances recognition performance. Our model recorded an accuracy of 95.8%, precision of 95.5%, recall of 94.9%, and F1-score of 95.2%, outperforming state-of-the-art methods by about 7-9% across all measures. This significant enhancement proves the efficacy of utilizing both convolutional and recurrent architectures for modeling spatiotemporal differences among exercises. In addition, the introduced framework is computationally lightweight and can be implemented for real-time feedback in training and fitness settings.",10.1109/icicke65317.2025.11136632,2025,,IEEE
MetaSTC: A Backbone Agnostic Spatio-Temporal Framework for Traffic Forecasting,"Traffic flow prediction is a critical issue in transportation engineering and presents distinct challenges when handling large-scale datasets in the real world. Existing complex spatio-temporal forecasting paradigms use the same parameters to fit traffic sequences with varying spatio-temporal features, and tend to train an average performance model over different time series. This approach greatly reduces their accuracy when applied to larger road networks. Moreover, the significant differences in traffic data distribution from one city to another can also pose great challenges. The same model may be excellent for one city and mediocre when applied to another. To this end, we propose a Meta Backbone Agnostic Spatio-Temporal Clustering Framework for Traffic Forecasting on Large-Scale Road Networks named MetaSTC. We tackle the disparities of spatio-temporal features of traffic flow through a spatio-temporal clustering-based strategy. We design meta-learner for large-scale road network that dynamically extracts the shared information across roads in the same sub-task. In this way, the model can represent task-specific details with a simpler model and make quick and accurate predictions. Our paradigm is backbone-agnostic and can be combined with different traffic prediction models, solving the problem caused by the difference in data distribution. Extensive experimental results conducted on real-world traffic dataset demonstrate the high accuracy and computational efficiency of our model over SOTA approaches.",10.1109/icdm59182.2024.00112,2024,1,IEEE
A Brief Review of Unsupervised Learning Algorithms for Zero-Day Attacks in Intrusion Detection Systems,"This research paper presents a brief review of ten popular unsupervised algorithms widely utilized in pattern recognition publications. The algorithms are assessed based on their popularity, strengths, limitations, and resource require-ments. Considering these factors, we propose two most-preferred algorithms suitable for adoption in IDS (Intrusion Detection Systems) to address the problems associated with Zero Day exploits or attacks. Our review of the surveyed algorithms facilitated the recommendation of specific algorithms that can enhance IDS capabilities in detecting and mitigating Zero-Day attacks and anomalous intrusion attempts. These algorithms leverage unsupervised learning techniques to overcome the limitations of traditional signature-based approaches. By incorporating these algorithms, IDS can better handle sophisticated and evolving attacks that often evade detection. In conclusion, this research provides valuable insights into the strengths, limitations, and resource requirements of popular unsupervised algorithms used in pattern recognition. It highlights the potential of adopting these algorithms in IDS systems to bolster their ability to detect and respond to Zero-Day attacks. By recommending the integration of these algorithms, we contribute to the development of intelligent IDS solutions that can adapt to dynamic threat landscapes.",10.1109/icmi60790.2024.10585925,2024,1,IEEE
STGNNM: Spatial-Temporal Graph Neural Network with Mamba for Cellular Traffic Prediction,"Accurate long-term prediction of cellular traffic is a critical task in the rapidly developing field of intelligent communications. However, due to the high mobility of users and the complex scheduling mechanism within the network, cellular traffic data presents significant spatial-temporal dependencies, which pose a considerable challenge to long-term cellular traffic prediction. Although Transformer-based models perform well in dealing with long-term dependencies, their quadratic computational complexity leads to low efficiency and high overhead. Moreover, existing studies are often insufficient in dealing with the spatial-temporal correlation of cellular network traffic, limiting the further improvement of prediction accuracy. To overcome these challenges, we propose a novel deep learning model, Spatial-Temporal Graph Neural Network with Mamba (STGNNM). First, we introduce a bidirectional Mamba module to capture the dynamic characteristics of the time series. Second, we apply a double-view graph learning module. The Graph Convolutional Network (GCN) captures the characteristics of neighboring base stations, while the Graph Attention Network (GAT) records the relationships between distant base stations. Finally, the bidirectional Mamba module processes spatial-temporal features comprehensively. We conduct extensive experimental evaluations on a real-world cellular traffic dataset. The results show that STGNNM outperforms the current state-of-the-art methods in all evaluation metrics, demonstrating its superior performance and effectiveness in cellular network traffic prediction.",10.1109/wcsp62071.2024.10827036,2024,,IEEE
Graph Neural Network-Based Internet Traffic Prediction in 6G Networks with Genetic Algorithm Hyperparameter Optimization,"Accurate internet traffic prediction is a key challenge in managing next-generation networks such as 6G. This paper presents a novel approach based on Graph Neural Networks (GNNs) for predicting internet traffic in 6G networks. The proposed model integrates Graph Attention Networks (GAT) and Transformer architectures to learn spatial and temporal dependencies in traffic data. A K-Nearest Neighbors (KNN)-based graph construction method is utilized to represent spatial relationships between network cells. The model’s performance is enhanced by leveraging a Genetic Algorithm (GA) for hyperparameter optimization. Experimental results demonstrate the effectiveness of the proposed model in achieving superior prediction accuracy, as evidenced by improvements in RMSE, and MAE compared to baseline models. This work offers a scalable solution for traffic prediction in 6G networks.",10.1109/compsac65507.2025.00100,2025,,IEEE
A Novel Spatial-Temporal Deep Neural Network for Electricity Price Forecasting,"Electricity price forecasting is a difficult task because it depends on various factors such as weather, fuel, load, and bidding strategies. These characteristics bring a lot of volatility to electricity prices. In addition, there exist coupling relationships between different price zones in Europe. CNN-based or LSTM-based methods cannot capture the relationship by their structures or there is a need to extract these couplings explicitly manually. In this work, an end-to-end graph neural network is proposed for the first time to learn the coupling between different price zones automatically. The proposed model mainly consists of two parts: a graph learning module and a temporal learning module, which both are designed to learn spatial information of different price zones and temporal information of historical data, respectively. The performance of the proposed model is evaluated on one-year public data collected from the Nord Pool. The results indicate that our model provides a better solution for electricity price forecasting.",10.1109/icapai58366.2023.10193970,2023,,IEEE
"ROI-demand Traffic Prediction: A Pre-train, Query and Fine-tune Framework","Traffic prediction has drawn increasing attention due to its essential role in smart city applications. To achieve precise predictions, a large number of approaches have been proposed to model spatial dependencies and temporal dynamics. Despite their superior performance, most existing studies focus datasets that are usually in large geographic scales, e.g., citywide, while ignoring the results on specific regions. However, in many scenarios, for example, route planning on time-dependent road networks, only small regions are of interest. We name the task of answering forecasting requests from any query region of interest (ROI) as ROI-demand traffic prediction (RTP). In this paper, we make a primary observation that existing methods fail to jointly achieve effectiveness and efficiency for RTP. To address this issue, a novel model-agnostic framework based on pre-Training, Querying and fine-Tuning, named TQT, is proposed, which first customizes input data given an ROI, and then makes fast adaptation from pre-trained traffic prediction backbone models by fine-tuning. We evaluate TQT on two real-world traffic datasets, performing both flow and speed prediction tasks. Extensive experiment results demonstrate the effectiveness and efficiency of the proposed method.",10.1109/icde55515.2023.00107,2023,9,IEEE
Contrastive Learning for Multivariate Time Series Classification: an Early Fusion Approach,"In recent years, the use of contrastive learning methods for time series classification has shown promising results. State-of-the-art approaches leverage self-supervised contrastive learning representations that encode the underlying series’ features. On top of the latent representation, classification is addressed as a downstream task. While the effectiveness of contrastive models in univariate series classification is established, their portability towards a multivariate scenario is still debated. In this work, we explore the use of contrastive time series representations on multivariate data. We compare the performance of state-of-the-art contrastive models on 30 benchmark datasets and explore the use of an early fusion network to combine the input dimensions. The preliminary results show that incorporating a preliminary stage of information fusion is beneficial to improve the performance of state-of-the-art contrastive time series classifiers.",10.1109/aict59525.2023.10313147,2023,,IEEE
Evaluating Time Series Predictability via Transition Graph Analysis,"This study is focused on exploring time series intrinsic predictability using transition graph analysis. The goal is to find out whether a special graph that reproduces system transition along its trajectory in the state space is useful for distinguishing time series of “good” and “bad” predictability. We perform a state space clustering to construct a weighted and directed transition graph and then to calculate different graph characteristics. We train several predictive models (in particular, the well-known auto-regression, singular spectrum analyses, artificial neural network and specific dynamic models of local approximation and maximal similarity) for time series and apply k-means algorithm to divide the set of the series into two parts using the properties of the corresponding transition graph. As a result we have artificial and real-world datasets divided into two clusters in one of which the mean forecasting error is much less than in the other. The F<inf>1</inf>-score value (≈ 0.87) for this clustering shows that our approach performs better than those in some related works. We also train several classification models on a set of artificial series so that they are able to distinguish real-world time series of “good” and “bad” predictability. The results of this work can be used for data engineering in time series forecasting tasks and for predictive model design and evaluation. The datasets, the framework implementation and the results related to our study are publicly available on GitHub.",10.1109/icdmw53433.2021.00135,2021,5,IEEE
"Guest Editorial: Deep Neural Networks for Graphs: Theory, Models, Algorithms, and Applications","Deep neural networks for graphs (DNNGs) represent an emerging field that studies how the deep learning method can be generalized to graph-structured data. Since graphs are a powerful and flexible tool to represent complex information in the form of patterns and their relationships, ranging from molecules to protein-to-protein interaction networks, to social or transportation networks, or up to knowledge graphs, potentially modeling systems at very different scales, these methods have been exploited for many application domains.",10.1109/tnnls.2024.3371592,2024,146,IEEE
